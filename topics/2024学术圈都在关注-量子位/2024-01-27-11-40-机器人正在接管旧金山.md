# “机器人正在接管旧金山”

文章作者: 量子位
发布时间: 2024-01-27 11:40
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247714809&idx=2&sn=b64d8be2a71b3e066ae2a2d160d0aed3&chksm=e8df308bdfa8b99dac6d6f4177b8bd2aa5e891de066e7c839ce25ff789d136f05ed2f31826f9#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjW82MORUJ7nu7PPWCiaic4tcP237yDE10r0XNicVBAUdiapkkDAcjKVDoLJA/300

##### 西风 发自 凹非寺  
量子位 | 公众号 QbitAI

一批人形机器人在美国旧金山街头出没，引得过往行人驻足留观：

‍‍![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjWKsDsqoQgjOUK5et9lnzXNkLts2U024OLreEIyFsIJ3dCRARTy1hhVg/640?wx_fmt=gif&from=appmsg)‍

可能还去上了个课，从加州大学伯克利分校校门大摇大摆走出：

‍![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjWycg2cic9rhnHn2sfSauPvkEqaXhTtUnibNxUgfpiaiaglxicShMVywXVh8w/640?wx_fmt=gif&from=appmsg)

路线不对，踩着小碎步，稳步调头：

‍‍![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjWKviaHZ9E51En2h0iciaC6rV36BOVpHkkiaTW9TicZP8YqMK08OQLelxmyJQ/640?wx_fmt=gif&from=appmsg)‍

或者不装了，调什么头，直接倒着走：

‍![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjWTSGZKt7ZNxE9dmpchhDSt5ScNMokmv3uD5S2rTodvFvPyOzZEBIekw/640?wx_fmt=gif&from=appmsg)‍

在各种场景下都可以看到它们的身影：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjW2SLth7c5ib4mDbEukG9GwhP7U0m1IicibiaIX0AzrIdj2piaOibqpB72ta0g/640?wx_fmt=gif&from=appmsg)

于是乎，网友传出了“机器人正在接管旧金山”的消息🤣：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjW28QOialr1A1clnaSotv99FVEzZQjFIEhwoUGvJppkQ06zxg0ZMNp82A/640?wx_fmt=gif&from=appmsg)

要不是视频中还有人类出镜，网友都要怀疑这是不是真的在旧金山：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjW9Idl6M1HB3iaILGFcHk80DibtAANOx2gibnibUDZhianibJYos2ia4db1gnibQ/640?wx_fmt=png&from=appmsg)

这就是来自加州大学伯克利分校的人形机器人成果。研究人员提出了使用序列建模和动作预测的**Causal Transformer模型** 。

使得人形机器人可以在室内外各种环境中稳健行走，应对不同地形，甚至还能背个书包，提袋垃圾：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjWefzibtcictqM8WwhzzeZyUSuCF0Cx1HQXM8DAjSYLF9jicYtzp8FqFzgA/640?wx_fmt=png&from=appmsg)

## 怎么做到的？

此前，尽管一些人形机器人在特定环境下表现良好，但广泛存在泛化和适应新环境方面的问题。

来自加州大学伯克利分校的研究人员提出了运用Causal Transformer的方法。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjWVFBXZriaxt1HhdK537uyiayuLy96UzOWpdzsn28u9uLw2nGXkiazpPBdQ/640?wx_fmt=png&from=appmsg)

这是一种Transformer模型，通过自回归从观察-动作历史信息中预测下一个动作，也就是模型的输出（预测的动作）只依赖于其输入（观察-
动作历史信息）中的先前信息。

具体来说，在处理“观察-动作对”时，模型会将每个“观察-
动作对”作为一个token，并通过自注意力机制来学习这些token之间的关系。在自注意力计算中，模型会为每个token分配权重，这些权重反映了在预测当前动作时，序列中其他token的重要性。

由于Causal Transformer限制了自注意力只能考虑前面的token，它能够捕捉到序列中的因果依赖，即当前动作的决策是基于之前观察-
动作的历史信息。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjWJ66sdSsgf0kibGQP98Tw4CNiaYATmxCUfqUjwOXmyjzsonoOfxibLlib3Q/640?wx_fmt=png&from=appmsg)

通过这种方式，Causal Transformer能够使机器人在复杂和动态的环境中，在没有未来信息的情况下做出适应性更强的决策。

训练阶段，研究人员使用**强化学习** 方法，在Isaac Gym模拟器进行大规模并行训练，模拟了机器人的刚体和接触动力学。

为了模拟机器人的闭链动力学，引入了“虚拟弹簧”模型。在模拟中随机化机器人的动态属性、控制参数和环境物理属性，以及添加噪声和延迟到观察中。

‍![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjW9eCnlICfTN0uC7HugBMG1RaViciardDakzibpZhc8jewQNM9g9ribBs0og/640?wx_fmt=gif&from=appmsg)‍

从模拟到现实的转移方面，研究人员在机器人初创公司Agility
Robotics提供的高保真度模拟器中验证策略，该模拟器准确模拟了Digit机器人的动态和物理属性。

经过实验，Digit机器人能够在多种环境中可靠行走，展现出对外部干扰的鲁棒性：

‍![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjWVRry40icH0GJ9GmiaRrs35SkUibialAibIQMhs58ABZabC1u3MAKQ0bcgvQ/640?wx_fmt=gif&from=appmsg)‍  

以及在不同地形和载荷条件下的适应性：

###### **‍
‍![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjWWVHU9IHUPBxTSJSf5QicODibx4qzoAeDCzvwOvTRQD3ERS2mvIuibJPmg/640?wx_fmt=gif&from=appmsg)‍**

###### **△** 左，脚被绊住；右，下坡‍

顺带保持手臂摆动协调有力，不顺拐：

‍‍‍![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjW8mpZzdfPEXibcoES7UXic08zGtEfCMiaKqauFMsgialsH0APibWXicngJ7DA/640?wx_fmt=gif&from=appmsg)‍‍  

## Digit人形机器人

再来介绍一下demo中的这款人形机器人——**Digit** 。

背后公司**Agility Robotics** ，前身为俄勒冈州立大学的Dynamic Robotics Laboratory。2022年，获亚马逊投资。

Agility Robotics的主要产品是以鸵鸟等鸟类为发想的双足步行机器人，主要研发成果包含Cassie、Digit两个机型。

其中Cassie是只有下半身的双足机器人：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjWelySheFWkL2e549AuiafCjyBZzoiah8shia7M3KicPZ3mHYHc7NoQvxqkg/640?wx_fmt=gif&from=appmsg)

至于Digit，像是下面这个，已经成为亚马逊75万机器人员工中的一员，不过还处于测试阶段，负责搬运亚马逊标志性的黄箱子：

‍![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDAtPibCicGAWKicQko1P7ibzjWHwIsxneia1VVkbEEJXbJNqCOxLollc2ebBtkTB7Wiat1K188wvQtMZZQ/640?wx_fmt=gif&from=appmsg)‍

Agility
Robotics表示，将在今年向合作伙伴交付第一批Digit，Digit的初步应用包括仓库和配送中心内的散装材料处理，预计2025年全面上市。

他们最近还宣布开设了一家新机器人制造工厂RoboFab™，声称第一年预计生产数百台机器人，之后每年产能最多可达10000台。Digit也将在新工厂中上岗，进行搬运、装载等工作。

参考链接：  
[1]https://twitter.com/minchoi/status/1749784839824216511  
[2]https://learning-humanoid-locomotion.github.io/

— **完** —

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg)

