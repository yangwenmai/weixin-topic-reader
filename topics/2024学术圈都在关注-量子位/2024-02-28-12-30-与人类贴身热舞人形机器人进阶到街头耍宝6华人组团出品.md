# 与人类贴身热舞！人形机器人进阶到街头耍宝，6华人组团出品

文章作者: 量子位
发布时间: 2024-02-28 12:30
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247718661&idx=1&sn=cf131e536f9fdc178fb106e8490e8aa4&chksm=e8df2077dfa8a96186079c359ccb9f2165842f06394f8ada8b7fda6c0b7335a8aae45f8aaf25#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JccvAibHxQlc9pplIwwibRS5MdKx4ibsLXdv4AIGgOqP2o2bkARiaQawmXug/300

##### 衡宇 丰色 发自 凹非寺  
量子位 | 公众号 QbitAI

注意看，小帅一个转身，卫衣帽子里面居然 **空 无 一 头** ：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcxHC1YMuhvzia1cG1SDdaQzhiaFLODqpCicTfl0LRyiaxH2t2icSpQpPjpKA/640?wx_fmt=gif&from=appmsg)

好啦，这不是惊悚恐怖片，而是来自UCSD（加州大学圣地亚哥分校）全华人团队的最新研究成果。

他们提出一种特别的全身控制策略（ExBody），能对人形机器人进行全身控制。策略**主要训练人形机器人上半身** ，下半身则专注于负责维持稳定。

这样训练出来的人形机器人，能实现稳健的运动和动态运动跟踪。

简而言之，**会的活多，表现力还强** 。

比如和人类边贴贴边跳舞，增进增进人形机器人和人类之间的感情：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9Jc3PkPodIAFxjNlMicbicHAFus0iaQXqk7nXqytRmicJNeDmowYjchvma8sw/640?wx_fmt=gif&from=appmsg)

穿着荧光小马甲，就能立刻上岗街头指挥人车交通：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcgsFpEx4JtJGaGSerMKydnNRWoIchKqgicKyUN1ff8o4jn1wyUbWTIHg/640?wx_fmt=gif&from=appmsg)

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9Jcqz19ibHmrhgH0icZ5md32DxCtibWtB65eYsia89vsbKz0DticlG39EqKoAg/640?wx_fmt=gif&from=appmsg)

研究论文资料显示，**这个研究团队共6人** ，其中过半是UCSD的在读博士生。

为什么要对人形机器人做这样的训练呢？论文共同一作Xuxin Cheng在推特上卖力宣传的同时，做出了解释。

> 机器人总是被要求化身各行各业的打工人！我们就想跟它一起探索另一条方向的路～

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcgOVmicoQ7ia53ibVVjTWA8xIJhu9wJiavyrxsMckVCJY9gr6ticSLBLElgw/640?wx_fmt=png&from=appmsg)

## 当人形机器人“富有表现力”

团队的这项研究名为《Expressive Whole-Body Control for Humanoid
Robots》，研究目标是让人形机器人在现实世界中产生丰富、多样和富有表现力的动作。

在经过团队的调教后，人形机器人能做出什么样的行为呢？

路遇朋友**迎面击掌** ，这是不在话下的。

我都能脑补出它大声喊了一句Hey Man……

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9Jcbazh3WILXy6aeO2xdlF2zrS0x0q98Ticrjrz9ycIx85Ujicf9y7KvPqQ/640?wx_fmt=gif&from=appmsg)

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9Jc8E00kLDZHFlmn5jpM7jkeLuoPRt4ocNA3gbibC6NMCWvS1zXl2nF7Pg/640?wx_fmt=gif&from=appmsg)

亲切一点，**路遇兄弟，来个抱抱** ：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9Jcc8hh8R89TzBFghVBAZQrpv35sop8D9dSZ2DchS9qq08VJ9FAFUicbTA/640?wx_fmt=gif&from=appmsg)

有点搞笑的事，不管是击掌还是拥抱，机器人下半身跺脚的行为并不会停止，只是会稍微放缓。

眼尖的朋友们可能已经发现了，上面的击掌实验在不同环境、不同地面进行。

团队也明确表示，通过新研究训练出来的人形机器人，可以在各种不同的地形地面上健步如飞。

除了上文展示过的草地和石板路，**沙滩** 对它来说同样是小菜一碟：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9Jc9ic4Ic0UeBKjYc3wYibrLdicT5pZJDib6wOKiafms0VWhc3Bn0GotFK80Tg/640?wx_fmt=gif&from=appmsg)

**平整的办公室地面** 也可以轻松应对：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JciaKtRuTfen8PccIkEpHcfmTgj9h2LFibKMXX19DjZr4cj6uXc9fobMAw/640?wx_fmt=gif&from=appmsg)

团队给出的更多展示中，还表现了更多**遇到外界阻力时行动自如** 的demo。

狠狠拽它：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcEAmuu1FAiadnLLCr09Z9Vcb0r0btm0A5jZBLicsbe6O8GslGDqvUugWw/640?wx_fmt=gif&from=appmsg)

拿大球砸它：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcB5axNDicVz4d6PYefX8ANlDHqNqv1NRB5hDRCuuoqsExLRImoUnE8Lw/640?wx_fmt=gif&from=appmsg)

还知道**抬手示意** ，“喂，你可以帮我背上小书包了”。

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAic3LHzK7WZ99SicborKia9Jcs7xKfUBKbYeuribYxtACsHNYL6sLoZod48hdhic3z25Z6ODPG9Q4luXg/640?wx_fmt=gif&from=appmsg)

各种操作，看得大伙儿一愣一愣的。

纽约大学计算机科学助理教授发推特应援，称这么高水平控制力和表现力的研究成果，居然是一个6人组成的学术团队的产出，“难以置信”！

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcDMuBnE4SVpRoIlKNA7vW2BB0yDoajahZaTlRW6GDOMagYSibW2pRy6g/640?wx_fmt=png&from=appmsg)

更多的网友则选择用“Cool”来形容这项工作：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcvGy7fahWa90Za6SWeyYQFjloicAFqFy7a6HLbY7zvcDgptFZHQF89qA/640?wx_fmt=png&from=appmsg)  
![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcLItKUgOMoFC4ib3I0DiaTKgFWxXv5aMgy7Php4Wk2QqqbDOResOam4Mg/640?wx_fmt=png&from=appmsg)  
![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcLB63OqIOknMemdapPzdqZ91BzRrfT94xvv6FaejXhtShdBrtv5xyXg/640?wx_fmt=png&from=appmsg)

## “无他，照着人类学”

所以，究竟怎么才能让机器人像以上般“张牙舞爪”、富有类人表现力？

设想的思路无他：照着人类学。

学习资料既包括各种人体动捕数据集，也包括生成模型、video2pose模型给出的模拟数据。

通过在强化学习框架中进行**全身控制** 的大规模训练，机器人就可以在现实世界中进行动作的泛化了。

然而，这样的Sim2Real思想**实际还是遇到了问题** 。

作者介绍，典型数据集中的人体模型有69个自由度，但他们所用的机器人只有19个。

除此之外，理论和实际的扭矩限制也不相同。

这就很尴尬了，等于**学会的知识实际根本不能拿来就用** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcWWM6AZAaicaUiapWeSDgRMiaZJa4efK765pROeno15ArGK48VHJuLUPJA/640?wx_fmt=png&from=appmsg)

那怎么办？

那就做**一个小小的改动** ：

只让上半身进行模仿，负责各种表现力，下半身则只负责在任意速度内把两条腿控制稳定就行。

作者姑且就管这个方法就叫做“表现型全身控制”（Expressive Whole-Body Control (Exbody)）。

由此，该机器人的整体框架就长这样：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcwF4Nfzia2LsjOINwcdLlUojFo0JKH5dTib5442qkia6xibmbuRTLkxJQQg/640?wx_fmt=png&from=appmsg)

首先，在拿到各种数据集后，系统会有一个运动重定向，用于获取一系列与符合机器人运动学结构的运动片段。

然后在从这些片段中提取表达目标和根运动目标，进行“Exbody”策略的强化学习训练，最终将指令部署到真实机器人身上。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcqS6xicXyh2ZNZkftNhe0jpWBawWL7qkPyT1um4CGJ8XDuJ915Wib79tg/640?wx_fmt=png&from=appmsg)

其中，表达目标就是机器人上半身要完成的，根运动目标则归于下半身（当然，这部分也可以用遥控命令直接给出）。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcvpLvY09J61icshHZ3ltZQ1HoicCiaibjkdxUup16FNBba9ibxbAQuCBMQgw/640?wx_fmt=png&from=appmsg)**

###### **△** 所用数据集

最终，和各种基线方法相比，该机器人取得了如下成绩：

有几项比较突出的指标，整体表现还不错。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcpAGhzykWmIT57Dkuqxjd0JNU8820svRtk9gibXHR0g1CYffZdDdarkg/640?wx_fmt=png&from=appmsg)

（MELV：Mean Episode Linear Velocity Tracking Reward，线性速度跟踪奖励 MEK：Mean episode
key body tracking reward，关键身体追踪奖励）

而从下图来看，Exbody的策略也能让机器人在表现时（例如击掌）膝盖弯曲更多，抬脚时脚离地面更高。言外之意，动作更卖力更富有表现力一些～当然，也更稳。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcKg7sAsQD2v4TxOzNdoVB6f6krkl22RTficE6sbszgJCOKVGC0Fc7licg/640?wx_fmt=png&from=appmsg)

## 全华人团队出品

本研究一共6位作者，全部为华人，全部来自加州大学圣地亚哥分校（UCSD）。

共同一作有两位：

  * **Xuxin Cheng** ，UCSD博一在读，硕士毕业于CMU机器人专业，本科则毕业于北理工自动化专业。

  * **Yandong Ji** ，同UCSD博一在读，硕士毕业于UC伯克利机械工程，本科毕业于南开大学电子计算机工程专业。

通讯作者为他们的导师**Xiaolong Wang** ，UCSD电气工程系助理教授。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAic3LHzK7WZ99SicborKia9JcoXibEKKbCoB6RzPJpgLoLQEjwLn5Z0c5pJogtGkWgXkqTMv6cic9OYVw/640?wx_fmt=png&from=appmsg)

他博士毕业于CMU，目前的研究方向集中于CV和机器人技术等等，谷歌学术显示论文引用次数23000+。

哦对了最后，团队成员还包括本次研究所用的机器人**![](https://res.wx.qq.com/t/wx_fed/we-
emoji/res/v1.3.10/assets/newemoji/Yellowdog.png)**：来自宇树科技的**Unitree H1** 。

## One More Thing

要说最近的机器人进展，还真不少。

先是OpenAI和微软押注的**Figure** 刚刚宣布，新一轮融资筹集了约6.75亿美元，融资前估值约20亿美元。

紧接着发布了个视频，介绍了旗下人形机器人Figure 01的最新进展，称“一切都是自主的”：

再有就是那个面部表情极其丰富，有时惊艳有时又惊悚的**Ameca** ，最新宣布已具有视觉能力。

她能观察所处房间的整个情况，然后用各种各样的声音语气（包括但不限于马斯克、海绵宝宝）跟你绘声绘色地描述。

就怪有意思的hhhhhh

参考链接：  
[1]https://expressive-humanoid.github.io/resources/Expressive_Whole-
Body_Control_for_Humanoid_Robots.pdf  
[2]https://expressive-humanoid.github.io/  
[3]https://twitter.com/xiaolonw/status/1762528106001379369

— **完** —

**报名中！**

**2024年值得关注的AIGC企业 &产品**

量子位正在评选**2024年最值得关注的AIGC企业** 、 **2024年最值得期待的AIGC产品** 两类奖项，欢迎[报名评选]()！

评选报名**截至2024年3月31日![](https://res.wx.qq.com/t/wx_fed/we-
emoji/res/v1.3.10/assets/newemoji/LetMeSee.png)**

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC7IzBlicP1jwLsfiaw2A2ibBoWRgd47kXexFUOSSzXn5f9fDcza39rny2BgqyDQkDrSoLCDh3Ag7XwA/640?wx_fmt=png&from=appmsg)

**中国AIGC产业峰会**
同步火热筹备中，了解更多请戳：[在这里，看见生成式AI的应用未来！中国AIGC产业峰会来啦！](http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247717398&idx=1&sn=bb6e373ad0ff839c524094ebdb83e918&chksm=e8df2564dfa8ac7277a76ca2c9e4793d08729828edfaf96a5283daaacd497375630c911b1661&scene=21#wechat_redirect)

商务合作请联络微信：18600164356 徐峰  

活动合作请联络微信：18801103170 王琳玉

  

**点这里 👇关注我，记得标星噢**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg)

