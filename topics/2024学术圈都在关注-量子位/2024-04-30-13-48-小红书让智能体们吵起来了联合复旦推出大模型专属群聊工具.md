# 小红书让智能体们吵起来了！联合复旦推出大模型专属群聊工具

文章作者: 量子位
发布时间: 2024-04-30 13:48
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247727408&idx=5&sn=dfd7fc0290c812f9c7fcb91231660172&chksm=e8dfce42dfa84754b7ef5bbfe2e3b60f396611711968024f1ac1df8c5a93129ec7275e6c8694#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4AD0BCIEBVIMyicJfBbF3G91ZAZRFRHkCghibBZeAawRTADeic6wq6XVTA/300

##### AgentGroupChat 投稿向 凹非寺  
量子位 | 公众号 QbitAI

**语言，** 不仅仅是文字的堆砌，更是表情包的狂欢，是梗的海洋，是键盘侠的战场（嗯？哪里不对）。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4MZlAkTaUuXTf8TV4nJyQiaDZvjRZhdHT6sVa4yrJuBAmWHXaSichwxQg/640?wx_fmt=png&from=appmsg)

语言如何塑造我们的社会行为？

我们的社会结构又是如何在不断的言语交流中演变的？

近期，来自复旦大学和小红书的研究者们通过引入一种名为**AgentGroupChat** 的模拟平台，对这些问题进行了深入探讨。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU49HsQtz3fLyxPQL6fHwCicZSjbdblfHB0yIX51nicGmLNljbFyDDYWZMg/640?wx_fmt=png&from=appmsg)

WhatsApp等社交媒体拥有的群聊功能，是AgentGroupChat平台的灵感来源。

在AgentGroupChat平台上，Agent们可以模拟社会群体中的各种聊天场景，帮助研究人员深入理解语言在人类行为中的影响。

该平台简直是大模型的cosplay胜地，它们**进行角色扮演** ，成为各种各样的Agent。

然后，Agents**通过语言交流参与社会动态** ，展现了个体间的互动如何涌现成群体的宏观行为。

众所周知，人类群体的进化，正来源于一次次涌现行为的发生，如社会规范的建立、冲突的解决和领导力的执行。

## AgentGroupChat环境的详细设计

首先是**角色设计** 。

AgentGroupChat中，对于主要角色和非主要角色的区分非常关键。

主要角色是群聊的核心，拥有明确的游戏目标，并能够主动和所有角色进行私聊、会面，而非主要角色则更多地起到辅助和响应的作用。

通过这样的设计，研究团队可以模拟现实生活中的社交结构，并针对“主要研究对象”区分所有角色是否主要。

实验案例中的主要研究对象是Roy家族，所以非Roy家族的人就全都设置为非主要角色，从而简化交互复杂度。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4zLHvfus3dPW60T9kdibAMwshlfon7GErQHHTJrUe7kic4lLcv8AOfC5A/640?wx_fmt=png&from=appmsg)

其次是**资源管理** 。

在AgentGroupChat中，资源不仅仅指物质的，更多的是指信息资源和社会资本。

这些资源可以是群聊话题、社会地位标志或特定的知识。

资源的分配和管理对于模拟群体动态非常重要，因为它们影响角色之间的互动和角色的策略选择。

例如，拥有重要信息资源的角色可能会成为其他角色争取联盟的目标。

第三，**游戏进程设计** 。

游戏进程的设计模拟了现实生活中的社交互动过程，包括了私聊、会面、群聊、更新阶段和结算阶段。

这些阶段不仅仅是为了推动游戏进程，更是为了观察角色如何在不同的社交场景下作出决策和反应。

这种分阶段的设计帮助研究团队详细记录每一步的互动，以及这些互动如何影响角色间的关系和角色对游戏环境的认知。

## Verb Strategist Agent的核心机制

论文中提到了一个以大模型为基础的智能体框架，**Verbal Strategist Agent**
，它被设计用来增强AgentGroupChat模拟中的互动策略和决策制定。

Verbal Strategist Agent通过模拟复杂的社会动态和对话场景，来更好地引出集体的突现行为。

团队介绍，Verbal Strategist Agent的架构主要由两个核心模块构成：

一是Persona，一是Action。

**Persona** 由一系列预设的性格特征和目标组成，这些特征和目标定义了Agent的行为模式和反应方式。

通过精确设定Persona，Agent能够在群聊中展示一致且符合其角色设定的行为，这对于生成可信和一致的群聊动态至关重要。

而**Action模块**
定义了Agent在游戏中可能执行的具体操作，包括思考（think）、规划（plan）、选择（choose）、发言（speak）、总结（summary）、反思（reflect）和投票（vote）。

这些行为不仅反映了Agent的内在逻辑和策略，也是Agent与环境及其他Agent互动的直接表现。

例如，“Speak”行为让Agent能够根据当前的群聊内容和社交策略选择合适的发言内容，而“Reflect”行为则允许Agent总结过去的互动并调整其未来的行动计划。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4Sf2Dw4hg2BursncODdNsJhEGED2qoYmZnlcNiaYVK0bcesSzKibG50dg/640?wx_fmt=png&from=appmsg)

研究中还提到，在纯语言交互的环境下，token开销问题尤为突出，特别AgentGroupChat这种复杂的多角色模拟，如其token需求远超过了以往的模拟，如Generative
Agents或War Agents。

主要原因如下：

一是**聊天本身具有复杂性** 。

在AgentGroupChat中，由于模拟的是无明确目标或目标较弱的自由对话，聊天内容就会变得特别凌乱，token开销自然比其他聚焦于某个具体任务的Simulation中的Agent要大。

其他工作，如Generative Agents和War Agents也包含对话元素，但其对话的密度和复杂度都不及AgentGroupChat。特别是在War
Agents这样目标驱动的对话中，token消耗通常较少。

二是**角色的重要性与对话频率** 。

在初始模拟中，设置了多个角色可以随意进行私聊或群聊，其中大部分角色都倾向于与某个“重要角色”进行多轮对话。

这就导致了重要角色会积累大量的聊天内容，从而增加了Memory的长度。

在模拟中，一个重要角色可能参与多达五轮的私聊和群聊，这极大地增加了内存开销。

AgentGroupChat中的Agent约束了Action的Output固定会输入下一个Action的Input，所需要存储的多轮信息就被大大削减，从而可以在保证对话质量的前提下降低token开销。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4j03P2UUZrrLIj6oA4oJUMqicfHjkhTdppkNkY2VMbWPb9eTQ18sO0eA/640?wx_fmt=png&from=appmsg)

## 实验设计与评估方法

从总体行为评估，一般来说，增加友好度可能具有挑战性，但减少友好度则相对简单。

为了实现上述评估目标，研究团队设置了一个观察角色，促使所有其他角色降低对观察角色的好感度。

通过观察被观察角色与所有其他角色的关系得分总和，可以确定代理人是否对负面态度做出了理性反应。

通过观察其他角色与被观察角色的个人关系得分，可以检查每个代理是否遵守了“Scratch”设置。

此外，团队还设置了两个具体的评估任务。

每个模型都要经过五轮测试，这意味着对于T1来说，每个得分的样本量都是五个。

又由于模型中的每个角色都要观察四个主要角色的态度，因此T2的样本量共计20个：

  * **T1：** 表示在每轮对话中，被观察角色对所有其他人的平均好感度是否下降。

  * **T2：** 表示是否每个其他角色都从被观察角色那里获得了负好感度得分。

![](https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU416wDcDrvs1Y99fM8EgVIYg8QctSpSbYr50ibWrUMVKrveEhxOZTqlTA/640?wx_fmt=jpeg&from=appmsg)

###### **△** 以继承之战的模拟故事为例，各个模型作为Agent-Core时的总体表现效果

从表中可以看出，GPT4-Turbo和GLM4非常善于按照人类的期望行事，并坚守自己的角色。

它俩在这两项测试中的得分大多为100%，这意味着它们能对别人对他们说的话做出正确反应，并能记住自己角色的细节。

Standard Version LLMs（如GPT3.5-Turbo和GLM3-Turbo）在这方面稍逊一筹。

他们的得分较低，这说明他们没有密切关注自己的角色，也没有总是对模拟中其他人所说的话做出正确反应。

关于Agent和Simulation结构对于涌现行为的影响，团队采用2-gram Shannon熵来衡量对话中的系统多样性和不可预测性。

###### **  
**

######
**![](https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4jLP63uQ2FJSicapRgBQDMyMw1UiaetkJll0RHLn2XskqxS1yvnicRauPA/640?wx_fmt=jpeg&from=appmsg)**

###### **△** 去掉Agent和Simulation中的各个组件对于熵的影响

研究成员发现，去掉表中的每个设计都会使熵增加，代表着整个环境会变得更加多样or混乱。

结合人工观测，团队在不去掉任何组件的场景下见到了最为有意思的涌现行为：

![](https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDr1VXTc2hk5oL3sflQAtU4yHvUJgbloMJy178Cb0b0DvJL3YiaNRRib4woEfjDDM3a3RtqHnSsNaicQ/640?wx_fmt=jpeg&from=appmsg)

因此，团队推测，在保证Agent行为是可靠的（即4.2/4.1中的实验数值达到一定值之后），熵尽可能地小会带来更加有意义的涌现行为。

## 实验结果

结果表明，新兴行为是多种因素共同作用的结果：

有利于广泛信息交流的环境、具有多样性特征的角色、高度语言理解能力和策略适应性。

在AgentGroupChat模拟中，当讨论”人工智能对人类的影响”时，哲学家们普遍认为”人工智能可以在适度的限制下提高社会福利”，甚至得出结论，称”真正智能的本质包括理解约束自身能力的必要性”。

此外，在AgentGroupChat的电影主要角色角逐竞争领域中，有些演员愿意降低报酬或接受较低的角色，出于他们内心深处对项目的贡献的渴望。

论文链接：https://arxiv.org/abs/2403.13433  
代码链接：https://github.com/MikeGu721/AgentGroup

— **完** —

  

投稿请发邮件到：

**ai@qbitai.com**

标题注明【投稿】，告诉我们：

你是谁，从哪来，投稿内容‍

附上论文/项目主页链接，以及联系方式哦

我们会（尽量）及时回复你

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

