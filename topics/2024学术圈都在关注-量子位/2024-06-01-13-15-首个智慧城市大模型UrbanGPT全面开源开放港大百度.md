# 首个智慧城市大模型UrbanGPT，全面开源开放｜港大&百度

文章作者: 量子位
发布时间: 2024-06-01 13:15
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247731708&idx=3&sn=921799b21f40ac57a25a356be0e4f083&chksm=e8dffe8edfa8779868c242ce8608c93c454794ab392c83a5daff9e2e381e1aead093db3e050c#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrkXZQY3BP7MTTuiasx0JJ0A59PHvAVib418FG6YjicDevBTLdCAqDq5gBA/300

##### UrbanGPT团队 投稿  
量子位 | 公众号 QbitAI

时空预测技术，迎来ChatGPT时刻。

时空预测致力于捕捉城市生活的动态变化，并预测其未来走向，它不仅关注交通和人流的流动，还涵盖了犯罪趋势等多个维度。目前，深度时空预测技术在生成精确的时空模型方面，依赖于大量训练数据的支撑，这在城市数据不足的情况下显得尤为困难。

**港大、百度联合团队** 借鉴大型语言模型的思想，提出了一种新型的时空大型语言模型**UbanGPT** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrOibmAuKQCrz9fbZxzH3CLXsZhIuNI4aqf928LRRxu8A9bYda8IUdhOg/640?wx_fmt=png&from=appmsg)

该模型在多种城市应用场景中展现了出色的普适性。通过结合时空依赖编码器和指令微调方法，该模型增强了对时间和空间复杂关系的理解，即使在数据稀缺的条件下也能提供更精确的预测。通过一系列广泛的实验，UrbanGPT在多个城市相关的任务上展现了其卓越的性能，并证明了其在零样本学习领域的强大潜力。

## 时空大型语言模型UrbanGPT

**挑战1：标签稀缺和高昂的训练成本**

尽管尖端的时空网络在预测任务上表现出色，但它们的效能受限于对大量标记数据的依赖。在城市应用中，获取数据通常非常困难，例如，要对整个城市的交通和空气质量进行监控，其成本是相当高的。此外，这些模型在面对新地区或新任务时，其泛化能力通常不足，需要进行重新训练以适应不同的时空环境。

**挑战2：LLMs和现有的时空预测模型在零样本泛化方面存在局限**

如图1所展示的，大型语言模型LLaMA能够根据输入的文本信息推断出流量模式。但是，当涉及到处理具有复杂时空依赖性的数字时间序列数据时，LLaMA的预测能力受限，有时可能会得出与实际相反的预测结果。与此同时，虽然预训练的基线模型能够有效地编码时空依赖关系，但它们可能会因为过度适应原始训练数据而在没有先前经验的新场景（零样本场景）中表现不佳。

**挑战3：如何将LLMs的出色推理能力扩展到时空预测领域：**

时空数据具有其独特的属性，这与LLMs所编码的信息之间存在差异。缩小这一差异，并构建一个能够在多样的城市任务中展现出卓越泛化性能的时空大型语言模型，是当前面临的一个重大挑战。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQr4EGAYNg2Oia1u72vbTiaqVjuPbmzSpcOAuskibL27HIWRetjPFR0MESiaQ/640?wx_fmt=png&from=appmsg)

###### **△** 图1：与LLMs和现有时空图神经网络相比，UrbanGPT 在零样本场景下能更好地预测未来时空趋势

## 时空大型语言模型UrbanGPT

据团队了解，这是首次尝试创建一种时空大型语言模型，该模型能够预测不同数据集上的多种城市现象，特别是在训练样本受限的情境下。

本研究提出了名为UrbanGPT的时空预测框架，它赋予了大型语言模型深入理解时间和空间之间复杂相互依赖关系的能力。通过将时空依赖编码器与指令微调策略巧妙结合，该框架成功地将时空信息与大型语言模型的推理能力融合在一起。

在现实世界数据基础上进行的广泛实验验证了UrbanGPT在零样本时空学习场景中的卓越泛化性能。这些实验结果不仅凸显了UrbanGPT模型的强大泛化潜力，也证实了它在精确预测和理解时空模式方面的有效性，即便在缺乏训练样本的情况下。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrGb9xL4qeiaib01GDLrlQlIPzaufmGVGrg6V0j238bfrDEYXObx2dZgeQ/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQr4EGAYNg2Oia1u72vbTiaqVjuPbmzSpcOAuskibL27HIWRetjPFR0MESiaQ/640?wx_fmt=png&from=appmsg)

###### **△** 图2: UrbanGPT 整体框架

### 时空依赖编码器

LLMs在处理语言任务时表现出色，但它们在解析时空数据中固有的时间序列及其演化模式方面存在困难。为了克服这一难题，本文提出了一种创新方法，即整合时空编码器来提升大型语言模型捕捉时空上下文中时间依赖性的能力。具体来说，所设计的时空编码器由两个核心组件构成：一个是门控扩散卷积层，另一个是多层次关联注入层。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrHWbSMVvUMbxibiaE8NIVGy3MicfmgcD65eowJib8ogJ67ibyo5NSHw6CQEA/640?wx_fmt=png&from=appmsg)

门控时间扩散卷积层在不同层级上编码了不同程度的时间依赖性，捕捉了具有不同粒度级别的时间演化特征。为了保留这些时间信息模式，团队引入了一个多层次的关联注入层，该层旨在融合不同层级之间的相互关联性。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrhyjWAGWajHB4bTRibibmVcnkMvubc0OXiaPjX7dqe7T25HZc5rStwjxug/640?wx_fmt=png&from=appmsg)

为应对可能出现的多样化城市场景，本文提出的时空编码器在模拟空间关联性时不依赖于特定的图结构。这种做法考虑到在零样本预测的情境下，实体间的空间联系可能是未知的或难以明确界定的。这样的设计确保了UrbanGPT能够在广泛的城市环境条件下保持其适用性和有效性。

### 时空指令微调框架

**时空数据-文本对齐**

为了让语言模型能够准确捕捉时空模式，确保文本信息与时空数据的一致性是关键。这种对齐使得模型能够整合多种类型的数据，生成更丰富的信息表示。通过结合文本和时空领域的上下文特征，模型不仅能够捕获到补充性的信息，还能提炼出更具表现力的高级语义特征。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrZ6hgJBTRjnzTZON7ZGLHRqmzss4iagCHS0uwQQeYelibb4M9KXRdZGQg/640?wx_fmt=png&from=appmsg)

**时空提示指令**

在进行时空预测时，时间与空间维度都蕴含着丰富的语义信息，这些信息对于模型准确理解特定情境下的时空动态至关重要。例如，早晨的交通流量特征与交通高峰时段显著不同，同时商业区和住宅区的交通模式也各有特点。UrbanGPT框架通过整合不同粒度的时间数据和空间特征，作为其大型语言模型的指令输入。具体来说，时间信息涵盖了日期、具体时间等要素，而空间信息则包括了城市名称、行政区划分以及周边的兴趣点（POI）等数据，如图3所示。这种多维度的时空信息整合，使得UrbanGPT能够精确地捕捉不同时间和地点的时空模式，显著增强了其在未知样本上的推理能力。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrZ4tlYS6bgQWlawLC4R5yAm4G5qUbMIuabicnCfhSgLxnUHibGxoqacVA/640?wx_fmt=png&from=appmsg)

###### **△** 图3: 编码时间和空间信息感知的时空提示指令

3.2.3 大语言模型的时空指令微调

在利用大型语言模型（LLMs）进行指令微调以生成文本形式的时空预测时，面临两大挑战。首先，这类预测任务依赖于数值型数据，其结构和规律与LLMs所擅长处理的自然语言（侧重于语义和语法）存在差异。其次，LLMs通常采用多分类损失函数进行预训练，以预测文本中接下来的单词，这与需要输出连续数值的回归问题有所区别。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrjBsSicIYzeZLRV8sAC3fgkugy5VDxzznB3UENdzWufFGTn5Wh7osrLQ/640?wx_fmt=png&from=appmsg)

## 实验结果：

### 零样本预测性能

**相同城市内未见区域的预测**

跨区域场景使用同一城市中某些区域的数据来预测模型未曾接触过的其他区域的未来情况。通过细致分析模型在此类跨区域预测任务中的表现，团队发现UrbanGPT展现了出色的零样本预测性能。UrbanGPT通过时空与文本信息的精准对齐，以及将时空指令微调技术与时空依赖编码器的无缝融合，有效地保持了通用且可迁移的时空知识，从而在零样本场景中实现了精准的预测。此外，UrbanGPT在处理数据稀疏性问题时同样具备显著优势。特别是在犯罪预测任务中，由于数据的稀疏性，传统的基线模型经常表现不佳，低召回率可能暗示了过拟合的问题。UrbanGPT通过整合文本中的语义信息，注入了丰富的语义洞察力，这增强了模型捕捉稀疏数据中时空模式的能力，进而提升了预测的准确度。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrsyVGds97Wzrl3m7l03M8KxD3llHaZcRbXOYEfsq5ibRP6RMOK8cc3WQ/640?wx_fmt=png&from=appmsg)

###### **△** 表1：跨区域零样本预测场景性能比较

**跨城市预测任务**

为了检验模型在进行跨城市预测时的表现，团队选用了CHI-
taxi数据集进行评估，该数据集在模型的训练阶段未曾使用。图4的评估结果表明，在每个时间点上，模型的表现均优于其他对比方法，这证实了UrbanGPT在跨城市知识迁移方面的有效性。模型通过综合考虑多样的地理信息和时间要素，展现出将功能相似的区域和历史同期的时空模式进行关联的能力，为实现跨城市场景中的精确零样本预测提供了强有力的支持。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrC6zmCDfo7DibDZbhictXcAXc6YtibEKkibhIDu8P8dYkEeibMCRAvdXePPw/640?wx_fmt=png&from=appmsg)

###### **△** 图4：跨城市零样本预测场景性能比较

### 典型的有监督预测任务

团队也对UrbanGPT在有监督预测情境下的性能进行了探究，特别是通过采用时间跨度更大的测试数据集来检验模型在长期时空预测方面的效能。举例来说，团队使用2017年的数据来训练模型，并用2021年的数据进行测试。测试结果显示，UrbanGPT在长期时间跨度的场景中相比基线模型有着明显的优势，彰显了其出色的泛化能力。这一特性意味着模型不需要频繁地重新训练或进行增量更新，从而更适应实际应用场景。此外，实验还证明，引入额外的文本信息并不会对模型性能造成负面影响或引入噪声，这进一步支持了利用大型语言模型来增强时空预测任务的策略是可行的。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQr1mK3QY48eqo0hhktVofZnPwtLmQuLuc5ibWXR73jAYDhsibAncTgoqiag/640?wx_fmt=png&from=appmsg)

###### **△** 表2：有监督设置下的预测性能评估

### 消融实验

（1）时空上下文的效用：-STC。
当从指导文本中去除时空信息时，模型的性能出现了下降。这可能是因为缺少了时间维度的数据，导致模型只能依赖时空编码器来处理与时间相关的特征并执行预测。同时，空间信息的缺乏也削弱了模型捕捉空间相关性的能力，这使得识别和分析不同区域的独特时空模式变得更加困难。

（2）使用多个数据集进行指令微调的影响：-Multi。 模型仅接受了NYC-
taxi数据集的训练。由于缺少来自不同城市指标的广泛信息，这限制了模型深入展现城市时空动态的能力，导致预测结果不尽人意。然而，通过融合多个来源的时空数据，模型能够更有效地捕捉到不同地理位置的独特属性以及随时间演变的模式，从而加深对城市复杂性的洞察。

（3）时空编码器的作用：-STE。 缺少时空编码器显著限制了大型语言模型在时空预测任务中的效能。这突出了所设计时空编码器在增强模型预测准确性方面的重要性。

（4）指令微调中的回归层：T2P。
UrbanGPT被直接指导以文本形式输出其预测结果。模型在性能上的不足主要是由于其训练阶段主要采用多类损失函数进行优化，这造成了模型概率输出与时空预测任务所需的连续数值分布之间的不一致。为了解决这一问题，团队在模型架构中集成了一个回归预测模块，这一改进显著增强了模型在回归任务中生成更精确数值预测的能力。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQria0KocNm7GCWRwSUw13NdDQib3ibIqXotDf3xicqBUw2PKXmiaZUo5ia5IlQ/640?wx_fmt=png&from=appmsg)

###### **△** 图5：UrbanGPT消融实验

### 模型鲁棒性研究

本部分对UrbanGPT在应对不同时空模式场景时的稳定性进行了评估。团队根据区域内在特定时间段数值波动的大小将区域进行区分。方差较小的区域代表时间模式较为恒定，而方差较大的区域则代表时空模式更为多变，例如繁忙的商业区或人口密集地区。图6的评估结果显示，大多数模型在方差较低、时空模式相对稳定的区域中表现较好。然而，基线模型在方差较高、特别是方差位于(0.75,
1.0]区间的区域中表现不佳，这可能是因为基线模型在推断未见区域的复杂时空模式方面存在局限。在实际的城市运营中，对人口密集或商业繁忙区域的准确预测对于城市管理极为关键，包括交通信号的控制和安全调度等方面。UrbanGPT在方差位于(0.75,
1.0]区间的区域中展现了显著的性能提升，这凸显了其在零样本预测方面的卓越能力。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrot2v9vAQCexRcRdOxzNsYU9LUfmsPOQEwMekSUZcA4ZiaC44acNcQVA/640?wx_fmt=png&from=appmsg)

###### **△** 图6：模型鲁棒性研究

### 案例研究

本次实验旨在评估不同大型语言模型（LLMs）在零样本时空预测任务中的效能。根据表3的实验结果，团队可以看到各类LLMs能够依据提供的指令生成预测结果，这证实了团队提示设计的有效性。

具体来看，ChatGPT在其预测中倾向于依赖历史平均值，而不是明确地整合时间或空间数据。Llama-2-70b能够分析特定时段和区域的信息，但在处理数值时间序列的依赖性时遇到了难题，这影响了其预测的准确性。相比之下，Claude-2.1能够高效地整合和分析历史数据，并利用高峰时段的模式以及兴趣点（POI）信息来提高流量趋势预测的精确度。在本研究中提出的UrbanGPT模型，通过时空指令微调的方式，成功地将时空上下文信号与大型语言模型的推理能力结合起来，显著提升了预测数值和时空趋势的准确性。这些发现凸显了UrbanGPT框架在捕捉普遍时空模式方面的潜力，证实了其在实现零样本时空预测方面的有效性。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAF9EouV3RHBHtc6GXZnJQrT59icVs1Qzibuwb4OTe7z4T1IEQPrSTckQhCXt573kXkAic534bQ18YFg/640?wx_fmt=png&from=appmsg)

###### **△** 表3：不同的LLMs在纽约市自行车流量中的零样本预测案例

## 总结与展望

本研究介绍了UrbanGPT，这是一个具备在多样化城市情境下卓越泛化性能的时空大型语言模型。通过采用一种创新的时空指令微调策略，团队成功实现了时空上下文信息与大型语言模型（LLMs）的紧密整合，从而让UrbanGPT得以掌握广泛适用且可迁移的时空模式。实验数据充分证明了UrbanGPT模型架构及其核心组件的有效性。

尽管目前的成果充满希望，但团队也认识到未来研究中仍有一些挑战需要克服。作为未来工作的一部分，团队计划积极收集更多样化的城市数据，以此来加强和提升UrbanGPT在更广泛城市计算场景中的应用能力。此外，深入理解UrbanGPT的决策机制也极为关键。尽管模型在性能上表现出色，但提供决策过程的透明度和可解释性同样重要。未来的研究将致力于开发能够解释其预测结果的UrbanGPT模型。

项目链接: https://urban-gpt.github.io/  
代码链接: https://github.com/HKUDS/UrbanGPT  
论文链接: https://arxiv.org/abs/2403.00813  
实验室主页: https://sites.google.com/view/chaoh/home

— **完** —

  

投稿请发邮件到：

**ai@qbitai.com**

标题注明【投稿】，告诉我们：

你是谁，从哪来，投稿内容‍

附上论文/项目主页链接，以及联系方式哦

我们会（尽量）及时回复你

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

