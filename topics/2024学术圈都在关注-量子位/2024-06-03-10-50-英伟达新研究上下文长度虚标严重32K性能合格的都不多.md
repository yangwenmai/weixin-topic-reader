# 英伟达新研究：上下文长度虚标严重，32K性能合格的都不多

文章作者: 量子位
发布时间: 2024-06-03 10:50
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247731877&idx=2&sn=af1823595150cfb9d771f0eb1f2f00d9&chksm=e8dffdd7dfa874c187fc0d850c42f81e3b9391f6e0371d863ea30d5203fe5672c6636052cb93#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKymsq0jFNiav3XUpHFPrvhOGLXVhtaGpA6pF57JQVJnhfNiafvdIB3ldjg/300

##### 西风 发自 凹非寺  
量子位 | 公众号 QbitAI

无情戳穿“长上下文”大模型的虚标现象——

英伟达新研究发现，包括GPT-4在内的10个大模型，生成达到128k甚至1M上下文长度的都有。

但一番考验下来，在新指标“有效上下文”上缩水严重，能达到**32K** 的都不多。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKyyKQ8EWPnRI1IQWLrDYpy6T7qaRNGPL1TXPMYyDMAn10akKwpxibkKYg/640?wx_fmt=png&from=appmsg)

新基准名为**RULER** ，包含**检索、多跳追踪、聚合、问答**
四大类共13项任务。RULER定义了“有效上下文长度”，即模型能保持与Llama-7B基线在4K长度下同等性能的最大长度。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKyJiaDLCiaQczOzoxgsfsgEwDhdkIPZeviadzkGiae4AopOkHbYia2PxJe1eg/640?wx_fmt=png&from=appmsg)

这项研究被学者评价为“非常有洞察力”。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKyQ72jFuqc9VjPP7mvdJfEZZoo78Z9PmtvRQtTJHdcDia6vuEr6RI6unQ/640?wx_fmt=png&from=appmsg)

不少网友看到这项新研究后，也非常想看到上下文长度王者玩家Claude和Gemini的挑战结果。（论文中并未覆盖）

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKyib1pNNKXUmbsiajylOmicVr09eJZj6ib8GxWQXX6IgOrdHI8FJWZQict5Gg/640?wx_fmt=png&from=appmsg)  
![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKyV4g6zlZ67LFxiaicutYhwg7ArPiamW6DDklEuhwypicRPbgtUCuDEzMv3w/640?wx_fmt=png&from=appmsg)

一起来看英伟达是如何定义“有效上下文”指标的。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKyAvT6C8xe5eks14bwD30bGr37kZe7SCaWIvP2EJXiax7o691KAcodibxQ/640?wx_fmt=png&from=appmsg)

## 测试任务更多、更难

要评测大模型的长文本理解能力，得先选个好标准，现圈内流行的ZeroSCROLLS、L-Eval、LongBench、InfiniteBench等，要么仅评估了模型检索能力，要么受限于先验知识的干扰。

所以英伟达提出了RULER方法，一句话概括就是**“确保评估侧重于模型处理和理解长上下文的能力，而不是从训练数据中回忆信息的能力”** 。

RULER的评测数据减少了对“参数化知识”的依赖，也就是大模型在训练过程中已经编码到自身参数里的知识。

具体来说，RULER基准扩展了流行的“大海捞针”测试，新增四大类任务。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKyjVA83moicKTbyUc51wRK6icV14OSmicliadhwJ8f5WibNgpp9OA2EOfuXlw/640?wx_fmt=png&from=appmsg)

**检索** 方面，从大海捞针标准的单针检索任务出发，又加入了如下新类型：

  * **多针检****索** （Multi-keys NIAH, MK-NIAH）：上下文中插入多个干扰针，模型需检索指定的那一个

  * **多值检索** （Multi-values NIAH, MV-NIAH）：一个键（key）对应多个值（values），模型需要检索出与特定键关联的所有值。

  * **多查询检索** （Multi-queries NIAH, MQ-NIAH）：模型需根据多个查询在文本中检索出相应的多个针。

除了升级版检索，RULER还增加了**多跳追踪** （Multi-hop Tracing）挑战。

具体来说，研究人员提出了**变量追踪** （VT），模拟了指代消解（coreference
resolution）的最小任务，要求模型追踪文本中变量的赋值链，即使这些赋值在文本中是非连续的。

挑战第三关是**聚合** （Aggregation），包括：

  * **常见词汇提取** （Common Words Extraction, CWE）：模型需要从文本中提取出现次数最多的常见词汇。

  * **频繁词汇提取** （Frequent Words Extraction, FWE）：与CWE类似，但是词汇的出现频率是根据其在词汇表中的排名和Zeta分布参数α来确定的。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKy7cuMT1FPp9xmdFca6cq2VLp9LjRqAJvjZnFn0M15V3IsF24wHMSB9w/640?wx_fmt=png&from=appmsg)

挑战第四关是**问答任务** （QA），在现有阅读理解数据集（如SQuAD）的基础上，插入大量干扰段落，考查长序列QA能力。

## 各模型上下文实际有多长？

实验阶段，如开头所述，研究人员评测了10个声称支持长上下文的语言模型，包括GPT-4，以及9个开源模型开源模型Command-R、Yi-34B、Mixtral（8x7B）、Mixtral（7B）、ChatGLM、LWM、Together、LongChat、LongAlpaca。

这些模型参数规模范围从**6B到采用MoE架构的8x7B** 不等，最大上下文长度从**32K到1M** 不等。

在RULER基准测试中，对每个模型评测了13个不同的任务，覆盖4个任务类别，难度简单到复杂的都有。对每项任务，生成500个测试样例，输入长度从4K-128K共6个等级（4K、8K、16K、32K、64K、128K）。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKy8WXhvUicZVq9Miceia2ia3Wk7w5mX4Arzgiclv9qZPQUxQmvkn2bNnoC50g/640?wx_fmt=png&from=appmsg)

为了防止模型拒绝回答问题，输入被附加了answer prefix，并基于recall-based准确性来检查目标输出的存在。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKypGWjWQIltibKsSWbj5NOCnhPQYgmQCSR33l8Rk3PFq7lyxCk5Co6xYw/640?wx_fmt=png&from=appmsg)

研究人员还定义了“有效上下文长度”指标，即模型在该长度下能保持与基线Llama-7B在4K长度时的同等性能水平。

为了更细致的模型比较，使用了加权平均分数（Weighted Average, wAvg）作为综合指标，对不同长度下的性能进行加权平均。采用了两种加权方案：

  * wAvg(inc)：权重随长度线性增加，模拟以长序列为主的应用场景

  * wAvg(dec):权重随长度线性减小，模拟以短序列为主的场景

来看结果。

普通大海捞针和密码检索测试看不出差距，几乎所有模型在其声称的上下文长度范围内均取得满分。

而使用RULER，尽管很多模型声称能够处理32K
token或更长的上下文，但除了Mixtral外，没有模型在其声称的长度上保持超过Llama2-7B基线的性能。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKyVAnthMgYM325W5F1SSFqVWVR0pibawCzZFlpU5OSlZXygqh8kJdR9xg/640?wx_fmt=png&from=appmsg)

其他结果如下，总的来说，GPT-4在4K长度下表现最佳，并且在上下文扩展到128K时显示出最小的性能下降（15.4%）。

开源模型中排名前三的是Command-R、Yi-34B和Mixtral，它们都使用了较大的基频RoPE，并且比其它模型具有更多的参数。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKy1144ibaedZQPsttxugSgNyibWj7kVeJRhCR3XIkZibUsYib48UGs6nRiaOw/640?wx_fmt=png&from=appmsg)  
![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKyU5LnRFQrNxjIHlzLLR5wo03Qr0OA68Zj4ic5ecUiaO6nrcqLE8zF6joQ/640?wx_fmt=png&from=appmsg)  
![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKyJNhyz4vDAB7TmRkI4feZFKUib07ejG0bnfiaO2cxjghIhcyic2RoRnMPA/640?wx_fmt=png&from=appmsg)  
![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKyA0cJtb60dzVic8icL9TEibIN7ECjHNTBJQSecPFv2EEpiaNahpheU3W6Yw/640?wx_fmt=png&from=appmsg)  
![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBXIHcMRMgAfZlUVQmDxMKydiafCKAcRdBxSeQKliaBtTvicKhPdeVTc4qKxLT79440ib1q879yfa5OFA/640?wx_fmt=png&from=appmsg)

此外，研究人员还对Yi-34B-200K模型在增加输入长度（高达256K）和更复杂任务上的表现进行了深入分析，以理解任务配置和失败模式对RULER的影响。

他们还分析了训练上下文长度、模型大小和架构对模型性能的影响，发现更大****的上下文训练通常会带来更好的性能，但对长序列的排名可能不一致；模型大小的增加对长上下文建模有显著好处；非Transformer架构
（如RWKV和Mamba）在RULER上的表现显著落后于基于Transformer的Llama2-7B。

更多细节，感兴趣的家银们可以查看原论文。

论文链接：https://arxiv.org/abs/2404.06654

参考链接：  
https://twitter.com/rohanpaul_ai/status/1797231094195962266

— **完** —

**量子位年度AI主题策划** 正在征集中！

欢迎投稿专题 **一千零一个AI应****用** ，**365行AI落地方案**

或与我们分享你在**寻找的AI产品** ，或发现的**AI新动向**

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&from=appmsg)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg)

