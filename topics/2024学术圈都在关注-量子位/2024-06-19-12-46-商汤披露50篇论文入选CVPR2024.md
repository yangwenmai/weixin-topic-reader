# 商汤披露：50篇论文入选CVPR 2024

文章作者: 量子位
发布时间: 2024-06-19 12:46
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247734450&idx=3&sn=e4fe153f68986cf4b081e28062305edc&chksm=e8dfe3c0dfa86ad6064d580aae638bc000c0ca3cc430cd57b6307de2fdc66185285ee6dac316#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtA41gqXEK9M7Realzlsqv98pAoFAhVVXUkdMNWKcMbiaA6Q4DL5N1gK6PclxLT0nCxAld8lZGLgCKw/300

##### 一水 发自 凹非寺  
量子位 | 公众号 QbitAI

CVPR正在进行中，中国科研力量再次成为场内外焦点之一。

日前，AI顶会常客选手**商汤科技** ，已经披露了今年成绩单：50篇论文入选，其中还有9篇被录用为Oral、Highlight。

这些成果，既是商汤科研和技术实力的最新证明，也透露着这家知名AI公司**对于产业趋势和技术趋势的预判** ——

论文涉及自动驾驶、机器人等前沿方向。

## 大规模视觉语言基础模型：InternVL

商汤科技、上海AI实验室等联合设计了一个大规模的视觉语言基础模型——InternVL。

首次将大规模视觉编码器扩展到**60亿** 个参数，与LLM进行对齐，在准确性、速度和稳定性之间取得了良好平衡。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98BdOMdYdjibY0V2Bpqb7zRRVUMSOGtAH1ibgryqoooSQYiaZnNZUacUpuw/640?wx_fmt=png&from=appmsg)  
论文：https://arxiv.org/abs/2312.14238

为了有效训练大规模视觉语言基础模型，InternVL还引入了一种**渐进式图像-文本对齐策略** 。

该策略最大限度地利用**网络规模的噪声图像-文本数据** 进行对比学习，并将细粒度、高质量的数据用于生成学习。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98VwKVYhJoHeSkU851gv7yEkTuD54p5LrBU4S2Zx4FsZLlS9eoiaBcrzw/640?wx_fmt=png&from=appmsg)

通过验证，相较于当前最先进的视觉基础模型和多模态大语言模型，InternVL在广泛的**通用视觉语言任务上** 能够取得更领先的结果。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98RGJx85YUCD8wwKO8kfRqBXH13amF54vyyYz1JViayXhRDhxAyq4bpAg/640?wx_fmt=png&from=appmsg)

另外，InternVL工作的**最新版本InternVL 1.5** 具备强大的视觉编码器和更深层次的场景理解能力。

InternVL 1.5支持动态高分辨率，能够**准确识别和理解图像** 中的各种细节以及文字信息。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98BQBeHiaKQTF30GhxEOOApoXD8hOcrGE6ILjDcjEDnfc2FUuFR8RszDA/640?wx_fmt=png&from=appmsg)  
Demo：https://internvl.opengvlab.com/

**第三方评测结果显示** ，InternVL
1.5在多模态感知、通用问答、文档理解、信息图表理解以及数理理解等方面综合能力领先开源模型，比肩GPT-4V、Gemini Pro等闭源模型。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98CtVCWiaDgWvJoFW8B1B1ysjic0nX8FdKoVawdFXNQgicGOMzk0ISFcaew/640?wx_fmt=png&from=appmsg)

不仅如此，为了补充多模态系统在高质量图像生成中的优质表现，对传统模型进行优化，商汤还提出了一个**“基于时间信息块的时间特征维护量化（TFMQ）”**
扩散模型框架。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98MjdK9hgfsJ4mgguNMk8qTYbANWv0WbecnGiaXKO8pJzVnm0965wyBeg/640?wx_fmt=png&from=appmsg)  
论文：https://arxiv.org/abs/2311.16503

该框架时间信息块仅与时间步骤相关，与采样数据无关，创新地设计并引入了**时间信息感知重建（TIAR）和有限集校准（FSC）方法**
，从而可以在有限的时间内对齐全精度时间特征，最小化精度损失的同时提高图像生成效率。

配备此框架，可以保持最多的时间信息并确保**端到端的图像生成质量** 。在各种数据集和扩散模型上的广泛实验证明了该技术已经达到**SOTA** 水平。

## 场景级3D开放世界感知算法：RegionPLC

场景级别的3D开放世界感知是**机器人领域** 非常重要的能力之一。

它能够使机器人在复杂、多变的环境中**自主导航、理解和交互** ，从而提升执行复杂任务的效率、准确性和安全性。

商汤科技和联合实验室的研究团队提出了一种直接结合点云和自然语言的**新开放世界理解算法** ——RegionPLC，**无需额外训练**
就可以和大语言模型结合进行一些场景级别的开放问答。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98RFNqoCeeoia43ic6PdcfRQq70iaGVeLibicwJIeFAmdSJah2hb3x0xkSkSw/640?wx_fmt=png&from=appmsg)  
论文：https://arxiv.org/abs/2311.16503

该算法扩展到了更细粒度的**区域级别点云和语言的结合** ，能够生成更密集和细粒度的描述。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98zmqxte7HzTAYLiaaGw0I7tdYvzTlXb1YxRxIIO72oGhDCc2yLcPiagDA/640?wx_fmt=png&from=appmsg)

在该研究中，研究人员设计了一种**基于互补的数据混合策略SFusion** ，只会混合在3D空间中互补的3D-text
pairs，减少在优化时产生冲突的概率。这样的设计使得RegionPLC可以结合不同2D大模型的优势，达到更好性能。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98KrJVM7qmCuAnejEOqCRELKfdHmTQ4FrvOwn0rurvHFlIVtwNMGwUuA/640?wx_fmt=png&from=appmsg)

通过大量实验证明，RegionPLC在ScanNet、ScanNet200和nuScenes数据集上的性能优于现有的3D开放世界场景理解方法，并在具有挑战性的**长尾或无注释场景中**
表现非常出色。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98bUpStia5fzOFwXXujJ95Rj9XyfYvkDgfWqSNiaUOhias9pmmdICN9MpYA/640?wx_fmt=png&from=appmsg)

除了对场景的识别和理解，**智能体的社会化交互能力** 也是人工智能迈向更高阶的关键所在。

为此，商汤及联合实验室提出了**“数字生命计划（Digital Life Project）”**
，即通过AI技术和动作合成技术创造出能够在数字环境中模拟交互的**自主3D虚拟角色** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98NSHZTTHUkwuue7HicMH5ibzoQ0WiaoLBOQg2wwK6Qa3CF62Spk9iaO1v3w/640?wx_fmt=png&from=appmsg)  
论文：https://arxiv.org/abs/2311.16503

这些角色不仅可以进行对话，还将拥有自己的人格，并感知所处的不同社交环境，做出相对应的身体动作来表达情感和反应。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv989YE1QjbRCTKhHatCjqdcy43nSGFbRcdPf1KDDhshjCibibWVq0uVrzhA/640?wx_fmt=png&from=appmsg)

数字生命计划包括“SocioMind”和“MoMat-MoGen”**两个核心部分。**

其中，SocioMind是一个**模拟人类思想和判断的数字大脑**
。它能够结合大语言模型和基于心理学原理的反思过程，使角色自主地发起和参与对话，规划接下来的故事发展。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv988ibbQF4mRIxvaW0BcZLRbvtCBL2CCDHv4UTqyrlEJHOvDmZhW4D6DLw/640?wx_fmt=png&from=appmsg)

而MoMat-MoGen是一套**用于控制角色身体动作的3D系统** 。它结合了动作匹配（Motion Matching）和动作生成（Motion
Generation）技术，在数字大脑的驱动下，让角色能根据场景做出合理的反应。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtA41gqXEK9M7Realzlsqv98yvyzGc3FtnTsAibHL8bVeIBiaYlcicLpAb0CnNicZERVjKr2WEWMSgheEg/640?wx_fmt=png&from=appmsg)

## CVPR最佳论文发布在即

本次CVPR共有来自全球的2719篇论文被接收，录用率为23.6%，**相较去年下降2.2%。** 可以看到，其他国内玩家也表现不俗，都有不少论文入选。

比如像**腾讯优图实验室** ，此前曝光称有20篇入选，覆盖多模态、人脸识别、视觉分割等多个方向。

这周，CVPR2024在美国西雅图正在进行中。

也就在这两天，CVPR最佳论文奖即将出炉，可以期待一下。

— **完** —

**量子位年度AI主题策划** 正在征集中！

欢迎投稿专题 **一千零一个AI应****用** ，**365行AI落地方案**

或与我们分享你在**寻找的AI产品** ，或发现的**AI新动向**

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&from=appmsg)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg)

  

