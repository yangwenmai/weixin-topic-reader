# Q*项目公开发布！研究团队并非OpenAI

文章作者: 量子位
发布时间: 2024-06-25 17:06
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247735472&idx=4&sn=b23b3e722070baab89797f7ef2a16cb2&chksm=e8dfefc2dfa866d4eba8fadd9049b93fbc90fbc5d118b328e31b7bd51342347bf1debc82bdef#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYaIraqWHa4WSbJ4MdDVgRRibwdmVsp3PXl83N3EWhlXSe6pvL4hPElRA/300

##### 昆仑万维 投稿  
量子位 | 公众号 QbitAI

**Q*项目公开发布** ，可让小模型达到参数量比其大数十倍、甚至上百倍模型的推理能力。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYG1eFjHou3gK5tbUU6gVnib1m9FJCk9mbaDrzNTdAxRkha5AicdopGyJg/640?wx_fmt=png&from=appmsg)

自去年11月伴随着OpenAI内讧，其神秘Q*项目被爆出后，业内对OpenAI Q*的讨论和猜测就没停过，而OpenAI这边一直避而不谈。

在当时，一些人就从名字猜测Q*可能与Q-Learning有关，例如Meta科学家田渊栋提出Q*可能是Q-learning和A*的结合：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYJ8iaibx2Wn7iaJqeerugWhsdlgylqokTNKN7YZ0JmL9TgK67Iq6BzS7gg/640?wx_fmt=png&from=appmsg)

而现在，一项名为Q*的项目突然公开发布，而且真的**和****Q-Learning、A*有关** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRY0rghBMcxXfupEibsaav1nUMu7MnxuLc03E0O5TMrAicjJibe0tOWicWZjg/640?wx_fmt=png&from=appmsg)

不过，研究团队并非OpenAI，更不是DeepMind（相传，OpenAI的Q*项目前身是GPT-Zero，由Ilya
Sutskever发起，名字致敬了DeepMind的Alpha-Zero）。

而是来自国内**昆仑万维颜水成团队与新加坡南洋理工大学** 的一项新工作。

团队表示，希望Q*算法能够打破OpenAI的封锁，提升现有开源模型的推理能力。实验中，Q*算法的表现也很给力：

  * 在GSM8K数据集上，Q*帮助Llama-2-7b提升至**80.8%** 的准确率，超越了ChatGPT；

  * 在MATH数据集上，Q*帮助DeepSeek-Math-7b提升至**55.4%** 的准确率，超越了Gemini Ultra；

  * 在MBPP数据集上，Q*帮助CodeQwen1.5-7b-Chat提升至**77.0%** 的准确率，缩小了与GPT-4的编程水平差距。

网友看到这项工作后一时间炸开了锅，研究命名无疑成为了讨论的一大焦点，网友的评论却很一致：

> 这就是Q*。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYKzWo1WFngbNZjIhdLBfq0kQgGOBYWwDjQYibWjcIQQo4HsEE2F7aticg/640?wx_fmt=png&from=appmsg)

虽然不是那个Q*，但却是真正的Q*：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYozXI2v1w3KFHKrxMoVU4IxEbNdZY7EWJFplykBwSKoHCLhCt6UGwCQ/640?wx_fmt=png&from=appmsg)

谁让OpenAI至今不发布任何名为Q*的工作：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYlxYQgn0MhtMVFErYrft8g6zM91agDTKmalicVdoA1mvN4XTvTpbuywQ/640?wx_fmt=png&from=appmsg)

抛开命名，从研究本身来讲，有网友看过论文后感叹这项研究真不简单：

> 越思考，就越觉得Q*的这个方法是正确的。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYQXFib8CvBtQzwlNtRnDHPh1wUU5aNX98lhNo2FkWic2OXhdQGUSjyHuQ/640?wx_fmt=png&from=appmsg)

甚至有网友认为有种AGI的感觉：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYvdWicAiajQ0CZuLkssB30Alc3ravHKELJdoJTic90A3Z92EUTS8G4z7cA/640?wx_fmt=png&from=appmsg)

那么，Q*到底长啥样？

## 复杂推理任务全盘规划

总的来说，在《**Q*: Improving Multi-step Reasoning for LLMs with Deliberative
Planning** 》这项工作中，研究人员首先将大语言模型的**推理轨迹分解为若干个状态**
，对于每一个状态，参考DeepCubeA中的设计，通过将定义Path
Cost的![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYe5xk7F3rqnc2nrLibFxq3KOgQvKqHsHhyxTuwXwV8gSf0TiaHyqJeMicQ/640?wx_fmt=png&from=appmsg)函数和定义Accumulated
Reward的![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYYlpwccVAqvq9JtHxf8CBoCm5qicjeOBdT57rDMFXMhW0XGN9rib6ek3Q/640?wx_fmt=png&from=appmsg)集成到同一个![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYLVD376J97ncgjEhSFXMVibmkSia0cPFAkJGzQz5via6AP2zjE75uSCscA/640?wx_fmt=png&from=appmsg)函数内，实现了对历史状态收益和未来期望收益的综合考虑。

最后利用**A*搜索算法** 对状态进行最佳优先搜索，实现了对复杂推理任务的全盘规划，从而提升开源模型在推理任务上的性能。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRY4BnkyxDnooz50zRK0vw9Hb9gLgeTQACtKBeOOPUbCjCr8pfA8ciabbQ/640?wx_fmt=png&from=appmsg)

其中![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYe5xk7F3rqnc2nrLibFxq3KOgQvKqHsHhyxTuwXwV8gSf0TiaHyqJeMicQ/640?wx_fmt=png&from=appmsg)表示当前轨迹中的多个历史状态，即![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRY69Zz727H5ke8Ah0Re0xxUicd2m1P4M1iawKCEiblJbWeibwJ6u4MPO7rOg/640?wx_fmt=png&from=appmsg)，的聚合收益。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYqjJdKFzdwL55mlgEXxRaEPGLicn3MN0PooQDjAlOJiaAibMQzyDWT31fA/640?wx_fmt=png&from=appmsg)

具体![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYe5xk7F3rqnc2nrLibFxq3KOgQvKqHsHhyxTuwXwV8gSf0TiaHyqJeMicQ/640?wx_fmt=png&from=appmsg)的函数形式可以通过人为定义，例如判断当前代码是否符合语法规则等，或者通过构建process
reward
model进行监督学习得到；![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYe5xk7F3rqnc2nrLibFxq3KOgQvKqHsHhyxTuwXwV8gSf0TiaHyqJeMicQ/640?wx_fmt=png&from=appmsg)中的聚合方式可以为求和、最大值、最小值等。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYfmEiciaIfxO12pvwUc4FO30Dem2icZuOaPlDwwruv5zd0gicR6LmOibL3Rg/640?wx_fmt=png&from=appmsg)

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYgB1zHmZumXb4otYxqjX5XJ96oQBTv2bhm5nBWwbET021ZKib85FJUNw/640?wx_fmt=png&from=appmsg)

为了获得状态-
动作对![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYsbs32rUhkBte6f4lRhbmiaM99fy8ib3SHGqtDyWlLACFxy16Z4JuEfNQ/640?wx_fmt=png&from=appmsg)的最优Q值以实现规划，研究人员在当前LLM策略生成的数据上通过监督学习的方式训练了一个**代理Q值模型**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYVZQr0uVoMiaH9W81ttbSiclKkeRNffYibQvQ0Angc4k7P2zBkYibqJic81Q/640?wx_fmt=png&from=appmsg)
。

训练过程中的真实标签![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYoNhLviaKf222hSUnAyibxsbkcPeibX0DRiaCnnjviaCb7sWrunJ97IMibS3A/640?wx_fmt=png&from=appmsg)可以由三种不同的方式得到，包括离线强化学习，蒙塔卡罗采样估计和利用更强大的语言模型补全。

随后，研究团队通过一系列实验，证实了Q*框架可以显著提升LLM的推理能力。

如开头所述，在GSM8K数据集上，Q*帮助Llama-2-7b提升至80.8%的准确率，超越了ChatGPT；在MATH数据集上，Q*帮助DeepSeek-
Math-7b提升至55.4%的准确率，超越了Gemini Ultra;
在MBPP数据集上，Q*帮助CodeQwen1.5-7b-Chat提升至77.0%的准确率，缩小了与GPT-4的编程水平差距。

具体结果见下图：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYrSeIibC0IQ67O9FeVyib3BXavrg6eiaicPKPem4laB1LBVZIUtDb8maljQ/640?wx_fmt=png&from=appmsg)  
![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYJtnPhGcPTtemKV6OMckoR6bwrIla7LxQTcic0JNviaP49Jq5b9IzfLEw/640?wx_fmt=png&from=appmsg)  
![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBibYu0RAia66GiajerMs39FRYiatibUaqvCFGRtKZ7beKe8OCUviaBdicvfs0ic9ggV8lQRIFOBYYmxbOcXw/640?wx_fmt=png&from=appmsg)

Q*能够帮助参数量仅为7b的小模型达到参数量比其大数十倍甚至百倍模型的推理能力，大幅提升模型的性能，并显著降低了计算资源的需求。

不过，昆仑万维团队也表示，Q*的研究尚在初级阶段，算法在各个环节还有进一步的改进空间。

> 未来，会继续深入此项研究，不断提升国产开源模型推理能力，打破OpenAI闭源封锁，为AI前沿技术发展带来全新可能。

更多细节，感兴趣的家人们可以查看原论文～

论文链接：https://arxiv.org/abs/2406.14283

— **完** —

  

投稿请发邮件到：

**ai@qbitai.com**

标题注明【投稿】，告诉我们：

你是谁，从哪来，投稿内容‍

附上论文/项目主页链接，以及联系方式哦

我们会（尽量）及时回复你

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

