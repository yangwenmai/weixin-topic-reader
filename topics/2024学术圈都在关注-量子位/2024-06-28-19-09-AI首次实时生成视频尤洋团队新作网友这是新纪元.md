# AI首次实时生成视频！尤洋团队新作，网友：这是新纪元

文章作者: 量子位
发布时间: 2024-06-28 19:09
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247736139&idx=3&sn=962071fc6f7bea869a0281e8149946d6&chksm=e8dfec39dfa8652f5f9062b516ec2316a868645ea6657c10bd3f566e00a4c6b90cd537dfb723#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNaC2v2G8BGv5HG7oBbhaWa8FnnNRiaa3iasiabKDru0asFZTMibe1YdGdoDQ/300

##### 一水 发自 凹非寺  
量子位 | 公众号 QbitAI

**尤洋团队****新作** ，首个基于DiT的实时视频生成方法来了！

先来直观感受一下效果（右侧为新方法）：

这是团队在Open-Sora上，使用**5个4s（192帧）480p** 分辨率视频进行的测试。

新方法名为**Pyramid Attention Broadcast（PAB）** ，由新加坡国立大学尤洋以及3位学生推出。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNaUNvLkPCuqMc9H2qR8gWjaHwibc1Uc9dfgic5gpNtDDQfy4151X16rjPA/640?wx_fmt=png&from=appmsg)

具体来说，PAB通过减少冗余注意力计算，可实现高达**21.6FPS** 和**10.6倍加速** ，并且**不会牺牲**
基于DiT的流行视频生成模型（包括Open-Sora、Open-Sora-Plan和Latte）的质量。

作为一种**免训练** 方法，PAB可为将来任何基于DiT的视频生成模型提供实时功能。

看完效果对比，网友们纷纷惊叹：

> 这将是新纪元。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNaFIetBibgUppfr1IuzoehTWKAJUfv2KGqpec7c8x56IeROvQ7sm8p2tg/640?wx_fmt=png&from=appmsg)

也引来了众多专业人士的转发和点评，如MIT博士Yilun Du表示：

> 是一个展示了如何将视频生成加速到实时速度的酷炫工作！可能会为视频策略和模拟的现实世界用例开辟新的领域。

![](https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNaR9g9v5ibek85fHwxtv0iasexMfOG3XrD8wOBavbTenvBIDWoL71S7mGg/640?wx_fmt=jpeg&from=appmsg)

那么，新方法具体如何破解实时生成视频这个难题的呢？

## 减少冗余注意力计算

一开始，团队比较了当前扩散步骤与前一步骤的**注意力输出差异** 。

这些差异通过**均方误差（MSE）** 进行量化，并对每个扩散步骤的所有层进行平均。

团队捕捉到**两个关键信息** ：

  * 随着时间推移，注意力差异遵循**U形模式** ，中间70%差异较小

  * 注意力差异的**排序** 为：空间>时间>交叉

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNaHibAACkBArC53A1whx0pL9dd7dhZVfJmmdykdibMP1sNYFDFg2k2ZjicA/640?wx_fmt=png&from=appmsg)

具体而言，**不同时间步骤的注意力差异呈现出U形模式** ，在第一步和最后一步的15%步骤中发生显著变化，而中间70%的步骤非常稳定，差异很小。

其次，**在稳定的中间部分** ，不同类型的注意力表现出差异：**空间注意力变化最大** ，涉及高频元素，如边缘和纹理；**时间注意力显示出**
与视频中的运动和动态相关的中频变化；**跨模态注意力** 最为稳定，它将文本与视频内容联系起来，类似于反映文本语义的低频信号。

对此，团队正式提出用PAB来**减少不必要的注意力计算** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNakBlWzZDibicVvl2iaicibJib83m9L7EKEq1nxafvfNtRd5zCqfHFblrCJ9rw/640?wx_fmt=png&from=appmsg)

PAB通过**根据每种注意力的差异将注意力输出到不同的后续步骤** ，从而节省计算量。

**举个例子**
，就像广播电台把一个信号发送给多个听众一样，如果某个步骤的注意力结果在接下来的几个步骤中仍然适用，就不需要重新计算，而是直接使用之前的结果。

团队发现，即使没有后期训练，这种简单策略也能实现**高达35%的加速** ，并且质量损失可以忽略不计。

为了进一步增强PAB，团队**基于动态序列并行（DSP）** 改进了序列并行。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNapJicTXqr7ydTXWRkF5mXuZibByOf05vE8j7Mt0EmDj5OjJ1CLAz2PszA/640?wx_fmt=png&from=appmsg)

序列并行通过**在多个GPU上分割视频** 以降低延迟，但DSP带来的时间注意力需**两次全对全通信** ，导致高通信开销。

而PAB由于时间注意力不再需要被计算，使这些通信开销减少了**50%以上** ，从而优化了实时视频生成的分布式推理效率。

**借助并行功能** ，PAB可实现高达**21.6FPS** 和**10.6倍加速** ，并且**不会牺牲**
基于DiT的流行视频生成模型（包括Open-Sora、Open-Sora-Plan和Latte）的质量。

![](https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNaRZNcZsu66BW3WiaLWIRN4lAycC6pS91F4UicWpWwj40XT9LwibZCkdFnA/640?wx_fmt=jpeg&from=appmsg)

展开来说，团队测量了PAB在**8个英伟达H100 GPU上** 为不同模型生成单个视频的总延迟。

**使用单个GPU时** ，PAB实现了1.26倍到1.32倍的速度提升，这一提升在不同调度器中保持稳定。

**扩展到多个GPU时** ，PAB实现了高达10.6倍的速度提升，且这一提升几乎**与GPU数量成线性关系** 。

## 背后团队

简单介绍一下提出PAB的团队成员，总共有4位。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNaXAsyc4P5HmXPDHibk6rA9gQTxF1EQWicPGgWufGKxw8dI7fFHcuI4NFg/640?wx_fmt=png&from=appmsg)

**尤洋教授** 想必大家都比较熟悉了，清华计算机系硕士，UC伯克利博士，毕业后加入新加坡国立大学计算机系，担任校长青年教授 （Presidential
Young Professor）。

2021年7月，在北京中关村创办了**“潞晨科技”** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNa3jE9bWbHmUnfXRRCDoSYXjFIxhyEwILrkNExOqf9sE7OS60MY0LmRg/640?wx_fmt=png&from=appmsg)

作者之一**Xuanlei Zhao（赵轩磊）** ，华科大计算机科学与电子信息专业工程学士，硕博均在新国立（目前为博一），**导师为尤洋**
，研究方向包括但不限于算法、数据结构、计算机网络、信号处理、通信系统等方面。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNa71AI34p3bMWic4dicDIx39FkOMdKXZWOS1vc8bm4JicHft7krsruCeuNA/640?wx_fmt=png&from=appmsg)

作者之一**Kai Wang（王锴）** ，新国立HPC-AI实验室博士生，导师为**尤洋**
，本科就读于北师大珠海分校电气工程与自动化系，硕士就读于中科院深圳先进技术研究院(MMLAB-
SIAT)，研究重点是以数据为中心的人工智能和高效机器学习。他和尤洋教授共同指导了这个项目。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNaicz5K1cgcvtHHDicyMStQRBGJ4CwGheth6DrOhNUsvyzAiaic2On0icN1Cw/640?wx_fmt=png&from=appmsg)

最后一位**Xiaolong Jin（金小龙）** ，本科就读于中国科学技术大学少年班学院，目前是普渡大学在读博士生。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCu5GKXQVefzA3m6LOFVeNals3GFibNjUP86Y6BsRib3jwmr4hPMGNez9dErmRCLCpea3TnfMHyovzQ/640?wx_fmt=png&from=appmsg)

目前相关研究**已公开** ，感兴趣可以进一步了解。

项目主页：  
https://oahzxl.github.io/PAB/  
开源地址：  
https://github.com/NUS-HPC-AI-Lab/OpenDiT  
参考链接：  
[1]https://x.com/oahzxl/status/1805939975420330298  
[2]https://kaiwang960112.github.io/#work_experience  
[3]https://oahzxl.github.io/  
[4]https://x.com/YangYou1991  
[5]https://www.linkedin.com/in/xiaolong-jin-514651284/

— **完** —

**量子位年度AI主题策划** 正在征集中！

欢迎投稿专题 **一千零一个AI应****用** ，**365行AI落地方案**

或与我们分享你在**寻找的AI产品** ，或发现的**AI新动向**

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&from=appmsg)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg)

