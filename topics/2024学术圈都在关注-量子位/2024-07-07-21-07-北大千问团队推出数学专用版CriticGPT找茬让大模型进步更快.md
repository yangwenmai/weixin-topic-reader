# 北大千问团队推出数学专用版CriticGPT，“找茬”让大模型进步更快

文章作者: 量子位
发布时间: 2024-07-07 21:07
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247737911&idx=3&sn=fd2f4c83f06666a1a1f3cd4883bd7491&chksm=e8df9545dfa81c53d6ccbc22e881b8505c7cf52acf88a564f0f3585c8949781dfceb93e21a82#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtATxwIsb9Sj7SqvUibjrcOhGRJaWfu08gsd19TZnnr5aeLImea397Mxf2adgS1GLXNWgj8cLb5Noug/300

##### 蔡泽凡 投稿  
量子位 | 公众号 QbitAI

批评不仅能让人进步，也能让大模型的能力提升。

OpenAI就用这个思路造了个“找茬模型”CriticGPT。非常巧合的是，就在CriticGPT放出的前几天，北大联合千问等团队以类似的思路设计出了“数学专用版”CriticGPT。

在无需训练的设置下，验证器能够在推理时辅助模型在GSM8K上的准确率从86.6%提升到88.2%。

在GSM8K数据集上，它可以让模型的准确率从86.6%提升到88.2%。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtATxwIsb9Sj7SqvUibjrcOhGeygtKkwaEu8LGlPuticaPeRFKoWe1Ce6y9cppnibHTVJakq4bpWIEOgA/640?wx_fmt=png&from=appmsg)

CriticGPT的核心思路是在代码中故意设置bug并进行详细标注，然后用得到的数据训练出会debug的模型。

北大团队发现，这种方法不仅在代码当中有用，**也能帮助语言模型解决数学问题** 。

于是团队利用相似的思路，把代码换成数学问题，推出了“数学版CriticGPT”——**Math-Minos** 。

## 用GPT4逐步提出修正意见

在数学推理领域，**验证解决方案的正确性** ，是确保推理质量的关键步骤。

然而，现有的数学验证器大多依赖于二元分类标签进行训练，这种方式在提供正确或错误原因的解释上存在明显不足，无法给验证器提供足够充分的监督信号来训练。

Math-Minos则克服了这一局限，提供了更深入的解释，极大地丰富了验证器的训练信息。

它引入了**逐步的自然语言反馈** 作为理由标签，不仅指出了解决方案的正误，还能逐步分析出错误的原因。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtATxwIsb9Sj7SqvUibjrcOhGgkr60fHTFD0TQqGV0jicWRttPL9wlRw9BQ1OiaamJP7pjlO8gXqQQL8A/640?wx_fmt=png&from=appmsg)

在自然语言反馈的获取上，研究团队一开始使用GPT-4生成训练数据，但通过实验发现，即使是GPT-4，在逐步评价数学推理任务时也会出现一定比例的错误。

为了一定程度避免这个问题，研究人员通过在提示中引入**步骤级别的二元分类标签** ，简化了GPT-4的任务，使得GPT-4能够更准确地生成评估。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtATxwIsb9Sj7SqvUibjrcOhGx2sntRazIplIKtOYCpOsvh59dnIWp8zABL6pVSicicLFD0xqGqwJL6Zg/640?wx_fmt=png&from=appmsg)

首先，通过监督式微调，使用自然语言反馈作为训练数据，有效提升了模型的评估能力。

其次，通过标准的ORM（Outcome Reward Model，输出奖励模型）和PRM（Process Reward
Model，过程奖励模型）训练，实现了高效的推理，这种做法有两个好处。

一是通过两阶段训练，可以将二分类数据和监督微调数据解耦。

由于监督信号的稀疏性，训练二分类的数据往往远多于监督微调的数据，而研究发现，**仅需要少量的监督微调数据，就可以很大程度提升模型的评估能力** 。

另一方面，在验证器进行验证时，不需要显示地生成自然语言反馈，让推理过程更高效。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtATxwIsb9Sj7SqvUibjrcOhGTz5NqSzP1KQgb4SxWC9Uq5YwOiaHQ260x5xibGiaFfV9u4GxhSHRkKRQQ/640?wx_fmt=png&from=appmsg)

## ORM任务表现明显提升

总得来看，研究人员在训练阶段添加了30K的自然语言反馈数据，为Mistral-7B验证器带来了数学能力的提升，在Best-of-256的实验设置下：

在ORM的设置下，MATH-
Minos将Mistral-7B的准确率在GSM8K数据集从86.2%提升到87.3%，在MATH数据集从35.9%提升到37.4%。

在PRM的设置下，MATH-
Minos将Mistral-7B的准确率在GSM8K数据集从87.1%提升到87.6%，在MATH数据集从36.7%提升到37.8%。

在与Self-Consistency结合的设置下，MATH-
Minos将Mistral-7B的准确率在GSM8K数据集从87.1%提升到88.2%，在MATH数据集从37.8%提升到38.6%。

在ORM和PRM任务设置中，Math-Minos均展现出了优越的性能，特别是在ORM设置中，其改进更为显著。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtATxwIsb9Sj7SqvUibjrcOhGlMQd0kicic5ooQR6QhiagPV56aUpShCnzuH47DEx1zsCVRaGgSM0Nt51A/640?wx_fmt=png&from=appmsg)

另外，研究团队还对生成器在步骤级别产生的错误进行了深入分析，将其归类为五种类型——无关错误、累积错误、计算错误、逻辑错误和其他错误。

分析结果表明，在多步骤推理中，步骤错误的可能原因有很多种，而且模型在这些错误类型中都有可能出错，这进一步强调了引入自然语言反馈来指导模型学习的重要性。

实验发现，在两个数据集上，累积错误（即一个步骤的错误很可能直接导致所有后续步骤的错误）在所有错误类型中占到的比例最高。

不同数据集上的错误分布也有不同的特点，在相对简单的GSM8K上，计算错误更多；在更困难的MATH数据集上，逻辑错误更多。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtATxwIsb9Sj7SqvUibjrcOhGnl4ydTPia7KaclyXKhiccIAwQqQkQSG3HiauFODoic1gVJ2AS6JktV0Jcg/640?wx_fmt=png&from=appmsg)

通过构建元评估集，研究团队评估了验证器在没有生成器影响下，准确判断最终答案的能力。

结果显示，Math-Minos在训练过程中的元评估一致优于传统的ORM，并且展现出更快的收敛速度和更精准的判断能力。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtATxwIsb9Sj7SqvUibjrcOhGfxgicmbB7vYuFYqsMINUNzD1jYF9xsI1Apiah9iaAyoDBUfBkrjA2jEkw/640?wx_fmt=png&from=appmsg)

同时实验结果也表明，Math-Minos具有很强的Scale Up的潜力。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtATxwIsb9Sj7SqvUibjrcOhGtqzE81icBE9qZfChvMe8reHZJ7tib4QiaPUpgupS9PEqSjFiajgbFpfwcw/640?wx_fmt=png&from=appmsg)

总之，Math-Minos的开发不仅提升了数学验证器的性能，更为自然语言处理领域提供了一种新的训练范式。

研究团队希望这项工作能够启发未来研究，探索自然语言反馈与分类式验证器的潜在整合，推动大型语言模型在复杂推理任务上的能力。

论文地址：  
https://arxiv.org/abs/2406.14024  
GitHub：  
https://github.com/KbsdJames/MATH-Minos

— **完** —

  

投稿请发邮件到：

**ai@qbitai.com**

标题注明【投稿】，告诉我们：

你是谁，从哪来，投稿内容‍

附上论文/项目主页链接，以及联系方式哦

我们会（尽量）及时回复你

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

