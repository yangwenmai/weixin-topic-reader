# DeepMind新方法：训练时间减少13倍，算力降低90%

文章作者: 量子位
发布时间: 2024-07-10 12:13
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247738370&idx=4&sn=6d4735e6b0f5785e7dedab386d40f94a&chksm=e8df9370dfa81a66711cea525062e62e43f084921caaf8bcc5ab8cd892f12bf30958ae059d25#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRVtuIiaibnWCYeHlDcScXXRicSumE0xnrougj2bJu69OQAoKv9ibjGtiaCOw/300

##### 一水 发自 凹非寺  
量子位 | 公众号 QbitAI

大幅节省算力资源，又又又有新解了！！

DeepMind团队提出了一种新的**数据筛选方法** JEST——

将AI训练时间减少13倍，并将算力需求降低90%。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRYAIzu2NhjTAiaWjBXJ4j7m04mkashcTtje8lm6G355hT0dszWH1X0bg/640?wx_fmt=png&from=appmsg)

**简单来说** ，JEST是一种用于**联合选择最佳数据批次** 进行训练的方法。

它就像一个智能的图书管理员，在一大堆书（数据）中挑选出最适合当前读者（模型）阅读的几本书**（数据批次）** 。

这样做可以让读者更快地学到知识（训练模型），还能节省时间（减少迭代次数）和精力（减少计算量）。

**研究显示** ，JEST大幅加速了大规模多模态预训练，与之前的最先进水平**（SigLIP）** 相比，迭代次数和浮点运算次数**减少了10倍** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRz6YibeO9ibH8SFFyGSVITfNibyonApkddQ5icHYW9HicrsvkM773xkhs4wA/640?wx_fmt=png&from=appmsg)

对于上述结果，有网友惊呼：

> 新研究将成为AI训练的游戏规则改变者！

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKR5E6kLmD2POC9oX5n7sSXlXnXv2EW8KI7Ss9jVyArH0OutssP7oLbZA/640?wx_fmt=png&from=appmsg)

还有人点出了**关键** ：

> 对于担心人工智能需求过高的电网来说，这可能是个极好的消息！

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKR453x2rNAyicke3DtnYLcp04lYfxoIHJchHVt4ibesibEGrrgbhU0720yQ/640?wx_fmt=png&from=appmsg)

那么，新方法究竟是如何运作的？接下来一起看团队成员相关揭秘。

## 揭秘新方法JEST

首先，**现有的** 大规模预训练数据筛选方法速度慢、成本高，并且没有考虑到批次组成或训练过程中数据相关性的变化，这**限制了多模态学习中的效率提升** 。

因此，DeepMind团队研究了**联合选择数据批次** 而非单个样本是否能够**加速多模态学习** 。

研究得出了**3个结论** ：

  * 挑选好的数据批次比单独挑选数据点更为有效

  * 在线模型近似可用于更高效地过滤数据

  * 可以引导小型高质量数据集以利用更大的非精选数据集

基于上述，JEST能够在**仅使用10%的FLOP预算** 的情况下超越之前的最先进水平。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRMDKicPjavV4YWC1GcwlAnWmMibzbI53S7cNzCXwtLnH1R2vP1Ad1TdxA/640?wx_fmt=png&from=appmsg)

这一结果是如何实现的呢？

据团队介绍，他们**在之前的工作中** 已展示了，对**最好的50%数据** 进行训练如何显著提高FLOP效率。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRF5GibTblqqEhM03M9BeHawDGPzVEnxAh6BlBTkFXj2pXYs9qCN8FxRQ/640?wx_fmt=png&from=appmsg)

而现在，新研究证明**过滤更多数据（高达90%）** 可以产生更好的性能。

这里有**三个关键** ：

  * 选择好的批次 > 选择稍微好的数据点

  * 调整默认的ADAM超参数

  * 非常高质量（但很小）的参考数据集

具体而言，JEST是从一个更大的候选数据集中**选择最佳的训练数据批次。**

在**数据选择标准** 上，JEST借鉴了之前关于RHO损失的研究，并结合了学习模型和预训练参考模型的损失来**评估数据点的可学习性**
。JEST选择那些**对于预训练模型来说较容易** ，但**对于当前学习模型来说较难** 的数据点，以此提高训练效率和效果。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRWCapjPicBxRf8DzDOpbUw5rR5udLluiaFkyUJ3hjIe9spmiak2AkZxMVQ/640?wx_fmt=png&from=appmsg)

成员Nikhil进一步解释了**多模态对比学习的过程** ，即通过最大化文本和图像嵌入的对齐性，同时最小化不相关数据之间的对齐性，来提高模型的性能。

利用这一点，团队采用一种**基于阻塞吉布斯采样** 的迭代方法，逐步构建批次，每次迭代中根据条件可学习性评分选择新的样本子集。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRiazUIz0Xs5nxV3XutWGJv8O8k6teBUA3ia0Dj8VxOuT1Ue7HrRhT6qaA/640?wx_fmt=png&from=appmsg)

**与单独选择数据相比，** 新方法在过滤更多数据时持续改进。包括使用仅基于预训练的参考模型来评分数据也是如此，即**CLIPScore**
，这是离线基础数据集筛选的流行基线。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRlZOiaxoic9Enk0LkvLfKCkgCt1FdqFUia5DibKoQpfxibE47xJrpePdvkUw/640?wx_fmt=png&from=appmsg)

不过，**过滤更多数据会增加浮点运算次数** （FLOPs），因为评分需要学习者和参考模型进行推理传递。

对此，团队在数据集中缓存了预训练的参考模型分数，他们采用了**FlexiViT架构** 进行低分辨率评分，并在多种分辨率下进行了训练。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRLBR3uw6DehK1g97ic5RYPwXX8IX8eWnEa6zayI2VapYJTVkAC2g28BA/640?wx_fmt=png&from=appmsg)

这一研究证明了：

> 多分辨率训练对于协调评分和学习者模型至关重要

另外，研究强调了**使用高质量的精选数据集** 来训练参考模型的重要性，这有助于优化大规模预训练的数据分布，从而提升模型的泛化能力。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRAnkQRIKrNX9TGduhOLicTcvNr5UVcaTTOvMgJvqkmFRg6JOhHWz11eg/640?wx_fmt=png&from=appmsg)

总而言之，相关变体**JEST++** 和**FlexiJEST++** 的性能显著优于许多其他先前的SOTA模型，同时使用的计算量更少。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRhvfSjR6phswrUrweGAW0ZicslPvoh5swxdFMicK6pwCB35icEY6GrfS8g/640?wx_fmt=png&from=appmsg)

针对大家可能的疑问：

> 为什么不只在用于参考模型的精选数据集上进行训练呢？

团队预先解释，相关结果表明精选的参考模型是专家型模型（在某些任务上表现良好）。JEST++利用专家型参考模型，**将其转化为通用模型**
，在所有基准测试中都取得了改进。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRm0bxuDBKWofUoP7mQXEmnKOBxsKPfiaEhmEt4U1ws2ctmOFdX89danA/640?wx_fmt=png&from=appmsg)

最后，研究发现JEST++最终可以通过消除对预训练数据集的任何筛选需求来简化数据管理流程。

通过使用预训练参考模型，在未经筛选（原始）的网络规模数据上进行训练，**性能几乎没有下降** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRyLYWricfTpSH1viaBc0E1RTJZHZIAIHV5mruCPcXNMY5lQejkPB2UZpw/640?wx_fmt=png&from=appmsg)

## 来自DeepMind

上述研究由来自DeepMind的**4位成员** 共同完成。

**Talfan Evans**
，至今在DeepMind工作3年多，是机器学习团队的一名研究科学家，近期研究方向是大规模模型数据训练和任务对齐。曾就读于伦敦帝国理工学院戴森机器人实验室（空间/视觉感知系统中的实时分布式推理）。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRfEzm3VWloQhZ9XGkbicfMJa0ia1XjFVXcen7utpA8yWWN09ep4YKD2jg/640?wx_fmt=png&from=appmsg)

高级研究员**Olivier Hénaff** ，至今在DeepMind工作5年多，专注于了解**生物和人工智能的基本原理**
。在DeepMind一直研究自监督算法，近期对视觉表征如何构建我们的记忆、实现灵活的感知推理和长视频理解感兴趣。曾就读于美国纽约大学神经科学中心博士和法国巴黎综合理工学院硕士（数学）。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRsepKXLFtwsQ2qiaibCuw2zMdt5QyH1vWOXnAxqhOUSJdE7w5FBttXv4w/640?wx_fmt=png&from=appmsg)

研究科学家**Nikhil Parthasarathy**
，至今在DeepMind工作5年多，负责建立视觉感知模型，研究方向涵盖表示学习、计算机视觉、计算神经科学和视觉感知。曾就读于纽约大学博士，斯坦福大学本硕。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKR328ZMBKPVs296RAqdibDpuLjv2L3aibPqRajcje7b5VicvtjaeoPHUvAg/640?wx_fmt=png&from=appmsg)

研究工程师**Hamza Merzic**
，2018年加入DeepMind，研究领域包括主动学习、视觉想象、表征学习、强化学习、深度学习和机器人技术。他是瑞士联邦理工学院的硕士生，并在2023年至今期间担任博士生导师。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBSPkACebJwxOcm4RYhggKRjIQvCSAaFBMh8Oiag56OuTfc7zefbSUnwomBkiaciblc2oPkrYVhRjOQg/640?wx_fmt=png&from=appmsg)

目前相关论文已公开，感兴趣可以进一步了解。

论文：  
https://arxiv.org/abs/2406.17711  
参考链接：  
[1]https://x.com/rohanpaul_ai/status/1809792337293566209  
[2]https://x.com/olivierhenaff/status/1805995802352910557  
[3]https://x.com/nikparth1/status/1806001404294672775  
[4]https://x.com/talfanevans/status/1805996146826817726

— **完** —

**量子位年度AI主题策划** 正在征集中！

欢迎投稿专题 **一千零一个AI应****用** ，**365行AI落地方案**

或与我们分享你在**寻找的AI产品** ，或发现的**AI新动向**

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&from=appmsg)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg)

