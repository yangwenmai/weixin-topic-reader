# 曝Bengio新动向：世界模型+数学证明，确保AI系统正常运作

文章作者: 量子位
发布时间: 2024-08-08 12:51
发布地: 未知地区
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247742974&idx=4&sn=74f265ba3fe049dc66463fd89d40dca3&chksm=e8df828cdfa80b9ac6e4552917e85079ff54680b6c099b56762fc09342f9c9bf55cdcc0fc687#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyupbjATA85t5L38kszuatAicMU6v3pKLtRF3clQibA8sxDoGYkibdfvJRQg/300

##### 西风 发自 凹非寺  
量子位 | 公众号 QbitAI

深度学习三巨头之一Yoshua Bengio的下一步动向公开了，关于AI安全——

加入了一个名为**Safeguarded AI** （受保护的人工智能）的项目，担任科学总监。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyuUNEsF46QINTjk0nRudicm4jBNCpF5AJv8H98bnLkXARpXUPFEKnV9dw/640?wx_fmt=png&from=appmsg)

据介绍，Safeguarded AI旨在：

**通过结合科学的世界模型和数学证明，构建一个负责理解和降低其它AI Agent风险的AI系统。**

主打的就是一个量化安全保障。

该项目由英国高级研究与发明局（ARIA）提供支持，据说未来ARIA将投入共5900万英镑（约合RMB5.37亿）。

Bengio表示：

> 如果你计划部署某种技术，鉴于AI行为异常或误用可能带来非常严重的后果，你需要提出充分的理由，最好能提供强有力的数学保证，确保你的AI系统将正常运作。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyutuYy8fqmBN6XeVSr9Sheh7GQT60RicgQHkQFapWTE93yZ1maNPGW0zw/640?wx_fmt=png&from=appmsg)

## “受保护的AI”

Safeguarded AI项目被划分为三个技术领域，每个领域都有特定的目标和预算：

  * **支架** （Scaffolding），构建一个可扩展、可互操作的语言和平台，用于维护现实世界模型/规范并检查证明文件。

  * **机器学习** （Machine Learning），使用前沿AI帮助领域专家构建一流的复杂现实世界动力学的数学模型，并利用前沿AI训练**自主系统** 。

  * **应用** （Applications），在关键的网络-物理操作环境中部署一个由“把关AI”保护的自主AI系统，通过量化的安全保障**释放重要的经济价值** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyuyRs5yPcEWSMdrMswZEjHk5AAehtRY55IohiacQWC19HN4pTOO6vaUjg/640?wx_fmt=png&from=appmsg)

官方表示，Bengio加入后将**特别关注TA3和TA2** ，在整个计划中提供科学战略建议。

ARIA还计划投入1800万英镑（约合RMB1.64亿）成立一个非营利组织，领导TA2的研发工作。

Safeguarded AI项目总监是前Twitter高级软件工程师**David “davidad” Dalrympl****e**
，去年9月份加入ARIA。

对于Bengio的到来，Dalrymple还在X（原推特）上传了俩人的合照：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyu1Ol7E1icbnevHujdJHe3S5yBqfMftQzMWib6DAuH8rVDS1BYNjDbdLHQ/640?wx_fmt=png&from=appmsg)

关于“构建一个负责理解和降低其它AI Agent风险的AI系统”的具体方法，David “davidad” Dalrymple、Yoshua
Bengio等人写了份文件。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyuJEyEINqgjJ8UrFQb5IbHyu7WoGibyWqLy0RibpdbibHv9cu20CgDvVaPg/640?wx_fmt=png&from=appmsg)

其中提出了一套称为“**Guaranteed Safe AI** （保证安全的AI）”的模式，主要是通过三个核心相互作用量化AI系统的安全保障：

  * **世界模型** ，提供数学描述，阐述AI系统如何影响外部世界，并妥善处理贝叶斯和奈特不确定性

  * **安全规范** ，定义哪些效果是可接受的数学描述

  * **验证器** ，提供证明AI符合安全规范的可审计证书

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyusSgu9TajNIpRqux3UwonwZCYwicRicibxLWhY10NBa01vzX720VIgNnicw/640?wx_fmt=png&from=appmsg)

他们还为创建世界模型的策略，划分了L0-L5安全等级：

  * Level 0：没有明确的世界模型。关于世界的假设隐含在AI系统的训练数据和实现细节中。

  * Level 1：使用经过训练的黑盒世界模拟器作为世界模型。

  * Level 2：使用机器学习生成的概率因果模型的生成模型，可以通过检查它是否为特定的人类制作的模型（例如科学文献中提出的模型）分配足够的可信度来进行测试。

  * Level 3：使用（一个或多个）概率因果模型（或它们的分布），可能在机器学习的帮助下生成，这些模型经过人类领域专家的全面审核。

  * Level 4：使用关于真实世界现象的世界模型，这些模型被正式验证为基本物理定律的合理抽象。

  * Level 5：不依赖具体的世界模型，而是使用覆盖所有可能世界的全局性安全规范。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyub1jt9MmdmypnsWvicXKTtL6bHc85oB3iaiaPzWfdYxhUm2AIFXJDcDFpQ/640?wx_fmt=png&from=appmsg)

## “AI风险”备受学术圈关注

“AI风险”一直是行业大佬们关注的焦点话题之一。

Hinton离职谷歌，就是为了自由地讨论AI风险问题。

之前，更是有吴恩达、Hinton、LeCun、哈萨比斯等[AI巨佬们线上“对喷”](http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247702163&idx=1&sn=c8bc0b8ee823299895126b689ce7d630&chksm=e8df61e1dfa8e8f7d3bf759db98a4a99e18a2dd11e3fc4e750971c964cf1e9918d57f076c1bd&scene=21#wechat_redirect)的大型场面。

吴恩达曾表示：

> 对AI的最大担忧其实是，**AI风险被过度鼓吹** ，导致开源和创新被严苛规定所压制。
>
> 某些人传播（AI灭绝人类的）恐惧，只是为了搞钱。

![](https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyuBFqHicKVxWllW6CNb08as1BmdLF6zbp00lLWBQrRGsJ2ddrloiaGsJcA/640?wx_fmt=other&from=appmsg)  
![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyuD8QMkzj505g1c6ucyG7ab9vwE7mtoOfX4ibUQZozbmzqMtkAjhbhnYw/640?wx_fmt=png&from=appmsg)

DeepMind CEO哈萨比斯则认为：

> 这不是恐吓。AGI的风险如果不从现在就开始讨论，后果可能会很严重。
>
> 我不认为我们会想在危险爆发之前才开始做防范。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyudr8p27Hiciby0881Fh6KW7p3QCEJzABV6nPeKextAJfib9MxFvXjAtibvQ/640?wx_fmt=png&from=appmsg)

Bengio之前还和Hinton、姚期智、张亚勤等人工智能大拿，发表了一封公开信《在快速进步的时代管理人工智能风险（Managing AI RIsks in
an Era of Rapid Progress）》。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCT90OmZDCwGsDrDicLxfOyuy9kb2xib8iadMgqQYb1vicjWQNLBMiakGhdz3lZcNKlYYrOvM7yiaaibPcWw/640?wx_fmt=png&from=appmsg)

其中就指出人类必须认真对待AGI在这10年或下一个10年内在许多关键领域超越人类能力的可能。建议监管机构应该对AI发展全面洞察，尤其警惕那些在价值数十亿美元的超级计算机上训练出来的大模型。

就在一个月前，Bengio还以“Reasoning through arguments against taking AI safety
seriously（回应反对认真对待AI安全的观点）”为题写了一篇文章，其中分享了他的最新想法，感兴趣的家人可以康康～

https://yoshuabengio.org/2024/07/09/reasoning-through-arguments-against-
taking-ai-safety-seriously/

Guaranteed Safe AI：

https://arxiv.org/abs/2405.06624

参考链接：  
[1]https://www.technologyreview.com/2024/08/07/1095879/ai-godfather-yoshua-
bengio-joins-uk-project-to-prevent-ai-catastrophes/  
[2]https://www.reddit.com/r/singularity/comments/1emcwox/ai_godfather_yoshua_bengio_has_joined_a_uk/  
[3]https://x.com/davidad/status/1821155265456033803

— **完** —

**量子位年度AI主题策划** 正在征集中！

欢迎投稿专题 **一千零一个AI应****用** ，**365行AI落地方案**

或与我们分享你在**寻找的AI产品** ，或发现的**AI新动向**

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&from=appmsg)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg)

