# NeurIPS'24「组合学习」Workshop，开启征稿啦！MIT、DeepMind等大佬齐聚

文章作者: 量子位
发布时间: 2024-08-29 21:31
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247746357&idx=5&sn=6b5b51aa2f0d525289b07d63bd326ec2&chksm=e8dfb447dfa83d51643184f5272e0b9ec87f1762fb3e0da997a5a365bf71173a1a2b70224604#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDQNJh5Wiav0tYv3kARIs9lcJzn3tjT0BTTWl4icpdKa1vts7hN3OvX1LHrzquTj0f9kJVicIowy32Rw/300

##### Compositional Learning 投稿  
量子位 | 公众号 QbitAI

NeurIPS 2024以“**组合学习：观点、方法、及展望** ”为主题的Workshop开启征稿啦～

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDQNJh5Wiav0tYv3kARIs9lccibQa9nsbN6O6yfalS80jGjrOcuxeQ9Dlr7OlHCBng3PkwicRleBCXmw/640?wx_fmt=png&from=appmsg)

组合学习受到人类天生能够从简单概念理解和生成复杂思想能力的启发，旨在赋予机器类似的理解、推理和学习能力。

通过重新组合已学到的组件，组合学习天然具备提升机器对真实动态环境中分布外样本的泛化能力。

该优点亦促成了面向对象的学习（object-centric learning）、组合泛化（compositional
generalization）、和组合推理（compositional
reasoning）等领域的活跃研究，并在包括机器翻译、跨语言迁移、语义解析、可控文本生成、事实知识推理、图像字幕生成、文本到图像生成、视觉推理、语音处理、强化学习等众多任务中得到了广泛应用。

尽管在这些领域已取得可观进展，但包括大模型（LLMs）在内的现有模型的组合泛化和推理能力在真实动态环境中仍面临严峻挑战。

在组合学习面临的诸多挑战和全新机遇中，来自南洋理工大学、哈佛大学、麻省理工学院、Mila-Quebec人工智能研究所&HEC
Montreal、纽约大学、图宾根大学的学者联合组织了本次研讨会。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDQNJh5Wiav0tYv3kARIs9lcZzKosCpIF1kGYTzIPMyXzocB7sslTm8nSUcCcuPFNhub35A0WicuiaCg/640?wx_fmt=png&from=appmsg)

本次研讨会将基于该领域的最新进展，重点关注以下四个议题：

**（观点） 在什么情形下，以及为什么，基础模型在组合泛化或推理中应该具备优异性能？**

这个问题对于评估基础模型的内在能力和理解其学习动态至关重要。我们的目标是汇集来自各领域的研究者，从实验和理论的角度探索可能影响基础模型中组合性的因素（例如，模型架构、规模、组合类型、输入等）。

**（方法）我们能否找到或设计出可跨不同领域迁移的、与现有基础模型兼容的组合学习方法？**

这一议题旨在促进各领域研究者之间的讨论，以研发更鲁棒且与模型无关的组合学习策略。可继续探索的研究方向包括通过数据增强算法、基于mixture-of-
experts的模块化算法。

**（观点及方法）模块化学习策略在现有研究中是实现组合性的手段之一，然而针对该策略仍存在一个关键科学问题：结构模块化是否一定保证组合泛化能力？两者之间是否存在关联？**

本次研讨会将涵盖各种模块化学习策略（例如，适配器、prompts、稀疏化），并从理论和实验两方面回答上述问题。

**（展望）在将组合学习策略扩展到持续学习环境时，会存在哪些独特挑战？可能的解决方案是什么？**

组合学习的最终目标是通过不断组合已有组件持续适应动态变化的世界，以减少模型性能随时间退化的风险。通过该议题，本次研讨会将讨论面向连续学习现有组合学习方法所面临的挑战，例如和记忆体及知识存储相关的问题，并探索潜在解决方案。

## 征稿启事

欢迎对上述问题感兴趣的机器学习研究者提交论文，特别鼓励组合泛化、组合推理、模块化深度学习、迁移学习、持续学习和基础模型等领域的研究者投稿，也欢迎研究神经科学的学者投稿，以提供更广阔的视角。

感兴趣的主题包括但不限于：

  * Empirical analysis of compositional generalization/reasoning capacity in various foundation models

  * Mechanism understanding of compositional generalization/reasoning in foundation models

  * Reliable and model-agnostic compositional generalization methods

  * Modular and dynamic architectures

  * Theoretical foundations and empirical findings of connections between modular structures and compositional generalization

  * Continual/transfer learning through compositionality

  * Compositional learning for various application domains, such as computer vision, natural language processing, reinforcement learning, and science.

### 格式要求

提交的论文必须是PDF格式并匿名化。

内容页限制为四页，包括所有图表；参考文献和补充材料可以增加额外的页面。

评审人可以选择阅读补充材料，但不做强制要求。

最终稿可以扩展至五页内容。

### 双重提交政策

接受正在进行的和未发表的工作投稿，也接受提交时正在审稿或最近被接受但未发表的论文。

### 联系方式

如有任何问题，可联系：

compositional-learning-neurips2024@googlegroups.com

如果您愿意担任本次研讨会的评审人，请在此处报名：

https://docs.google.com/forms/d/e/1FAIpQLSc7PKRLrjsxBSXmtvuiR0rkbOBrcowBuHxQdupIfcxhO52KIw/viewform

### 重要日期

  * 提交截止日期: 2024年9月10日，AOE

  * 录取通知: 2024年10月10日，AOE

  * 视频录制截止日期（仅限口头报告）: 2024年10月20日

  * 最终研讨会定稿截止日期: 2024年10月30日

官方网址：https://compositional-learning.github.io/

提交网址：https://openreview.net/group?id=NeurIPS.cc/2024/Workshop/Compositional_Learning

— **完** —

  

投稿请发邮件到：

**ai@qbitai.com**

标题注明【投稿】，告诉我们：

你是谁，从哪来，投稿内容‍

附上论文/项目主页链接，以及联系方式哦

我们会（尽量）及时回复你

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

