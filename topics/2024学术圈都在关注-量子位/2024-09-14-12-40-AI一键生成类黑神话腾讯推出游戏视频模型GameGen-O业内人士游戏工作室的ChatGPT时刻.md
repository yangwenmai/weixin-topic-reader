# AI一键生成“类黑神话”！腾讯推出游戏视频模型GameGen-O，业内人士：游戏工作室的ChatGPT时刻

文章作者: 量子位
发布时间: 2024-09-14 12:40
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247749334&idx=3&sn=7026eda20361bd52c1d78a5d3fb361b3&chksm=e8dfb9a4dfa830b2052e6d9990eacac0485b995cadcca994880ce82c5572eb17d7817b7517a9#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvf4b4mMVt3oXWfUhMcRxjD8SchabK9jFczNicXjxc3yAFSwRFxjRPuicA/300

##### 一水 发自 凹非寺  
量子位 | 公众号 QbitAI

什么？**大模型** 也许很快就能生成《黑神话·悟空》这种3A大作了？！

直接看一则demo，《西游记》这就上桌：

搭配BGM，是不是有内味儿了（doge）。

这就是腾讯近日推出的**GameGen-O** ，一个专门**生成开放世界视频游戏** 的Transformer模型。

简单说，这个模型能够模拟各种游戏引擎功能，生成游戏角色、动态环境、复杂动作等等。

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tv42vLzVTvJQsJPIhFGFfQSSAbzqcibeSfQCzdAKAZuhcpsdWBQEvZLxA/640?wx_fmt=gif&from=appmsg)

当然也支持**交互控制** ，用户可以通过文本、操作信号和视频提示来控制游戏内容。

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvWLQpwjBG0j8K4681ZKDdfF0yRib7fQZrHlhxeEiaiavtticxPTzLasyO5w/640?wx_fmt=gif&from=appmsg)

消息一公布就在𝕏（前推特）开启了刷屏模式，网友们开始列队尖叫：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvzUYUE7hyjx1KOmNma49Zz8Jr3BXol0KRHSmicjzU2MK9I71JFIT2MTQ/640?wx_fmt=gif&from=appmsg)

游戏工作室Azra Games的联创兼CTO更是直言：

> GameGen-O将成为**游戏工作室的ChatGPT时刻** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvzibDF7MPicia4Ph3eAQ9ks5PMhfuuXrBfpeicxJp7vxiassoqbc0ic3zYia2w/640?wx_fmt=png&from=appmsg)

## “游戏工作室迎来ChatGPT时刻”

具体来说，这个项目由腾讯联合港科大、中国科大推出。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvj10Ugkhq2BIHSC1Zblytk2q5b4HIGmW6CAIapQ5fD1CIlpKicmThCPg/640?wx_fmt=png&from=appmsg)

推测想要做的事儿，是用AI模型替代一些**游戏开发环节** 。比如目前公布的游戏角色创建、游戏环境生成、动作生成、事件生成以及各种交互控制。

下面我们挨个预览一波~

现在，用GameGen-O就能直接生成各种角色了，西部牛仔、太空人、魔法师、警卫……一键生成。

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvUic9wLpoUM85f7zIVtOsC8icI2mMEOrmGzLNjuyq4EPBMhc9ma4nC4FA/640?wx_fmt=gif&from=appmsg)

经费不足造成真实取景困难，也有plan B了！

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvAE1jPLbgPqOJzv1DNEh2orqmRoenXlu7DF9QPKOViafA50PzJxH8ucQ/640?wx_fmt=gif&from=appmsg)

给队友展示骚操作，各种人称视角的动作生成也能轻松拿捏。

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvNN17EP9sgY6iaGmjegGZd8NM9jJAo2R5FuOexcVia8x0RfmBibLpDXeBw/640?wx_fmt=gif&from=appmsg)

游戏必备环节——给玩家偶尔上亿点难度，海啸、龙卷风、火灾事件这就安排（doge）。

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvvbzaX1T0y4tuHgZBJYy4a3iatWRn5EGOxTv4vU8LVVzWh5Q0ZahDR5A/640?wx_fmt=gif&from=appmsg)

与此同时，GameGen-O也支持开放域生成，即不限风格、环境、场景那种。

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvba5tW5aeibibThXiciaPib2LLCgfHaSG7P2W71n2gfCncnXFMvnSLvibPaibg/640?wx_fmt=gif&from=appmsg)

最后，用文本、操作信号和视频提示就能实现**交互** ，向左、向右、走向黎明……

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvVn5qzibdeqNuDKQTicneFrAGPFZttyIO2MTGicXYY0icnGJwA4OJIibb8Jg/640?wx_fmt=gif&from=appmsg)

好家伙，谁都知道游戏开发有多烧钱，这下，普通玩家也能用GameGen-O制作游戏了。

一位AI架构师网友更是断言：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvLgd2iatMSuIvxx6x7uDllG1GRpYTPZnkgxV7492cVzIBqjMQcUWo8iaw/640?wx_fmt=png&from=appmsg)

## 用GPT-4o标注数据

为了开发这个模型，团队自述主要进行了**两项工作** ：

  * 构建**专有数据集OGameData** ，采用GPT-4o标注数据

  * 经历**两个阶段** 的训练过程

具体来说，团队首先提出了一个**数据集构建管道** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvOrtXeib4mNYIwMph8wmico2GFA4iaMHwlLPKmYbLBjlkmNaxnh4ePbe6w/640?wx_fmt=png&from=appmsg)

团队从互联网上收集了**32,000个** 原始视频，这些视频来自**数百款**
开放世界游戏，时长从几分钟到几小时不等，类型包括角色扮演、第一人称射击、赛车、动作益智游戏等。

然后由**人类专家** 对这些视频进行识别和筛选，最终得到大约**15,000个** 可用视频。

下一步，将筛选后的视频通过场景检测技术切割成**片段** ，并对这些视频片段进行基于美学、光流和语义内容的严格**排序和过滤** 。

接下来使用**GPT-4o** 对超过4,000小时的高质量视频片段进行细致的**注释** ，这些片段的分辨率从720p到4k不等。

为了实现交互控制性，团队从注释后的数据集中选择最高质量的片段，并进行**解耦标签** （decoupled labeling）。

这种标签设计用于描述**片段内容状态的变化** ，确保训练模型的数据集更加精细和互动。

对于这种人类专家和GPT-4o一起工作的形式，有网友认为：

> 这是**递归自我改进** （recursive self-
> improvement）的一种形式。（人类专家确保了注释的准确性，并通过反馈机制帮助GPT-4o进行自我改进）

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvggIziaStUgzhp3DnDupdY2UwcibEpSbExMzEMibx44NGM65Rny13j7szg/640?wx_fmt=png&from=appmsg)

完成数据准备工作后，团队经过**基础预训练+指令调整** 两个过程来训练GameGen-O。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvl7CDCMyastvZkJ7LqNVvvO2AAvhMJk8O25iayh1AxUXvn8OOIibs5GIg/640?wx_fmt=png&from=appmsg)

在**基础训练阶段** ，GameGen-O模型使用了一个**2+1D VAE** （变分自编码器，如Magvit-v2）来压缩视频片段。

为了使VAE适应游戏领域，团队对VAE解码器进行了特定领域的调整。

团队采用了不同帧速率和分辨率的**混合训练策略** ，以增强跨帧率和跨分辨率的泛化能力。

另外，模型的**整体架构** 遵循了Latte和OpenSora V1.2框架的原则。

通过使用掩码注意力机制，让GameGen-O**具备了文本到视频生成** 和**视频续集** 的双重能力。

团队介绍称：

> 这种训练方法，结合OGameData数据集，使得模型能够稳定且高质量地生成开放领域的视频游戏内容，并为后续的交互控制能力奠定了基础。

在这之后，预训练的模型被固定，然后使用可训练的**InstructNet** 进行微调，这使得模型能够根据多模态结构指令生成后续帧。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvibBO1UqliaYRChL20HoR5565lMiaNk0dL391Ba32dEHlxiam0LhQECzZvw/640?wx_fmt=png&from=appmsg)

InstructNet主要用于接受各种**多模态输入** ，包括结构化文本、操作信号和视频提示。

在InstructNet分支的调整过程中，当前内容被用作条件，从而在当前片段内容和未来片段内容之间建立了**映射关系** ，这在多模态控制信号下进行。

造成的结果是，在推理时，GameGen-O允许用户**基于当前片段不断生成和控制下一个生成的片段** 。

目前，GameGen-O已创建**GitHub官方仓库** ，只不过还没来得及上传代码。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDYicjZLciaE0CiaF6b8BCk1tvQibalWQBazSu1dvpox1TcCuP41snnGETbjfiaPjYDKicoj7s5UfYsE1yg/640?wx_fmt=png&from=appmsg)

感兴趣的童鞋可以先收藏一波了~

项目主页：  
https://gamegen-o.github.io/

GitHub官方仓库：  
https://github.com/GameGen-O/GameGen-O/

参考链接：  
[1]https://x.com/_akhaliq/status/1834590455226339492  
[2]https://x.com/8teapi/status/1834615421728948581?s=46

— **完** —

**量子位年度AI主题策划** 正在征集中！

欢迎投稿专题 **一千零一个AI应****用** ，**365行AI落地方案**

或与我们分享你在**寻找的AI产品** ，或发现的**AI新动向**

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtDpTavEwUl8aOlFLGHaPnaKXJcMUeJtGXVLliac6P6XxYHIKhnz0NPUgVvlrXAvJC33ibh8aYDdyudA/640?wx_fmt=png&from=appmsg)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg)

