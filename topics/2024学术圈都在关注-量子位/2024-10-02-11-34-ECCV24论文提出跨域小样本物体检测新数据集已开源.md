# ECCV'24论文提出跨域小样本物体检测新数据集｜已开源

文章作者: 量子位
发布时间: 2024-10-02 11:34
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247752081&idx=3&sn=51a862a02e8002789233fde4a99ba92a&chksm=e8dfaee3dfa827f5128b654f2a9aeca8b260d784f73fadeee05416c3189648604497ca060bac#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBcicr4mtMw93ic89fOucRw2Y9UviaToqTW1eiccy6eEdZ4N1o0Xb90rweOa4qZ12pG9noribxUBMyxLwg/300

##### CD-ViTO团队 投稿  
量子位 | 公众号 QbitAI

解决**跨域小样本物体检测** 问题，入选ECCV 2024。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBcicr4mtMw93ic89fOucRw2YO3hvddFLmQhPLXCe7ia9gYibV166pj0ibjsIsCrTRiaHISibZHf30YlMIAg/640?wx_fmt=png&from=appmsg)

最新研究认为目前大多数跨域小样本学习方法均集中于研究分类任务而忽略了目标检测。

来自复旦大学、苏黎世联邦理工学院、INSAIT、东南大学、BOE科技的研究团队，提出了一个用于算法评测的**CD-FSOD数据集**
及用于衡量领域差异的**style、ICV、IB数据集指标** 。

对现有目标检测算法进行了广泛实验评估。

除此之外，团队还提出了一种名为**CD-ViTO** 的新方法，基于优化一个在经典FSOD上达到SOTA的开放域物体检测器而得到。

CD-ViTO在多数情况下优于基准，成为该任务的新SOTA。

目前该项研究已入选ECCV 2024，所有数据集、代码、以及相关资源都已开源。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBcicr4mtMw93ic89fOucRw2Y096E8AynRmkOgCow2z0ibAIkicNKvS7Fcq963YAayjqwZtpWL3BPibMsA/640?wx_fmt=png&from=appmsg)

## 研究目的

跨域小样本学习任务（Cross-Domain Few-Shot Learning，CD-
FSL）解决的是源域与目标域存在领域差异情况下的小样本学习任务，即集合了小样本学习与跨域两个任务的难点问题：

  * 源域S与目标域T类别集合完全不同，且目标域T中的类别仅存在少量标注样本，例如1shot，5shot；

  * S与T属于两个不同领域，例如从自然图像迁移到医疗图像。

大多数的现有方法均集中于研究分类问题，即Cross-Domain Few-Shot Classification，
但是同样很重要的物体检测任务（Object
Detection，OD）却很少被研究，这促使了研究团队想要探究OD问题在跨域小样本的情况下是否也会遭遇挑战，以及是否会存在跟分类任务表现出不同的特性。

与CD-FSL是FSL在跨域下的分支类似，跨域小样本物体检测（Cross-Domain Few-Shot Object Detection，CD-
FSOD）同样也可以堪称是FSOD在跨域下的分支任务。

所以研究团队先从经典的FSOD开始分析。大多数的FSOD方法都可以被粗略地划分为：

  * meta-learning based，典型方法包括Meta-RCNN；

  * finetuning based，例如TFA，FSCE，DeFRCN。

然而近期出现了一个名为**DE-ViT的开放域方法**
，通过基于DINOv2构建物体检测器同时在FSOD以及开放域物体检测（OVD）上都达到了SOTA的效果，性能明显高于其他的FSOD方法，因此这引发了团队思考：

> **现有的FSOD方法，尤****其是SOTA的DE-Vi****T open-set detector能不能在跨域的情况下仍表现优异？**
>
> **如果不能，****什么是难点问********题，以及是否有办法能够提升open-set detector的性能？**

先用下图来揭示一下问题的答案：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBcicr4mtMw93ic89fOucRw2YRiaKOUUHWbVlVyicvmev8saC21c5c7USxlOsV6ov0wHFQ0iaoaeH2lz7g/640?wx_fmt=png&from=appmsg)

如上左图所示，哪怕是SOTA的open-set detector DE-ViT（绿色星形）**在跨域泛化的情况下性能也会出现急剧下降** 。

而本文研究团队基于DE-ViT搭建的CD-ViTO方法 （橙色星形）能够使原本性能下降的模型得以进一步提升。

而右图，展示了相比于in-domain的小样本物体检测，跨域小样本物体检测通常会面临三个问题：

1）目标域T的类间距离（ICV）通常较少；  
2）目标域的图像可能会出现前景与背景边界模糊（Indifinable Boundary，IB）；  
3）目标域T得图像相较于源域S而言视觉风格（style）发生变化。

ICV、IB、Style也成为了研究人员用于衡量不同数据集在跨域下的特性。

## 主要工作及贡献

下面首先总结一下CD-ViTO团队在解答两个问题的过程中的主要工作及贡献：

**Benchmark, Metrics, and Extensive study**

为了回答问题1，即研究现有的物体检测器能不能泛化至跨域小样本物体检测任务中：

研究人员研究了CD-FSOD任务下的三个影响跨域的数据集特性：Style, ICV, IB；提出了一个CD-
FSOD算法评测数据集，该数据集包含多样的style，ICV，IB；对现有物体检测器进行了广泛研究，揭示了 CD-FSOD 带来的挑战。

**New CD-ViTO Method**

为了回答问题2，即进一步提升基础DE-ViT在CD-FSOD下的性能，研究团队提出了一个新的CD-
ViTO方法，该方法提出三个新的模块以解决跨域下的small ICV、indefinable boundary以及changing styles问题。

  * Learnable Instance Features：通过将初始固定的图像特征与目标类别之间进行对齐，通过增强特征可分辨程度来解决目标域ICV距离小的问题 。

  * Instance Reweighting Module：通过给不同的图像设置不同的权重，使得严具有轻微 IB 的高质量实例分配更高的重要性，从而缓解显著的 IB 问题；

  * Domain Prompter：通过合成虚拟领域而不改变语义内容来鼓励模型提升对不同style的鲁棒性。

**CD-FSOD数据集 &Extensive Study**

下图为研究团队构建的CD-FSOD数据集，该数据集以MS-COCO作为源域S，以ArTaxOr、Clipart1K，DIOR，DeepFish，NEU-
DET，UODD作为六个不同的目标域T；

团队也分析并在图中标注了每个数据集的Style、ICV、IB特征，每个数据与数据之间也展现了不同的数据集特性。

所有的数据集都整理成了统一的格式，并提供1shot、5shot、10shot用于模型测评。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBcicr4mtMw93ic89fOucRw2YO3hvddFLmQhPLXCe7ia9gYibV166pj0ibjsIsCrTRiaHISibZHf30YlMIAg/640?wx_fmt=png&from=appmsg)

数据集更多的介绍，比如数据类别数，样本数等可以在论文中找到细节。

**Extensive Study**

团队对现有的四类目标检测器进行了实验，包括：

  * 典型的FSOD方法：Meta-RCNN、TFA、FSCE、DeFRCN

  * 现有的CD-FSOD方法：Distill-cdfsod

  * 基于ViT的方法：ViTDeT-FT

  * 开放域方法：Detic（-FT）， DE-ViT（-FT） (DE-ViT仅利用视觉信息，Deti则依赖视觉-文本相似性）

其中“-FT”表示团队用目标域T的少量样本对方法进行了微调。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBcicr4mtMw93ic89fOucRw2Y3ZxINtD9hgm8NefdXdJKuI8amXoz1AjnSP6TFic0rT3cgSJ9SiclM3Vg/640?wx_fmt=png&from=appmsg)

团队结合实验结果对这个任务以及相关方法展开了详细的分析，主要有以下这几点结论：

  * 现有FSOD方法可以泛化到跨域问题吗？**A：不能**

  * 基于ViT的方法会比基于ResNet的方法好吗？**A：看情****况**

  * 开放域方法能够直接用于应对CD-FSOD问题？**A：不能**

  * 开放域方法的性能可以进一步得到提升吗？**A：可以**

  * 不同的开放域方法是否呈现不同的特性？**A：是的**

  * Style，ICV，IB是如何影响domain gap的？**A：在分类里影响巨大的style对于OD任务而言影响相对较少；ICV有较大影响但是可以被有效缓解；IB是这三者中最具挑战的。**

详细的分析就不在这里展开了，感兴趣的朋友可以看看文章。

## CD-ViTO方法&主要实验

本文方法整体框架结构图如下所示：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC7XVwez5WViaAypUKOSs8QvmdurXm0nH0gkzVSxc0WdEARDgiaAz6v9eibuU4ibGjcsxdGDmGvc8Kl3g/640?wx_fmt=png&from=appmsg)

整体来看，本文研究团队的方法是基于DE-ViT搭建的（图中蓝色块）， 首先将DE-ViT方法简化为图中所示的几个模块，主要包括Pretrained
DINOv2 ViT， RPN，ROI Align， Instance Features， Dection Head，One-vs-Rest
Classification Head。

DE-ViT的核心想法是利用DINOv2提取出来的视觉特征对query image boxes与support
images中所构建出来的类别prototypes进行比较，从来进行分类和定位。

基于DE-ViT方法，团队提出了三个新的模块（图中黄色块）以及finetune（图中火苗）以搭建CD-ViTO。如前所述，每个模块都各自对应解决CD-
FSOD下存在的一个挑战。

**Learnable Instance Features**

原本的DE-ViT首先利用DINOv2获取instance features，然后简单对同类特征求和的方式得到support的class
prototypes。

然而在面对目标域类别之间可能很相似的情况，直接使用这种预训练的模型所提取出的特征会导致难以区分不同类别。

因此团队提出将原本固定的特征设置为可学习参数，并通过结合finetune方法将其显式地映射到目标域类别中，以此增加不同类之间的特征差异程度，缓解ICV问题。

团队对比了使用该模块前后的类间cosine相似性，结果说明他们的模块可以降低类间相似度，从而提升ICV。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBcicr4mtMw93ic89fOucRw2Y1l00r76J6tsQX7s1ZUp0eicFCMhtAnt56CUy1auoRXANZLRrQA9GBPw/640?wx_fmt=png&from=appmsg)

**Instance Reweighting Module**

图像模糊边界的问题本身很难得到解决，这个模块的主要想法是通过学习可调整的权重给不同质量的样本赋不同的权重，使得严重IB的图像被抑制，没有或者轻微IB地图像被鼓励。

模块的设计如框架图右上所示，主要包含一个可学习的MLP。

同样的，团队也对该模块做了可视化分析，他们按照所分配到的权重从高到低给图像排序，得到如下结果。从图中可见，前后景边缘模糊的图像得到的权重要低于边缘清晰的图像。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBcicr4mtMw93ic89fOucRw2Ydfh0pkt6VVRv3ol4WG1rlEcUApAuRCjCdADhM902N6IA4okrGibK0wQ/640?wx_fmt=png&from=appmsg)

**Domain Prompter**

Domain Prompter的设计主要是希望方法能够对不同的domain鲁棒，如框架图右下所示，在原有object
prototype的基础上，团队额外引入数量为$N_{dom}$维度为D（等于prototype维度）的虚拟domains变量作为可学习参数。通过学习和利用这些domains，他们希望最终达到：

1） 不同domain之间相互远离，增加多样性 （domain diversity loss）

2）
添加不同domain至同一类别prototype所生成得到的两个变种仍为正样本，添加不同domain至不同类别prototype生成得到的两个变种为负样本
（prototype consistency loss）

两个loss与finetuning所产生的loss叠加使用进行网络的整体训练。

如下T-SNE可视化图说明学习到的domains之间相互远离；叠加不用domains至class prototype不影响语义变化。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBcicr4mtMw93ic89fOucRw2YicsmvPPUXrK8BN2BG8Eicqqso2hzbLfXtvl0gIwWxyFtiaAM7euZ90Lnw/640?wx_fmt=png&from=appmsg)

作为简单但有效的迁移学习方法，团队也采用了在目标域T上对模型进行微调的思路，论文附录部分有提供不同finetune策略的不同性能表现，团队主方法里采用的是仅微调两个头部。

团队在1/5/10shot上与其它方法进行了对比实验。

实验说明经过优化后的CD-ViTO方法在大多数情况下都优于其它的对比方法，达到了对基本DE-ViT的有效提升，构建了这个任务的新SOTA。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBcicr4mtMw93ic89fOucRw2Y9sLRdEe5cnYOewjuNPIP0suhk0I1wYTCd3GrdTjxKZR7IqiaVlVuMAQ/640?wx_fmt=png&from=appmsg)

论文链接：https://arxiv.org/pdf/2402.03094  
网页链接：http://yuqianfu.com/CDFSOD-benchmark/  
GitHub链接：https://github.com/lovelyqian/CDFSOD-benchmark  
中文讲解视频：https://www.bilibili.com/video/BV11etbenET7/?spm_id_from=333.999.0.0  
英文讲解视频：https://www.bilibili.com/video/BV17v4UetEdF/?vd_source=668a0bb77d7d7b855bde68ecea1232e7#reply113142138936707

— **完** —

  

投稿请发邮件到：

**ai@qbitai.com**

标题注明【投稿】，告诉我们：

你是谁，从哪来，投稿内容‍

附上论文/项目主页链接，以及联系方式哦

我们会（尽量）及时回复你

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

