# OCR-Omni来了，字节&华师统一多模态文字理解与生成 | NeurIPS2024

文章作者: 量子位
发布时间: 2024-10-19 19:08
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247753432&idx=4&sn=a4ce5cce27fac2b180f1f1c8b50d1eab&chksm=e8dfa9aadfa820bceceefaba867ffc5faf9da08291e26e9c0189c6b4c1d014e9d509ba4ddec3#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTWhNkT6YlEnT60RQJpPrLibxLPXW448bibFoqnhQVmCFWFyZw517euvFNQ/300

##### TextHarmony团队 投稿  
量子位 | 公众号 QbitAI

多模态生成新突破，字节&华师团队打造TextHarmony，在单一模型架构中实现模态生成的统一，并入选NeurIPS 2024。

过去,视觉文字领域的大模型研究聚焦于单模态生成，虽然在个别任务上实现了模型的统一，但很难在OCR领域的多数任务上做到全面整合。

例如，Monkey等视觉语言模型（VLM）擅长文字检测、识别和视觉问答（VQA）等文本模态生成任务，却无法胜任文字图像的生成、抹除和编辑等图像模态生成任务。反之，以
AnyText 为代表的基于扩散模型的图像生成模型则专注于图像创建。因此，OCR领域亟需一个能够统一多模态生成的大模型。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTWLjbZoJc6UVtPbILIp2sQiaFpQLeM4dLAS7Nnu9lw6mFrS64YVSSqqtw/640?wx_fmt=png&from=appmsg)

为解决这一难题，字节跳动与华东师范大学的联合研究团队提出了创新性的多模态生成模型TextHarmony，不仅精通视觉文本的感知、理解和生成，还在单一模型架构中实现了视觉与语言模态生成的和谐统一。

目前论文已经上传arXiv，代码也即将开源，链接可在文末领取。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTWUI800zhKV3uibNXADO0BNSRm7OjvqtgO8Jtfo3u3Ej0Xjicd8rSK6sJg/640?wx_fmt=png&from=appmsg)

## TextHarmony: 核心贡献

TextHarmony的核心优势在于其成功整合了视觉文本的理解和生成能力。传统研究中，这两类任务通常由独立模型处理。TextHarmony
通过融合这两大类生成模型，实现了视觉文字理解和生成的同步进行，从而统筹了 OCR 领域的多数任务。

研究表明，视觉理解和生成之间存在显著差异，直接整合可能导致严重的模态不一致问题。具体而言，多模态生成模型在文本生成（视觉感知、理解）和图像生成方面，相较于专门的单模态模型，性能出现明显退化。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTWjp2bam1CE8alSvX3gfmzHUjetSQZKOvYEtalUnIr1Rx5CTna9mnxpA/640?wx_fmt=png&from=appmsg)

数据显示，多模态生成模型在文本生成任务上较单模态模型效果降低 5%，图像生成任务上最高降低8%。而 TextHarmony
成功缓解了这一问题，其在两类任务上的表现均接近单模态专家模型水平。

#### 技术创新

TextHarmony 采用了 ViT、MLLM 和 Diffusion Model 的组合架构：

  * ViT 负责图像到视觉 token 序列的转换。

  * MLLM 处理视觉 token 和文本 token 的交叉序列，输出两类 token：

  * 文本 token 经文本解码器转化为文本输出。

  * 视觉 token 与文本 token 结合，作为 Diffusion Model 的条件指引，生成目标图像。

这种结构实现了多模态内容的全面理解与生成。

**Slide-LoRA：解决方案**

为克服训练过程中的模态不一致问题，研究者提出了 Slide-LoRA 技术。该方法通过动态整合模态特定和模态无关的 LoRA（Low-Rank
Adaptation）专家，在单一模型中实现了图像和文本生成空间的部分解耦。

Slide-LoRA 包含一个动态门控网络和三个低秩分解模块：

  * 模态特定 LoRA 专家聚焦于特定模态（视觉或语言）的生成任务。

  * 模态无关 LoRA 专家处理跨模态的通用特征。

  * 动态门控网络根据输入特征，灵活调度不同专家的参与度。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTWWFtlgG2frlSS9gkm2aL8EjqAUGNNcDPkHamIrO7fAic7QraXCyPU9Wg/640?wx_fmt=png&from=appmsg)

**DetailedTextCaps-100K: 高质量数据集**

为提升视觉文本生成性能，研究团队开发了 DetailedTextCaps-100K 数据集。该集利用闭源 MLLM（Gemini
Pro）生成详尽的图像描述，为模型提供了更丰富、更聚焦于视觉和文本元素的训练资源。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTWUAoqRXFSSu3ozPrWts5ur0SStXgwktKmdCFgqC0uFDTa1oZr52x1TA/640?wx_fmt=png&from=appmsg)

#### 训练策略

TextHarmony 采用两阶段训练方法：

  1. 首阶段利用 MARIO-LAION 和 DocStruct4M 等图文对预训练对齐模块和图像解码器，构建基础的文本生成与图像生成能力。

  2. 次阶段运用视觉文本的生成、编辑、理解、感知四类数据进行统一微调。此阶段开放 ViT、对齐模块、图像解码器和 Slide-LoRA 的参数更新，以获得统一的多模态理解与生成能力。

## 实验评估

研究者对 TextHarmony 在视觉文本场景下进行了全面评估，涵盖理解、感知、生成与编辑四个维度：

视觉文本理解：TextHarmony 显著优于多模态生成模型，性能接近 Monkey 等专业文字理解模型。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTWNHr4D7vvyTUTnMOYMaIkTRlTdLPwWiba8Klt45vUE9XgtVwpsJS8G1Q/640?wx_fmt=png&from=appmsg)

视觉文本感知：在OCR定位任务上，TextHarmony超过了TGDoc、DocOwl1.5等知名模型。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTWAvBummBuAAYI9YRFtUPudR8GIpzyjSX6YWJ6ViaLzNzFAj9UX5VaickQ/640?wx_fmt=png&from=appmsg)  

视觉文本编辑与生成：TextHarmony 大幅领先于现有多模态生成模型，且与 TextDiffuser2 等专业模型相当。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTWm5PUXyxRPEmfoqUibZJAKbDEsvUjdQKBbJmHY4oVVMYdCiaDLH73eqIQ/640?wx_fmt=png&from=appmsg)

### 文字生成效果对比

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTWpAJ05hMUk916fzsOQDW9diccTboV5VpZrJGok8lJ0XkMflD5VEGMhRw/640?wx_fmt=png&from=appmsg)

### 文字编辑效果对比

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTW21J8oCibSalasb4APyxEnianvjC7X1zBLPsiaWM0d8ez4Dc0JgicQj6OvQ/640?wx_fmt=png&from=appmsg)

### 文字图像感知与理解可视化

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAuicnr79UHBOLSpAdUD5RTWn6zD75uFcqlN1F3hWWE2BEDyEyIYAGg2E5eZMsMHtzjehGgibzS5udg/640?wx_fmt=png&from=appmsg)

## 总结与展望

TextHarmony 作为 OCR 领域的多功能多模态生成模型，成功统一了视觉文本理解和生成任务。通过创新的 Slide-LoRA
技术，它有效解决了多模态生成中的模态不一致问题，在单一模型中实现了视觉与语言模态的和谐统一。TextHarmony
在视觉文字感知、理解、生成和编辑方面展现出卓越性能，为复杂的视觉文本交互任务开辟了新的可能性。

这项研究不仅推动了 OCR 技术的进步，也为人工智能在理解和创造方面的发展提供了重要参考。未来，TextHarmony
有望在自动文档处理、智能内容创作、教育辅助等多个领域发挥重要作用，进一步推动人工智能的应用。

论文链接: https://arxiv.org/abs/2407.16364  
代码开源: https://github.com/bytedance/TextHarmony（即将开源）

— **完** —

  

投稿请发邮件到：

**ai@qbitai.com**

标题注明【投稿】，告诉我们：

你是谁，从哪来，投稿内容‍

附上论文/项目主页链接，以及联系方式哦

我们会（尽量）及时回复你

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

