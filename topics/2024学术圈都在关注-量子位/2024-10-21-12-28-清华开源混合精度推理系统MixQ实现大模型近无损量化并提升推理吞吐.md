# 清华开源混合精度推理系统MixQ，实现大模型近无损量化并提升推理吞吐

文章作者: 量子位
发布时间: 2024-10-21 12:28
发布地: 未知地区
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247753689&idx=4&sn=d2f79881e6ef970b2c31c1c082e890ce&chksm=e8dfa8abdfa821bd273a31f8ea962e92d14de16011d0276555abb0169660e88cede08c232ad0#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdmtnva2ekjklgQkia6FDTM8WVCePSciabMicAOZKlEnNEJbicIEP574NekQ/300

##### PACMAN实验室 投稿  
量子位 | 公众号 QbitAI

一键部署LLM混合精度推理，端到端吞吐比AWQ最大提升6倍！

清华大学计算机系PACMAN实验室发布开源混合精度推理系统——**MixQ** 。

MixQ支持8比特和4比特混合精度推理，可实现**近无损的量化部署** 并**提升推理的吞吐** 。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzd4sMqib7RhQHbPDEgy2yJe30RfH7hAtpueFicNPYSTibvfbkI3mwicDcpzA/640?wx_fmt=png&from=appmsg)**

###### **△** 图1 MixQ吞吐与已有开源工作比较

MixQ同时量化权重和激活，使用低精度张量核心（INT8/INT4 Tensor
Core）实现推理加速；同时，MixQ提取激活中少量的离群值，使用高精度张量核心（FP16 Tensor
Core）保持推理准确性，通过系统优化掩盖高精度访存开销。

不仅保持推理的准确性，而且通过使用低精度算力有效提升吞吐，充分发挥硬件计算潜力（图1）。

同时，研究团队提供了**基于VLLM和Tensorrt-LLM的混合精度推理** ，用户可以方便地一键部署模型。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdGPwQtyKjyXbLBhXxXuicpx5C8SCEfW8tX0ia2icZJDxH95eW1kPb8PkNg/640?wx_fmt=png&from=appmsg)**

###### **△** 图2 使用VLLM一键部署4比特和8比特混合精度量化并推理

MixQ已支持多个主流大模型LLaMA3，Qwen2，Baichuan2，ChatGLM等。据了解，目前MixQ开源技术已被清程极智等AI行业公司应用在实际产品中。

该工作同时于高性能计算领域顶级国际会议SC’24发表，第一作者清华大学博士后陈逸东、通讯作者为翟季冬教授。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdhysudkZuVMtJjibgK4CibdZUupFdCTiaOIuAVHsoSVJRibqHibVPfZg8LGg/640?wx_fmt=png&from=appmsg)

## 研究背景：已有量化技术总结

量化的主要技术路线有两条，**第一条是权重量化** 。

权重量化的理论加速比是16/量化的比特数。例如，将模型压缩成为4bit，那么理论加速比为16/4=4倍。

然而，当服务商面临大量的用户同时访问时，权重量化的系统吞吐会低于FP16的吞吐，其主要原因是权重量化计算过程中将低精度权重恢复成FP16然后计算，这导致权重量化并不使用低精度算力，当场景表现为compute
bound的时候，性能较低。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdIT1e6LjzshqRNUa73EMZrxa2TQ1NpRaHHw3uE5ZCOe6B3OibnzbnR2A/640?wx_fmt=png&from=appmsg)**

###### **△** 图3 用户请求多权重量化吞吐低于FP16

**第二条技术路线是量化权重和激活** ，使用**低精度的张量核心** 来提升系统的吞吐。

直接将激活量化为低比特可能会出现较大的精度损失。其原因在于激活矩阵中存在离群值（图4）。

一个有效的方法是SmoothQuant，主要思想是通过平滑激活矩阵来降低量化激活的误差。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdMYRYeCwhfhWcODfLImr3JiarpvMFIuhI1TDc59L2ztHGIdCq1KkRumQ/640?wx_fmt=png&from=appmsg)**

###### **△** 图4 激活矩阵中存在离群值

**混合精度量化则是一类全新的量化方法** ，该方案先做了一个矩阵分解，对绝大部分权重和激活用低比特存储，将离群值用FP16存储，分别做矩阵乘法。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdPE2kzG6xD4c8K4FoicLicNQw6jV8YJHl1nMXG9rHCMPwHTtyNgGSmMnQ/640?wx_fmt=png&from=appmsg)  

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzd8NibGSl71qKPf7mjjI03Da7XcOibEBFKKuzZCMpKUyPDER7FiblpVZYUQ/640?wx_fmt=png&from=appmsg)**

###### **△** 图5 混合精度量化示意图

混合精度量化的一个优势就是可以实现近乎无损精度的量化。使用混合精度量化的LlaMA模型在MMLU
20个领域上的数据集进行推理准确率测试表明，**采用8bit混合精度量化后的准确率下降不到0.1%** ：

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdNG9aH77KgSYOBbG8PVX7b6LbQAHCyMjN4JFibzGxIzVWKMxuF2Cl91Q/640?wx_fmt=png&from=appmsg)**

###### **△** 图6 混合精度量化分类准确率

不过，此前已有的混合精度量化的系统的性能普遍不高，主要瓶颈在针对离群点进行**查找、访存和计算** 的开销占比大。

以混合精度库Bitsandbytes为例，实测试表明，Bitsandbytes在用户请求数量为512时仅有1.08倍的加速。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdib4Upfxc8WvicqumkUNiatCmA9fRVoF3OnIicMkm97LNEzCia6dWLoroHeQ/640?wx_fmt=png&from=appmsg)**

###### **△** 图7 Bitsandbytes的在LLaMA70B上的Kernel性能测试

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzduFXOsnb1ogfiaco53Uhr5HibBZrfbnicVavGMeSse3CwsVsK2Wx8Un7Rg/640?wx_fmt=png&from=appmsg)**

###### **△** 图8 Atomic operator是混合精度推理系统的瓶颈之一

那么，如何优化对离群点的查找、访存和计算的开销呢？

## MixQ的解决方案

MixQ的核心思想是基于**离群点的局部性**
对混合精度的计算图做等价变换，使得变换后的混合精度的计算图可以避免离群点查找的额外开销；在此基础上，通过图层融合和设计高效的混合精度数据结构降低访存开销；最后通过CUTLASS生成高性能的混合精度算子，达到提升系统性能的效果。

MixQ的设计基于以下的观察：

**离群点的局部性** 。对LLM的激活矩阵分析发现，**在不同的decode阶段的离群点的分布是有规律的** 。

如图9，红色的点表示的是第一次出现的离群点，绿色的点表示的是重复出现的离群点，随着decode的进行，多数离群点出现在了固定的channel。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdBWeCHmrD4j02tVrjiaP1BbgGeJyNcgpM2feGUJyCX10BQBsr88ibjYkw/640?wx_fmt=png&from=appmsg)**

###### **△** 图9 decode阶段离群点的分布规律

因此，研究人员得到一个重要的结论：在大部分的decode阶段是不需要重复检测离群点的，也就是说我们可以避免检查离群点的开销。

剩下的问题是，如何知道哪些时候不需要重复检查离群点呢？这个答案就隐藏在量化系数中。

在量化的过程中需要对矩阵进行amax的操作。因此，通过amax得到的结果可以判断矩阵中是否存在离群点。如amax的值大于阈值，那矩阵中存在离群点。反之则不存在。

更重要的是，amax操作可以和前一个操作融合。这样不仅以极低的代价检测离群点的存在，还通过对图层进行融合来降低量化的开销。

基于以上的分析，MixQ的设计使用了三个关键技术：

一是**对计算图的等价变换** 。

针对混合精度的计算逻辑进行了等价变换以后，通过计算激活矩阵的amax的值，避免了检测离群点的开销。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdPzOczYZs38QSckrmDyUicCxfhxdHvzmbfvlzBwFMpIJoiakllJnvwlDA/640?wx_fmt=png&from=appmsg)  

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdpSX8u4Df4H2ibCdsa2iaXmdzTjAciaHxP8ffQd5PDdAmN5Er3ey1ctODg/640?wx_fmt=png&from=appmsg)**

###### **△** 图10 优化混合精度的计算逻辑

二是**设计混合精度数据结构** 。

MixQ将离群点“拼接”成了一个新的矩阵。这一方法相较于ATOM采用的重排列（reorder）具有更低的开销。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzd3p0ib2Nzngg0vPOKf8auw6aYIzPwibvDsZgZM38rqy6zZ1vkhd2snpuA/640?wx_fmt=png&from=appmsg)**

###### **△** 图11 MixQ：order-reserved数据结构

三是**使用CUTLASS编写高性能的混合精度的算子** ，这一关键技术的实现依赖于NVIDIA提供的高性能矩阵乘法模板CUTLASS 3.x。

MixQ在寄存器中反量化低精度的计算结果并与高精度的结果进行相加。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzddCxCVrExmwAWia5P1htrFbtK0hrArkmDK4XTGMsazJpgpTMUeVnNN0g/640?wx_fmt=png&from=appmsg)**

###### **△** 图12 融合dequantize、scale和add操作

下面来看MixQ的实验结果，以LLaMA 70B为例。

在准确率表现方面，MixQ的准确率和Bitsandbytes一致。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzd4ho3rwxpNPp6dDqL2u3MFWDolLibMX0G2R8TP3icbRvN7icpgB8C6MDAg/640?wx_fmt=png&from=appmsg)**

###### **△** 图13 MixQ的推理精度

在性能表现方面，MixQ 8bit kernel是Bitsandbytes的1.9倍。

MixQ 4bit Kernel的性能达724TFLOPs，是FP16的3.13倍。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdpcmIyJ2DdJQrVGfOMTZLhaISr9YAzpRACZfdOcxp3Kw9SrZhtBv4qg/640?wx_fmt=png&from=appmsg)**

###### **△** 图14 MixQ Kernel性能

端到端测试下，MixQ在batch=512相对Bitsandbytes和AWQ加速1.78和6倍。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzdpXUr9B2GmaALCEcibudYP8kzmrJKHTkXcKNfKF0Vdibj3gNCrPWY4ELg/640?wx_fmt=png&from=appmsg)

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCfEeQVAHCict3MEmZqWCvzd7j85ax6cFLWiaiczAMWxnFdRml8ZvkUdOd5ia7VQK6n9FTa3cy1aJHWJQ/640?wx_fmt=png&from=appmsg)**

###### **△** 图15 多batch测试；上：MIXQ的推理输出（19.21it/s）；下：FP16的推理输出 （13.56it/s）

项目地址：  
[1]https://github.com/Qcompiler/MixQ_Tensorrt_LLM  
[2]https://github.com/Qcompiler/MIXQ  
[3]https://github.com/Qcompiler/vllm-mixed-precision

— **完** —

  

投稿请发邮件到：

**ai@qbitai.com**

标题注明【投稿】，告诉我们：

你是谁，从哪来，投稿内容‍

附上论文/项目主页链接，以及联系方式哦

我们会（尽量）及时回复你

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

