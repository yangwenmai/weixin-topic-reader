# 10秒创造一个世界！吴佳俊团队新作实时交互式3D世界生成，比现有技术快100倍

文章作者: 量子位
发布时间: 2024-10-26 13:00
发布地: 江苏
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247754943&idx=4&sn=ff19196cc8457e32b7323a02c0b13415&chksm=e8dc53cddfabdadbf222f6fcaf188c366edd839eb8a91547ccb08ebabf4de34be8e895e6ce02#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIvCnBAkyHHa7uibmE0gG7v3re5ibyMJfl5D5ypwK4BibJlpZAER6icDaDCg/300

##### WonderWold团队 投稿  
量子位 | 公众号 QbitAI

斯坦福吴佳俊团队与MIT携手打造的最新研究成果，让我们离实时生成开放世界游戏又近了一大步。‍‍

从单一图像出发，在用户的实时交互下生成无限延展的3D场景：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIIjBSsyetRFZoru0d5mCrjFswdmj2oebYJve8Rab8hcLhlo40Q6YLmw/640?wx_fmt=gif&from=appmsg)

只需上传一张图片，就能踏入一个由AI创造的虚拟世界。用户可以通过移动视角和输入文本提示，实时决定接下来要探索的方向和场景内容：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIurdmwVakgxnlLVE6xvSsMoiaLbN8FejgDMjVoTjiaIq34aOWt8Hvve0A/640?wx_fmt=gif&from=appmsg)

从鸟瞰图的视角，可以清晰看到虚拟世界的生成过程：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwI9QBlkjUiaibShLDOdqb7N8B90FUOOicloVoR1DRuw8hYFWBSib6BgC57TQ/640?wx_fmt=gif&from=appmsg)

无论是魔幻森林、现实都市，还是宁静乡村，WonderWorld都能在眨眼间为你呈现：

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwI0Nl9mHOUGVynWRgbqaia9EYDxTT3CyZBE02WCfDHr28wdNiaskA3rFfQ/640?wx_fmt=gif&from=appmsg)

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIdsc5zwFRS2dFY4NK3lWbwgI7Sr6FB5vCKOeKgezcnBSBMtJfqiakVzw/640?wx_fmt=gif&from=appmsg)

这项工作名为**WonderWorld** ，由斯坦福吴佳俊团队和MIT联合打造。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIeVM77RDOIHc1UMforJ8lSp0pawBL7DPO3DZICDmSLLshRGMAOSZhDA/640?wx_fmt=png&from=appmsg)

WonderWorld的项目主页上还有能以**第一视角移动的交互式场景** ：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIWL4akXFL9ZtBlp74ZLpw3hbVqdv27L35iblzGXayjkhfj1S1C2jwkNA/640?wx_fmt=png&from=appmsg)

资深游戏创业者，GOAT Gamin的首席AI官兴奋地表示：“它还能对非真实感的图片work。有无限多的可能性！”

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIanTeWhsZiaEmIr96eMpR2ibIrMBrltQCDZL7MpibAzP4LpZyy18WcyxGA/640?wx_fmt=png&from=appmsg)

在硅谷广受欢迎的Hacker News上，WonderWorld也一度被放在头版讨论：

![](https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIFRgSeicIm3EMeUU3F94CLwFLYK6eymqpo1XrEx31DK63COrpruLAl9A/640?wx_fmt=jpeg&from=appmsg)  

要知道，之前的生成式AI方法都需要数十分钟甚至若干小时才能生成一个单独的场景，WonderWorld的速度可谓打开了交互式新世界的大门。

那这究竟是如何做到的？

## 交互式生成 3D 世界

要让用户来控制生成一个3D世界，**最核心的难点在于生成速度**
。先前的AI生成3D场景的方法大都需要先逐步生成许多目标场景的2D图片来补全被遮挡的部分，然后再优化得到一个3D场景的表示。这个过程耗时颇多。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIyJVobHABBCibP21te1KTpv5ZNT2Jt0xA37t8iaXgVGdeoJmvfaTpOHFA/640?wx_fmt=png&from=appmsg)

WonderWorld的核心突破在于其惊人的速度。

研究团队开发的**FLAGS**(Fast LAyered Gaussian Surfels)
场景表示方法，使得系统能在短短10秒内生成一个新场景。这一速度比现有方法快了近100倍，真正将交互式3D世界生成推向了实时的门槛。

具体来说，WonderWorld生成新场景时，会先生成一张场景的2D图片（对于第一个场景则是直接使用输入图片），从图片中生成三张layer
images，再从layer images来生成 FLAGS 表示。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwImCkBeib1s99iav7S85KQngYDR2Y0Fc8vh5DhltIfGlBCEXm8q520icymA/640?wx_fmt=png&from=appmsg)

FLAGS表示由三层**Gaussian surfels** 组成：**天空层，背景层，以及前景层** 。每一层都从对应的layer
image中生成。天空和背景的layer image 都单独进行了遮挡的补全，因此WonderWorld不需要逐步生成多张图片。

另外，FLAGS表示的每个Gaussian surfel都唯一对应一个layer image
上的像素，因此它可以使用估计的像素级别几何信息（如单目深度和单目法向量）来初始化Gaussian surfels的参数，从而加速其优化过程。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIVfFRVMgiaV11pwIGn8JrIibTYyqLHP1bBxssDrvPEOeSibichbv8vNmEaQ/640?wx_fmt=png&from=appmsg)

最后，WonderWorld 还针对多个3D场景之间经常出现几何“裂缝”的问题，提出了**Guided depth diffusion**
。核心想法是，利用已经生成的 3D 场景的深度信息作为
guidance，使新生成场景的深度与其一致。只要新旧场景在连接处的深度一致，那么场景的裂缝就得以弥合。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIAKRoz2YVC5Po4NLqKaLeUoSubicJ2GkYMzW6iaeDnoe9QAbsMxrriajQw/640?wx_fmt=png&from=appmsg)

值得一提的是，无论是2D图片生成还是深度估计模块，都可以直接采用预训练模型，因此整个框架不需要任何训练。

## 实验测试

由于先前没有任何方法可以做到交互式3D场景生成，研究人员采用了连贯3D场景生成的方法**WonderJourney**
，单一场景生成的**Text2Room** 以及**LucidDreamer** 作对比。由于缺乏现有可用评估数据集，研究人员生成了28个场景作为测试。

研究人员首先展示了更多的交互式生成的场景，从而说明WonderWorld可以在应用到不同场景类型以及不同视觉风格：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwI8xZempIL6LWGQnvxuQBM1NdaBUSLpeSMDkgSPQVmmFYictzd4Zebzcw/640?wx_fmt=png&from=appmsg)

与基准方法的比较表明，WonderWorld明显优于各个方法：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIcFj1e9nHia6AMATHwUagyo61VC4H4GiboX0HjJTwTcD6HXYibX7jVVz8g/640?wx_fmt=png&from=appmsg)

从人类偏好评估的角度，WonderWorld 也显著更受青睐：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIRnrlkZpnKHkYcm8MCfhTOeGhm8T8V1It3KprE5zOk4r8LBQcBoaqKA/640?wx_fmt=png&from=appmsg)

此外，从一张输入图片，WonderWorld能够接受不同的用户控制，生成不同的场景内容：

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIKKEg9lnbS1ZwMboPDuLwPIBY4muSnXO8QoSHYEF8YIRgyFwoCOA8gg/640?wx_fmt=png&from=appmsg)

## 作者简介

该篇论文主要作者来自斯坦福大学吴佳俊团队。

论文一作**俞洪兴** ，斯坦福大学五年级博士生。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIUgQVaQYUA3jcNacibokUqk9fMy6UELW9yNSmZS3YBgB2WCWQ7ibQfexQ/640?wx_fmt=png&from=appmsg)

主要研究领域为重建可交互的物理世界。他曾获得 SIGGRAPH Asia 最佳论文奖，高通奖学金，以及 Meta 奖学金和 NVIDIA 奖学金的提名。

**吴佳俊** ，现任斯坦福大学助理教授，隶属于斯坦福视觉与学习实验室（SVL）和斯坦福人工智能实验室（SAIL）。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtC1GZ3VFV3alHDgZqQdaHwIiaQWcXLBykFvLTJPUNicWibEhRzPForox4Z0IzNAPQcaFECB7HO6G1CIQ/640?wx_fmt=png&from=appmsg)

在麻省理工学院完成博士学位，本科毕业于清华大学姚班，曾被誉为“清华十大学神”之一。

论文链接：  
https://arxiv.org/pdf/2406.09394

参考链接：  
[1]https://x.com/Koven_Yu/status/1835769026934673595  
[2]https://kovenyu.com/wonderworld

— **完** —

  

投稿请发邮件到：

**ai@qbitai.com**

标题注明【投稿】，告诉我们：

你是谁，从哪来，投稿内容‍

附上论文/项目主页链接，以及联系方式哦

我们会（尽量）及时回复你

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

