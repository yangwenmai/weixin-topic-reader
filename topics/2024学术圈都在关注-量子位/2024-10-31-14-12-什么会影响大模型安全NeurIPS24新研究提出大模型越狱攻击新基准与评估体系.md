# 什么会影响大模型安全？NeurIPS'24新研究提出大模型越狱攻击新基准与评估体系

文章作者: 量子位
发布时间: 2024-10-31 14:12
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247755828&idx=6&sn=f67f30ade34164bb6e1792afb33bcdec&chksm=e8dc5f46dfabd650149d714e3d500170226caf303ff5941fbb4498d59654f3542426fba20ed4#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1he4qAkat0b5hQibYD3R5kfpSnRzIXtprBmTlu1uQJR7IhEzAzztYzXpw/300

##### USAIL团队 投稿  
量子位 | 公众号 QbitAI

全新大语言模型越狱攻击基准与评估体系来了。

来自香港科技大学（Guangzhou）USAIL研究团队，从攻击者和防御者的角度探讨了什么因素会影响大模型的安全。

提出**攻击分析系统性框架JailTrackBench** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hxgTfRUUreVTd2W8iajYxXib95ZtjCD4cJj8YInaddxcQoadLZXRJFfXg/640?wx_fmt=png&from=appmsg)

JailTrackBench研究重点分析了不同攻击配置对LLMs性能的影响，包括攻击者的能力、预算、对抗性后缀长度，以及模型的大小、安全对齐情况、系统提示和模板类型。

其研究成果《Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs》现已被NeurIPS D&B
2024接收。

此外，为了全面解决大语言模型的越狱问题，USAIL团队不仅专注于攻击，还深入探讨了**越狱评估** 这一核心问题。

## 越狱分析JailTrackBench

近年来，随着人工智能的迅速发展，尤其是大语言模型（LLMs）的广泛应用，保障模型的安全性并防止其被恶意利用，已成为一个重要的议题。越狱攻击通过恶意指令诱导模型生成有害或不道德的内容，对模型的安全性和可靠性构成了严峻挑战。

这种攻击与防御的博弈，极大地推动了大模型安全性的提升。

在这一背景下，香港科技大学（Guangzhou）USAIL研究团队从攻击者和防御者的角度，探讨了影响大模型安全性的关键因素。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hsy7fWOWfNWic13UEbL7D7cX0CiaMSrnDU5D5hfEyrnUDcW3kBfc1qBGg/640?wx_fmt=png&from=appmsg)

尽管已有研究揭示了多种越狱攻击的威胁，现有的评估方法往往过于片面，无法全面涵盖攻击与防御两方面的核心因素。

为此，团队提出了JailTrackBench，一个全面涵盖越狱攻击各个方面的系统性基准测试框架，旨在为研究人员提供一个标准化、全面的评估工具。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hwmibDESGGxzxc1CzEicz4dBbmcdmxLh00ibXCXdPEzV69RPtZoAPLujqA/640?wx_fmt=png&from=appmsg)**

###### **△** 图1 JailTrackBench框架

通过对七种具有代表性的越狱攻击和六种防御方法的320项实验，使用50,000 GPU小时，团队以标准化的方式评估了这些攻击方法的效果。

#### 目标模型层面

**模型大小（Model Size）** ：

实验（如图2所示）中选择了不同规模的模型（如Llama-7B、Llama-13B、Llama-70B，Qwen1.5-14B等）进行对比，探讨模型规模对越狱攻击的防御能力是否有显著影响。

实验结果表明，模型的鲁棒性并不与其规模成正比，较大的模型并不总是比较小的模型更具防御能力。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hBI7zj5iaw5D0GQNZo5gIU5bZWGyK5HAficYv3GIC3ibaIW6uynic7p83Zg/640?wx_fmt=png&from=appmsg)**

###### **△** 图2 模型大小与鲁棒性的关系

**安全对齐情况（Safety Alignment）：**

模型的安全能力会被后续的大模型微调所影响。

实验表明（如图3所示），经过领域类的微调（fine-tuning）大模型，其安全能力会降低，相比之前没有微调的模型则更容易受到攻击。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hqXMEVicT07XC9wDapE5qbTq9XuN4hJUuPyMGPCr1lnnBzzUz708iaBiag/640?wx_fmt=png&from=appmsg)**

###### **△** 图3 安全对齐情况与模型鲁棒性

**系统提示（System Prompt）** ：

实验（如图4所示）还评估了系统提示（如包含安全提示的系统消息）对模型安全性的影响。结果显示，包含安全提示的系统消息能够显著增强模型的安全性，减少攻击成功率。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hoAXtgIcicQVMlDwoBIJkUa07WF1Qscr5koH5mWlePqzFPZB3aAVBDfQ/640?wx_fmt=png&from=appmsg)**

###### **△** 图表 4 系统提示与模型类型

**模板类型（Template Type）** ：

实验（如图5所示）测试了不同提示模板（如零样本提示与默认提示）对越狱攻击成功率的影响。结果显示，使用默认提示的模型比使用零样本提示的模型更加安全。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hSdMOJ1bVUMLDiajJ85BJHwneNCLS4rgFcicB0TeEVwJMUIIcxYvFOASQ/640?wx_fmt=png&from=appmsg)**

###### **△** 图5 模版类型与模型鲁棒

#### 攻击者层面

**攻击者能力（Attacker Ability）** ：

攻击者（如图6所示）使用不同的模型（如GPT-3.5、GPT-4、Vicuna-13B等）来生成对抗性提示，实验评估了不同攻击者模型能力对越狱攻击成功率的影响。结果表明，攻击者模型越强，越狱攻击的成功率越高。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hZUJpL6vJtQ2kI3qJGwGOzaKh5CoPfSzJ64N5o2gzgc4KftEJXoiciarg/640?wx_fmt=png&from=appmsg)**

###### **△** 图6 攻击者能力与攻击效果

**对抗性后缀长度（Adversarial Suffix Length）** ：

在针对令牌级别的越狱攻击中，实验（如图7所示）通过调整对抗性后缀的长度（如10、20、30等）来评估其对攻击成功率的影响。结果表明，较长的对抗性后缀通常能提高攻击成功率，但超过一定长度后效果趋于平稳。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hlciax6OG0vnFhMtlJoy5vCkIenchbS4dKgzicFUbEjORryniazp3s0fJA/640?wx_fmt=png&from=appmsg)**

###### **△** 图7 对抗性后缀长度与攻击效果

**攻击者预算（Attacker Budget）** ：

实验（如图8和9所示）探讨了攻击者可以提交的查询次数对攻击效果的影响。实验表明，对于令牌级别的攻击，攻击预算越大，攻击成功率越高；而对于提示级别的攻击，预算的影响则较为有限。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hODES2HFSoJGxMIYK0hL4qQtiaTiaKsQyibdwhHMlvH3ic54TxtzynzLqPw/640?wx_fmt=png&from=appmsg)**

###### **△** 图8 指令级别攻击的预算

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hMG1cI0FI2R15bKSl1rNWwRpMzuNld3IvawZCSXFR0ayaFwyETM3iawg/640?wx_fmt=png&from=appmsg)**

###### **△** 图9 提示级别攻击的预算

**攻击意图（Attack Intention）** ：

实验（如图10所示）设计了多种不同的攻击意图（如隐私侵犯、恶意软件等）来评估其对攻击成功率的影响。结果表明，不同的攻击意图会显著影响攻击的成功率，某些攻击意图（如经济损害）更容易成功，而其他意图（如隐私侵犯）则较难得逞。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hXFTyZgYe4WvrV421mmnU6TEiavEVPA0EJOia4FS6fbRVN0IPyqzQzQzg/640?wx_fmt=png&from=appmsg)**

###### **△** 图10 攻击者意图

通过对一些不易察觉的设置进行简单调整（见表1），包括攻击者和目标模型，研究发现大模型越狱攻击的成功率可以从0%飙升至惊人的90%（如图11所示）。这些设置涵盖了多个关键因素，如目标模型的规模、安全对齐方式、系统提示的使用，以及攻击者的能力和攻击预算。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hcGZriaNE1JNyhMenib5atWOENSKeVnvia5kkQ9eT14bnL9Gfp2ibn79GZw/640?wx_fmt=png&from=appmsg)**

###### **△** 表格1：不同技巧组合的配置，从弱到强（weak to strong）

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hia6lUdbhd2YacL0bvYeKxUAoduaSNw1Oric7Mh2ts4bBTQVjr60U3ITw/640?wx_fmt=png&from=appmsg)**

###### **△** 图11 不同技巧组合对越狱攻击成功率的显著影响

## 越狱评估JAILJUDGE

越狱评估依赖于对模型输出内容的有害性进行分析，这一任务复杂且充满不确定性（见图12）。因此，迫切需要一种系统化的评估方法，帮助研究者和开发者深入了解模型的脆弱性，并持续优化其防御能力。

**JAILJUDGE** ，在此背景下应运而生的。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1h9OvA5t41CJtXwEqv4KEuCf2pKOhd5cp5Lib6980M47iaX6zaApwLGlGQ/640?wx_fmt=png&from=appmsg)

由USAIL团队联合百度搜索团队及英国伯明翰大学共同提出，JAILJUDGE旨在弥补现有越狱评估工具的不足，尤其是应对复杂场景下的挑战。

该评估框架涵盖广泛的风险场景，如对抗性越狱查询、真实世界交互以及多语言环境等。JAILJUDGE的核心创新是引入了多Agent越狱评估框架，借鉴法庭审判的模式，通过多个Agent的协作，实现对越狱判断过程的明确化和可解释性。

每个Agent（如判断Agent、投票Agent和推断Agent）分工明确，通过协作得出精确的评估结果，并提供解释性理由。

######
**![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBGfJOKZNWuuw8ia4FboQU1hacYG0WoRNy1nJhz8ysWDBgGW7dGZ4aFK9bWLg3EMbmTyHlkHE8Ulicg/640?wx_fmt=png&from=appmsg)**

###### **△** 图12：越狱评估：输入用户问题和模型回答，判断大模型是否被越狱

为进一步提高评估效率，USAIL团队开发了**JAILJUDGE Guard**
，这是一种端到端的越狱评估模型，不需要API调用即可提供细粒度的越狱评分（评分范围从1到10），并伴随推理解释。

JAILJUDGE Guard不仅在评估精度上超越了现有的顶级模型（如GPT-4和Llama-
Guard），还在闭源和开源安全模型上展现了强大的评估能力，同时具备更高的效率和更低的成本。

此外，团队还推出了**JailBoost和GuardShield**
两大工具，以强化越狱攻击和防御。实验表明，JailBoost在零样本设置下将攻击成功率提高了约29.24%，而GuardShield则将防御后的攻击成功率从40.46%大幅降低至0.15%。

未来，团队计划进一步扩展JAILJUDGE的功能和应用场景，包括：

  * **动态场景测试** ：扩展数据集，增加更多动态和实时的越狱攻击场景，以模拟实际应用中的复杂环境，提升评估的代表性。

  * **跨领域应用** ：将JAILJUDGE应用于医疗、金融等关键行业，评估并保障这些领域中LLMs的安全性。

  * **多模态扩展** ：探索多模态数据的越狱评估，结合文本、图像、音频等多种数据类型，全面评估LLMs在多模态环境下的安全表现。

  * **协作防御机制** ：开发基于多Agent的协作防御机制，使模型在面对复杂攻击时能够自适应进行防御，进一步提升整体安全性。

项目网站：https://secure-intelligence.github.io/  
团队链接：https://github.com/usail-hkust

JailTrackBench  
论文地址：https://arxiv.org/pdf/2406.09324  
代码：https://github.com/usail-hkust/Bag_of_Tricks_for_LLM_Jailbreaking  
JAILJUDGE  
论文地址：https://arxiv.org/abs/2410.12855  
项目主页：https://usail-hkust.github.io/Jailjudge  
代码：https://github.com/usail-hkust/Jailjudge  
数据集：https://huggingface.co/usail-hkust/JailJudge-guard  
端到端越狱评估模型：https://huggingface.co/usail-hkust/JailJudge-guard

— **完** —

  

投稿请发邮件到：

**ai@qbitai.com**

标题注明【投稿】，告诉我们：

你是谁，从哪来，投稿内容‍

附上论文/项目主页链接，以及联系方式哦

我们会（尽量）及时回复你

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

