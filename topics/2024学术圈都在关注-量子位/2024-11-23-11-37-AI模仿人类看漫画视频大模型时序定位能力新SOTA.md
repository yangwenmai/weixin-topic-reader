# AI模仿人类看漫画，视频大模型时序定位能力新SOTA

文章作者: 量子位
发布时间: 2024-11-23 11:37
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247760645&idx=4&sn=7553f4215e781b6170468e3bd2945657&chksm=e8dc4c77dfabc56198f8af741e7214c3987f3846097d9c41b5ee3efe9aca7a05f2d8e5b3114c#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAZUq2pLhNEKWFRuBiccKBpulUUAcX7Wlfy2BHpPhW3Jbyp5pHmEhg0ZReSF4XFrE2BgDbfAQVmQhw/300

##### NumPro团队 投稿  
量子位 | 公众号 QbitAI

用看漫画的方式，大幅提升视频大模型时序定位能力！

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAZUq2pLhNEKWFRuBiccKBpuj93yFlRCTx7PbwRMRFbHnl6mBFkBbzW01XiaicAXuSibm9kWF7vzicpxEA/640?wx_fmt=png&from=appmsg)

方法名为**NumPro** ，**无需训练** ，通过**数字视觉提示** 就能增强。

就像漫画中用编号的画格引导读者按顺序理解故事，将视觉内容与清晰的时间线联系起来一样。

NumPro通过**在视频帧上添加独特的数字标识符** ，将视频时序定位转化为直观的“翻阅漫画”式过程，使Vid-
LLMs能够轻松“读取”事件时间线，准确关联视觉内容与相应的时序信息。

实验中，NumPro显著提升了视频时序定位能力，在多个基准上超越此前SOTA，而且还能保持对模型通用视频理解能力影响较小。

这项工作由来自东南大学、马克斯·普朗克信息学研究所、腾讯微信团队、加州大学伯克利分校的研究人员共同完成。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAZUq2pLhNEKWFRuBiccKBpuh0yia8w4cp7Dibno1n9H62p7x2bQEXFspfHVtBGMlt8ib7vTB5ibtKRmlA/640?wx_fmt=png&from=appmsg)

## NumPro方法核心创新

视频大语言模型（Vid-LLMs）在视频内容理解问答对话方面已取得显著进展，但在精确的时序定位任务（Video Temporal Grounding,
VTG）上仍面临挑战。

例如，在实际应用中，识别视频中事件的发生时刻，如定位厨师添加调料的精确时间，对于现有模型来说颇具难度，这一挑战阻碍了视频理解技术在众多领域的深入应用。

传统方法在增强模型的VTG能力时，往往需要大量的重新训练或复杂的模型适配，灵活性和可迁移性受限。

NumPro是如何实现的呢？

**无需训练设置** （Training-Free）：

在无训练设置下，NumPro直接为每个视频帧标记对应的帧号。

借助Vid-LLMs内置的光学字符识别（OCR）能力，模型能够通过与视觉内容相关联的帧号“读取”时间线。

为明确添加数字的目的，在每个事件查询前添加简单指令，告知模型帧号的含义。如此，Vid-LLMs可直接将帧号与语言查询链接，准确识别帧级边界。

**微调优化设置** （Fine-tuning Setting）：

为进一步提升性能，NumPro-FT在经过了NumPro增强数据集上对Vid-LLMs进行微调。

此过程将帧号与训练数据中的时间跨度对齐，将时序定位能力嵌入模型的学习表示中。

微调时，冻结视觉编码器，仅对视觉投影仪和大语言模型（LLM）组件进行优化，并采用低秩适应（LoRA）技术调整LLM，有效减少参数数量和训练开销。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAZUq2pLhNEKWFRuBiccKBpuv4Qk4wHAQsDaWH1Bzia7CG8rwKvVE65J70bDrJNMwqO57eEVlEialiaZA/640?wx_fmt=png&from=appmsg)

为确保NumPro的有效性，研究团队从**字体大小、颜色和位置** 三个关键因素对其进行精心设计优化。

通过基于CLIP的实验，使用Number Accuracy和Caption Accuracy两个指标平衡数字的可识别性和对视觉内容的干扰。

最终确定了字体大小为40、颜色为红色、位置在右下角的最优设计，该设计能最大程度发挥Vid-LLMs的OCR和视觉语言对齐能力，实现精准的视频时序定位。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAZUq2pLhNEKWFRuBiccKBpuOicjeoEDZYbnnoZjqicV9FZxvy0VImGORUjK7alALLJU4zic4r0EY2xpQ/640?wx_fmt=png&from=appmsg)

## 实验成果显著

在标准VTG基准测试中，NumPro表现卓越。

在Moment Retrieval任务中，无需训练的NumPro使Vid-LLMs性能接近或超越以往最优水平。

而经过NumPro-FT微调后，LongVA-7B-DPO在Charades-
STA和ActivityNet数据集上的多个指标上均大幅超越现有SOTA，展现出NumPro在提升模型时序定位能力方面的巨大潜力。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAZUq2pLhNEKWFRuBiccKBpuk8ERy4kibopOOaruFAFibwuFFfiaoibXnF2UJ5eqHhL8gsf3CpHPOASEYA/640?wx_fmt=png&from=appmsg)

NumPro不仅在领先模型上效果显著，对多种Vid-LLMs也具有广泛的适用性。

应用于不同模型如LLaVA-Video-7B、LLaVA-
OneVision-7B和Qwen2-VL-72B等，均带来了显著的性能提升。此外，在与微调结合时，NumPro-
FT始终优于传统微调方法，尤其在较长视频数据集上表现出色。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAZUq2pLhNEKWFRuBiccKBpueHkRjVqZRict0j8R2RQ4jSLbRBxBsHkf815mZZ0h2bT3N3udz76O36g/640?wx_fmt=png&from=appmsg)

将NumPro集成到通用视频问答任务（如VideoInstruct基准测试）中，发现其对一般理解指标影响极小，在保持强大通用视频理解能力的同时，显著提升了视频时序定位能力。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAZUq2pLhNEKWFRuBiccKBpuIbQMwXdoYC0qojAwichckvw3d0u1XKKgNiapK6JAj8bQCztCARQiaXxbQ/640?wx_fmt=png&from=appmsg)

论文连接：https://arxiv.org/pdf/2411.10332  
代码仓库：https://github.com/yongliang-wu/NumPro

— **完** —

**定档12月11日**

**「MEET2025智能未来大会」开启****报名**

**李开复** 博士、**周志华** 教授、智源研究院**王仲远** 院长都来量子位**MEET2025智能未来大会** 探讨行业破局之道了！

[首批嘉宾阵容在此](http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247757251&idx=2&sn=11dec7ffe71ebe12995699ca9fd33277&chksm=e8dc5ab1dfabd3a7f85258405138d5cfd9b0ae5853b1fea0b16638dd3686869d036a8b349d1f&scene=21#wechat_redirect)，**观众报名通道已开启
！**欢迎来到MEET智能未来大会，期待与您一起预见智能科技新未来！

**  
**

**点这里 👇关注我，记得标星哦～**

**一键三连「点赞」、「分享」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg)

