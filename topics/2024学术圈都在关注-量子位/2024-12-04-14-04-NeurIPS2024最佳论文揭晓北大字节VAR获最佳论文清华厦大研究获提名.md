# NeurIPS 2024最佳论文揭晓！北大字节VAR获最佳论文，清华厦大研究获提名

文章作者: 量子位
发布时间: 2024-12-04 14:04
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247763774&idx=3&sn=9127a6daa95231895093f27ddadac929&chksm=e8dc704cdfabf95ac3512e7600ba0b4f51d7e1c6ef2d796d202322e9747f934e96427316a89d#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAh9MlP6vG4rng17ccgOhvzO0BkbGVfx38AsdG3Z0xn3zSynYqpSYiblWsZOxULqDFg6tk6Cs7Cqrw/300

##### 一水 发自 凹非寺  
量子位 | 公众号 QbitAI

就在刚刚，NeurIPS 2024**最佳论文** 出炉！

4篇获奖论文中，有3篇为华人一作，分别来自北大、新国立、厦大清华等。

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtAh9MlP6vG4rng17ccgOhvzDQibl1ibyIpueEuvumpaX3lgbwNKSHm5BaRJ9vEAXJx7ddVqjyicwujIg/640?wx_fmt=gif&from=appmsg)

据了解，NeurIPS 2024将于12月10日（星期二）至12月15日（星期日）在温哥华举办。

和去年相比，今年能够获奖的难度再次升级——

本届共收到**15671篇** 有效论文投稿，比去年又增长了27%，但最后接收率仅有**25.8%** （去年为26.1%），大概4043篇左右。

接下来，快来康康获奖论文有哪些吧～

## 两篇最佳论文（Best Paper）

**1、《Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale
Prediction》**  
（视觉自回归建模：通过Next-Scale预测生成可扩展图像）

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAh9MlP6vG4rng17ccgOhvzCRS8eriaRTu0hicydm59jicFFJCnvGZJ3cLHCfUZ9nxNcpVTw2V9pFuoA/640?wx_fmt=png&from=appmsg)

本文由北京大学、字节跳动研究者共同完成。

论文核心提出了一种新的**图像生成框架Visual Autoregressive modeling (VAR)**
，首次使基于GPT风格的自回归模型在图像生成任务中超越了扩散模型，并验证了VAR模型的可扩展性和零样本泛化能力。

具体而言，论文引入了一种**多尺度的自回归策略**
。与传统的按像素或token顺序生成图像的方法不同，VAR模型通过从低到高分辨的多尺度token图进行自回归生成，每一尺度的token图都依赖于前一尺度的结果。

这种方法的一个关键优势是，它能够显著减少生成高分辨率图像时所需的自回归步骤，从而降低了计算复杂度，提高了生成速度。

最终，VAR模型在ImageNet数据集上的验证表明，它能显著超越现有的自回归模型和一些扩散模型，并且还表现出了视觉生成领域的**Scaling
Laws** 。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAh9MlP6vG4rng17ccgOhvzpyZAhB4uKWY12r1TtE1xZdXibWmFdlmUYhzYyqAfuxE09X93ww8xJFw/640?wx_fmt=png&from=appmsg)

**2、《Stochastic Taylor Derivative Estimator: Efficient amortization for
arbitrary differential operators》**  
（随机泰勒导数估计器：任意微分算子的有效摊销）

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAh9MlP6vG4rng17ccgOhvzkZzicQ26f9YgVBMCiaD4bcF9D86iaXdBSiaKRlhhmTnfgvqpsDcAeTfg4w/640?wx_fmt=png&from=appmsg)

本文由新加坡国立大学、 Sea AI Lab研究者共同完成，论文一作为**Zekun Shi** 。

论文核心介绍了一种名为**Stochastic Taylor Derivative Estimator (STDE)**
的高效算法，用于优化包含高维和高阶微分算子的神经网络损失函数，特别是在物理信息神经网络（PINNs）中。

具体而言，研究展示了如何通过正确构造单变量高阶AD输入切线（input
tangent），有效地对多元函数的任意阶导数张量进行任意收缩，这可用于有效地随机化任何微分算子。

当应用于PINNs时，与使用一阶AD进行随机化相比，本文方法提供了**1000倍以上** 的速度提升和**30倍**
以上的内存减少，而且现在可以在单个NVIDIA A100 GPU上，8分钟内解决100万维的偏微分方程（PDEs）。

总之，这项工作开启了在大规模问题中使用高阶微分算子的可能性。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAh9MlP6vG4rng17ccgOhvz95SM16A5WHME6iajScF9WNIHTib6SxbHCXQLCpOrEBSeUyibBBqaKMT0A/640?wx_fmt=png&from=appmsg)

## 两篇Best Paper Runner-up

（Best Paper Runner-up通常授予在某个领域表现杰出但未能获得最佳论文的研究工作，大众通常认为其水平代表亚军）

**1、《Not All Tokens Are What You Need for Pretraining》**  
（并非所有token都是预训练所需的）

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAh9MlP6vG4rng17ccgOhvzpjhDj0UE54K2bfEXoiaZfm09MdE68v5tG0Q5eetWNd7nI4ODlAVC7RQ/640?wx_fmt=png&from=appmsg)

本文由厦门大学、清华大学、微软研究者共同完成，论文共同一作为**Zhenghao Lin和Zhibin Gou（苟志斌）** 。

论文核心提出了一种新的名为**RHO-1**
的语言模型预训练方法，它挑战了传统的预训练方法，即对所有训练tokens应用下一个token预测损失。其主要观点是，并非所有语料库中的tokens对于语言模型训练都同等重要。

通过分析不同tokens的训练动态，论文发现不同tokens的损失模式存在差异，并且有些tokens的损失减少是显著的，而有些则不然。

基于这些发现，论文引入了一种称为**选择性语言建模** （Selective Language Modeling,
SLM）的新方法。SLM通过使用一个参考模型对tokens进行评分，然后只对评分较高的tokens进行训练，从而选择性地训练有用的tokens。

这种方法在15B OpenWebMath语料库上的持续预训练中，使得RHO-1在9个数学任务上的少数样本准确率（few-shot
accuracy）实现了高达30%的绝对提升。在MATH数据集上，经过微调后，RHO-1的1B和7B模型分别达到了40.6%和51.8%的准确率，仅使用了DeepSeekMath所需预训练tokens的3%。

此外，在对80B通用token进行持续预训练时，RHO-1在15个不同任务上实现了6.8%的平均提升，数据效率和语言模型预训练的性能都得到了提升。

不仅如此，论文还展示了SLM在数学和通用领域的有效性，并通过实验和分析强调了在大语言模型预训练过程中**考虑token级别** 的重要性。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAh9MlP6vG4rng17ccgOhvzuCrnkuJpcCMEBicfibQChhKqTOPB0cl71lTu4ib7tLBKL9ibKjntnvkYew/640?wx_fmt=png&from=appmsg)

**2、《Guiding a Diffusion Model with a Bad Version of Itself》**  
（使用扩散模型的一个糟糕版本引导其自身）

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAh9MlP6vG4rng17ccgOhvzcTfyb4TCIbcPhJ1aVu0pfMviciby2FwQ9ICutiaFsy6KT2IAiaSl2m01Ag/640?wx_fmt=png&from=appmsg)

本文由英伟达和阿尔托大学共同完成，论文一作为**Tero Karras** 。

论文核心提出了一种名为**自引导（autoguidance）** 的方法，通过使用主模型自身的一个较小、较少训练的版本作为引导模型，来提高图像生成质量。

论文指出，常见的无分类器引导方法是使用无条件模型来引导条件模型，这样既能实现更好的提示词对齐，也能得到更高质量的图像，但代价是**多变程度下降。**
而自引导方法通过引导模型的不完美性，能够在不减少多样性的情况下提高图像质量。

实验表明，这能显著提升ImageNet生成效果。论文使用公开可用的网络，为64×64分辨率下的生成创造了1.01的FID记录，为512×512创造了1.25的FID记录。此外，该方法也适用于无条件扩散模型，可极大提高其质量。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAh9MlP6vG4rng17ccgOhvz78z0HrNPdBT65IsYlnNnwiccNpm9JRUJ3m39HiblL8ic56mLfOia8dXIhw/640?wx_fmt=png&from=appmsg)  
![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAh9MlP6vG4rng17ccgOhvzqflMnU32ib3Rcff5RA0v2TMlIPyUiagFsxvUMQGLELVsibpPb3WOAicemA/640?wx_fmt=png&from=appmsg)

最后，感兴趣的家人们可以进一步查阅原论文~

最佳论文链接（按文章顺序）：  
[1]https://arxiv.org/pdf/2404.02905  
[2]https://arxiv.org/abs/2412.00088  
[3]https://openreview.net/pdf?id=0NMzBwqaAJ  
[4]https://arxiv.org/pdf/2406.02507

— **完** —

**12月11日**

**「MEET2025智能未来大会」****报名啦**

****💫** 李开复**博士、**周志华** 教授、智源研究院**王仲远** 院长都来量子位**MEET2025智能未来大会** 探讨行业破局之道了！

[💥
最新嘉宾阵容在此](https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247760478&idx=1&sn=a962f5ec367464f7b1ef4226ee14d668&scene=21#wechat_redirect)，**[点击报名参会]()**
欢迎来到MEET智能未来大会，期待与您一起预见智能科技新未来！

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8RMEMluHvXXn1Z5LDMHyQDicntpicVpMsiahfwsMg8MgGdO5ejzPW4teXw/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy81Il9DgaJxrgRX4zUb1xz8rPohAl28PjjYeXhR6dhSAAu5pMRmv7qjQ/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy89cNOibEdSw85cxuZjib7atGmDGNZ8dqSFUN2zgGz4RGPSKXoH7jkB5xA/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8iaKUicyqOGlPDL65A12QsuK70pZZOnOSB0SME9ZMfSCc5Qq0mm5nMgPQ/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8syKpcjniaRmtrLQrJg9GNgYIomwg4Qq3lFyqGYSbfuxGTWjeiacSpnhw/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8eJP5ftZURBKZAKehicVhzseicHFJaHJsAh2nbW063mWK8AGhWkJqBnYw/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8gj4IHyTGoqcvk9uXu3Y2nCWYO0Y1ibQyrwxyk2ul3jt7UkdGUfoKicmg/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy85CvF6A92e5diaSgxyERG8ETXXv6uFP3Lickd82YaDhmxqSICMfOpyYibw/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy82rnZIKQSe8fw1GLmtulnqYSucGKlAEb7ibd8lY7qblypUXVXxRiaEdFQ/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8HaiaMW3xF5PHZVAJTf7iaUEk7b3MkrV9FyJarUp8vtTxbAkrxC296ckw/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8OeMWxTH6QaXgyWqIjdj69eJZPnRBsZNEpBDibHgG1Yo6DwOEO0MOBwQ/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8HEOPgI8kIX7icbx6P5diby6ob9hUeLiaKibyYjsSlpHKeAZWIq1P3N4Lmg/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8B9eM7jib5vlJjFuQz2ibjU76GfINibud4o9sWFrCvRxUVkL0zLDaIyicQA/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8uMoHRibmdmvuHOZmhCZib80NcRl6lgdchI434o3iaYhQ3jI7blPAuTUAw/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8vpwKZSgZrGAyzduqMvYtvYAqNX3GFcDJia46ZHAvdxPcrnGPLicMXqmg/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8byuVf0rybEw8geo3fuNCnRQhUwKh7WQU8RIA2qUAdib3j7ibgsCnmXCg/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCVlQQnHDzSB3veUaiaBQdy8PsGcsUFKmLAERib0Iq0ibqtyvgnGL9nZQcz3GCicPMs8vfG0FgUmwoBug/640?wx_fmt=png&from=appmsg)![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M1vIWlXly8hwEkeb05aM7fcomv9Hbo9IHZqJ4xZW14l4HDJrL5kqicf9LzBf1MKwEMkxvf16CfNOrFj8pKYhHnSj/640?wx_fmt=svg&from=appmsg)

左右滑动查看最新嘉宾阵容

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M1vIWlXly8hwEkeb05aM7fcomv9Hbo9IHZqJ4xZW14l4HDJrL5kqicf9LzBf1MKwEMkxvf16CfNOrFj8pKYhHnSj/640?wx_fmt=svg&from=appmsg)

**点这里 👇关注我，记得标星哦～**

**一键三连「点赞」、「分享」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg)

