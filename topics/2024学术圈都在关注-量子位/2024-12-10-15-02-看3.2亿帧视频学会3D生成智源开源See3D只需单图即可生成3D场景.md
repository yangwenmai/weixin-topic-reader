# 看3.2亿帧视频学会3D生成，智源开源See3D：只需单图即可生成3D场景

文章作者: 量子位
发布时间: 2024-12-10 15:02
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247766083&idx=2&sn=7c83f5a862d91d246a72b571de43ccc8&chksm=e8dc6731dfabee274d64d7844bcd74338f7e072a4f7ac20ae7722b1f39c3e741e0ac6ae723dc#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtAse0zhFAHTicEgNAOXTlpCqWsehXeeacpBYEWzx04P7YT3WImymqiaozkA2UDhGkPyb5tAEYMSPTew/300

##### 梦晨 发自 凹非寺  
量子位 | 公众号 QbitAI

近日，著名AI学者、斯坦福大学教授李飞飞团队WorldLabs推出首个「空间智能」模型，仅输入单张图片，即可生成一个逼真的3D世界，这被认为是迈向空间智能的第一步。

几乎同时，国内**智源研究院** 推出了首个利用大规模无标注的互联网视频学习的3D生成模型**See3D** —See Video, Get 3D。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAse0zhFAHTicEgNAOXTlpCqH1SNWLTBCw0dcNWSCD4RrbvCCop6wYorc8q1GNuWDLOyNVJzYNKIlw/640?wx_fmt=png&from=appmsg)

###### **△** See3D支持从文本、单视图和稀疏视图到3D的生成，同时还可支持3D编辑与高斯渲染

不同于传统依赖相机参数（pose-condition）的3D生成模型，See3D采用全新的视觉条件（visual-
condition）技术，仅依赖视频中的视觉线索，生成相机方向可控且几何一致的多视角图像。

这一方法不依赖于昂贵的3D或相机标注，能够高效地从多样化、易获取的互联网视频中学习3D先验。

See3D不仅支持零样本和开放世界的3D生成，还无需微调即可执行3D编辑、表面重建等任务，展现出在多种3D创作应用中的广泛适用性。

相关的模型、代码、Demo均已开源，更多技术细节请参考See3D论文。

论文地址:  
https://arxiv.org/abs/2412.06699  
项目地址:  
https://vision.baai.ac.cn/see3d

## 效果展示

  

1\. 解锁3D互动世界：输入图片，生成沉浸式可交互3D场景，实时探索真实空间结构。

‍  

（备注：为了实现实时交互式渲染，当前对3D模型和渲染过程进行了简化，离线渲染真实效果更佳。）

‍  

‍**△** 实时3D交互  
‍

2\. 基于稀疏图片的3D重建：输入稀疏的(3-6张)图片，模型可生成一个精细化的3D场景。  

  

###### ****

###### **△** 基于6张视图的3D重建

######  

###### **△** 基于3张视图的3D重建

######  

###### 3\. 开放世界3D生成：根据文本提示，生成一副艺术化的图片，基于此图片，模型可生成一个虚拟化的3D场景。

######  

**△** 开放世界3D生成样例  
4\. 基于单视图的3D生成：输入一张真实场景图片，模型可生成一个逼真的3D场景。  

###### **△** 基于单张图片的3D生成

## 研究动机

3D数据具有完整的几何结构和相机信息，能够提供丰富的多视角信息，是训练3D模型最直接的选择。然而，现有方法通常依赖人工设计（designed
artists）、立体匹配（stereo matching）或运动恢复结构（Structure from Motion, SfM）等技术来收集这些数据。

尽管经过多年发展，当前3D数据的积累规模依然有限，例如DLV3D(0.01M)、RealEstate10K(0.08M)、MVImgNet(0.22M)和Objaverse(0.8M)。这些数据的采集过程不仅耗时且成本高昂，还可能难以实施，导致其数据规模难以扩展，无法满足大规模应用的需求。

与此不同，人类视觉系统无需依赖特定的3D表征，仅通过连续多视角的观察即可建立对3D世界的理解。单帧图像难以实现这一点，而视频因其天然包含多视角关联性和相机运动信息，具备揭示3D结构的潜力。

更重要的是，视频来源广泛且易于获取，具有高度的可扩展性。基于此，See3D提出“SeeVideo,Get3D”的理念，旨在通过视频中的多视图信息，让模型像人类一样，学习并推理物理世界的三维结构，而非直接建模其几何形态。

## 方法介绍

为了实现可扩展的3D生成，See3D提供了一套系统化的解决方案，具体包括：

**1）数据集：**
团队提出了一个视频数据筛选流程，自动去除源视频中多视角不一致或观察视角不充分的视频，构建了一个高质量、多样化的大规模多视角图像数据集WebVi3D。该数据集涵盖来自1600万个视频片段的3.2亿帧图像，可通过自动化流程随互联网视频量的增长而不断扩充。

###### **△** WebVi3D数据集样本展示

**2）模型：**
标注大规模视频数据的相机信息成本极高，且在缺乏显式3D几何或相机标注的情况下，从视频中学习通用3D先验是更具挑战的任务。为解决这一问题，See3D引入了一种新的视觉条件——通过向掩码视频数据添加时间依赖噪声，生成一种纯粹的2D归纳视觉信号。这一视觉信号支持可扩展的多视图扩散模型（MVD）训练，避免对相机条件的依赖，实现了“仅通过视觉获得3D”的目标，绕过了昂贵的3D标注。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAse0zhFAHTicEgNAOXTlpCqvAltTdjcnal2eFtSFP9YNB1xibU2SNKDbxUibMPYVe6wkuh1bJkyggvA/640?wx_fmt=png&from=appmsg)**△**
See3D方法展示

**3）3D生成框架：**
See3D学到的3D先验能够使一系列3D创作应用成为可能，包括基于单视图的3D生成、稀疏视图重建以及开放世界场景中的3D编辑等，支持在物体级与场景级复杂相机轨迹下的长序列视图的生成。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtAse0zhFAHTicEgNAOXTlpCq6lYcbRL7vwcAXhAJP2NCIFB0JthYcFwleaFUQczo6JVPyuc9bCRBbQ/640?wx_fmt=png&from=appmsg)**△**
基于See3D的多视图生成

## 优势

**a) 数据扩展性：**
模型的训练数据源自海量互联网视频，相较于传统3D数据集，构建的多视图数据集(16M)在规模上实现了数量级的提升。随着互联网的持续发展，该数据集可持续扩充，进一步增强模型能力的覆盖范围。

**b) 相机可控性：**
模型可支持在任意复杂的相机轨迹下的场景生成，既可以实现场景级别的漫游，也能聚焦于场景内特定的物体细节，提供灵活多样的视角操控能力。

**c) 几何一致性：**
模型可支持长序列新视角的生成，保持前后帧视图的几何一致性，并遵循真实三维几何的物理规则。即使视角轨迹发生变化，返回时场景依然保持高逼真和一致性。

## 总结

通过扩大数据集规模，See3D为突破3D生成的技术瓶颈提供了新的思路，所学习到的3D先验为一系列3D创作应用提供了支持。希望这项工作能够引发3D研究社区对大规模无相机标注数据的关注，避免高昂的3D数据采集成本，同时缩小与现有强大闭源3D解决方案之间的差距。

*本文系量子位获授权刊载，观点仅为作者所有。

  

— **完** —

![](https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtCMTiaQvFTH1BuicE6KgJEARU6aCY4PfZHwOUZ0icduoLL4pFsRC23KyvGAhjp4fIYWfVCaicicyVRAxHA/640?wx_fmt=jpeg)

**量子位** QbitAI

վ'ᴗ' ի 追踪AI技术和产品新动态

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg)

