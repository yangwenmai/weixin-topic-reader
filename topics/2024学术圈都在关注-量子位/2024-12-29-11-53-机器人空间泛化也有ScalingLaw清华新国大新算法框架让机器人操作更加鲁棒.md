# 机器人空间泛化也有Scaling Law！清华新国大新算法框架让机器人操作更加鲁棒

文章作者: 量子位
发布时间: 2024-12-29 11:53
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247769727&idx=3&sn=b1a8ca232f2e6f76031777d1e83c32ea&chksm=e8dc690ddfabe01b181eebdd5b17018ee5b5e3b54ca3488b8dcba834eb625f7f38de2a02fb84#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBicrYIMUGlphjhzjAxd3yb8SDXRgg2icxiaic94oJIib9kbNibj44T3sLX0bw8Cf8a66IyrNZpmIKNrw1A/300

##### 谭恒楷 徐学舟 投稿  
量子位 | 公众号 QbitAI

在机器人空间泛化领域，原来也有一套Scaling Law！

来自清华和新加坡国立大学的团队，发现了空间智能的泛化性规律。

在此基础上，他们提出了一套新颖的算法框架——**ManiBox** ，让机器人能够在真实世界中应对多样化的物体位置和复杂的场景布置。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicrYIMUGlphjhzjAxd3yb8cEqbR7CQWuVIdu264sfBYen852qYQVJDXtvsTodicjQzsVuGS9FfQBw/640?wx_fmt=png&from=appmsg)

在实际测试中，ManiBox实现了**34440cm³** 最大操作空间范围的高效覆盖，抓取成功率高达90%-100%。

在具身智能和机器人操作实验室中，往往会选择固定的setting进行实验，在业内被称为**“完美摆放位置”** 。

但在现实环境中，实现机器人的**空间泛化** ，以应对多样化的物体位置和复杂的场景布置，一直是个艰难的挑战。

显然，实现空间智能所需要的，绝不是只在实验室中操作一块极小的空间范围内的物体。

为此，研究团队基于发现的**具身智能的空间泛化性Scaling Law** ，推出了ManiBox这项成果。

## 让机器人走出实验室

ManiBox是一个创新性的机器人操作算法框架，深入探索了具身智能的空间泛化性的Scaling Law，并通过**大量模拟器数据和Bounding
Box** 这样的视觉低维特征引导，成功实现了**空间泛化、背景泛化和物体泛化** 的抓取任务。

除了开头展示的34440cm³空间泛化之外，ManiBox还实现了物体和背景的泛化。

物体方面，无论是苹果、钢杯，还是玻璃烧杯，ManiBox对各种形状、大小的物体都能精准抓取。

同时面对各种背景挑战，无论是不同颜色桌布、复杂桌面，还是动态光源和视频干扰，ManiBox始终表现稳定。

除了这几个泛化维度，ManiBox的强大适应性还让其轻松扩展至复杂操作任务，并在真实环境中成功完成了抓取半空中物体、杂乱桌面上的物体，甚至倒水等操作。

**抓取半空中物体** 时，ManiBox能灵活应对动态目标：

在**拥挤环境** 中，也能够精准抓取：

还可以精细操作复杂物体的局部，比如**抓取杯子的把手** ：

除了抓取之外，通过修改teacher policy，还能实现向不同瓶子中倒水的操作，精准调整角度与力度，并实现平稳且可控的液体倾倒：

另外作者的实验还表明，即使在**视觉遮挡率高达40%或Bounding Box识别噪音高达5%** 的情况下，ManiBox依然展现强大的鲁棒性和操作能力。

即便在黑暗环境下，检测模型**大部分时间下没有检测到目标物体** ，纯靠策略的泛化性，机械臂也能精准完成抓取任务：

通过下面的这组图片，可以看到ManiBox确实只有少数时间检测模型检测到了目标物体。

![](https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBicrYIMUGlphjhzjAxd3yb8W1njzoRjFiaHb0Nu11nM6aUGeeunV9xwmjmwslLpJK1aPdoseToqeMA/640?wx_fmt=jpeg&from=appmsg)

可以看出，ManiBox不仅能够完成常规抓取，还能扩展到更复杂的任务，适应不同的精细操作场景，展现了出色的**Sim2Real能力** 。

并且这些动作，**用户只需输入一个物体的prompt，ManiBox即可自动执行对应物体的抓取、倾倒等操作** ，显著提升了机器人操作任务的鲁棒性与灵活性。

那么，ManiBox是如何实现的呢？

## 基于具身智能空间泛化Scaling Law

ManiBox背后的核心思想主要在于以下两点：

  * 一是利用**规模化** （scalable）**、自动化的action数据生成方式** ，来在策略模块上进行训练，形成模型对action的认知，以缓解action模态数据稀缺的问题。（对应生成action的Policy）

  * 二是充分**利用互联网级别的数据量** （internet-scale data），在视觉、文本模态上形成通用的模型，来提供完成任务的重要指示信息。（对应Bounding Box这样的低维视觉特征及其背后的视觉模型）

当然更基础的，还有作者在空间泛化上取得的理论突破。

ManiBox深入探索了具身智能的空间泛化性Scaling Law，首次揭示了操作任务中的两大关键关系。

一方面，团队发现**任务的成功率与数据量呈现出米氏-曼特恩** （Michaelis-Menten）**动力学曲线** ：

  * 在成功率比较低的时候，增加数据量可以显著提升成功率；

  * 成功率达到80%-90%之后，数据量即使再继续增加，模仿学习策略的成功率也逐渐趋于饱和，上升缓慢；

  * 数据量趋于无穷的情况下，成功率趋于100%；

  * 成功率与数据量的关系用公式表示为：success_rate= 100% * D / (K_m + D)，其中D是数据量，K_m是达到50%成功率所需的数据量。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicrYIMUGlphjhzjAxd3yb8jgsF7nQIvLSLgYWUKcnT7MOl5O5RTqyLzE5N8rvJVpiam9rEkgWAQng/640?wx_fmt=png&from=appmsg)

另一方面，作者还发现**空间泛化所需数据量与空间体积呈现幂律关系** ，即**更多数据可显著提升更大空间范围内的泛化能力** ：

  * 如果要扩展到x倍的空间体积，那么数据量需要扩展大约x^0.35倍；

  * 在文中的setting中，34400cm^3相对于1cm^3，前者空间泛化所需的数据量是后者的34400^0.35=38倍。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicrYIMUGlphjhzjAxd3yb89tCw8P6YTbdmR5NSfmPR20nnM0ZAUbHIiaPM0yCCbHZxHRv7aibxNzjg/640?wx_fmt=png&from=appmsg)

在理论的基础之上，ManiBox通过**policy generalization**
方法来有效解决了空间泛化性问题，确保策略能够在多样化的环境，即便视觉模型存在较大的不确定性中，也能表现出强大的适应性。

借助YOLO-World这样的开集边界框检测模型，ManiBox精准提取多视角的低维空间信息，**将复杂的高维视觉问题转化为简化的状态建模问题**
，从而为策略训练提供了坚实的基础。

最终，通过训练一个基于状态的策略（state-based policy），实现了从仿真到真实世界的高效迁移。

同时结合随机掩码（random
mask）技术和历史轨迹信息，ManiBox显著提升了策略在应对视觉噪声和检测失败场景下的鲁棒性，进一步加强了模型的泛化能力和在真实环境中的表现。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicrYIMUGlphjhzjAxd3yb8MjmFqkOwEZLaYhRwy25109ea7AGgOMicDtpiaaEU6zL27Uh0ALXhA1Iw/640?wx_fmt=png&from=appmsg)

在训练上，作者还采取了高效数据生成与学生策略学习相结合的模式：

  * 教师策略：通过强化学习与模仿学习相结合的框架，ManiBox可以做到2h训练完强化学习策略，仅用一天时间 自动化采集了36,000条高质量模拟数据，涵盖多种物体形状、大小和空间配置；

  * 学生策略：在此数据上训练，仅需2分钟即可完成模型学习，达成零样本迁移，在真实场景中高效部署；

  * 基于强化学习的操作策略，相比传统的视觉方法可以有更强大通用性和鲁棒性，比如传统的视觉方法需要利用IK（逆运动学）求解joint position。

![](https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBicrYIMUGlphjhzjAxd3yb8Q3QoRjIvBxcJJQbexYaR8yN1RNXufBdOS83wiaqxKCFtTRRQYaVv0Cw/640?wx_fmt=png&from=appmsg)

ManiBox的推出不仅为机器人操作任务提供了一种高效可靠的解决方案，更定义了一种 “数据驱动的空间智能” 方法，让机器人在复杂真实场景的实用性成为可能。

它为机器人在复杂真实场景中的表现奠定了理论和技术基础，具有广泛的工业与家庭应用潜力。

作者预计，未来我们可以想象机器人在更多复杂任务中展现卓越表现。

## 作者简介

该工作有两位共同一作。

一位是清华大学计算机系TSAIL实验室的二年级博士生**谭恒楷** （Hengkai
Tan），主要研究方向是具身智能和强化学习，此前在ICML等顶级会议发表论文，还曾是全国青少年信息学奥林匹克竞赛（NOI）的银牌，全国84名，他也是RDT大模型的作者之一。

![](https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBicrYIMUGlphjhzjAxd3yb8N4sd0pM5Ffz2mvKMX2RNT8ibtOibKhARx8LQdz4XbKyJXbYuywGDDianw/640?wx_fmt=jpeg&from=appmsg)

另一位是新加坡国立大学数学系大四本科生**徐学舟** （Xuezhou
Xu)，研究兴趣在于具身智能和强化学习，他曾参与关于跨本体预训练的研究项目PEAC，该研究已被NeurIPS2024接收。

![](https://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtBicrYIMUGlphjhzjAxd3yb8gr5yPFnUcCNDsVra8b3xX6ibticRQmx29Oq3Xqj7c4EaTAI8zWwgqXVw/640?wx_fmt=jpeg&from=appmsg)

PEAC提出了跨本体无监督预训练CEURL，在多个本体上统一预训练，从而控制多个本体快速适应下游任务，实现了真实世界机器狗不同关节失灵的运动控制。

ManiBox延续了作者此前工作的类似思想，即利用规模化、自动化的action数据生成方式来训练策略，实现策略的泛化性。

作者发表在ICML2024上的FCNet在2023年实现了四足机器狗在真实世界极端地形的行走，包括过膝深的雪、结冰的河面、乱石、45度坡、楼梯等，同时有着更低的续航、更高的推理效率和更高的数据效率。

项目主页：  
https://thkkk.github.io/manibox  
论文地址：  
https://arxiv.org/abs/2411.01850  
作者其他项目：  
PEAC：https://yingchengyang.github.io/ceurl  
FCNet：https://thkkk.github.io/fcnet  
RDT-1B：https://rdt-robotics.github.io/rdt-robotics/

— **完** —

  

投稿请发邮件到：

**ai@qbitai.com**

标题注明【投稿】，告诉我们：

你是谁，从哪来，投稿内容‍

附上论文/项目主页链接，以及联系方式哦

我们会（尽量）及时回复你

![](https://mmbiz.qpic.cn/mmbiz_gif/YicUhk5aAGtC5nGy7YMGhQ0ZJeyibWyL0KVCtiaLEPMyd4Bszuo0bFIOxZOvdmqdxnOosYXyu5aI7MXpyUrUWfz6g/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

  

**点这里 👇关注我，记得标星哦～**

**一键三连「分享」、「点赞」和「在看」**

**科技前沿进展日日相见 ~**

![](https://mmbiz.qpic.cn/mmbiz_svg/g9RQicMD01M0tYoRQT2cMQRmPS5ZDyrrfzeksiay90KaDzlGBH61icqHxmgFKfvfXtVuwTHV740CDLAaXU1LIfZyoJEpYKcRIiaE/640?wx_fmt=svg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

