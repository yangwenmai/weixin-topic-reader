# Google和OpenAI都没护城河，开源的Together种子轮拿了2000万美金

文章作者: 投资实习所
发布时间: 2023-05-23 13:22
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=MzIyMDA3MjMwNw==&mid=2455850757&idx=1&sn=d5391d14124b8b5caa3baa0a506d42c9&chksm=80447f19b733f60f07158bfa5af5c99f7b5d0e6680f0c40af8656b3e4034ca1b79f5cacb85d8#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/sBQys0vjP4oR8aMwLdcJibSQFfV0DlNsYUyegqjZQDDI9Eu5ujbWXx0PbzqYeViauYTQBbjRoFI9fXicGYJlSAy0Q/300

开源在推动科技进步方面一直起着非常重要的角色，AI 领域也一样。前段时间，Google 内部泄露的一份研究文件显示，无论是 Google 还是
OpenAI，在 AI 大模型领域都没有护城河，而且随着时间的推移，当下大家所具有的优势会越来越弱，而导致这一结果的原因就在于开源力量的不断崛起，比方说
Databrick 发布的 Dolly 以及 Meta 的 LLaMA 等。

而开源浪潮越来越有席卷 AI 领域的趋势，越来越多的公司和开发者加入了这股浪潮，作为开源代码和模型中心枢纽的 Huggingface
在最近举办的一个开源庆祝活动上，就吸引了 5000 多名开发者的参加，被称为 AI 的 Woodstock 时刻。

或许也是看到了这个趋势，有消息称 OpenAI 也打算在最近发布其开源模型。而主打开源的 AI 和云平台 Together，最近正式宣布完成了 **2000
万美金的种子轮融资，由 Lux Capital 领投** ，跟投方吸引了一大众机构和个人天使投资人，包括我们比较熟悉的 SV Angel、First
Round Capital、A Capital 以及 PayPal 联合创始人、Cloudera 联合创始人、Oasis Labs
联合创始人、OpenSea 联合创始人、Uniswap 首席运营官以及 Transformer 架构的共同发明人等。

Together 声称自己的使命是**通过提供领先的开源 AGI 模型和云平台来增强创新和创造力，使任何人在任何地方都可以使用 AI，**
其目的是帮助创建超越封闭模型的开放模型，并将开源作为整合 AI 的默认方式。他们认为大型开放模型应该像开源一样易于使用，利用
Together，研究人员、开发人员和公司能够通过一个结合数据、模型和计算的直观平台来利用和改进人工智能。

目前 Together 已经发布了 GPT-JT、OpenChatKit 和 RedPajama 等几个项目，声称获得了数十万 AI 开发人员的支持，其中
OpenChatKit 被认为是开源版的 ChatGPT。Together
团队认为，封闭的模型让研究人员无法访问训练数据，他们没办法下载模型并对其进行自定义，也无法从训练过程中学习以用于未来的研究，而开源 AGI
模型和数据集使开放社区能够进行更高级的研究，并在这些模型的基础上创建新的模型，进而将创新推向新的方向。

对于训练基础大模型，网络是关键瓶颈之一，不仅需要大量强大的 GPU ，还需要这些 GPU
通过非常快速的网络连接，而这种类型的数据中心仅有少数组织能使用，**Together 声称他们的研究使模型训练或微调期间的网络流量减少了 200 倍**
。这意味着你现在可以跨多个不同的网络利用 GPU
参与大型模型的训练或微调，而不会损失所生成模型的质量，因此可以实现更具可扩展性的基础架构。![](https://mmbiz.qpic.cn/mmbiz_jpg/sBQys0vjP4oR8aMwLdcJibSQFfV0DlNsYrfNkUF5ydFXS1SuIlCw5biaS0qicA86FW9SocmfrY49GJa49w1ltddyQ/640?wx_fmt=jpeg)作为领投方，Lux
认为 Together 正在引领 **AI 的 Linux 时刻**
，通过打造一个充满活力的开放生态系统，让从个人到企业的任何人都可以参与其中。当企业在制定 AGI
战略时，他们需要寻找隐私、透明、定制和易于部署的特性，而当前的封闭模型和云产品无法满足这些要求。Together
正在构建的云平台将用于运行、训练和微调开源模型 ，他们声称该平台将以比主要供应商（比如 Google Cloud、AWS、Azure 等）
“低得多”的价格提供可扩展的计算能力。

在泄露的 Google 内部研究《我们没有护城河，OpenAI 也没有》这篇文章中，特别提到说：

> 虽然我们的模型在质量方面仍然稍微领先，但差距正在惊人地迅速缩小。开源模型更快、更可定制、更私密。他们正在使用 100 美元和 13B 参数做我们在
> 1000 万美元和 540B 时所苦苦挣扎的事情。而且他们在几周而不是几个月内就能做到。这对我们有深远的影响：

  * 我们没有秘密配方。我们最好的希望是向谷歌之外的其他人学习和合作，我们应该优先考虑启用第三方集成。

  * 当免费的、无限制的替代品在质量上可比时，人们不会为受限制的模型付费。我们应该考虑我们真正的附加值在哪里。

  * 庞大的模型正在拖慢我们的速度。从长远来看，最好的模型是那些可以快速迭代的模型。

![](https://mmbiz.qpic.cn/mmbiz_jpg/sBQys0vjP4oR8aMwLdcJibSQFfV0DlNsYTMuBDtFt1cnNHwJjib3lFTt6ib8RBjshiaa7VQ14ThE72ErLmA24XcPsQ/640?wx_fmt=jpeg)

里面提到说，大量创新往往只隔了几天时间，许多新想法来自普通人。训练和实验的入门门槛已从主要研究组织变成一个人、一个晚上和一台强大的笔记本电脑。

文章举例说，开源的贡献对图像生成领域至关重要，使 Stable Diffusion 走上了与 Dall-E
完全不同的道路。开放模型导致了大量的产品集成、Marketplace、用户界面和创新，而这些在 Dall-E 中没有发生。

这产生了明显的效果：在影响力方面，与变得越来越无关的 OpenAI 的解决方案相比，Stable Diffusion 快速占据了主导地位。这些未来也可能会在
LLMs 上发生同样的事情，因为广泛的结构元素是相同的。

**如果我们可以更快地迭代小模型，那么长期来看大模型的优势将不再**

文章拿最近非常流行的 LoRA 举例说，LoRA 更新非常便宜（约 100
美元）并且容易生成和分发，训练时间不到一天就可以完成。在这种速度下，所有这些微调的累积效应很快就能克服起始的大小劣势。实际上，从工程师小时数的角度来看，这些模型的改进速度远远超过我们使用最大变体所能做到的，而且最好的已经基本上和
ChatGPT 无法区分了，这使得专注于维护一些全球最大的模型会使我们处于劣势。

**数据质量比数据大小更具可扩展性**

许多项目通过在小型、高度筛选的数据集上训练来节省时间。随着开源让 LLMs
的研究成本越来越变得可以负担，这会导致在技术方面保持竞争优势变得更加困难，而且这种以广度优先的方式探索解决方案的空间，远远超过了我们自己的能力。

另外，作为你自己的客户意味着你更了解应用场景。因此我们应该做的是拥有生态系统：让开源为我们工作。Google
本身的成功在很大程度上就依赖于这种开源带来的生态系统，比方说 Chrome 和 Android。

文章里说，**我们越是严格控制我们的模型，我们就越能使开放的替代品具有吸引力，我们不能希望既推动创新又控制创新** ，在这一点上，OpenAI
面临同样的挑战。

这或许就是类似 Together 这样的公司瞄准的未来，Together 创立于 2022 年 6 月份，其创始团队包括是Vipul Ved
Prakash、Ce Zhang、Chris Re 和 Percy Liang 等，其中 Vipul Ved Prakash 此前创立了社交媒体搜索平台
Topsy ，该平台在 2013 年被苹果收购后他成为苹果的高级总监。

而 Lux 合伙人 Shahin Farshchi 最近也分享了他对开源、超级大模型以及专业中小模型的一些看法：

  * 超级大模型会给消费者带来很大价值，但较小的专业模型同样会扮演非常重要的角色。OpenAI 通过出色的能力掌握了强大的力量，但其核心问题可能是当它出现规模收益递减时。

  * 在电影行业，我们现在既有具有强大预算的超级电影，也有基于社交媒体的小微电影内容，在交通工具领域，我们骑自行车、坐公共汽车，也坐飞机和高铁，甚至在疾病治疗领域，也变得越来越个性化。

  * 尽管我们都喜欢灵丹妙药，但是大多数解决方案并没办法“一刀切”，通用人工智能可能会获得最多的关注，但长期来看可能远不及专业模型。在电脑领域，我们也经历了超级计算机，之后是个人电脑以及手机，而现在我们可以根据自己的工作负载调用计算能力。

  * 基于过去的经验，我们可以期待巨型模型会在某些广泛的领域起作用，就像公共汽车一样，而较小的模型会针对特定领域快速发展，就像 F1 赛车。

  * OpenAI “这辆公共汽车”将通过在数据管理、针对通用领域的指令微调以及高效地执行 RLHF 方面进行创新来进行解决。甚至构建在社交媒体上抓取音频和视频的模型，以进一步训练他们的模型。

  * 这些公共汽车将非常适合大众，但同时，“有用”的工作将由专门的模型完成，这些模型使用高质量的数据进行训练，并使用特殊的算法来充分利用每个令牌来提高训练效率。

从长远来看，未来的 AI 既有类似公共汽车这种广泛可用的 GLLM、经过微调的类似出租车和自有车队的
GLLM，也会有更专业细分类似自有跑车这种在通用平台上大规模定制的 LLM，它将是一个非常丰富的组合，而这个过程中的每一步可能都拥有非常巨大的机会。

这个观点和我之前在《[未来的 AI 格局不会被单一的通用 AI
模型所主导](http://mp.weixin.qq.com/s?__biz=MzIyMDA3MjMwNw==&mid=2455850616&idx=1&sn=efbef90b87a77c8b0edd7f64150c25d8&chksm=80447e64b733f772ec9c6071de219b3a8f917430bf750b6d78055e48bd6d1f90b430a359cf74&scene=21#wechat_redirect)》这篇文章里所说的非常类似。

延伸阅读：1.[15万家律所排队使用，法律AI
Harvey再次获得红杉领投2000万美金](http://mp.weixin.qq.com/s?__biz=MzIyMDA3MjMwNw==&mid=2455850683&idx=1&sn=faf180c251a383821fe092103007ce67&chksm=80447ea7b733f7b13073cac1423de8a2929d4cf88f7c43fe9be329aa6a25d2862b538c772c59&scene=21#wechat_redirect)2.[未来的
AI 格局不会被单一的通用 AI
模型所主导](http://mp.weixin.qq.com/s?__biz=MzIyMDA3MjMwNw==&mid=2455850616&idx=1&sn=efbef90b87a77c8b0edd7f64150c25d8&chksm=80447e64b733f772ec9c6071de219b3a8f917430bf750b6d78055e48bd6d1f90b430a359cf74&scene=21#wechat_redirect)

