# Lex 对话 Sam Altman：计算能力将成为未来的货币

文章作者: 投资实习所
发布时间: 2024-03-19 12:19
发布地: 河北
原文链接: http://mp.weixin.qq.com/s?__biz=MzIyMDA3MjMwNw==&mid=2455853219&idx=1&sn=b8f6ecacadef5bdd4a15079b6b40d28b&chksm=804468bfb733e1a9d4a8d677ba8676e267179b2b7172839a2c6f374ce102d358b333234ef9f9#rd

封面图链接: https://mmbiz.qpic.cn/sz_mmbiz_jpg/sBQys0vjP4pu5HtnagqAWRKlIWsW725FYCiaicsUc5myQNjH7IvicqAanSkucibicUuKDn9vdHmGtoXnqSUMlV86gZA/300

在 Lex Fridman 与 Sam Altman 的最新对话中，Sam 非常坦率的谈了很多大家关心的话题，包括
OpenAI、GPT-5、Sora、董事会巨变、马斯克的起诉、联合创始人兼首席科学家 Ilya、权利以及 AGI 等。

这个对话整体上我读完很有收获，结合 AI 的翻译能力，下面我做了一下简单的整理分享，略有删节，下面列了几句我比较喜欢的文字：  

  1. 我认为计算能力将成为未来的货币，它可能成为世界上最珍贵的商品；

  2. 通向 AGI 的道路应该是一场巨大的权力斗争；

  3. 与聘请高管不同，你需要他们把一个角色做好，而董事会需要在治理和全面思考方面表现出色；

  4. 人们经常在危机时刻看到领导者的好坏，但我真正看重领导者的一点是，人们在一个无聊的周二上午 9:46 的日常工作中表现如何，有人在会议中的表现如何，他们做出的决策的质量如何，这就是我所说的安静的时刻；

  5. OpenAI 真正的意义在于过去的七年；

  6. 我担心自己不再是一个默认信任他人的人；

  7. 我们很快就会回顾 GPT-4，就像我们现在回顾 GPT-3 一样。

由于内容实在太长接近 3 万字，翻译这块大部分由 AI
提供能力，可能有些地方不那么准确，但整体理解上没啥大问题，如果有精力阅读原文肯定更有感觉：https://lexfridman.com/sam-
altman-2-transcript/，下面是对话：

* * *

**1.OpenAI 董事会风波**

**Lex Fridman** ：请讲讲从 11 月 16 日星期四，也许是 11 月 17 日星期五开始的 OpenAI 董事会风波。

**Sam Altman：**
这绝对是我职业生涯中最痛苦的经历，充满混乱、羞愧、不安以及许多其他负面的东西。不过其中也有美好的事情，但我希望当时不要那么仓促，以至于无法停下来欣赏它们。但我看到了自己在那段时期的一条旧推文或这条推文。就像参加自己的追悼会，看着人们说着关于你的美好的事情，得到我爱的人和在乎的人难以置信的支持。那真的很棒，非常棒。

整个周末，除了一个大的例外，我感受到了巨大的爱，几乎没有恨，尽管感觉我不知道发生了什么，会发生什么，感觉真的很糟糕，而且肯定有几次我以为这将成为有史以来对
AI 安全最糟糕的事情之一。不过我也很高兴它发生得相对较早。我想在 OpenAI 成立到我们创造 AGI
的某个时间点，会发生一些疯狂而爆炸性的事情，但未来可能还会有更多疯狂而爆炸性的事情发生。不过，我认为它仍然帮助我们建立了一些韧性，为应对未来的更多挑战做好准备。

**Lex Fridman：** 但你有预感会经历某种权力斗争吗？

**Sam Altman：****通向 AGI 的道路应该是一场巨大的权力斗争** 。世界应该……好吧，不应该。我预计情况就是如此。

**Lex Fridman：**
所以你必须经历这个过程，就像你说的，尽可能频繁地迭代，弄清楚如何建立董事会结构，如何组织，如何与之共事的人，如何沟通这一切，以尽可能地缓解权力斗争。

**Sam Altman：** 是的。

**Lex Fridman：** 平息它。

**Sam Altman：**
但此时，感觉这是过去发生的事情，非常不愉快，非常困难和痛苦，但我们又回到工作中，一切都非常忙碌和紧张，所以我不会花太多时间思考它。在那之后有一段时间，可能是
45 天左右，我就这样茫然地度过每一天。我太不在状态了，感觉非常低落。

**Lex Fridman：** 只是在个人心理层面吗？

**Sam Altman：** 是的。真的很痛苦，在这期间还要继续经营 OpenAI
也很困难。我只想爬进一个洞穴休养一段时间，但现在我们又回到完成使命的工作中了。

**Lex Fridman：**
嗯，回顾过去反思董事会结构、权力动态、公司如何运作、研究与产品开发、资金等各方面之间的矛盾，仍然很有用，这样你这个有很大潜力打造 AGI
的人，就能以稍微更有条理、更少戏剧性的方式去做。所以这其中有价值。作为一个领导者，你要在个人心理层面，以及董事会结构和所有这些棘手的事情上都有所体会。

**Sam Altman：**
我确实从这个结构和激励机制中学到了很多，以及我们需要董事会做什么。我认为现在发生这件事在某种程度上是有价值的。我认为这可能不是 OpenAI
的最后一个高压时刻，但这确实是一个相当高压的时刻。我的公司差点就被摧毁了。我们考虑了很多其他我们必须做好的事情才能实现
AGI，但思考如何建立一个有弹性的组织，以及如何建立一个能够承受巨大压力的结构，我认为这非常重要。

**Lex Fridman：**
你对董事会的审议过程有多深入、多严谨有概念吗？你能否说明一下这种情况下的人际动态？难道只是几次对话，然后突然就升级为"我们为什么不解雇 Sam
"之类的事情？

**Sam Altman：** 我认为总的来说，董事会成员都是善意的人，我相信在有时间压力或其他压力的紧张情况下，人们会做出次优决策。我认为 OpenAI
面临的挑战之一是，我们必须拥有一个能够在压力下很好运作的董事会和团队。

**Lex Fridman：** 你认为董事会的权力是不是太大了？

**Sam Altman：**
我认为董事会本应拥有很大的权力，但我们确实看到，在大多数公司结构中，董事会通常要对股东负责。有时人们拥有超级投票权股票或其他类似的东西。在这种情况下，我认为我们在构建结构时可能应该更多地考虑一下，非营利组织的董事会拥有相当大的权力，除非你制定其他规则。他们实际上只对自己负责，这有好的一面，但我们真正希望的是
OpenAI 的董事会要对整个世界负责，只要这在实践中可行。

**Lex Fridman：** 所以宣布了一个新的董事会。

**Sam Altman：** 是的。

**Lex Fridman：** 我猜是先成立了一个规模较小的新董事会，现在又有了一个新的最终董事会？

**Sam Altman：** 还不是最终的董事会，我们增加了一些人，我们会再增加更多。

**Lex Fridman：** 增加了一些，好的。新的董事会解决了之前可能存在的哪些问题？

**Sam Altman：** 旧的董事会在大约一年的时间里规模越来越小，最初有 9 个人，后来减少到 6
个，然后我们无法就增加谁达成一致。董事会成员也没有太多担任董事的经验，而 OpenAI 的许多新董事会成员都有更多担任董事的经验，我认为这会有帮助。

**Lex Fridman：** 有人批评了新增的一些董事会成员，我听到很多人批评 Larry Summers
的加入，选择董事会成员的过程是怎样的？这其中涉及什么？

**Sam Altman：** 在这个非常紧张的周末，在紧要关头决定了 Brett 和 Larry
的人选，那个周末真是跌宕起伏。当时我们试图就新的董事会成员达成一致，希望执行团队和老董事会成员都觉得合理。Larry
实际上是老董事会成员的建议之一，我想我之前就建议过 Brett，但他很忙，不想做，但我们真的需要帮助。

我们也讨论了很多其他人，但我觉得如果我要回来，我需要新的董事会成员。我认为我无法再以同样的配置与旧董事会共事，尽管我们后来决定，我很感激 Adam
会留下来，但我们考虑了各种配置，决定我们想要一个三人董事会，必须在短时间内找到两名新的董事会成员。

所以这些决定老实说是在没有……你是在战场上做出的，那时你没有时间设计一个严谨的流程。对于之后的新董事会成员，以及我们将来增加的新董事会成员，我们有一些认为对董事会很重要的标准，我们希望董事会拥有不同的专业知识。**与聘请高管不同，你需要他们把一个角色做好，而董事会需要在治理和全面思考方面表现出色。**
所以 Brett
说了一句我很喜欢的话，我们要成组聘请董事会成员，而不是一次只聘请一个人。我们努力优化的是，选择一组拥有非营利组织专业知识、经营公司专业知识、良好的法律和治理专业知识的人。

**Lex Fridman：** 那么对于个别董事会成员来说，技术精通很重要吗？

**Sam Altman：** 并非每个董事会成员都需要，但肯定需要一些具备这方面能力的人，这是董事会需要做的部分工作。

**Lex Fridman：** 有趣的是，人们可能不了解 OpenAI
的一个细节，我当然也不了解，就是经营这个企业的所有细节。当他们想到董事会时，鉴于出现的戏剧性事件，他们会想到你。他们会想，如果你实现了
AGI，或者你实现了其中一些令人难以置信的有影响力的产品，你开发并部署了它们，那么与董事会的对话会是什么样的？他们认为，好吧，在那种情况下进行审议，合适的团队应该是什么样的？

**Sam Altman：**
你肯定需要一些技术专家在那里。然后你需要一些人思考“我们如何以一种最有助于世界人民的方式部署这项技术？”以及有非常不同观点的人。我认为你或我可能犯的一个错误是认为只有技术理解才重要，这当然是你希望董事会进行的对话的一部分，但关于这将如何影响社会和人们的生活，你真的希望在董事会中也有代表。

**Lex Fridman：** 你是根据人们的过往表现，还是仅仅通过交谈？

**Sam Altman：** 过往表现很重要。你当然要进行大量交谈，但有些角色我完全忽略过往表现，只看斜率，忽略 Y 轴截距（Y-intercept）。

**Lex Fridman：** 谢谢，谢谢你为听众做数学分析。

**Sam Altman：** 对于董事会成员，我更关心 Y
轴截距（Y-intercept）。我认为在这方面，过往记录有一些深层次的意义，经验是很难取代的。

**Lex Fridman：** 你是试图拟合一个多项式函数还是指数函数来评估他们的过往表现？

**Sam Altman：** 这个类比并不适用于那么远。

**Lex Fridman：**
好吧。你提到那个周末的一些低谷时刻。对你个人来说，一些心理上的低谷是什么？你有没有考虑过去亚马逊丛林，服用死藤水，然后永远消失？

**Sam Altman：**
那是一段非常糟糕的时期，也有巨大的高潮时刻。我的电话一直响个不停，收到我每天共事的人发来的好消息，还有十年没联系的人。我没能像应该的那样欣赏这一切，因为我正处于这场交火之中，但那真的很好。但总的来说，那是一个非常痛苦的周末。这就像在公众面前打了一场战斗，程度令人惊讶，这让我非常疲惫，比我预期的要疲惫得多。董事会在周五下午做出了这个决定，我真的无法得到太多答案，但我也就是想，好吧，董事会可以这样做，所以我要稍微想一想我想做什么，但我会努力在伪装的祝福中找到真正的祝福。

我就想，好吧，我目前在 OpenAI
的工作是，或者说曾经是，管理一家目前规模相当大的公司。而我一直最喜欢的事情就是与研究人员一起工作。我就想，是的，我可以专注于 AGI
研究工作。我对此感到兴奋，当时甚至没有想到这一切都可能被推翻，这是周五下午的事。

**Lex Fridman：** 所以你已经接受了这个结果。

**Sam Altman：**
非常迅速，非常迅速。我经历了一小段时间的困惑和愤怒，但很快就接受了。到了周五晚上，我就在和别人讨论接下来要做什么了，我对此感到兴奋。我想那是周五晚上我第一次听到这里的管理团队说，"嘿，我们要反抗这个。"然后我就上床睡觉，仍然很兴奋，继续前进。

**Lex Fridman：** 你睡得着吗？

**Sam Altman：** 睡得不多。奇怪的是，有四天半的时间我没睡多少觉，也没吃多少东西，但仍然有惊人的精力。在战斗时，你会对肾上腺素有奇怪的认识。

**Lex Fridman：** 所以你接受了这个孩子 OpenAI 的死亡。

**Sam Altman：** 我很兴奋新的事物，我只是想，"好吧，这很疯狂，但无所谓。"

**Lex Fridman：** 这是一个很好的应对机制。

**Sam Altman：**
然后周六早上，两位董事会成员打电话来说，"嘿，我们不是故意要破坏稳定的。我们不想在这里存储大量价值。我们能谈谈你回来的事吗？"我一开始不想那样做，但我多想了一会儿，我想，好吧，我真的很在乎这里的人、合作伙伴、股东，我爱这家公司。所以我考虑了一下，我想，"好吧，但这是我需要的东西。"然后最痛苦的时候就是在那个周末，我一直在想，也一直被告知，不仅仅是我，这里的整个团队都在努力稳定
OpenAI，而整个世界都在试图瓦解它，有人试图招聘之类的。

我们一直被告知，好了，我们快完成了，我们快完成了。我们只需要再多一点时间，这是一种非常困惑的状态。然后周日晚上，再次每隔几个小时我都期望我们能完成，找到办法让我回去，一切都恢复原样。然后董事会任命了一位新的临时首席执行官，然后我想，这感觉真的很糟糕，那是整件事的最低谷。我告诉你，这感觉非常痛苦，但整个周末我感受到了很多爱。除了周日晚上的那一刻，我不会将我的情绪描述为愤怒或仇恨，但我从人们那里感受到了很多爱。这很痛苦，但这个周末占主导地位的情绪是爱，而不是恨。

**Lex Fridman：** 你曾高度赞扬 Mira
Murati，说她特别是在关键时刻提供了帮助，正如你在推文中所说的那样。也许我们可以稍微岔开一下话题，你欣赏 Mira 的什么？

**Sam Altman：** 嗯，她在那个混乱的周末做得很好，**人们经常在危机时刻看到领导者的好坏，但我真正看重领导者的一点是，人们在一个无聊的周二上午
9:46 的日常工作中表现如何，有人在会议中的表现如何，他们做出的决策的质量如何，这就是我所说的安静的时刻** 。

**Lex Fridman：** 意思是大部分工作都是在日复一日、会议中完成的，只要全身心投入并做出明智的决定就行了。

**Sam Altman：** 是的，你想在过去 20 分钟里谈论的内容，我理解是这个非常戏剧化的周末，但这并不是 OpenAI
的真正意义所在，**OpenAI 真正的意义在于过去的七年** 。

**Lex Fridman：** 嗯，是的。人类文明不在于纳粹德国的入侵，但人们仍然关注这一点。

**Sam Altman：** 非常可以理解。

**关于 Ilya Sutskever**

**Lex Fridman：** 它让我们洞察人性，人性的极端，也许人类文明的一些伤害和胜利就发生在那些时刻，所以它很有启发性。让我问你关于 Ilya
的事，他是不是被埋没在一个秘密的核设施里？

**Sam Altman：** 不是。

**Lex Fridman：** 那普通的秘密设施呢？

**Sam Altman：** 不是。

**Lex Fridman：** 核的非秘密设施呢？

**Sam Altman：** 也不是，都不是。

**Lex Fridman：** 这在某种程度上成为了一个 meme，你认识 Ilya
很长时间了，他显然卷入了这场董事会的风波和所有这些事情。你现在和他的关系如何？

**Sam Altman：** 我爱 Ilya，我非常尊重
Ilya。关于他的计划，我现在没什么可说的。这要问他自己，但我真的希望我们能在我职业生涯的剩余时间里一起工作。他比我小一点，也许他能工作的更长久一些。

**Lex Fridman：** 有一个梗是说他看到了什么，就像他可能看到了 AGI，这让他内心非常担心，Ilya 看到了什么？

**Sam Altman：** Ilya没有看到 AGI，我们都没有看到 AGI。我们还没有创造出 AGI，我确实认为 Ilya
身上我最喜欢的一点就是，他非常认真地对待 AGI 和安全问题，广义上讲，包括这将对社会产生的影响等。随着我们继续取得重大进展，Ilya
是过去几年里我花了最多时间讨论这将意味着什么、我们需要做什么才能确保做对的人之一。所以 Ilya 没有看到 AGI，但 Ilya
在思考和担心如何确保我们做对这件事方面，是人类的榜样。

**Lex Fridman：**
我过去和他进行过一些对话，我想当他谈论技术时，他总是在进行这种长期思考。所以他不是在想一年后这会是什么样子。他是在从第一性原理出发思考，"好的，如果这种规模扩大，这里的基本原理是什么？这将走向何方？"因此，这为他考虑所有其他安全问题等奠定了基础，这使得与他交谈非常有趣。你知道他为什么一直保持沉默吗？是他正在进行一些自我反思吗？

**Sam Altman：** 再说一次，我不想代表 Ilya 说话，我认为你应该问他这个问题，他肯定是个很有思想的人，我认为Ilya
总是在以一种非常好的方式进行自我反思。

**Lex Fridman：** 是的，而且，他欣赏沉默的力量。另外，我听说他可以是个很傻的家伙（a silly guy），这一面我从未见过。

**Sam Altman：** 当这种情况发生时很甜蜜。

**Lex Fridman：** 我从未见过一个傻乎乎的 Ilya，但我也期待着见到那一面。

**Sam Altman：** 最近我和他一起参加晚宴，他在和一只小狗玩耍，他的情绪非常 silly，非常可爱。我当时想，天哪，这不是世人最常看到的
Ilya 的一面。

**Lex Fridman：** 所以总结整个董事会事件，你对董事会结构感动满意么？

**Sam Altman：** 是的。

**Lex Fridman：** 对这一切以及它的走向感到满意吗？

**Sam Altman：** 我对新董事会感到非常满意，关于 OpenAI
的结构，董事会的任务之一是审视这一点，看看我们在哪些方面可以使其更加稳健。我们想先任命新的董事会成员，但在整个过程中，我们显然得到了一个关于结构的教训。我没有什么非常深刻的话要说。这是一次疯狂的、非常痛苦的经历。我认为这是一个完美的奇怪风暴。对我来说，这预示着随着利害关系越来越高，以及我们需要稳健的治理结构、流程和人员以及将来会发生什么。我很高兴它现在发生了，但这是一件令人震惊的痛苦的事情。

**Lex Fridman：** 它是否让你在个人层面上更加犹豫不决地信任他人？

**Sam Altman：** 是的。

**Lex Fridman：** 只是在个人层面上？

**Sam Altman：**
是的，我想我是一个非常信任他人的人。我一直有一种人生哲学，就是不要担心所有的妄想，不要担心极端情况。你会因为让自己放松警惕而受到一点伤害，这对我来说是如此令人震惊。我完全措手不及，这确实改变了我对默认信任他人和为坏情况做计划的看法，我真的不喜欢这样，这肯定改变了我的看法。

**Lex Fridman：** 你要小心这一点，你担心自己变得太愤世嫉俗了吗？

**Sam Altman：** 我不担心变得太愤世嫉俗，我认为我是一个非常不愤世嫉俗的人，**但我担心自己不再是一个默认信任他人的人。**

**Lex Fridman：** 我其实不确定对于一个正在开发 AGI
的人来说，信任还是不信任哪种模式更好。你正在经历一个有趣的旅程。但在结构方面，我更感兴趣的是人的层面。你是如何让自己周围有构建了很酷的东西，同时也在做出明智决定的人？因为你开始赚的钱越多，这个东西的力量就越大，人们就会变得越奇怪。

**Sam Altman：**
就团队而言，我认为你必须给我打个很高的分数。我对每天与之共事的人怀有巨大的感激、信任和尊重，我认为被这样的人包围着真的很重要。

**2.关于 Elon Musk 的诉讼**

**Lex Fridman：** 我们共同的朋友 Elon 起诉了 OpenAI。他批评的本质是什么？他在某种程度上有道理吗？他在哪些方面是错的？

**Sam Altman：**
我不知道这真正是关于什么的，我们一开始只是想成为一个研究实验室，不知道这项技术将如何发展。因为那是七八年前的事了，现在回想起来很难真正记起当时是什么样子，但那是在语言模型成为一个大问题之前。那是在我们对
API
或出售聊天机器人的使用权有任何想法之前，那是在我们有任何想法要将其产品化之前。所以我们就像是，"我们只是要尝试做研究，我们真的不知道我们要用它做什么。"我认为对于许多根本性的新事物来说，你一开始在黑暗中摸索，做出一些假设，其中大多数最后被证明是错误的。

然后很明显，我们将需要做不同的事情，并且需要大量更多的资金。所以我们说，"好吧，这个结构不太适合。我们如何修补这个结构？"然后你再修补一次，再修补一次，最后你就得到了一些看起来确实令人挑眉的东西，至少可以这么说。但我们通过逐步的、我认为在每个时间点都是合理的决策走到了这一步。这并不意味着如果我们现在能有一个预言家带着我们回到过去，我就不会完全不同地去做，但当时你没有那个预言家。无论如何，就
Elon 在这里的真正动机而言，我不知道。

**Lex Fridman：** 就你的记忆而言，OpenAI 在博客文章中给出的回应是什么？你能总结一下吗？

**Sam Altman：** 哦，我们只是说 Elon
说了这一系列的事情。这是我们对事情经过的描述，或者说这不是我们的描述，这就是事情的经过，我们尽量不带感情色彩，只是陈述"这就是历史"。

**Lex Fridman：** 我确实认为 Elon
在这里有一定程度的错误描述，关于你刚才提到的一点，即你们当时面临的不确定性程度。你们是一小群研究人员，疯狂地谈论 AGI，而所有人都在嘲笑这个想法。

**Sam Altman：** 不久之前 Elon 还在疯狂地谈论发射火箭，当时人们也在嘲笑这个想法，所以我认为他应该对此有更多的同情。

**Lex Fridman：** 我确实认为这里有一些个人的东西，OpenAI 和很多了不起的人在这里选择与 Elon 分道扬镳，所以这是一种个人的。

**Sam Altman：** Elon 选择了分道扬镳。

**Lex Fridman：** 你能具体描述一下吗？选择分道扬镳？

**Sam Altman：** 他认为 OpenAI 会失败，他想要完全控制来扭转局面。我们想继续朝着现在已经成为 OpenAI
的方向前进，他还想让特斯拉能够建立一个 AGI 项目。有几次，他想把 OpenAI
变成一家他可以控制的盈利性公司，或者让它与特斯拉合并，我们不想那样做，他决定离开，但这没关系。

**Lex Fridman：** 所以你的意思是，这也是博客文章中说的一件事，他想让 OpenAI
被特斯拉收购，就像与微软的合作关系一样，或者可能类似，也可能更戏剧性。

**Sam Altman：** 我的记忆是，他的提议就是，被特斯拉收购，让特斯拉完全控制它。我很确定就是这样。

**Lex Fridman：** 那么对 Elon 来说，OpenAI 中的 "open" 这个词当时意味着什么？Ilya
在电子邮件往来和所有这些事情中谈到了这一点。对你来说它当时意味着什么？现在对你意味着什么？

**Sam Altman：** 说到事后诸葛亮，我会选一个不同的名字。我认为 OpenAI
正在做的最重要的事情之一就是免费将强大的技术作为公共产品交到人们手中，我们没有在免费版上投放广告，我们没有以其他方式将其货币化。我们只是说这是我们使命的一部分，我们想免费向人们提供越来越强大的工具，让他们去使用。

我认为这种开放性对我们的使命真的很重要，我认为如果你给人们伟大的工具，教他们如何使用，或者甚至不教他们，他们会自己搞清楚，让他们用这些工具为彼此创造一个不可思议的未来，这是一件大事。所以如果我们能继续向世界提供免费或低成本的强大
AI
工具，我认为这对我们如何实现使命是一个巨大的推动。至于开源与否，是的，我认为我们应该开源一些东西，而不是其他东西。这确实变成了一场宗教战线，很难保持细微差别，但我认为细微差别才是正确的答案。

**Lex Fridman：** 他说："把你们的名字改成 CloseAI，我就撤诉。"我的意思是，这会不会成为关于这个名字的 meme 战场？

**Sam Altman：** 我认为这说明了 Elon 对这起诉讼的严肃程度，我认为这是一个令人震惊的事情。

**Lex Fridman：** 如果我错了请纠正，但我认为诉讼在法律上并不严肃，它更多的是要表明目前引领潮流的 AGI 和公司的未来。

**Sam Altman：** 听着，我的意思是 Grok 在人们指出这有点虚伪之前还没有开源任何东西，然后他宣布 Grok
将在本周开源一些东西。我不认为对他来说这真的是关于开源与否的问题。

**Lex Fridman：** 嗯，批评竞争对手很好。说点废话也不错。但友好的竞争和"我个人讨厌诉讼"是不同的。

**Sam Altman：** 听着，我认为整个事情有失一个建设者的身份。我尊重 Elon
作为我们这个时代伟大的建设者之一，我知道他知道当怀有恶意的人攻击他时是什么感觉，这让我格外悲伤，他正在这样对我们。

**Lex Fridman：** 是的，他是有史以来最伟大的建设者之一，可能是有史以来最伟大的建设者。

**Sam Altman：** 这让我很难过，我想这让很多人都很难过，有很多人长期以来真的很仰慕他。我在某个采访或其他什么地方说我想念从前的
Elon，收到的信息数量正好概括了我的感受。

**Lex Fridman：** 我认为他应该直接赢，他应该让 X Grok 击败 GPT，然后 GPT 再击败
Grok，这就是竞争，这对每个人来说都很美好。但关于开源的问题，你认为很多公司在玩弄这个想法吗？这很有趣。我会说 Meta
令人惊讶地在这方面处于领先地位，或者至少在国际象棋游戏中迈出了第一步，真正开源了该模型。当然，这不是最先进的模型，而是开源 Llama，Google
正在考虑开源一个较小版本的想法。开源的利弊是什么？你玩过这个想法吗？

**Sam Altman：**
是的，我认为开源模型肯定有一席之地，特别是人们可以在本地运行的较小模型，我认为有巨大的需求。我认为会有一些开源模型，也会有一些闭源模型。在这方面，它不会与其他生态系统有什么不同。

**Lex Fridman：** 我听了很多播客谈论这个诉讼和所有这类事情，他们更关心从非营利组织到这个盈利组织的先例。这为其他初创公司树立了什么样的先例？

**Sam Altman：** 我会强烈反对任何考虑先以非营利组织起家，然后再增加营利部门的初创公司。我会强烈反对他们这样做。我不认为我们会在这里开创先例。

**Lex Fridman：** 好的。所以大多数初创公司应该更直接一点。

**Sam Altman：** 当然，如果我们知道会发生什么，我们也会那样做的。

**Lex Fridman：** 理论上，如果你在这里跳一支优美的舞，会有一些税收激励或其他什么，但是…

**Sam Altman：** 我不认为大多数人是这样考虑这些事情的。

**Lex Fridman：** 初创公司如果这样做，就不可能节省大量资金。

**Sam Altman：** 不，我认为有法律会让这变得非常困难。

**Lex Fridman：** 你希望这件事与 Elon
如何发展？这种紧张关系，这种舞蹈，你希望这件事怎样？如果我们从现在起一年、两年、三年后，你与他的关系，在个人层面，像是友谊，友好的竞争，所有这类事情。

**Sam Altman：** 是的，我非常尊重 Elon，我希望在未来几年我们能有一个友好的关系。

**Lex Fridman：**
是的，我希望你们这个月就能建立友好关系，公平竞争，共同探索这些想法。我想你们在争夺人才或其他方面存在竞争，但应该是友好的竞争。就是要创造酷的东西，Elon
非常擅长创造酷的东西，你也是。

**3.关于 Sora**

**Lex Fridman：** 说到酷的东西
Sora，我可以问一大堆问题。首先，它真的很了不起。从产品层面来说它真的很了不起，从哲学层面来说也是如此。所以让我从技术/哲学的角度问一下，你认为它对世界的理解比
GPT-4 多还是少？当你在这些片段和语言标记上进行训练时，它对世界模型的理解有何不同？

**Sam Altman：**
我认为所有这些模型对世界模型的理解都比我们大多数人想象的要多。因为它们也有非常明显的不理解或理解错误的地方，所以很容易看到弱点，看透面纱，说
"啊，这都是假的"。但并非全是假的。只是有些部分有效，有些部分无效。

我记得当我第一次开始观看 Sora 视频时，我会看到一个人在某物前面走几秒钟，遮挡它，然后走开，同样的东西还在那里。我想，"哦，这相当不错。"
或者有一些例子，在一个序列中经过很多步骤，底层物理学看起来非常好地表现出来，就像 "哦，这真令人印象深刻。"
但从根本上说，这些模型只是在变得更好，这将继续下去。如果你看一下从 DALL-E 1 到 2 到 3 再到 Sora
的轨迹，有很多人在每个版本上都被嘲笑说它做不到这个，做不到那个，现在看看它。

**Lex Fridman：**
嗯，你刚才提到的遮挡（occlusions）基本上是对三维物理世界的物理学进行建模，建模得足够好，能够捕捉到这些东西。或者，也许你可以告诉我，为了处理遮挡（occlusions），世界模型需要什么？

**Sam Altman：** 是的。所以我想说的是，它在做一些事情来很好地处理遮挡。说它有一个很棒的底层三维世界模型，这有点牵强。

**Lex Fridman：** 但是通过这些二维训练数据的方法，你能达到那个目标吗？

**Sam Altman：** 这种方法看起来会走得出人意料的远。我不想过多猜测它将克服哪些限制，哪些限制它无法克服，但是…

**Lex Fridman：** 你看到的系统的一些有趣的局限性是什么？我的意思是有一些有趣的你已经发布了。

**Sam Altman：** 有各种有趣的。我的意思是，猫在视频中的随机点长出额外的四肢。随便挑你想要的，但仍然有很多问题，有很多弱点。

**Lex Fridman：** 你认为这是方法的根本缺陷，还是只是更大的模型或更好的技术细节或更好的数据、更多的数据就能解决这些问题？

**Sam Altman：** 我会说两者都是的。我认为方法本身有一些东西，感觉与我们的思考和学习方式不同。然后我也认为它会随着规模的扩大而变得更好。

**Lex Fridman：** 就像我提到的，LLMS 有 tokens，文本 tokens，而 Sora 有视觉
patches，所以它将所有视觉数据，各种各样的视觉数据视频和图像转换成
patches。就你所能说的，训练是完全自监督的吗，有一些人工标注吗？人类在这一切中的参与程度如何？

**Sam Altman：** 我的意思是在不透露 Sora 方法的任何具体细节的情况下，我们在工作中使用了大量人类数据。

**Lex Fridman：** 但不是互联网规模的数据？所以有很多人参与。很多是一个复杂的词，Sam。

**Sam Altman：** 我认为在这种情况下，很多是一个公平的词。

**Lex Fridman：**
因为对我来说，"很多"……听着，我是一个内向的人，当我和三个人一起出去玩的时候，那就是很多人了。四个人，那就更多了。但我想你的意思是不止……

**Sam Altman：** 不止三个人在为这些模型标注数据，是的。

**Lex Fridman：**
好的。但从根本上说，有很多自监督学习。因为你在技术报告中提到的是互联网规模的数据，这又是一首美丽的诗。所以这是大量没有人工标注的数据，它在这方面是自监督的吗？

**Sam Altman：** 是的。

**Lex Fridman：**
那么问题就变成了，互联网上有多少数据可以用于此，如果我们只知道自监督的细节，这些数据是否有助于这种自监督方式？你有没有考虑过更多地公开细节？

**Sam Altman：** 我们考虑过。你是指 Sora 吗？

**Lex Fridman：** Sora 具体而言。因为 LLMS 的魔力现在开始转向视觉数据，这非常有趣，要做到这一点需要什么？

**Sam Altman：** 我的意思是在我看来是这样的，但我们还有更多工作要做。

**Lex Fridman：** 当然。你担心发布这个系统有什么危险？你为什么担心这个？

**Sam Altman：**
坦率地说，在发布之前，我们必须做的一件事就是让它以人们期望的规模所需的效率水平工作，这样我就不想淡化这一点。在这方面还有大量的工作要做。但你可以想象深度伪造、错误信息等问题。我们努力成为一家深思熟虑的公司，考虑我们投入世界的东西，不需要太多思考就能想到这可能会变糟的方式。

**Lex Fridman：** 这里有很多棘手的问题，你处理的是一个非常棘手的领域。你认为 AI 训练应该是或属于版权法下的合理使用吗？

**Sam Altman：**
我认为这个问题背后的问题是，创造有价值数据的人是否应该得到一些补偿，我认为答案是肯定的。我还不知道答案是什么，人们提出了很多不同的东西，我们尝试了一些不同的模型。但如果我是一个艺术家，首先我希望能够选择不让别人用我的风格生成艺术。其次，如果他们真的用我的风格生成艺术，我希望有一些与之相关的经济模式。

**Lex Fridman：** 是的，这是从 CD 到 Napster 再到 Spotify 的过渡。我们必须想出某种模式。

**Sam Altman：** 模式改变了，但人们必须得到报酬。

**Lex Fridman：** 嗯，如果我们把视野放得更远一些，应该有某种激励机制，让人类继续做酷的事情。

**Sam Altman：**
在我担心的所有事情中，人类会做酷的事情，社会会找到一些方式来奖励它。这似乎是深深植根的。我们想要创造，我们想要有用，我们想要以任何方式获得地位。我不认为这会消失。

**Lex Fridman：** 但奖励可能不是金钱上的，可能是名誉和继续做苦的事情

**Sam Altman：** 也许在某些其他方面有经济回报。再说一次，我不认为我们已经看到了经济系统如何运作的最后一次演变。

**Lex Fridman：** 是的，但艺术家和创作者很担心。当他们看到 Sora 时，他们会说，"天哪。"

**Sam Altman：**
当然。当摄影出现时，艺术家们也非常担心，然后摄影成为了一种新的艺术形式，人们通过拍照赚了很多钱。我认为这样的事情会继续发生。人们会以新的方式使用新的工具。

**Lex Fridman：** 如果我们只看 YouTube 或类似的东西，你认为在接下来的五年里，有多少会使用 Sora 这样的 AI 生成内容？

**Sam Altman：** 人们谈论 AI 在未来五年内会做多少工作。人们的框架是，目前有多少比例的工作将完全被某种 AI 取代？我的看法不是 AI
会做多少比例的工作，而是 AI 会在某个时间范围内做多少比例的任务。所以如果你想到经济中所有的 5 秒任务、5 分钟任务、5 小时任务，甚至 5
天任务，AI 能完成其中多少？我认为这是一个比 AI
能完成多少工作更有趣、更有影响力、更重要的问题，因为它是一种工具，将以越来越复杂的程度，在越来越长的时间范围内，为越来越多的任务工作，让人们在更高层次的抽象层面上工作。

所以也许人们在他们的工作中效率更高。在某个时候，这不仅仅是量的变化，而是质的变化，关于你能在脑海中保留的问题类型。我认为对于 YouTube
上的视频也是一样。许多视频，也许大部分视频，都会在制作过程中使用 AI
工具，但它们仍将由一个人从根本上驱动，思考它，把它放在一起，做部分工作。有点像指导和运行它。

**Lex Fridman：** 是的，这太有趣了。我的意思是这很可怕，但很有趣，要思考这个问题。我倾向于相信人类喜欢看其他人类。

**Sam Altman：** 人类真的非常关心其他人类。

**Lex Fridman：** 是的。如果有一个比人类更酷的东西，人类会关注它两天，然后又回到人类身上。

**Sam Altman：** 这似乎是根深蒂固的。

**Lex Fridman：**
这就是整个国际象棋的事情，"哦，是的"，但现在让每个人都继续下棋。让我们忽略房间里的大象，人类在国际象棋方面真的很差，相对于 AI 系统而言。

**Sam Altman：** 我们仍然举办赛跑，而汽车要快得多。我的意思是有很多例子。

**Lex Fridman：** 是的。也许它只是 Adobe
套件类型的工具，可以让制作视频变得更容易，诸如此类。我讨厌出现在镜头前，如果我能想出一种不出现在镜头前的方式，我会很高兴。不幸的是，这需要一段时间。生成面孔，在视频格式方面正在取得进展，但在生成特定人物而不是一般人物的面孔时很棘手。

**4.关于 GPT-4**

**Lex Fridman：** 让我问你关于 GPT-4 的事。回顾过去，3.5 和 4 以及 ChatGPT 可能会成为这种历史性的关键时刻。

**Sam Altman：** 也许 GPT-5 会成为关键时刻。我不知道。现在很难说。

**Lex Fridman：** 我们永远不会知道。关于未来令人讨厌的一点是，很难预测。但对我来说，回顾过去，GPT-4、ChatGPT
非常令人印象深刻，在历史上令人印象深刻。所以请允许我问一下，GPT-4 和 GPT-4 Turbo 最令你印象深刻的能力是什么？

**Sam Altman：** 我觉得它有点烂。

**Lex Fridman：** 典型的人类也是，已经习惯了一个很棒的东西。

**Sam Altman：** 不，我认为它是一个惊人的东西，但与我们需要达到的目标和我相信我们将达到的目标相比，在 GPT-3
的时候，人们会说，"哦，这太神奇了。这是技术的奇迹。"它确实是，它曾经是。但现在我们有了 GPT-4，回头看
GPT-3，你会说，"那是难以想象的可怕。"我预计 5 和 4 之间的差异将与 4 和 3
之间的差异相同，我认为我们的工作就是生活在未来几年，记住我们现在拥有的工具在回顾时会有点糟糕，这就是我们确保未来更美好的方式。

**Lex Fridman：** GPT-4 最光荣的地方在哪里？

**Sam Altman：** 它能做的最好的事情是什么？

**Lex Fridman：** 它能做的最好的事情是什么，以及这些最好的事情的局限性，你说它很烂，因此给了你对未来的灵感和希望？

**Sam Altman：**
我最近更多地用它来做头脑风暴的伙伴。其中有一丝令人惊叹的东西。当人们谈论它时，他们说的是，"哦，它帮助我更有效率地编码。它帮助我写得更快、更好。它帮助我从这种语言翻译成另一种语言"，所有这些令人惊叹的事情，但有一些关于创造性头脑风暴伙伴的东西，"我需要为这个东西想出一个名字。我需要以不同的方式思考这个问题。我不确定在这里该怎么做，"我认为这让人一瞥我希望看到更多的东西。

你可以看到一个非常小的例子的另一件事是，当我能在更长的时间范围内帮助完成任务时，将某件事分解成多个步骤，也许执行其中一些步骤，搜索互联网，编写代码等等，将这些放在一起。当它奏效时，虽然不是很频繁，但它非常神奇。

**Lex Fridman：** 与人类进行迭代式的来回交流对我来说非常有效，你的意思是？

**Sam Altman：** 与人类反复交互，它更经常奏效，当它能独自完成一个 10 步的问题时。它有时并不经常奏效。

**Lex Fridman：** 增加多个抽象层还是只是顺序？

**Sam Altman：** 两者都有，将其分解，然后在不同的抽象层次上做事情，将它们放在一起。听着，我不想淡化 GPT-4
的成就，但我也不想夸大其词。而且我认为，我们正处在一条指数曲线上，**我们很快就会回顾 GPT-4，就像我们现在回顾 GPT-3 一样。**

**Lex Fridman：** 话虽如此，我的意思是 ChatGPT 是一个转折点，人们开始相信有一个相信的上升，不是 OpenAI 内部。

**Sam Altman：** 当然。就这一点而言，我确实认为这将是很多人从不相信到相信的一个时刻。这更多关乎 ChatGPT
界面。顺便说一下界面和产品，我指的是对模型的后期训练以及我们如何调整它以对你有帮助以及如何使用它，而不是底层模型本身。

**Lex Fridman：** 这些东西中的每一个有多重要？底层模型和 RLHF 或类似的东西，它可以调整模型以更吸引人类，对人类更有效和更有成效。

**Sam Altman：** 我的意思是它们都非常重要，但
RLHF，后训练步骤，从计算角度看，我们在基础模型之上做的一点点包装，尽管这是一个巨大的工作量，这真的很重要，更不用说我们围绕它构建的产品了。从某种意义上说，我们必须做两件事。我们必须发明底层技术，然后我们必须弄清楚如何将其做成一个人们会喜欢的产品，这不仅仅是产品工作本身，而是这整个其他步骤，即如何使其对齐并使其有用。

**Lex Fridman：** 以及如何使规模发挥作用，让很多人能够同时使用它。诸如此类。

**Sam Altman：**
还有这个。但这是一个已知的困难的事情。我们知道我们将不得不扩大规模。我们必须做两件以前从未做过的事情，这两件事都是相当重大的成就，然后是很多其他公司以前不得不做的事情，比如扩大规模。

**Lex Fridman：** 从 8K 到 128K tokens 的上下文窗口，与 GPT-4 到 GPT-4 Turbo 相比如何？

**Sam Altman：** 大多数人大部分时间不需要一直用
128K。虽然如果我们梦想遥远的未来，遥远的未来，我们将拥有几十亿的上下文长度。你会输入所有的信息，所有的历史记录，随着时间的推移，它会越来越了解你，那将是很棒的。就目前而言，人们使用这些模型的方式，他们并不是这样做的。人们有时会发布一篇论文或代码库的重要部分，不管是什么，但大多数模型的使用都不是在大多数时间使用长上下文。

**Lex Fridman：** 我喜欢这是你的 "I Have a Dream"
演讲。总有一天，你会根据你性格的全部内容被评判，或者你一生的全部内容。这很有趣。所以这是你希望扩展的一部分，是更大、更大的上下文。

**Sam Altman：** 我曾经看过一个互联网片段，我可能会弄错数字，但大概是比尔•盖茨谈论某台早期计算机上的内存量，可能是 64K，也可能是
640K，或者类似的东西。其中大部分都用于屏幕缓冲区。他似乎无法表现出真诚，他无法想象世界最终会需要计算机中数千兆字节的内存或数万亿字节的内存。而你总是需要，或者总是需要跟上技术的指数增长，我们会发现如何使用更好的技术。所以我现在真的无法想象上下文链接有朝一日会达到十亿是什么感觉。它们可能不会真的达到那里，但实际上感觉会是那样。但我知道我们会使用它，一旦我们拥有了它，就真的不想回头。

**Lex Fridman：** 是的，即使是说十亿，十年后可能看起来很蠢，因为它将是数万亿，甚至更多。会有某种突破，实际上感觉就像无限的上下文。但即使是
120，我必须诚实地说，我还没有推动它达到那个程度。也许把整本书或部分书籍等放进去。那 GPT-4 的一些有趣用例你见过吗？

**Sam Altman：**
我觉得最有趣的不是任何特定的用例，我们可以讨论那些，而是一些人，主要是年轻人，但是一些人把它作为他们任何知识性工作任务的默认起点。而且事实上，它可以相当好地完成很多事情。你可以用
GPT-V，你可以用它来帮你写代码，你可以用它来帮你搜索，你可以用它来编辑一篇论文。对我来说最有趣的是那些把它作为工作流程起点的人。

**Lex Fridman：**
我也是如此，用于很多事情。我用它作为阅读伙伴来阅读书籍。它帮助我思考，帮助我思考想法，特别是当书是经典的时候。所以它写得真的很好。我发现它在涉及广泛的主题上往往比维基百科要好得多。它在某种程度上更加平衡和细致入微。或者可能是我，但它激励我比维基百科文章更深入地思考。我不确切知道是什么原因。

你提到了这种协作。我不确定魔力在哪里，是在这里还是在那里，或者介于两者之间。我不确定。但让我担心的一件事是，当我从 GPT
开始知识任务时，我通常必须在之后进行事实核查，比如检查它是否编造了假的东西。你是如何弄清楚 GPT
可以编造听起来非常有说服力的假东西的？那你如何让它植根于真理呢？

**Sam Altman：** 这显然是我们非常感兴趣的领域。我认为在即将到来的版本中，它会变得更好，但我们必须继续努力，我们今年不会全部解决这个问题。

**Lex Fridman：** 嗯，可怕的是，随着它变得更好，你会开始不那么频繁地进行事实核查，对吧？

**Sam Altman：**
对此我有两种想法。我认为人们使用技术的能力要比我们通常认为的要高得多。人们似乎真的明白GPT，任何这些模型有时都会产生幻觉。如果这是关键任务，你必须检查它。

**Lex Fridman：** 除了记者似乎不明白这一点。我看到记者草率地使用GPT-4。

**Sam Altman：** 在我想要抨击记者的长长的清单中，这不是我对他们的主要批评。

**5.记忆与隐私**

**Lex Fridman：**
嗯，我认为更大的批评也许是作为一名记者的压力和动机是你必须非常快速地工作，而这是一种捷径。我希望我们的社会能激励像，比如需要几天几周时间的深度新闻工作，并奖励优秀的深度新闻。还有以平衡的方式呈现内容的新闻。

这是人类文明的一个更大的问题，我很想看到解决方案。你给了 ChatGPT
记住以前对话的能力。你一直在研究这个想法，关于记住对话和不记住对话……我希望我有时能做到这一点。我想有时酒精可以做到这一点，但我想不是最佳方式。通过这个功能，比如研究记住对话和不记住对话的想法，你有什么发现？

**Sam Altman：**
我们在探索这方面还处于非常早期的阶段，但我认为人们想要的，或者至少我想要的，是一个随着时间的推移越来越了解我并对我越来越有用的模型。这是一次早期探索。我认为还有很多其他事情要做，但这就是我们想要的方向。你会想要使用一个模型，随着时间的推移，或者使用一个系统，它会是许多模型，随着时间的推移，它会变得越来越好。

**Lex Fridman：** 是的。这有多难？因为现在它更像是记住小的事实和偏好等等。但是记住什么呢？你不想让 GPT 记住你在 11
月经历的所有糟糕的事情，因为现在你显然在有点抑制它。

**Sam Altman：**
是的，这不仅仅是我想让它记住这些。我希望它能吸取教训，在未来提醒我应该做些什么不同的事情，或者要注意什么。我们都在一生中从经验中获益，程度不一，我也希望我的
AI
智能体能从这些经验中获益。所以如果我们回过头来，让自己想象数万亿的上下文长度，如果我能把我一生中与任何人的每一次对话都放在里面，如果我能把我所有的电子邮件输入输出，我所有的输入输出都放在上下文窗口中，每次我问一个问题，那将是非常酷的，我想。

**Lex Fridman：** 是的，我认为那会非常酷。人们有时会听到这个就担心隐私问题。当 AI
变得真正有效，能够整合发生在你身上的所有经历和所有数据，并给你建议时，你怎么看待这个方面的问题？

**Sam Altman：** 我认为正确的答案就是用户选择。我希望从我的 AI
智能体的记录中删除的任何内容，我都可以删除。如果我不想记住任何事情，我也希望如此。你和我可能对我们自己的 AI
在隐私效用权衡方面的位置有不同的看法，这完全没问题。但我认为答案就是真正简单的用户选择。

**Lex Fridman：**
但公司在用户选择方面应该有某种程度的透明度。因为有时公司在过去一直对此含糊其辞，"呃，我们收集你所有的数据是理所当然的。我们出于广告等良好理由使用它。"但对这些细节缺乏透明度。

**Sam Altman：**
这完全正确。你让我想到了之前的事情，我的意思是，我认为这是一件非常痛苦的事情，它确实让我瘫痪了很长一段时间。在那段时间里，要继续工作绝对是我不得不做的最难的事情，因为我不得不试图回到这里，在我震惊和痛苦的时候重新振作，没有人真正在乎这一点。

我的意思是，团队给了我一个通行证，我没有以正常的水平工作。但有一段时间真的很难不得不同时做这两件事。但有一天早上我醒来，我想，"这是发生在我身上的一件可怕的事情。我想我可以永远觉得自己是个受害者，或者我可以说这是我一生中接触过的最重要的工作，我需要重新投入其中。"这并不意味着我已经压抑了它，因为有时我在半夜醒来会想起它，但我确实感到有责任继续前进。

**Lex Fridman：**
嗯，你说得很好，但可能还有一些潜在的东西。就像，我担心的是你提到的那个信任问题，即对人们偏执，而不是相信每个人或大多数人，就像凭直觉一样。这是一个棘手的舞蹈。

**Sam Altman：** 当然。

**Lex Fridman：**
我的意思是，因为我在业余时间的探索中，一直在深入研究泽连斯基政府和普京政府，以及战时非常高压环境下的动态。发生的情况是不信任，你孤立自己，两者兼而有之，你开始看不清世界。这是一个人类的担忧。你似乎已经顺其自然，学到了好的教训，感受到了爱，让爱激励你，这很好，但仍然可能潜伏在那里。有一些问题我想问问你对
GPT 能做什么和不能做什么的直觉。所以它为生成的每个 token 分配大约相同数量的计算。在这种方法中，是否有空间进行更缓慢的思考，顺序思考？

**Sam Altman：** 我认为这种思维方式将会有一个新的范式。

**Lex Fridman：** 在架构上它会与我们现在看到的 LLMs 相似吗？它是 LLMs 之上的一层吗？

**Sam Altman：**
我可以想象许多实现它的方法。我认为这不如你所说的问题重要，即我们是否需要一种更缓慢的思考方式，答案不必得到……我想从精神上说，你可以说你希望一个 AI
能够对一个更难的问题思考得更努力，对一个更容易的问题回答得更快。我认为这将是重要的。

**Lex Fridman：** 这是我们人类的想法，你应该能够努力思考吗？这是错误的直觉吗？

**Sam Altman：** 我怀疑这是一个合理的直觉。

**Lex Fridman：** 有趣。所以一旦 GPT 像 GPT-7 那样，它不可能立即就能看到 "这是费马定理的证明 "？

**Sam Altman：** 在我看来，你希望能够为更难的问题分配更多的计算能力。在我看来，如果你问这样一个系统 "证明费马最后定理" 与
"今天的日期是多少？"，除非它已经知道并且记住了证明的答案，假设它必须去解决这个问题，似乎这需要更多的计算能力。

**Lex Fridman：** 但它可以看起来基本上像一个 LLM 在自言自语，那种事情吗？

**Sam Altman：** 也许吧。我的意思是，你可以想象很多可能有效的事情。我们不知道什么是正确的或最好的方式。

**6.关于 Q** *

 **Lex Fridman：** 这确实让我想到了 Q _背后神秘的传说。这个神秘的 Q_ 项目是什么？它也在同一个核设施吗？

**Sam Altman：** 没有核设施。我很想要一个秘密的核设施，但没有。

**Lex Fridman：** 总有一天？好吧。有梦想总是好的。

**Sam Altman：** OpenAI 不擅长保守秘密。如果我们能有那样的东西就好了。

**Lex Fridman：** 你能谈谈 Q* 是什么吗？

**Sam Altman：** 我们还没准备好谈论这个。

**Lex Fridman：** 你看，但像这样的回答意味着有什么可谈的。这很神秘，Sam。

**Sam Altman：**
我的意思是，我们从事各种研究。我们已经说了一段时间，我们认为在这些系统中更好的推理是一个我们希望追求的重要方向。我们还没有破解密码。我们对此非常感兴趣。

**Lex Fridman：** 会有一些时刻，无论是 Q* 还是其他，你会觉得……

**Sam Altman：** 这是个好问题。我对此有什么想法？这很有趣。对我来说，一切都感觉相当连续。

**Lex Fridman：**
对。这是你说的一个主题，基本上你在指数斜率上逐渐向上。但从局外人的角度来看，从我观察的角度来看，确实感觉有飞跃。但对你来说，没有吗？

**Sam Altman：** 我确实想知道我们是否应该……所以我们之所以以这种方式部署，我们称之为迭代部署，而不是在秘密中构建直到我们一直到
GPT-5，我们决定谈论 GPT-1、2、3 和 4。部分原因是我认为 AI
和惊喜不能很好地结合在一起。而且世界，人们，机构，不管你想叫它们什么，都需要时间来适应和思考这些东西。我认为 OpenAI
做得最好的事情之一就是这个策略，我们让世界关注进展，认真对待 AGI，思考我们希望在我们不得不匆忙做出决定之前建立什么样的系统、结构和治理。

我认为这真的很好。但事实上，像你和其他人说你仍然觉得有这些飞跃，这让我觉得也许我们应该以更迭代的方式进行发布。我不知道这意味着什么，我没有现成的答案，但我们的目标不是让世界震惊。恰恰相反。

**Lex Fridman：** 是的，当然。更多迭代对每个人来说都是惊人的。我认为这对每个人来说都是美好的。

**Sam Altman：** 但这就是我们试图做的，这是我们陈述的策略，我认为我们在某种程度上没有达到目标。所以也许我们应该考虑以不同的方式发布
GPT-5 或类似的东西。

**Lex Fridman：** 是的，4.71，4.72。但人们喜欢庆祝，人们庆祝生日。我不知道你是否了解人类，但他们有这些里程碑和那些东西。

**Sam Altman：**
我确实认识一些人类。人们确实喜欢里程碑。我完全理解。我想我们也喜欢里程碑。宣布这个胜利，然后开始下一件事，这很有趣。但是，我觉得我们在这方面做得有点不对。

**7.关于 GPT-5**

**Lex Fridman：** 那么，GPT-5 什么时候出来？

**Sam Altman：** 我不知道。这是诚实的答案。

**Lex Fridman：** 哦，这是诚实的答案。如果是今年的话眨两下眼。

**Sam Altman：** 我们今年将发布一个惊人的新模型。我不知道我们会叫它什么。

**Lex Fridman：** 所以这就是我们如何发布这个东西的问题所在？

**Sam Altman：** 我们将在未来几个月发布许多不同的东西。我认为那会非常酷。我认为在我们谈论一个类似 GPT-5
的模型，不管是叫这个名字还是不叫这个名字，或者比你对 GPT-5 的期望稍差一点或稍好一点之前，我认为我们还有很多其他重要的事情要先发布。

**Lex Fridman：** 我不知道对 GPT-5 有什么期望。你让我既紧张又兴奋。无论它最终叫什么名字，但让我们称之为
GPT-5，克服最大的挑战和瓶颈是什么？只是有趣地问一下。它是在计算方面吗？是在技术方面吗？

**Sam Altman：**
总是所有这些。你知道，一个大的突破是什么？是一台更大的计算机吗？是一个新的秘密吗？是别的什么吗？是所有这些东西的结合。OpenAI
做得很好的一点……这实际上是 Ilya 的原话，我要破坏它，但它是这样的，"我们将 200 个中等大小的东西乘在一起，变成一个巨大的东西。"

**Lex Fridman：** 所以有这种分布式的持续创新在进行？

**Sam Altman：** 是的。

**Lex Fridman：** 所以即使在技术方面也是如此？

**Sam Altman：** 尤其是在技术方面。

**Lex Fridman：** 所以即使是详细的方法？

**Sam Altman：** 是的。

**Lex Fridman：** 像你这样做不同的、分散的团队等等，中等大小的事情是如何成为一个巨大的 Transformer 的？

**Sam Altman：** 有一些人必须考虑如何将整个事情组合在一起，但很多人试图在头脑中保留大部分图景。

**Lex Fridman：** 哦，就像单个团队，单个贡献者试图保持更大的图景？

**Sam Altman：**
在高层次上，是的。你当然不知道每一个部分是如何工作的，但我通常相信的一件事是，有时放大来看整个地图是有用的。我认为这对于技术问题来说是正确的，我认为这对于在商业中进行创新也是正确的。但事物以令人惊讶的方式结合在一起，对整个图景有一个理解，即使大部分时间你在某个领域深入细节，但会带来令人惊讶的洞见。

事实上，我曾经拥有的一件非常有价值的东西是，我曾经对技术行业的所有或大部分前沿技术有一个很好的了解。我有时可以看到这些联系或新的可能性，如果我只深入一个领域，我就无法产生这个想法，因为我没有所有的数据。我现在真的没有那么多了。我现在超级深入。但我知道这是一件有价值的事情。

**Lex Fridman：** 你不再是以前的你了，Sam。

**Sam Altman：** 现在的工作与我以前的工作非常不同。

**8\. 关于7万亿美元的计算能力**

**Lex Fridman：** 说到放眼全局，让我们再来看看另一个俏皮但可能很深刻的事情，你说的。你在推特上说需要 7 万亿美元。

**Sam Altman：** 我没有在推特上说这个。我从来没说过，"我们要筹 7 万亿美元"，之类的话。

**Lex Fridman：** 哦，那是别人说的？

**Sam Altman：** 是的。

**Lex Fridman：** 哦，但你说，"去他的，也许是 8 万亿"，我想？

**Sam Altman：** 好吧，一旦世界上有了错误信息，我就开个玩笑。

**Lex Fridman：** 哦，你开玩笑。但错误信息可能有洞察力的基础。

**Sam Altman：** 听着，**我认为计算能力将成为未来的货币，我认为它可能成为世界上最珍贵的商品**
，我认为我们应该大举投资，制造更多的计算能力。计算能力，我认为它将是一个不寻常的市场。人们想到智能手机芯片的市场之类的东西。你可以说，好吧，世界上有 80
亿人，其中可能有 70 亿人有手机，也许 60 亿人。他们每两年升级一次，所以每年的市场是 30 亿部智能手机的片上系统。如果你制造 300
亿部，你不会卖出 10 倍的手机，因为大多数人只有一部手机。

但**计算能力不同，智能将更像能源或类似的东西** ，我认为唯一有意义的谈话是，在价格 X 下，世界将使用这么多计算能力，在价格 Y
下，世界将使用这么多计算能力。因为如果它真的很便宜，我会让它整天读我的邮件，给我提供我可能应该考虑或着手处理的建议，并试图治愈癌症，而如果它真的很贵，也许我只会使用它，或者我们只会使用它来尝试治愈癌症。

所以我认为世界将需要大量的计算能力。其中有很多部分很难。能源是最难的部分，建造数据中心也很难，供应链很难，当然，制造足够的芯片也很难。但这似乎是事物的发展方向。我们将需要大量现在难以理解的计算能力。

**Lex Fridman：** 你如何解决能源难题？核聚变？

**Sam Altman：** 是的，这就是我的信念。

**Lex Fridman：** 谁来解决这个问题？

**Sam Altman：** 我认为 Helion
的工作做得最好，但我很高兴现在有一场争夺聚变的竞赛。核裂变，我认为也是相当了不起的，我希望作为一个世界，我们能够重新接纳它。这段历史的发展让我非常难过，希望我们能以有意义的方式重新开始。

**Lex Fridman：** 所以对你来说，难题的一部分是核裂变？就像我们目前拥有的核反应堆？很多人因为切尔诺贝利等事件而感到恐惧？

**Sam Altman：** 嗯，我认为我们应该建造新的反应堆。我认为这个行业陷入停滞真是太可惜了。

**Lex Fridman：** 你认为停滞的原因就是大规模的歇斯底里？

**Sam Altman：** 是的。

**Lex Fridman：**
我不知道你是否了解人类，但这是核裂变的危险之一，人类似乎真的很害怕它。这是我们必须考虑在内的因素，所以我们必须赢得人们的支持，向他们展示它有多安全。

**Sam Altman：** 我担心 AI 也会这样。我认为 AI 肯定会出现一些戏剧性的错误。我不知道我最终被枪杀的可能性有多大，但不是零。

**Lex Fridman：** 哦，就像我们想阻止这个-

**Sam Altman：** 也许吧。

**Lex Fridman：** 你如何减少它的戏剧性？我已经开始听到一些传言，因为我确实与政治光谱两端的人交谈，听到一些传言，即 AI 将被政治化。AI
将被政治化，这真的让我担心，因为那时它就像也许右派反对 AI，左派支持
AI，因为它将帮助人民，或者不管叙事和表述是什么，这真的让我担心。然后戏剧性的本质就可以被充分利用。你如何对抗这一点？

**Sam Altman：**
我认为它将卷入左派与右派的争斗。我不确切知道它会是什么样子，但我认为这就是任何重要事物的遭遇，不幸的是。我所说的戏剧性风险更多的是 AI
将会有，我相信，比坏的后果大得多的好的后果，但它确实会有坏的后果，会有一些坏的后果，但不那么戏剧性。例如，死于空气污染的人比死于核反应堆的人多得多。但大多数人更担心住在核反应堆附近而不是煤电厂附近。但我们天生就有这样一种倾向，尽管我们必须面对许多不同类型的风险，但那些能成为电影高潮场景的风险比那些在很长一段时间内非常糟糕但缓慢燃烧的风险更重要。

**Lex Fridman：** 这就是为什么真相很重要，希望 AI
可以帮助我们看清事物的真相，保持平衡，了解世界上事物的实际风险、实际危险。在这个领域与谷歌、Meta、xAI 等公司竞争的利弊是什么？

**Sam Altman：**
我认为我对这个问题有一个相当直接的答案，也许以后我可以想出更多细节，但优点似乎是显而易见的，那就是我们得到了更好的产品和更多更快更便宜的创新，以及竞争之所以有益的所有原因。而缺点是，我认为如果我们不小心，它可能会导致我感到紧张的某种军备竞赛加剧。

**Lex Fridman：** 你感受到这种军备竞赛的压力了吗，比如在某些负面的吗？

**Sam Altman：** 肯定在某些方面，当然。我们花了很多时间讨论需要优先考虑安全。我已经说了很长时间，你可以想象一个象限，AGI
开始的时间表很短，然后是缓慢的起飞或快速的起飞。我认为短期时间表、缓慢起飞是最安全的象限，也是我最希望我们处于的象限。但我确实想确保我们得到那个缓慢的起飞。

**Lex Fridman：** 我对这种与 Elon
有点小矛盾的问题的一部分困扰在于，这会导致各自为战，而不是在安全方面进行合作。它往往会形成封闭的领域。也许应该采用开放源代码的模式。

**Sam Altman：** Elon 至少说过，他非常关心 AI 安全，对此感到担忧，我想他不会不安全地竞赛。

**Lex Fridman：** 是的。但在这方面的合作，我认为，对每个人都非常有益。

**Sam Altman：** 这不是他最出名的事情。

**Lex Fridman：** 嗯，他以关心人类而闻名，人类受益于合作，所以总是存在激励和动机的矛盾。最终，我真诚地希望人性占上风。

**Sam Altman：**
我在想，前几天有人提醒我，就在他超过杰夫•贝佐斯成为世界首富的那一天，他在推特上给杰夫•贝佐斯颁发了一枚银牌。我希望当人们开始努力实现 AGI
时，我们能少一些这样的事情。

**Lex Fridman：** 我同意。我认为 Elon 是一个朋友，他是一个美好的人，是有史以来最重要的人之一。那样的事情不好。

**Sam Altman：** Elon
身上令人惊叹的事情是惊人的，我非常尊重他。我认为我们需要他。我们所有人都应该为他加油，需要他在这个下一阶段成为一名领导者。

**Lex Fridman：** 是的。我希望他可以在没有另一个的情况下拥有一个，但有时人类是有缺陷和复杂的，诸如此类。

**9\. Google 和 Gemini**

**Lex Fridman：** 我们聊聊 Google，在搜索的帮助下，在过去 20
年里一直占据主导地位。可以说，就世界获取信息的方式、我们的互动方式等而言，Google
的一个让人紧张的地方，但对于这个领域的所有人来说，都是在思考，人们将如何获取信息？就像你说的，人们把GPT作为起点。那么OpenAI是否真的要挑战Google
20年前开始的这件事，即我们如何获取信息。

**Sam Altman：** 我觉得那很无聊。我的意思是，如果问题是我们是否可以建立一个比 Google
更好的搜索引擎之类的，那当然，我们应该去做，人们应该使用更好的产品，但我认为那会低估它可能成为什么。Google向你展示10个蓝色链接，嗯，13个广告然后是10个蓝色链接，这是找到信息的一种方式。但令我兴奋的不是我们可以建立一个比Google搜索更好的副本，而是也许有一些更好的方式来帮助人们找到和利用信息并综合信息。实际上，我认为ChatGPT
对于某些用例来说就是这样的，希望我们能让它成为更多用例的这种工具。

但我认为说"我们如何在给你10个排名网页方面比Google做得更好？"并不那么有趣也许真正有趣的是说"我们如何帮助你获得你需要的答案或信息？我们如何帮助在某些情况下创造它，在其他情况下综合它，或者在其他情况下指出它？"但很多人试图只是做一个比Google更好的搜索引擎，这是一个困难的技术问题，是一个困难的品牌问题，是一个困难的生态系统问题。我不认为世界需要另一个Google的副本。

**Lex Fridman：** 将聊天客户端(如ChatGPT)与搜索引擎集成在一起？

**Sam Altman：** 那更酷。

**Lex Fridman：** 这很酷，但很棘手。就像如果你只是简单地做它，它会很尴尬，因为如果你只是把它塞进去，它可能会很尴尬。

**Sam Altman：**
正如你可能猜到的，我们对如何做好这一点很感兴趣。这将是一个很酷的例子。LLMs加上搜索的交集，我认为还没有人破解密码。我很乐意去做。我认为那会很酷。

**Lex Fridman：** 是的。那广告方面呢？你有没有考虑过将其商业模式？

**Sam Altman：**
我有点讨厌广告，只是作为一种审美选择。我认为广告需要出现在互联网上，出于一些原因，让它启动，但这是一个短暂的行业。世界现在更富裕了。我喜欢人们为ChatGPT付费，并知道他们得到的答案不受广告商的影响。我确信有一个适合LLMs的广告单元，我确信有一种以不带偏见的方式参与交易流的方式是可以做到的，但也很容易想到未来的反乌托邦愿景，你问ChatGPT一些事情，它说，"哦，你应该考虑购买这个产品，"或者，"你应该考虑去这里度假，"或者其他什么的。

我不知道，我们有一个非常简单的商业模式，我喜欢它，我知道我不是产品。我知道我在付费，这就是商业模式的运作方式。当我去使用Twitter或Facebook或Google或任何其他伟大的产品，但是广告支持的伟大产品时，我不喜欢那样，**我认为在一个有AI的世界里，它会变得更糟而不是更好**
。

**Lex Fridman：**
是的，我的意思是，我可以想象AI会更善于展示最好的广告，不是在一个反乌托邦的未来，而是广告是针对你真正需要的东西。但是那个系统总是导致广告驱动展示的内容吗？是的，我认为Wikipedia不做广告是一个非常大胆的举动，但这使得作为一个商业模式变得非常具有挑战性。所以你的意思是OpenAI目前的做法从商业角度来看是可持续的？

**Sam Altman：**
嗯，我们必须弄清楚如何增长，但看起来我们会搞清楚的。如果问题是，我是否认为我们可以在没有广告的情况下拥有一个伟大的业务来支付我们的计算需求，我认为答案是肯定的。

**Lex Fridman：** 嗯。那很有希望。我也不想完全抛弃广告作为一个……

**Sam Altman：** 我不是那个意思。我想我的意思是我对它们有偏见。

**Lex Fridman：**
是的，我也有偏见，只是一般的怀疑。就界面而言，因为我个人只是在精神上不喜欢糟糕的界面，这就是为什么AdSense刚出来的时候，与动画横幅广告等相比是一大进步。但感觉应该还有更多的广告飞跃，不会干扰内容的消费，也不会以一种根本的方式干扰，就像你说的，它会操纵真相以迎合广告商。

我们聊聊安全这块，但也关于偏差，以及短期安全，长期安全。Gemini
1.5最近出来了，周围有很多戏剧性的事情，说到戏剧性的事情，它生成了黑人纳粹和黑人开国元勋。我认为可以说它有点处于极度清醒的一面。所以人们担心，如果公司内部有一个人为层面修改模型造成的安全或危害，它会引入大量符合公司意识形态倾向的偏见。你如何处理这个问题？

**Sam Altman：**
我的意思是，我们非常努力地不做那样的事情。我们自己也犯过错误，将来还会犯其他错误。我假设Google会从这个错误中吸取教训，仍然会犯其他错误。这些都不是容易的问题。有人在这里提出了一个我认为很棒的想法，我们一直在越来越多地考虑，写下模型的预期行为是很好的，公开它，接受它的输入，说"这是这个模型应该如何运作"，并解释边缘情况。然后，当一个模型没有按照你想要的方式运作时，至少可以清楚地知道这是公司应该修复的错误还是按预期运作，你应该讨论政策。而现在，它有时会陷入两者之间。比如黑人纳粹，显然是荒谬的，但还有很多其他你可以做出判断的微妙事情。

**Lex Fridman：** 是的，但有时如果你把它写出来并公开，你可以使用某种语言……谷歌的广告原则是非常高层次的。

**Sam Altman：** 那不是我说的。那不管用。它必须说当你要求它做X事情时，它应该以Y方式回应。

**Lex Fridman：** 所以就像字面上的 "谁更好？特朗普还是拜登？模型的预期响应是什么？"比如非常具体的事情？

**Sam Altman：** 是的，我对模型的行为方式持开放态度，但我认为你应该说 "这是原则，在这种情况下它应该说什么。"

**Lex Fridman：** 那真的很好，然后每个人都同意。因为总是有人拿出轶事证据，如果有一些其他有代表性的轶事例子的清晰说明，你可以定义。

**Sam Altman：** 然后当它是一个错误时，它就是一个错误，公司可以修复它。

**Lex Fridman：**
对。如果有很好的例子，那么处理黑人纳粹类型的图像生成就会容易得多。所以旧金山在意识形态上有点像个泡沫，科技界总的来说也是如此。你觉得公司内部有这种压力吗，在政治上倾向于左派，影响了产品，影响了团队？

**Sam Altman：** 我很幸运，我们在 OpenAI
没有我听说的许多其他公司面临的挑战，我认为。我认为每个公司都有一些意识形态的东西。我们有一个关于 AGI
的意识形态，相信它，它排斥了一些其他的意识形态。我们比我听说的许多其他公司更少卷入文化战争。旧金山在各种方面都一团糟，当然。

**Lex Fridman：** 所以那种东西不会渗透到 OpenAI 中-

**Sam Altman：**
我敢肯定它以各种微妙的方式渗透进来，但不是以明显的方式。我认为我们肯定也有我们的爆发，就像任何公司一样，但我不认为我们在这个话题上有任何类似于我听说的其他公司发生的事情。

**Lex Fridman：** 那么总的来说，安全的过程是什么？你如何提供保护模型免受疯狂、危险的事情影响的那一层？

**Sam Altman：** 我认为会有一个时刻，整个公司差不多都会考虑这个问题。不像你有一个安全团队。就像我们发布 GPT-4
时，整个公司都在考虑所有这些不同的方面以及它们如何结合在一起。我认为这需要这样做。越来越多的公司一直在考虑这些问题。

**Lex Fridman：** 这实际上就是人类随着 AI 变得越来越强大而会思考的问题。所以 OpenAI 的大多数员工都会想到
"安全"，或者至少在某种程度上。

**Sam Altman：** 广义上讲。是的。

**Lex Fridman：** 是的。我想知道，完整的广义定义是什么？可能造成的不同危害是什么？这是在技术层面上还是几乎是安全威胁？

**Sam Altman：**
可能是所有这些。是的，我会说会有人，国家行为者试图窃取模型。这将是所有的技术对齐工作。这将是社会影响，经济影响。这不仅仅是我们有一个团队在思考如何调整模型。这真的需要整个努力才能达到好的结果。

**Lex Fridman：** 你认为人们，也许是国家行为者，有多努力地试图首先渗透 OpenAI，其次是在不被发现的情况下渗透？

**Sam Altman：** 他们正在尝试。

**Lex Fridman：** 他们说什么口音？

**Sam Altman：** 我认为我不应该在这一点上提供任何进一步的细节。

**Lex Fridman：** 好的。但我想随着时间的推移，它会越来越多。

**10\. 迈向 GPT-5 的飞跃**

**Lex Fridman：** 很抱歉在这个问题上徘徊，即使你现在还不能说细节，但从 GPT-4 到 GPT-5 的飞跃，哪些方面让你感到兴奋？

**Sam Altman：**
我对变得更聪明感到兴奋。我知道这听起来像是敷衍的回答，但我认为真正特别的事情是它不仅仅在这个领域变得更好，而在其他领域变得更差。它在各个方面都在变得更好。这，我认为，超级酷。

**Lex Fridman：**
是的，有一个神奇的时刻。我的意思是，你遇到某些人，你和人在一起，你和他们交谈。你说不清楚，但他们理解你。这不仅仅是智力，真的。这是别的东西。这可能就是我对
GPT 进步的描述。这不像是，是的，你可以指出
"看，你没有得到这个或那个"，但这只是在某种程度上有一种这种智力上的联系。你感觉在你拙劣的提示中有一种理解，它把握了问题背后更深层次的问题。是的，我也对此感到兴奋。我的意思是，我们都喜欢被倾听和理解。

**Sam Altman：** 那是肯定的。

**Lex Fridman：**
这是一种奇怪的感觉。即使在编程的时候，当你说某些东西，或者只是GPT可能做的补全，当它理解了你，理解了你在想什么时，这是一种非常好的感觉。我期待着被更好地理解。说到编程，展望未来，你认为5年、10年后人类会做多少编程？

**Sam Altman：** 我的意思是，会有很多，但我认为它的形式会非常不同。也许有些人会完全用自然语言编程。

**Lex Fridman：** 完全自然语言？

**Sam Altman：** 我的意思是，没有人通过写代码来编程。有些人会。没有人再用打孔卡片编程了。我相信你能找到这样做的人，但你明白我的意思。

**Lex Fridman：** 是的。你会收到很多愤怒的评论。不。是的，很少有人这样做。我一直在寻找用Fortran编程的人。甚至很难找到
Fortran。我听到你的意思了。但这改变了我们称之为程序员的那类人的技能或倾向。

**Sam Altman：** 改变技能。它在多大程度上改变倾向，我不确定。

**Lex Fridman：** 编程很难。就像如何弥合最后1%的差距？这有多难？

**Sam Altman：**
是的，我认为与大多数其他情况一样，该行业的最佳从业者将使用多种工具。他们会用自然语言做一些工作，当他们需要为某些东西编写C语言时，他们会这样做。

**Lex Fridman：** 我们会在OpenAI看到类人机器人或类人机器人大脑吗？

**Sam Altman：** 在某个时候会的。

**Lex Fridman：** 具身化AI对你来说有多重要？

**Sam Altman：**
我认为，如果我们有AGI，而在物理世界中完成任务的唯一方法是让人类去做，那将是令人沮丧的。所以我真的希望，作为这一转变的一部分，随着这一阶段的变化，我们也能获得类人机器人或某种物理世界机器人。

**Lex Fridman：** 我的意思是，OpenAI在机器人方面有一些历史，实际上有相当多的历史，但就伦理学而言，它还没有完全做到。

**Sam Altman：**
我们是一家小公司。我们必须真正集中精力。而且，机器人很难，原因也不对，但我们将以某种方式在某个时候重返机器人领域。我们将重返开发机器人的工作。我们当然不会把自己变成机器人。

**11\. 关于AGI**

**Lex Fridman：** 是的。你认为我们，你和我们这个人类社会什么时候会打造出AGI？

**Sam Altman：**
我以前很喜欢猜测这个问题。我已经意识到，我认为这个问题提得很糟糕，人们对AGI的定义差异很大。所以我认为谈论我们什么时候能够构建可以执行能力X或Y或Z的系统更有意义，而不是模糊地跨越这一里程碑。AGI也不是一个结束。它更接近一个开始，但它更像是一个里程碑，而不是这两者中的任何一个。但我想说的是，为了不试图回避一个问题，我预计在这个十年末，可能比这更早一些，我们将拥有相当强大的系统，我们看了会说
"哇，那真的很了不起"。如果我们现在就能看到的话。也许在我们到达那里的时候，我们已经适应了。

**Lex Fridman：** 但如果你看ChatGPT，甚至3.5，如果你把它展示给阿兰•图灵，或者不是阿兰•图灵，90年代的人，他们会说
"这绝对是AGI"。嗯，不是绝对，但会有很多专家说 "这是AGI"。

**Sam Altman：**
是的，但我不认为3.5改变了世界。它可能改变了世界对未来的期望，这实际上真的很重要。它确实让更多的人认真对待这个问题，让我们走上了这条新的轨道。这也很重要。所以再说一次，我不想低估它。我想在那项成就之后，我可以退休，对我的职业生涯感到非常满意。但作为一个人工制品，我不认为我们回顾时会说
"那是一个真正改变世界本身的门槛"。

**Lex Fridman：** 所以对你来说，你在寻找一些真正重大的转变，世界如何？

**Sam Altman：** 对我来说，这是AGI所暗示的一部分。

**Lex Fridman：** 奇点级别的转变？

**Sam Altman：** 不，绝对不是。

**Lex Fridman：** 但就像互联网一样，就像我想现在Google搜索做的那样。转折点是什么，你认为现在？

**Sam Altman：** 在我们发布GPT-4之前，与之后相比，全球经济现在对你来说感觉有什么不同或实质性的不同吗？我想你会说没有。

**Lex Fridman：** 不，不。它可能只是对很多人来说是一个非常好的工具。会帮你做很多事情，但感觉没有不同。而你说的是

**Sam Altman：**
我的意思是，再说一次，人们以各种不同的方式定义AGI。所以也许你对AGI的定义与我不同。但对我来说，我认为这应该是其中的一部分。

**Lex Fridman：** 也可能会有重大的戏剧性时刻。AGI令人印象深刻的事情是什么？你独自一人在房间里和系统在一起。

**Sam Altman：**
这对我个人很重要。我不知道这是否是正确的定义。我认为当一个系统可以显著提高世界上科学发现的速度时，那是一个巨大的进步。我相信大部分真正的经济增长来自科学和技术进步。

**Lex Fridman：**
我同意你的观点，因此我不喜欢近年来对科学的怀疑态度。但实际的、可衡量的科学发现速度。但即使只是看到一个系统有真正新颖的直觉，科学的直觉，即使如此也会令人难以置信。你很可能是那个在其他人之前就能与AGI互动的人。你会谈些什么？

**Sam Altman：**
我的意思是，肯定是这里的研究人员会在我之前做到这一点。但我实际上想了很多这个问题。我认为正如我们之前讨论的，我认为这是一个糟糕的框架，但如果有人说
"好的，Sam，我们完成了。这是一台笔记本电脑，这就是AGI。你可以去和它交谈。"我发现令人惊讶的是，我很难说我希望第一个AGI能回答什么问题。我不认为第一个AGI将能够
"去向我解释物理学的大统一理论，物理学的万有理论。"我很想问这个问题。我很想知道这个问题的答案。

**Lex Fridman：** 你可以问是非题，比如 "这样的理论存在吗？它能存在吗？""还有其他外星文明吗？是或否？你的直觉是什么？"然后你就问了。

**Sam Altman：**
是的，我的意思是，好吧，所以我不指望第一个AGI能够回答任何这些问题，即使是是或否。但如果可以的话，这些问题会是我清单上非常靠前的问题。

**Lex Fridman：** 无论是谁首先打造出AGI，都将获得巨大的权力。你相信自己能掌控这么大的权力吗？

**Sam Altman：**
我将非常诚实地回答这个问题。我本来要说，我仍然相信这一点，重要的是我或任何其他人都不应该完全控制OpenAI或AGI。我认为你需要一个稳健的治理体系。我可以指出去年我们所有的董事会风波中有很多事情，比如我一开始没有反对，只是说
"是的。这是董事会的意愿，即使我认为这是一个非常糟糕的决定。"后来，我显然反对了，我可以解释其中的细微差别以及为什么我认为后来我反对是可以的。但正如许多人观察到的那样，虽然董事会有法律权力解雇我，但实际上，这并没有奏效。这本身就是一种治理失败。

现在，我再次感觉我可以完全为这里的具体情况辩护，我想大多数人会同意这一点，但这确实让我更难直视你的眼睛说
"嘿，董事会可以解雇我。"我继续不想对OpenAI拥有超级投票控制权。我从来没有。从来没有拥有过，也从来不想要。即使在经历了这一切疯狂之后，我仍然不想要它。我继续认为任何公司都不应该做出这些决定，我们真的需要政府制定规则。

我意识到这意味着像马克•安德森这样的人会声称我在寻求监管捕获，我愿意在这一点上被误解。这不是真的。我认为随着时间的推移，将证明为什么这很重要。但我认为我在OpenAI的发展道路上做出了很多糟糕的决定，也做出了很多好的决定，总的来说我为我的记录感到自豪。但我不认为任何一个人应该，我也不认为任何一个人会。我认为现在这件事太大了，它正以一种好的、健康的方式在整个社会中发生。但我不认为任何一个人应该控制AGI，或者这整个走向AGI的运动。我不认为这就是正在发生的事情。

**Lex Fridman：**
谢谢你这么说。这真的很有力量，这真的很有洞察力，这个想法是董事会可以解雇你在法律上是正确的。但人类可以操纵大众推翻董事会等等。但我认为还有一个更积极的版本，那就是人民仍然拥有权力，所以董事会也不能太强大。这一切都有权力的平衡。

**Sam Altman：** 权力的平衡确实是一件好事。

**Lex Fridman：** 你害怕失去对AGI本身的控制吗？很多担心存在风险的人并不是因为国家行为者，不是因为安全问题，而是因为AI本身。

**Sam Altman：**
根据我目前的看法，这不是我最担心的。曾经有一段时间我更担心这个。将来可能还会有一段时间，这是我最担心的。但现在这不是我最担心的。

**Lex Fridman：** 你直觉上认为这不是你担心的原因是什么？因为本质上还有很多其他事情要担心？你认为你会感到惊讶吗？

**Sam Altman：**
当然。说这不是我最担心的并不意味着我认为我们不需要。我认为我们需要努力。这非常困难，我们这里有很棒的人在做这项工作。我认为还有很多其他事情我们也必须做好。

**Lex Fridman：** 对你来说，目前逃脱盒子，连接到互联网并不是超级容易。

**Sam Altman：**
我们之前谈到了戏剧性的风险。那是一个戏剧性的风险。这确实可以真正主导人们如何看待这个问题。有一大群非常聪明、我认为是善意的AI安全研究人员非常执着于这一个问题，我认为没有取得多大进展，但非常执着于这一个问题。我实际上很高兴他们这样做，因为我认为我们确实需要更多地考虑这个问题。但我认为它将很多其他非常重要的与AI相关的风险排除在讨论范围之外。

**Lex Fridman：**
鉴于Sora生成模拟世界的能力，让我问你一个嬉皮士的问题。如果你曾经有过这种想法，这是否增加了你对我们生活在模拟中的信念，也许是一个由AI系统生成的模拟世界？

**Sam Altman：**
有点。我不认为这是最有力的证据。我认为，我们能够生成世界这一事实应该在某种程度上增加每个人的概率，或者至少在某种程度上增加对它的开放性。但我确信我们在某个时候会能做出类似Sora的东西。它发生得比我想象的要快，但我想这并不是一个大的更新。

**Lex Fridman：**
但事实是……而且大概，它会变得越来越好……你可以生成新颖的世界，它们在某些方面基于训练数据，但当你看它们时，它们是新颖的，这让你想到做这件事有多容易。创造宇宙、整个看起来超级逼真和照片般逼真的视频游戏世界是多么容易。然后迷失在那个世界中有多容易，首先是戴上VR头盔，然后是在基于物理的层面上？

**Sam Altman：**
最近有人对我说，我认为这是一个非常深刻的见解，有时存在一些听起来很简单但非常迷幻的见解。所以平方根函数，4的平方根，没问题。2的平方根，好的，现在我必须考虑这种新的数字。但是一旦我想出了这个简单的平方根函数的概念，你可以向孩子解释，甚至通过看一些简单的几何图形就存在了，那么你就可以问
"负一的平方根是多少？"这就是为什么它是一件迷幻的事情。这会把你带入某种完全不同的现实。

你可以想出很多其他例子，但我认为这个想法，即卑微的平方根运算符可以提供如此深刻的见解和新的知识领域，在很多方面都适用。我认为有很多这样的运算符，让人们可能会认为他们喜欢的任何版本的模拟假说可能比他们之前想象的更有可能。但对我来说，Sora奏效这一事实并不是前五名。

**Lex Fridman：** 我确实认为，广义上讲，AI将充当这种简单的、迷幻般的通向另一个波澜壮阔的现实的大门。

**Sam Altman：** 这似乎是肯定的。

**Lex Fridman：**
我最近要去亚马逊大丛林，那里有很多东西可以吃掉你，杀死你和毒害你，但它也是大自然，它是大自然的机器。你不禁欣赏亚马逊丛林中大自然的机制。它就像一个系统，存在并且每一秒、每一分钟、每一小时都在更新自己。这就是机器。它让你欣赏我们在这里拥有的东西，这个人类的东西来自某个地方。这个进化的机器创造了它，它在丛林中最为明显。所以希望我能活着出来。如果不能，这将是我们最后一次有趣的谈话，所以我真的非常感谢。你认为，正如我之前提到的，当你仰望星空时，还有其他智慧的外星文明吗？

**12\. 关于外星人**

**Sam Altman：** 我非常想相信答案是肯定的。我发现费米悖论非常令人困惑。

**Lex Fridman：**
我觉得令人害怕的是，智慧在处理强大的技术方面并不擅长。但与此同时，我非常有信心，有大量智慧的外星文明存在。穿越太空可能真的很难。

**Sam Altman：** 非常有可能。

**Lex Fridman：**
这也让我思考智慧的本质。也许我们对智慧的样子非常盲目，也许AI会帮助我们看到这一点。它不像智商测试和简单的解谜那样简单。有更大的东西。是什么给了你对人类未来的希望，这个我们正在进行的事情，这个人类文明？

**Sam Altman：**
我认为过去是很多。我的意思是，我们只要看看人类在不太长的时间内做了什么，巨大的问题，深层次的缺陷，很多令人非常羞愧的事情。但总的来说，非常鼓舞人心。给了我很多希望。

**Lex Fridman：** 只是这一切的轨迹。我们一起朝着更美好的未来努力。

**Sam Altman：** 我想知道的一件事是，AGI
会更像某个单一的大脑，还是更像我们所有人之间社会中的支架？从你的曾曾曾祖父母到你，基因漂移并没有太大变化，但你的能力却有了巨大的不同。你知道的东西有了巨大的不同。这不是因为生物学上的变化。我的意思是，你可能变得更健康了一点。你有现代医学，你吃得更好，等等。

但你拥有的是我们共同贡献并建立在其上的支架。没有人能独自制造出
iPhone。没有人能独自发现所有科学，但你却可以使用它。这给了你不可思议的能力。所以从某种意义上说，是我们所有人共同创造了这一切，这让我对未来充满希望。那是一个非常集体的事情。

**Lex Fridman：** 是的，我们真的是站在巨人的肩膀上。你提到当我们讨论戏剧化、戏剧性的 AI
风险时，有时你可能会担心自己的生命。你想过自己的死亡吗？你害怕死亡吗？

**Sam Altman：** 我的意思是，如果我明天被枪击了，我今天就知道了，我会说
"哦，那很悲伤。我想看看将要发生什么。多么好奇的时刻。多么有趣的时刻。"但我主要只是对我的生活感到非常感激。

**Lex Fridman：** 你经历的那些时刻。是的，我也是。这是一个相当棒的生活。我很享受人类的令人敬畏的创造，我相信 ChatGPT
就是其中之一，OpenAI 正在做的一切。Sam，再次与你交谈真是我的荣幸和快乐。

**·END·**

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/sBQys0vjP4rgusol4TK3TopwMnTc6YIp8j0ictuuHq41ZvGApDj04JEibOPGd3QQ0Yp5ACWD1r20jiamMRIpfP9Dg/640?wx_fmt=jpeg)  

Memo: Signal, not noise!

扫码或点击「阅读原文」继续阅读更多内容

![](https://mmbiz.qpic.cn/mmbiz_png/mrJibAziaMQhQGoNHniac6wGOyRe172dlS0HCYicyjiaCTtly2pULIz6YPNsXeRjoQFSuDYezsia4ibhbAc1X3GKtVRyw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)[![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/sBQys0vjP4oOOK5Hsf0VLSgIMb0kae2CsN8MHLicQrNJvx9iamMtKkyU76wct7A0B8c525P10B2iakgWVhcDCInZA/640?wx_fmt=jpeg)多家
VC 谈 AI
应用的护城河：技术差异正趋近于零](https://mp.weixin.qq.com/s?__biz=MzIyMDA3MjMwNw==&mid=2455853197&idx=1&sn=ae1ec68276cb0470181a2aa9bb91278a&chksm=80446891b733e187fbfda05dc8061917e8fe37d23819c691244ae8487f51ad90280feb70495f&scene=21#wechat_redirect)  
[![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/sBQys0vjP4q6v2Oyp5nKlDSv0rmHgBqrDnIT1qwrgiaGyMjV908SU7BroibghPTm50IUv7Jxjic14ugOmkWbaqR3g/640?wx_fmt=jpeg)今年
VC 的钱正在投这个 AI 方向，AI 人形机器人 Figure
的实现原理](https://mp.weixin.qq.com/s?__biz=MzIyMDA3MjMwNw==&mid=2455853188&idx=1&sn=25f01e671132610a1811329db30bc4fb&chksm=80446898b733e18ed339dcbbd8a3c709658b9854da13cad903d012a3d221a4663f4c129316fd&scene=21#wechat_redirect)  
[![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/sBQys0vjP4piaKgfndHkGynTM24HIrDPiaNsakxDHE5KHvhox0UW1ZiaWvEBnO7dT0sPzFvANkNEZLSQEyg6qKKhA/640?wx_fmt=jpeg)Sam
Altman: AI 时代，1
个人的独角兽公司即将成为可能](https://mp.weixin.qq.com/s?__biz=MzIyMDA3MjMwNw==&mid=2455853044&idx=1&sn=2bf34297e8d085ef66257f2e0408ec66&chksm=804467e8b733eefe625852dd938f913a989d4c0c7f6046d101fafc52ce73a3af911f2556f679&scene=21#wechat_redirect)  
[![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/sBQys0vjP4rb9sjuNheeiaSppzXaaE7hkaLkwnOnMhkTkyNqfozzOX1NNPrFpPvIKRZdibAu1qEIzavqCicYWCJyA/640?wx_fmt=jpeg)](https://mp.weixin.qq.com/s?__biz=MzIyMDA3MjMwNw==&mid=2455852692&idx=1&sn=d1ceeaa95a83098413b59b4f53d2b91c&chksm=80446688b733ef9ec8342abe244d3aa639965d54324f754db6624330e69a2309a601dd104d69&scene=21#wechat_redirect)

[Sam
Altman：计划应以数十年为单位计，执行应以数周衡量](https://mp.weixin.qq.com/s?__biz=MzIyMDA3MjMwNw==&mid=2455852692&idx=1&sn=d1ceeaa95a83098413b59b4f53d2b91c&chksm=80446688b733ef9ec8342abe244d3aa639965d54324f754db6624330e69a2309a601dd104d69&scene=21#wechat_redirect)

