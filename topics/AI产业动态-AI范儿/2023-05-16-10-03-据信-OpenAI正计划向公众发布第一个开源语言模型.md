# 据信-OpenAI 正计划向公众发布第一个开源语言模型

文章作者: AI范儿
发布时间: 2023-05-16 10:03
发布地: 北京
原文链接: http://mp.weixin.qq.com/s?__biz=Mzk0NzQzOTczOA==&mid=2247490454&idx=1&sn=11cbcfe1625e6c43c468020e237342e0&chksm=c3778a83f40003950bb283b74641a4f60922050008b1a8797d585c0c34cf0c09fe4f1114020f#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/OdmYSS49h7ErJaKzUaDbKfgJMfjvGIWcB7HfOribRpiaa9437uv48n4QQog5x2nvFy2GhOq26nm3zRtMia55J0Fiag/300

图｜OpenAI

文｜汤源

![](https://mmbiz.qpic.cn/mmbiz_png/OdmYSS49h7ErJaKzUaDbKfgJMfjvGIWcB0FVxYjMR2wYdlcxcI5DhCmGm0xe3ib13YOdYoG8mUd0C7FWy96YlLw/640?wx_fmt=png)

开源在google和chatGPT上越来越受欢迎，笔者判断OpenAI在开源计划中的应该是InstructGPT，而不是GPT本身。而这同样也会给google在LLMs方向的开源政策带来压力。

## 信源摘要  

###

“作为谷歌的竞争对手，OpenAI 正计划向公众发布他们的第一个开源语言模型，这可能会给谷歌带来压力，要求他们也这样做。OpenAI 270
亿美元的私人估值取决于他们专有的人工智能模型 GPT 是否被用于商业目的，不是开源软件。”

2023年2月，Meta
Platforms（原Facebook）发布了一系列先进的机器学习模型，它们能够理解对话式语言。这些模型向学术界和开发者开放，自此以来，人们利用它们创建了许多开源的替代品，来竞争Google、OpenAI和Microsoft等公司的专有AI软件。

开源AI模型在性能上已经“相当接近”专有模型，而且大多数软件开发者最终会选择使用免费的模型，这是加州大学伯克利分校计算机科学教授Ion
Stoica的观点。Stoica曾经参与开发了一个关键的开源AI模型，它使用了Meta的技术。

开源AI的发展正在“超越”专有AI的发展，而Google则面临着落后于时代的风险，因为它过于专注于专有软件。一位Google的高级工程师表示，Google应该在开源社区中树立自己的领导地位，并放弃对其模型的一些控制权。

Meta通过发布其模型也能从中受益，因为开发者会对其进行改进，并且Meta可以将这些改进纳入其内部AI。

OpenAI正在准备发布其首个开源语言模型，这可能会给Google带来更大的压力，促使其在开源AI方面发挥更大的作用。

开源AI模型比专有模型更便宜、更容易训练和使用，并且它们允许公司使用专有数据来解决自己的问题。

开源AI软件曾经阻碍过OpenAI的野心，而且有可能会再次出现同样的情况。OpenAI是一个与Google竞争的公司，它计划将其首个开源语言模型发布给公众。OpenAI的270亿美元私人估值依赖于其专有AI模型GPT被用于商业目的，而不是开源软件。

GPT是一个自回归语言模型，它有1750亿+个参数，比任何以前的非稀疏语言模型多10倍。GPT能够在少量示例或简单指令的条件下执行新的语言任务，这是目前大多数NLP系统仍然难以做到的。GPT在许多NLP数据集上都取得了强劲的表现，包括翻译、问答和填空任务，以及一些需要即时推理或领域适应的任务。

然而，GPT并不是开源的。它只能通过OpenAI的API使用，但是API非常昂贵。尽管高昂的成本限制了GPT在主流市场上的应用，但是研究人员和专业人士仍然积极地利用它构建原型和商业应用。

OpenAI API 由 GPT-3
语言模型提供支持，可以使用精心设计的文本提示（prompt）引导这些模型执行自然语言任务。但这些模型也可能产生不真实、有毒或反映有害情绪的输出。这部分是因为
GPT-3 被训练来预测大型互联网文本数据集上的下一个单词，而不是安全地执行用户想要的语言任务。换句话说，这些模型与他们的用户不一致。

通过人工反馈训练的模型为InstructGPT，这个模型主要用来调整已部署或将部署的LLM
GPT（如ChatGPT，GPT-4，甚至未来的GPT-5）。这些模型源自预训练的语言模型，如GPT-3。这些模型经过训练以遵循人类意图：既有指令给出的明确意图，也有真实性、公平性和安全性等隐含意图。OpenAI利用InstructGPT目前在以对齐为中心的微调方面有很多唾手可得的成果：与
100 倍大的预训练模型相比，人类更喜欢 InstructGPT，而其微调成本是 GPT-3 预训练计算的 <2% 和大约 20，000
小时的人工反馈。我们希望我们的工作能够激励业内其他人增加对大型语言模型对齐的投入，并提高用户对已部署模型安全性的期望。

也就是说我们通过API或页面接入的GPT服务，实际上都经过了InstructGPT的处理。而预训练模型智能体本身则非常强大，目前只对专业研究者，或者OpenAI内部开放。OpenAI首席科学家Ilya再之前的访谈中，曾提到他花了相当一部分时间试图真正理解GPT，主要就是和预训练智能体本身（可用认为是RawMode）对话，甚至声称GPT是人类有史以来最好的冥想导师。

与此同时，开源社区也在努力开发自己的语言模型，来挑战GPT的垄断地位。一些开源项目，如GPT-
Neo和GPT-J，已经成功地复制了GPT的架构和训练方法，使用公开可用的数据集来训练自己的模型。这些模型虽然没有达到GPT的规模和性能，但是它们也展示了令人印象深刻的能力，而且可以免费使用。

开源语言模型对于那些想要尝试或使用NLP技术的人来说是一个福音，因为它们降低了进入门槛和成本。开源语言模型也有助于促进AI的创新和民主化，因为它们可以让更多的人参与到AI的开发和应用中来。

开源语言模型对于专有AI公司来说则是一个挑战，因为它们威胁到了他们的商业利益和竞争优势。专有AI公司可能会面临两种选择：一种是继续保持其模型的封闭性，试图通过提供更高质量、更安全、更可靠的服务来吸引客户；另一种是加入开源运动，通过分享其模型和数据来赢得社区的信任和支持，并从中获得反馈和改进。

**OpenAI似乎正在选择后者。**

**根据最新的消息（theinfomation.com)，OpenAI即将发布其首个开源语言模型，这将是一个重大的里程碑，也将是一个对Google等竞争对手的挑战。OpenAI可能希望通过这一举动来证明其作为一个非营利组织的使命和价值观，以及其对于AI伦理和安全的关注。**

**笔者一直关注并研究GPT现象、以及看到OpenAI最近为商业化而更好解决GPT的对齐问题的努力，笔者判断OpenAI
在开源计划中的应该是InstructGPT，而不是GPT本身。而这同样也会给google在LLMs方向的开源政策带来压力。**

Google是否会跟随OpenAI的脚步，也开始在开源AI方面发挥更大的作用呢？这还不得而知。Google目前仍然拥有世界上最强大、最先进、最广泛应用的AI技术，并且在许多领域都处于领先地位。Google也有自己的开源项目，如TensorFlow和BERT，它们对于AI社区来说都是非常有价值的贡献。

然而，Google也面临着一些挑战和风险，比如法律诉讼、监管压力、员工流失、用户不满、道德争议等。Google可能需要重新审视其对于AI的战略和愿景，并考虑如何在保护其核心利益的同时，也能够与开源社区建立更好的合作关系。

总之，开源AI的崛起是一个重大的发展趋势，它可能会对AI的未来产生重要的影响。我们应该关注这一领域的动态，并期待更多的惊喜和创新。

## 参考

# -OpenAI - Our approach to alignment research

# （https://openai.com/blog/our-approach-to-alignment-research）

-Aligning language models to follow instructions

(https://openai.com/research/instruction-following)

  

**点这里****👇 关注我，记得标星哦～**

  

那些prompt了我的，

是否也prompt了你...

