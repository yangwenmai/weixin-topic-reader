# 非人类-ChatGPT领衔美国权威杂志《Nature》2023年度科学影响力人物，开启AI时代的新篇章

文章作者: AI深度研究员
发布时间: 2023-12-15 10:00
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247486950&idx=1&sn=20a0da4526137c10b1c2297f860d4cba&chksm=c00bbf03f77c3615efc5e9788caa9c2f22040052659288ab29308aa583fa61ec6a6cce9297ff#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAgSzOcdfWsQAiaLicHRGTsICiawlO1JVBy8yiahIx3LlxfBrW76DZczOhxzmJaOYTwvgpIfO1ibzdItaTA/300

![](https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAgSzOcdfWsQAiaLicHRGTsICiaDqQ9FAd63Mewzrr0l8J0Nky2TXGxdwVcUvtJJCnd25NMoXwIBrt7ibQ/640?wx_fmt=jpeg&from=appmsg)

《Nature》杂志每年都会选出在科学界产生巨大影响的重要人物，2023年，他们的榜单上出现了一个非人类——ChatGPT。这个聊天机器人因为给科学进步带来的影响而被特别提名。OpenAI的首席科学家Ilya
Sutskever也因为推动ChatGPT和其他AI系统的发展而入选。这一年的榜单聚焦了一系列杰出人物，他们的成就涵盖了从太空探索到环境保护，从生命科学的突破到核能研究的进展。这里有一些重点人物和他们的成就摘要：

\- 卡尔帕纳·卡拉哈斯提：作为工程师和经理，她在确保印度的月球任务成功方面起到了关键作用。- 玛丽娜·席尔瓦：为保护亚马逊雨林而努力，反对森林砍伐。-
林胜彦：从雄性小鼠细胞制造出活跃的卵子，为保护濒危物种开辟了新途径。- 安妮·克里彻：帮助实现了在实验室里产生太阳和氢弹才有的核反应。- Eleni
Myrivili：联合国首席高温官，致力于应对气候变化。**\- Ilya Sutskever：推动了ChatGPT等AI系统，改变了社会。** \-
James Hamlin：揭示了室温超导性研究中的缺陷。- Svetlana Mojsov：开发了价值数十亿美元的减肥药物。- Halidou
Tinto：推动了治疗致命疾病的第二种疫苗问世。- Thomas Powles：领导了一项治疗严重膀胱癌的变革性临床试验。**\-
ChatGPT：预示着科学领域一个崭新时代可能的到来。**

**  
**

而在这些成就显著的人物中，ChatGPT的出现预示着科学领域一个崭新时代的可能到来。**作为AI技术的代表，ChatGPT被视为开启科学新时代的象征。其影响不仅仅体现在技术上，更在于它如何改变我们对科学、智能甚至未来的理解。**  
我们特别挑选了Ilya Sutskever和ChatGPT的故事，希望通过他们的例子，读者能够更深入地了解2023年科学界的重大进展和未来的趋势。

**文章 1《OpenAI 的首席科学家 Ilya Sutskever 在关注人工智能（AI）安全的同时，也是创造 ChatGPT 的关键人物。》**

![](https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAgSzOcdfWsQAiaLicHRGTsICiauNFvx2caLwWIKOcq0852BKTwthjM2owkuNSUGZcd77czzvpKNyV22g/640?wx_fmt=jpeg&from=appmsg)

少年时期，Sutskever 曾求职于被誉为现代 AI 之父的 Geoffrey Hinton，希望从炸薯条的工作转而投身 AI 领域。Hinton 评价
Sutskever 为深度学习和大型语言模型（LLMs）——如 ChatGPT 这类对话 AI
机器人的创新先锋，并赞扬他不仅智力出众，更有着迅速行动的能力。在加州旧金山的 OpenAI，Sutskever 担任首席科学家，对 ChatGPT
的发展起到了关键作用。但他对 AI 的未来同样存有忧虑。**今年七月，他开始领导 OpenAI
一项为期四年的“超级对齐”项目，旨在研究如何控制超越人类智慧的 AI 系统。** 今年十一月，Sutskever 在一起涉及公司首席执行官 Sam
Altman 的复杂事件中发挥了重要作用，此事凸显了安全与商业发展之间的紧张关系。事件过后，他未向《自然》杂志透露更多信息。Hinton 认为
Sutskever 的愿景令人钦佩，强调了他对 AI 安全的深切关注。然而，也有观点认为，专注于未来 AI 系统的控制忽视了当前技术的实际危害，如 AI
训练数据的偏见和隐私泄露等问题，需要立即解决。纽约市 AI Now 研究所的 Sarah Myers West 提出，我们应关注当前的 AI
隐患，而不只是未来的可能性。例如人工智能系统在其训练数据中加强偏见，或可能泄露私人信息。AI 系统的不透明性同样值得关注。OpenAI
和其他一些公司对其代码和训练数据保密。Sutskever 认为，长期来看，保持系统闭源是防止其他人开发出强大 AI
的负责任做法。“随着技术的进步，开源模型将会带来不负责任的风险，”他今年四月提到。Sutskever
1986年出生于苏联，自幼表现出超常的学习能力，青少年时期在以色列就读大学编程课程。移居加拿大后，他从2003年开始与 Hinton
合作研究深度学习。2012年，他与 Hinton 的一名学生共同开发了
AlexNet，这是一种神经网络，在一场重要的图像识别竞赛中大获全胜。之后，Sutskever 加入 Google，参与开发了击败人类冠军的围棋程序
AlphaGo。2015年，Sutskever 与 Altman 及包括亿万富翁 Elon Musk 在内的众人共同创立了
OpenAI，这是一个以“造福人类”为宗旨的非营利组织。**对 Sutskever
而言，这是一次认真对待人工通用智能（AGI）追求的机会，旨在开发智能不逊于人类的系统。“研究者往往习惯于关注小事，但在
OpenAI，我们更愿意展望更大的图景，”他今年早些时候表示。** OpenAI 另一位联合创始人 Wojciech Zaremba 称赞
Sutskever 在 2018 年首次推出 GPT-1 后，促使公司加大对生成预训练转换器（GPT）系统的投入。与当时许多人不同，Sutskever
相信仅增加计算能力就能提升这些系统的智能。“他比大多数人都早意识到了这一点，”Hinton 表示。为了获得更多计算资源所需的资金，团队在 2019 年将
OpenAI 从非营利模式转为“限利”模式，并吸引了微软投入数十亿美元的资金和资源。这一举措取得了成功：大型语言模型得到了提升，而 2022 年 11
月发布的 ChatGPT 则成为一种现象级产品。然而，在这一成功的背后，今年 11 月 17 日，Sutskever 和其他 OpenAI 董事会成员解雇了
Altman，引起了内部动荡。许多员工包括 Sutskever 威胁要随 Altman 一起跳槽到微软，他事后对自己的行为表示后悔。当 Altman
五天后重返公司时，Sutskever 被解除了董事会职务。在此期间，Sutskever 对 AI 的看法一直非常大胆。2022 年，他甚至宣称 AI
可能已有初步的意识，这一言论引起了各种反应，包括敬畏、恐惧和嘲笑。他公开表示，人工通用智能（AGI）甚至超越人类整体智力的“超级智能”可能在几年或几十年内实现。“直到今天，我对他的积极态度仍感到惊讶，”曾在
2012 年斯坦福大学指导 Sutskever 的 AI 研究者 Andrew Ng 说。 _**Ng 还补充，Sutskever
的一个令人敬佩的特质是他能够选择一个方向，并不顾他人的看法，坚定地追求下去。**_****  
  
****文章 2《** ChatGPT 和科学：在 2023 年，这款 AI 系统既展现出积极的一面，也暴露了其不足》**

![](https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAgSzOcdfWsQAiaLicHRGTsICiamPYWstsVt7IzTl4vEHgMNg60HicYoInsQX898Aq7WOcVt8RkuTXSyHg/640?wx_fmt=jpeg&from=appmsg)

它参与撰写科学论文，有时甚至是悄无声息地。ChatGPT
还帮助设计演讲提纲、拨款申请和课程内容，生成计算机代码，成为研究思路的良好对照。然而，它也创造了虚假参考文献，编造事实，并传播仇恨言论。**最引人注目的是，它激发了人们的想象：或顺从、或引人入胜、或娱乐，甚至令人恐惧，ChatGPT
扮演了各种角色，包括一些用户并不期望的。** 2023年对科学产生重大影响的人物名单中为何包括一款计算机程序？虽然 ChatGPT
不是人，但它在过去一年对科学的影响深远而广泛。ChatGPT 的主要目标是根据其训练数据的风格，合理地持续对话。但这一过程中，它和其他生成型 AI
程序正在改变科学家的工作方式。它们还重新引发了关于 AI 的局限性、人类智能的本质以及如何调控人机互动的讨论。这就是为什么今年《自然》杂志的 10
大人物中新增了一个非人类的成员。许多科学家早已认识到大型语言模型（LLMs）的潜力。但对众多人而言，是 ChatGPT 在 2022 年 11
月作为免费对话代理的发布，迅速揭示了这项技术的强大潜力和潜在风险。这个程序由加州旧金山 OpenAI 的研究人员创建，其中包括今年《自然》杂志 10
大人物之一的 Ilya
Sutskever。它基于一个经过数千万美元投资训练的、拥有数千亿参数的神经网络，并在广泛的在线书籍和文档库上进行训练。此外，还有大量工作人员参与编辑和评估其回复，进一步优化了这个机器人的输出。今年，OpenAI
对 ChatGPT 的底层 LLM
进行了升级，并将其与其他程序连接，使其能够处理和创造图像，并使用数学和编程软件辅助。其他公司也纷纷推出了竞争产品。对于一些科研人员而言，这些应用已成为不可或缺的实验室助手，它们帮助总结或撰写论文、完善申请书和编写代码。ChatGPT
及相关软件还能帮助激发创意、加强科学搜索引擎，并发现文献中的研究空白，正如哈佛医学院从事医学研究 AI 的 Marinka Zitnik
所指出的。基于类似的科学数据训练的模型有望引领研究方向，如设计新分子或模拟细胞行为。然而，这项技术也存在风险。自动化对话代理可能帮助作弊和抄袭者，如果不受限制，它们可能会永久性地损害科学知识。一些科学家承认使用
ChatGPT 生成未声明的文章，其内容已开始在互联网上蔓延。错误和偏见问题是生成型 AI
固有的问题。**大型语言模型（LLMs）通过映射语言的相互关系来构建对世界的认知，并生成看似合理的内容，但它们无法判断真伪。这导致这些程序复制了其训练数据中的历史偏见或不准确性，并编造信息，包括不存在的科学参考资料。**
华盛顿大学西雅图分校的计算语言学家 Emily Bender 对使用所谓的合成文本生成器表示怀疑。她指出，ChatGPT
对环境影响巨大，存在问题偏见，并可能误导用户以为其输出源于人类。此外，OpenAI
正面临盗窃数据的诉讼，并因雇佣低工资自由职业者而被指控剥削性劳动行为。大型语言模型（LLMs）的庞大规模和复杂性使它们成为实质上的“黑箱”。当代码和训练资料未公开，如
ChatGPT 的案例，要理解它们为何产生某些输出更是一大挑战。尽管开源 LLM
运动在增长，但迄今为止，这些模型的能力仍不及大型专有程序。一些国家正在开发国家级 AI 研究资源，旨在让非大型公司的科学家能够构建和研究大型生成型
AI。但目前仍不明确法规将在多大程度上要求 LLM 开发者披露专有信息或加入安全功能。 _**目前还无人知晓 ChatGPT
类系统的潜力究竟有多大。它们的能力可能受限于计算能力或新训练数据的可用性。但生成型 AI 革命已经开启，并且已经再也没有回头路了。**_  
链接：https://www.nature.com/articles/d41586-023-03930-6  
AI知识和技能无限分享  
欢迎点击“分享、点赞、在看”

