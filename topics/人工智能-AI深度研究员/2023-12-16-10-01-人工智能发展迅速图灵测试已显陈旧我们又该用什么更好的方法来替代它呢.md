# 人工智能发展迅速，图灵测试已显陈旧，我们又该用什么更好的方法来替代它呢？

文章作者: AI深度研究员
发布时间: 2023-12-16 10:01
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247486967&idx=1&sn=591939a843bf81d44c54c721ff05a1fa&chksm=c00bbf12f77c360429d5a1c84fa53be9ca103a452af860e21e674382098e2cc9dec0b1efb574#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAghXlWYGPw5lyicUhQEANTlnUD3AOF1EUEfyJFbGuLic572eX4HmF5YdnVgRBIPbda0OrPl9Lvv0vJA/300

![](https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAghXlWYGPw5lyicUhQEANTlnO5WRIM1f1mdKj2Xjt4qlGCGsamAgtfj3pfPiczQZDaHCJUY1SSUnT5w/640?wx_fmt=jpeg&from=appmsg)

在探索人工智能的边界时，我们经常回顾图灵测试这一经典标准。在最新的文章《如果AI使图灵测试变得过时，那么更好的替代方案是什么？》提出了一个引人深思的问题。文章中提到，随着像OpenAI的ChatGPT这样的AI程序接近甚至通过图灵测试，我们不得不思考：这是否意味着AI已经达到了与人类智能相媲美的水平？文章深入探讨了图灵测试的局限性和当前AI技术的发展。尽管ChatGPT等程序在模仿人类对话方面表现出色，但这并不一定意味着它们具备与人类相同的思考和推理能力。因此，研究人员提出了一种新的评估框架，旨在更全面地测试AI程序的智能，特别是在推理和自省方面的能力。

  

 _**原文如下：**_

图灵测试专注于聊天能力——那我们是否能够测试思考能力？如果一台机器或 AI
程序达到或超越人类智能，这是否意味着它能完美地模拟人类？如果答案是肯定的，那么关于推理——我们在做决定之前运用逻辑和理性思考的能力——又该如何理解呢？我们该如何判断一个
AI 程序是否具备推理能力？为了回答这个问题，一组研究人员提出了一种新的框架，类似于对软件进行心理学研究。

“这个测试把‘智能’程序当作心理研究中的一名参与者，包含三个步骤：

**（a）在一系列实验中测试该程序的推理能力，**

**（b）测试它对自己推理方式的理解，**

**（c）如可能，检查程序源代码的认知适应性，”**

研究人员指出：评估机器智能的传统方法，如图灵测试，只能告诉我们机器是否擅长处理信息和模仿人类反应。例如谷歌的 LaMDA 和 OpenAI 的
ChatGPT 这样的当前 AI 程序已经接近通过图灵测试，但测试结果并不表明这些程序能够像人类那样思考和推理。

这就是图灵测试可能不再适用的原因，研究人员认为，需要新的评估方法来有效评估机器的智能。他们声称，他们的框架可以作为图灵测试的一个替代品。“我们提议用一个更专注和基本的测试来替代图灵测试，以回答这个问题：程序是否以人类的方式进行推理？”研究作者们提出。

  

图灵测试存在哪些问题？在图灵测试中，评估者通过文本通信玩不同的游戏，与真人和 AI
程序（机器或聊天机器人）交流。由于这是盲测，评估者无法分辨他们是在与人类还是聊天机器人交流。如果 AI 程序成功地产生类似人类的回应，让评估者难以区分人类和
AI 程序，那么这个 AI 就被认为通过了测试。但由于图灵测试基于主观解释，其结果也是主观的。

研究人员指出，图灵测试存在几个局限性。

**例如，测试中的游戏都是模仿游戏，旨在测试机器能否模仿人类。** 评估者完全基于他们收到的信息的语言或语调来做决策。ChatGPT
擅长模仿人类语言，即使在提供错误信息时也能做到。因此，这个测试并未评估机器的推理和逻辑能力。

**图灵测试的结果也不能告诉我们机器是否能进行自省。**
我们经常回顾过去的行动并反思我们的生活和决策，这是防止重复同样错误的关键能力。根据斯坦福大学的一项研究，这一点同样适用于
AI。研究表明，能够自我反思的机器对人类更实用。

“能够利用以往经验并有效适应新的或变化的环境的 AI 代理，将带来更具适应性、灵活性的技术，从家庭机器人到个性化学习工具，”斯坦福大学助理教授 Nick
Haber表示。

此外，**图灵测试未能评估 AI 程序的思考能力。** 在最近的一项图灵测试实验中，GPT-4 让评估者相信他们在与人类交流的时间超过了
40%。然而，这个得分并未回答一个基本问题：AI 程序能思考吗？

英国著名科学家 Alan Turing 创造了图灵测试，他曾说：**“如果计算机能够欺骗人类相信它是人类，那么它就应该被称为智能。”**
但他的测试只涉及人类智能的一个方面：模仿。尽管这一方面可以用来欺骗他人，但许多专家认为，如果不包含其他方面，机器永远无法实现真正的人类智能。

“通过图灵测试是否是一个有意义的里程碑尚不清楚。它没有告诉我们系统能做什么或理解什么，也没有告诉我们它是否建立了复杂的内在对话或能够在抽象时间范围内进行规划，这是人类智能的关键，”人工智能专家和
DeepAI 创始人 Mustafa Suleyman 对彭博社表示。

  

图灵测试的替代方案 研究作者、普林斯顿大学退休心理学教授 Philip Johnson-Laird 和德国 Chemnitz 工业大学研究员 Marco
Ragni 识别到图灵测试的局限性，并设计了一个三步骤框架，有潜力替代图灵测试。他们认为，只有当 AI
程序通过以下三个挑战时，才能被认为在智力上与人类等同：  
**第一步：一系列心理学实验。** 研究人员建议对 AI
程序进行多种心理测试，这些测试旨在检验人类的推理和逻辑思维，将它们置于需要探索和理解微妙差异的情境中。AI
模型应能从不同的可能性中推导出不同的结果，评估者首先应该通过这种方式来衡量它们的智力水平。例如，假设一个 AI 程序被要求准备详细的天气预报。如果这个 AI
模型不仅理解它所训练数据中的多云和湿度的基本含义，还能理解湿度、多云和温度之间的关联，它很可能比仅仅基于数据理解这些因素的 AI 做出更好的预报。  
**第二步：测试 AI 的自省能力** 研究作者推荐使用特殊的“程序”（在此指一系列相关问题），来看 AI
是否能解释其解决问题所用的推理或逻辑。他们坚信，一个智能的 AI
应该能够对其行为和表现进行自我反思——没有这种能力，它就不能被认为与人类一样智能。研究人员描述了这样一个例子：“如果 Ann 是聪明的，是否意味着 Ann
聪明或她富有，或者两者兼而有之？如果程序像人类一样拒绝这种逻辑上有效的推断，那么下一个问题是：你为什么认为这种推断不成立？这种答案是人类推理方式的标志：前提中没有支持
Ann 是富有的可能性。”  

**第三步：深入探索源代码**

最后一步是仔细检查 AI
程序的代码，以识别有潜力促进类似人类的推理、思考和推断的元素。“如果它包含了已知模拟人类表现的程序的主要组件，这将是决定性的证据。如果它依赖于某种深度学习，则答案将是模棱两可的——除非另一个算法能够解释该程序是如何推理的。如果其原理与人类的截然不同，则表示它未通过测试，”研究人员补充道。

然而，这项研究并没有清楚说明源代码审查将如何进行，这是这个框架的一个重大局限性。

关于这个过程的一个重要观点是，它不是将 AI
程序当作机器或聊天机器人来评估，而是视其为参与深入心理分析的真实主体。这种更加人性化的方法可能克服图灵测试的一些局限。但与图灵测试一样，它依赖于主观判断——需要人们对算法行为做出评价。因此，不同的评估者在判断机器智能时可能会有不同的看法。

因此，这篇论文并不是提供了一个客观测试的明确蓝图，而更可能是旨在激发关于如何最佳分析机器行为的讨论。

  

https://arstechnica.com/ai/2023/12/do-ai-improvements-call-for-something-
better-than-the-turing-test/

AI知识和技能无限分享  
欢迎点击“分享、点赞、在看”

