# 探秘AGI：时代杂志带我们深入了解人工智能的下一步革命

文章作者: AI深度研究员
发布时间: 2024-01-21 10:00
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247487729&idx=1&sn=7313cdbb63c1e43d8951b53814121502&chksm=c00ba214f77c2b024d493e4da62f427698ae18f06848fa240cdd65e16e4abef9c3700499c93e#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAiaTqgCujGwz0Cic8LPJQmJP6qd7sgkDXdS1BMgfZ77Miaoh0K8pia8Jxj6gJTJgTHTqb6kFDibOMof9icA/300

![](https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAiaTqgCujGwz0Cic8LPJQmJP6LhdWauPLy4kSSq6m5S51bcP6P9qoljTWm9NLfNc59h436DmJPAkPew/640?wx_fmt=jpeg&from=appmsg)

在1960年，后来赢得了经济学诺贝尔奖和图灵奖（Turing Award）的赫伯特·西蒙（Herbert Simon）在他的著作《管理决策的新科学》（The
New Science of Management Decision）中写道：“在20年内，机器将能够完成任何人类能做的工作。”

技术发展的历史上，不乏对前景过于乐观的预测，而这些预测往往并未成真。在人工智能领域，最为大胆的预言便是人工通用智能（AGI）的诞生——一种能执行任何人类任务的系统。因此，当谷歌DeepMind的联合创始人兼首席AGI科学家肖恩·莱格声称AGI在2028年有一半的可能性问世时，人们可能会倾向于将他视为另一位没有从历史中吸取教训的人工智能先驱。尽管如此，人工智能的进展仍然迅猛。2022年开发的OpenAI的GPT-3.5语言模型，在律师资格统一考试中得分213分（满分400分），排在最低的10%之列。仅数月后开发的GPT-4得分飙升至298分，跻身最高10%。众多专家预测这种进步将继续。莱格等人工智能领域的领军人物普遍持这种看法。Anthropic联合创始人兼CEO达里奥·阿莫代曾在8月表示，他预计在两到三年内将能开发出达到“人类水平”的AI。OpenAI的CEO萨姆·奥特曼也认为，人工通用智能可能在未来四到五年内问世。但在最近的一项调查中，1722名AI专家中的大多数对此持更为谨慎的态度。另一项对拥有出色研究AI背景的精英预测者进行的调查显示，他们的看法更为保守。正确预测未来的重要性不言而喻。莱格等多位人工智能先行者已警告，强大的未来AI系统可能导致人类灭绝。即便不考虑《终结者》式的极端情景，也有人警告说，一种能够完全替代人类工作的AI系统可能彻底取代人力劳动。**规模化假设**
许多在开发最大型、最强大AI模型的公司工作的人士相信，人工通用智能（AGI）的诞生指日可待。他们支持一种称为“规模化假设”的理论，即通过不断增加计算能力和数据来训练AI模型，即便途中需要一些逐步的技术进步，最终也必然会实现AGI。这个理论有一定的实证支持。研究者们发现了一种非常明确且可预测的关系：用于训练AI模型的计算能力与其在特定任务上的表现之间的关系。例如，在大型语言模型（LLM）——像ChatGPT这类聊天机器人的驱动系统——的情况下，规模化定律可以预测模型在预测句子中缺失词汇的能力。OpenAI的CEO萨姆·奥特曼最近对《时代》杂志表示，在2019年，当OpenAI的研究人员发现规模化定律后，他意识到AGI可能比大多数人预期的要早到来。即便在规模化定律被观察到之前，研究人员就已经明白，使用更多计算能力训练AI系统会提升其能力。过去70年来，用于训练AI模型的计算量以相对可预测的方式增加，同时其成本也在下降。早期基于计算能力增长预期的预测，专家们用来估计人工智能何时可能达到甚至超越人类的水平。1997年，计算机科学家汉斯·莫拉维克曾预测，廉价且广泛可用的硬件在2020年代将在计算能力上匹敌人脑。例如，广泛用于AI训练的Nvidia
A100半导体芯片售价约10,000美元，能进行约20万亿次浮点运算，而预计十年后开发的芯片性能将更为出色。但人脑的计算量估计从每秒一万亿次浮点运算到超过一百万亿次不等，这让人难以评估莫拉维克的预测准确性。另外，莫拉维克的预测未考虑到一个事实：训练现代AI系统所需的计算量远大于运行它们。近期，非盈利机构Epoch的研究者们提出了一种更精细的基于计算的模型。不同于估计AI模型何时将使用与人脑相似的计算量进行训练，Epoch的方法直接应用规模化定律，并做出了一个简化的假设：如果一个用特定计算量训练的AI模型能忠实复制一段文本——基于规模化定律预测的模型能几乎完美地连续预测下一个词——那么它就能完成创作该文本的任务。比如，一个能完美复制一本书的AI系统可以取代作家，而一个能无误复制科学论文的AI系统可以取代科学家。一些人可能会辩称，即便人工智能系统能产生类似人类的输出，也并不意味着它们能像人类那样思考。例如，罗素·克劳在2001年电影《美丽心灵》中饰演诺贝尔奖获得者数学家约翰·纳什，但没人会因为他表演得越好就认为他的数学能力越强。Epoch的研究人员指出，这种类比基于对语言模型工作方式的误解。随着规模扩大，大型语言模型（LLM）逐渐获得了类似人类的推理能力，而不仅仅是表面模仿人类行为。然而，也有研究者认为，目前的AI模型是否真正在进行推理尚不明确。Epoch的副主任塔马伊·贝西罗格鲁表示，Epoch的方法是对规模化假设进行量化建模的一种方式。他指出，Epoch的研究人员普遍认为，AI的进步不会像模型所暗示的那样迅速。模型预测到2025年开发出变革性人工智能的可能性为10%，到2033年的可能性为50%。变革性人工智能被定义为“一旦广泛部署，将引发类似于工业革命的巨大变革”。贝西罗格鲁认为，模型预测与莱格等人的预测之间的主要区别可能在于，实现变革性人工智能比实现AGI更具挑战性。

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAiaTqgCujGwz0Cic8LPJQmJP6IQRtBe0SiclQG91xBTH0qXgVlGyAiaubFBtaAYRz4lECYWdmEsJnO7Bw/640?wx_fmt=png&from=appmsg)

（图一）  

 _图一 人工智能开发的年度概率，在未来十年内开发出非常强大的人工智能系统的可能性相当高_

**咨询专家意见**
尽管许多顶级AI公司的领导认为目前的AI发展趋势将很快带来AGI，但这种看法并不普遍。为了更有系统地了解专家对人工智能未来的看法，机器智能研究所旗下的AI安全项目AI
Impacts于2023年秋季调查了2,778位专家，这些专家都在过去一年内在知名的人工智能期刊和会议上发表过同行评审文章。调查中，专家们被询问他们何时认为“高级机器智能”将成为可能。所谓的“高级机器智能”指的是那些能够“在不需要人类帮助的情况下，比人类工作者更好、更便宜地完成每项任务”的机器。尽管各人的预测差异较大，但平均预测值显示，到2047年出现这种情况的概率为50%，到2027年的概率为10%。与许多人一样，专家们似乎也对过去一年人工智能的快速进展感到意外，并据此调整了他们的预测。在AI
Impacts于2022年进行的同一调查中，研究人员估计高级机器智能到2060年出现的概率为50%，到2029年的概率为10%。研究者们还被询问他们认为何时各种独立任务将能由机器完成。他们预计到2028年，AI创作一首排行前40的热门歌曲的概率为50%，到2029年写出一本能上《纽约时报》畅销书榜的书的概率也为50%。

虽然个别预测差异很大，但许多专家认为在未来几十年内开发出AGI是有可能的。不需要外部帮助的机器完成任何任务比人类更好、更便宜的可能性。

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAiaTqgCujGwz0Cic8LPJQmJP6ibsYdlYzk0AOnm80vIwzBibDzDT9dDCbbYon8ia557jywWibu5t8xj5Bpg/640?wx_fmt=png&from=appmsg)

（图二）  

 _图二，人工智能研究者预测显示，1,712名回答者的平均预测用红线表示，而50个随机选取的个别预测则用灰线表示_  

**预测者持怀疑态度**

不过，大量证据表明专家并不擅长预测。社会科学家菲利普·特特洛克在1984至2003年期间，从284名专家那里收集了82,361个预测，提出了例如：苏联领导人戈尔巴乔夫会不会遭遇政变？加拿大能否维持政治联盟？等问题。特特洛克发现，专家的预测通常不比随机猜测更准确，而且专家越有名，他们的预测越不准确。随后，特特洛克和他的合作伙伴开始探寻是否有人能做出准确预测。在2010年美国情报高级研究项目活动发起的预测竞赛中，特特洛克的优秀判断项目团队表现突出，据称其预测比有机密信息的情报分析员还要准确30%。在比赛中，该项目识别出了“超级预测者”——即一贯做出超过平均准确度预测的个人。然而，芝加哥联邦储备银行的经济学家兼特特洛克预测研究所的研究主任伊兹拉·卡格尔表示，尽管超级预测者在两年或更短期的预测中表现出相当的准确性，但对于诸如何时开发AGI这样的长期问题，他们是否同样准确还不清楚。

超级预测者何时预计AGI会出现？在预测研究所于2022年6月至10月间举办的一次预测锦标赛中，31位超级预测者被问及他们认为备受争议的哲学家、《超级智能》一书作者尼克·波斯特罗姆何时会承认AGI的存在。超级预测者的中位数认为到2030年此事发生的概率为1%，到2050年为21%，到2100年为75%。

大部分超级预测者认为在未来几十年内开发出AGI的可能性较低 。

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAiaTqgCujGwz0Cic8LPJQmJP6Ov34rxhOJWiaeEQ2mibGpO5micLAicsglZqEL25H4nGiaq67RticEMmbyHJw/640?wx_fmt=png&from=appmsg)

（图三）  

 _图三，31名参与者的平均预测用红线表示。
灰线显示了个别预测。受访者被要求对2030年、2050年和2100年的概率进行预测，并基于这些回答拟合了概率分布_  

**谁的预测更准确？**
预测人工通用智能（AGI）何时会出现的三种方法——Epoch的规模化假设模型、专家调查以及超级预测者调查——都面临一个共同的问题：极大的不确定性。特别是在专家中，意见分歧较大，有10%的专家认为到2030年开发AGI的可能性很大，而有18%的专家认为AGI要到2100年之后才能实现。不过，平均来看，这些不同的方法给出了不同的答案。Epoch的模型预测变革性AI在2033年到来的概率为50%，专家中位数的预测是AGI在2048年前到来的概率为50%，而超级预测者则更加悲观，认为要到2070年。

图五包含不同预测方法对人工智能何时会被开发的预测的图表，分别显示了三种不同的预测方法：

  * 规模假设模型预测，到2033年，人工智能将有50%的机会被开发出来。

  * 1,712名人工智能专家的调查显示，到2048年，人工智能将有50%的机会能够比人类工人更好、更便宜地完成任何任务。

  * 31名超预测者的调查显示，到2070年，尼克·博斯特罗姆将有50%的机会认为人工智能已经存在。

图中的点表示了人工智能专家或超预测者做出的个体预测，这些预测是基于不同但相关的问题。因此，这三种预测方法并不完全可比。![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAiaTqgCujGwz0Cic8LPJQmJP6wt5DL7DcYoZAXjdWRIRjm0YIQVLRgbKoCtjrDM5Y6kopv3trn0vkOg/640?wx_fmt=png&from=appmsg)（图五）  
AI
Impacts的首席研究员卡特亚·格雷斯指出，关于AGI何时会出现的争论有许多不同的观点。首先，用目前的AI构建方法，增加计算能力、输入更多数据并稍微调整算法，这些是否足够？这个问题的答案部分取决于你对最近开发的AI系统印象有多深。是像微软的研究者所说，GPT-4是AGI的初露端倪？还是像哲学家休伯特·德雷福斯所言，这只是“第一个爬上树的猴子试图登月”的虚妄幻想？其次，即使目前的方法足以达成开发AGI的目标，格雷斯指出，我们距离最终目标还有多远尚不清楚。例如，训练数据的不足可能会成为进展的障碍。格雷斯还说，在这些更为技术性的辩论背后，还有人们对于世界可能发生的变化程度和速度的更基本的看法。从事AI工作的人通常对技术充满热情，并且愿意相信他们的创造可能会戏剧性地改变世界，而大多数人则认为这种观点不切实际。解决这种分歧的风险极高。AI
Impacts在询问专家们认为AI将多快达到某些里程碑的同时，还探讨了他们对AI技术社会影响的看法。在回答了关于AI对社会影响问题的1,345名受访者中，89%表示对AI生成的深度伪造技术感到相当或极度担忧，73%对AI可能赋予危险团体能力（例如设计病毒）表示类似的担忧。中位数受访者认为AGI导致“极其恶劣”的后果（如人类灭绝）的可能性为5%。考虑到这些担忧，以及调查显示有10%的专家认为到2030年人工智能可能能完成任何人类能做的工作，格雷斯主张政策制定者和公司应立即开始准备。格雷斯指出，这些准备工作可能包括投资安全研究、实施强制安全测试，以及在开发强大人工智能系统的公司和国家之间进行协调。去年，人工智能专家在一篇论文中也提出了许多类似的建议。加州大学伯克利分校的计算机科学教授、该论文的作者之一斯图尔特·罗素在去年10月对《时代》杂志表示：“如果政府现在果断行动，我们或许能在人工智能系统变得强大到无法控制之前，先学会如何确保它们的安全。”  
 _**原文链接：**_ https://time.com/6556168/when-ai-outsmart-humans/AI知识和技能无限分享  
欢迎点击“分享、点赞、在看”

