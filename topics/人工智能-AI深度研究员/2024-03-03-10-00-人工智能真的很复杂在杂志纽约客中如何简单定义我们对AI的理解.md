# 人工智能真的很复杂？在杂志《纽约客》中如何简单定义我们对AI的理解

文章作者: AI深度研究员
发布时间: 2024-03-03 10:00
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247488521&idx=1&sn=ef628225d9e745346a65e1f8dcb6da96&chksm=c00ba6ecf77c2ffa6d002ed177b6b9bdd63f877b1518caaceb602ff8ce8fadcb623405378cf7#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAhygkib45ictLQN0cpo628Yu0PV47iavgIfSWaMMe2Xb7GFZz0g7x9RsyiclNicxLt2u6KeVf6qkK11zfQ/300

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhygkib45ictLQN0cpo628Yu0BC5Zu9etNIm3bKa5hKYlvN6yhWRd82tyznJoWhzgJfibdnGIwAUlF0w/640?wx_fmt=png&from=appmsg)

在我们试图理解人工智能（AI）这个不断演进的技术领域时，面临的挑战不仅仅是技术本身的复杂性，还有如何将这种复杂性以易于理解的方式呈现给大众。在《纽约客》杂志的一篇引人入胜的文章中，Jaron
Lanier
提出了一个独特而富有洞见的视角，试图解开AI的神秘面纱。他不仅探讨了AI技术的本质，还深入讨论了如何在我们的社会中更有效地整合这项技术，强调了技术理解、良好习惯以及对技术后果共同责任感的重要性。

在这篇万字的文章中，Lanier以其标志性的深入浅出的风格，使用生动的比喻和例子，为我们描绘了一个关于AI的全新图景。他通过“树木”、“魔法森林”、“森林产品”和“幻影树”等比喻，让我们能够以一种全新的方式理解大型模型AI的工作原理，同时也提供了关于如何将这些技术融入我们日常生活的深刻见解。

  

 _**原文如下：**_

要深入了解人工智能的优点和限制，我们需要换一个角度看问题。单靠技术本身是不够的。要让技术发挥作用，它还需要得到社会的广泛理解、形成良好的使用习惯，并且大家共同承担起它所带来的后果。如果没有这样的社会支持，技术往往无法发挥其应有的效果或者应用不彻底。一个典型例子就是
covid 疫情期间开发的 mRNA
疫苗。尽管它们在医学上是一大突破，但由于公众普遍缺乏了解，它们的推广并没有达到预期效果。如果一项技术缺少了让它有效服务于人类社会的关键元素，那么它甚至不应该被称作是一项“技术”；如果我们无法理解技术的工作原理，就有可能陷入一种幻想式的思维。

换个方式说，我们需要通过一些简化的形象或图解，在心中构建对技术工作方式的基本理解。我对疫苗的知识有限，不能自己画出一张图解，但我心中有一个关于疫苗的简化图像，这让我大致能够理解相关新闻，把握疫苗的开发过程、可能的风险和未来走向。我对火箭、金融监管和核电的理解也是通过这样的简化图像来帮助的。这些图解虽不完美，但足以让我有一个基本的直觉判断。即使是专家们相互交流时，也常用这种简化的方式来帮助彼此更好地理解问题的全貌，而非仅仅局限于细节。

  

在这个问题上，我和我所在的计算机科学家群体中很多人的看法有所冲突。我认为，我们对外宣传的关于人工智能的简化图解实际上起到了反效果。我们把人工智能介绍给世界时，却伴随着一些既无益又让人迷惑的理念。最严重的问题可能是很多人传递出的人类将变得无用和灾难即将来临的观念。我难以理解为什么我的一些同行认为他们的工作可能导致人类灭绝，却还坚持认为这么做是有价值的。仿佛不将人工智能视为类似一种新兴宗教事物，我们很难理解这种论述。

除了这种世界末日的气氛外，我们在解释这项技术的本质及其工作原理上也做得不够好。一旦将复杂的抽象概念拆解成可以讲故事的具体内容，大多数非技术背景的人就能更好地理解，但这在计算机科学领域往往难以被接受。我们通常倾向于把人工智能系统视作一个庞大而不可解的整体。可能在某种程度上，我们对于揭示我们所做的工作持有抵触情绪，因为我们更愿意以一种神秘的方式去理解它。从“人工智能”这一术语本身开始，常用的术语都在强调我们是在创造新的生命体而不是新工具的概念。这种观点通过使用“神经元”、“神经网络”这样的生物学术语，以及“学习”、“训练”这样的拟人化术语被进一步强化，而这些术语是计算机科学家经常使用的。同时，“人工智能”没有一个固定的定义也是一个问题。任何关于人工智能的具体讨论都可能因为没有考虑到其他潜在的定义而被驳斥。这个术语的不确定性恰恰与一种认为人类架构即将被超越的形而上学情绪相符。

  

**I. 树**

最初的一步，也是最简单却可能最难解释的一步。我们可以从一个问题开始：怎样利用计算机判断一张照片显示的是猫还是狗？这个问题的难点在于猫和狗有很多相似之处：两者都有眼睛、鼻子、尾巴、爪子、四条腿和毛发。对于计算机来说，对图像进行测量——比如判断它是亮的还是暗的，或者是偏蓝还是偏红——这些都比较简单。但这类测量方式无法帮助区分猫和狗。对于其他类似的情况也是如此，比如，如何让程序分析某段文本很可能是由莎士比亚所写。

技术层面上的基本答案是一组复杂混合的统计数据，我们称之为神经网络。但首先需要明白的是，我们在这里讨论的是一项复杂的技术。神经网络，作为进入人工智能领域的基础入口，可以被看作是一种“民间技术”。当研究者们说一个人工智能“具有突现属性”，其实就是在说我们在构建网络之前并不知道它会有什么表现。人工智能并不是这种情况独有的领域，医学和经济学也有类似的情况。在这些领域里，我们通过尝试、再尝试，找到更有效的方法。我们不是从一个全面的理论出发，然后计算出一个理想的结果。虽然我们无法完美地预测复杂性，但我们还是能够处理和利用它。

  

让我们用一种有趣的方式来考虑如何区分一张猫和一张狗的图片。数字图像是由像素构成的，我们需要做的不仅仅是列出这些像素。一个办法是在图片上铺设一个网格，测量的不仅仅是颜色。举个例子，我们可以从测量每个网格内颜色变化的程度开始——现在每个小方格里都有一个数字，这个数字可能代表了图像该部分的边缘清晰度。仅仅是这样一层测量还不足以区别出猫和狗。但是，我们可以在第一层上再叠加一层网格，测量第一层网格的某些特性，然后再加一层，再加一层。我们可以构建一个层叠的塔，最底层测量图像的细节，而每一层都在测量它下面的那一层。这个基本概念已经存在了半个世纪，但我们直到最近才找到恰当的调整使其良好工作。没有人确切知道是否还有更好的方法。

这里，我想把我们的解释变成几乎像是儿童绘本中的插画一样。你可以把这些层层叠叠的网格想象成一棵大树，它从图像中直接生长出来。（这棵树可能是矩形的，不是圆形的，毕竟大部分图片都是矩形的。）在树里，每一个网格的每个小方格都带有一个数字。想象你正在爬这棵树，当你向上攀爬时，用X射线透视内部：你在最顶端发现的数字是基于下方数字的。

  

遗憾的是，目前为止我们还不能区分猫和狗。但现在，我们可以开始对我们的树进行“训练”了。（我知道，“训练”这个词有些拟人化，但我们就姑且不论。）想象一下，我们的树底部是平的，你可以往下面滑动图片。现在，取一些明确并正确标记了“猫”和“狗”的图片，一张一张地放在它最底层下面。测量值会一层层向上传递，直到达到树的顶层——如果你愿意，我们可以称其为冠层——这个冠层好比直升机中的人能看到的部分。初始时，冠层展示的结果可能会显得有些混乱。但我们可以深入到树内部——设想有一种魔法激光——来调整各层数字，以得到更好的结果。我们会提高那些在区分猫狗上最有效的数字。这个过程并不简单，因为改变一层的数字可能会在其他层产生连锁反应。如果我们成功了，最终，当照片里是狗的时候，冠层的叶子上的数字将全部变成1；当是猫的时候，这些数字将全部变成2。

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhygkib45ictLQN0cpo628Yu035CvaPqIENNJa8WxpqzKONT049ictVyxu5px2icIK5uQOWmeGuag0Uyw/640?wx_fmt=png&from=appmsg)

  

现在，我们惊人地创建了一个工具——一棵经过训练的树，它能够区分猫和狗。计算机科学家把每一层发现的网格元素称为“神经元”，这是为了暗示它们和生物大脑的联系，尽管这种相似性是有限的。虽然生物神经元有时也会像在大脑皮层中那样被组织成层，但这并不是常态；实际上，大脑皮层中的层比人工神经网络中的要少。然而，在人工智能领域，增加更多层次被证明可以极大提升性能，这就是为什么我们经常看到“深度”这个词，比如在“深度学习”中——它意味着层数很多。

找到一个完美的比喻是不可能的。在写这篇文章的时候，我试图用塔和其他高大的物体来比喻，而不是树——但树的自然和亲切感，以及它们如何通过菌丝体连接成一个整体、反映周遭的事件，能很好地与非技术人员沟通。这个比喻有个小问题，因为在计算机科学中，“树”也是一个非常常见的术语，指的是一种有分支的抽象结构。这里讨论的“树”与那种“树”并不相同。

我们的“树”是如何训练成熟的？训练的核心技巧依赖于一个称为“梯度下降”的方法，这个方法最早至少可以追溯到1847年，由数学家奥古斯丁-
路易·柯西提出。其基本理念是不断地对于哪些数字在树的不同层级上应该变得更加重要进行更好的猜测。这个过程面临的挑战是，一旦某个数字开始显示出其有效性，就有它变得过于突出的风险，这种突出是以牺牲其他有价值的数字为代价的。要使这个方法有效，需要找到一种平衡，以便发现那些应该更加突出的幸运但不可预测的数字组合。

  
实现这种平衡涉及到一种可以视为是对病毒式传播现象的一种调节，以避免某些事物仅因在恰当的时刻开始流行而变得极端知名或有价值的情况。这是一个引人深思的巧合，因为病毒式传播正以一种不太积极的方式改变着我们广阔的人类世界。我提起这一点，是希望能引起技术行业同仁们的关注。我们利用人工智能算法控制社交媒体的信息流动、管理金融等众多领域。在所有这些领域，病毒式传播现象已成常态。但是，在人工智能的应用中，我们必须采取措施抑制这种病毒式传播，以确保系统的正常运作。难道我们不应该在人工智能的部署过程中考虑采取类似的措施吗？这样做，是否能让我们的文化、政治和经济环境变得更加理性一些呢？

  

**II. 神奇的森林**

想象猫和狗是件简单的事，但相同的规则同样适用于文本、计算机代码、音乐、电影等等。从理论上讲，我们可以利用互联网上的所有数据，以及我们能接触到的任何其他数据，来构建一些被训练过以准确标识它们的“树”。我们能够创造出这样一个神奇的森林，其中的树木能识别几乎所有的数字形式的事物。

但这里有个难题。我们可以搜集到被准确标记的猫、狗以及其他许多事物的图片。然而，人类生产的大多数信息并没有被如此清楚和一致地标记，有些可能根本就无法标记。我们需要的是一种方法，这种方法能近似实现一个几乎普遍适用的标签系统。我们知道的一种能实现这一目标的属性是“邻近性”。比如说，假设在网络上，某个文本序列往往会出现在某种图片的附近。这暗示了文本和图片之间的关联。

如果我们使用邻近性来估算网络上所有事物是如何彼此连接的，那会是什么样子？换句话说，如果我们将邻近性作为语义的代理，情况又将如何？你可以想象一片广阔的树木从这种关联中生长出来，延伸到远方，可能通过聚集或地下菌丝网连接在一起——一个相互分类的巨大森林。在互联网上，“猫”这个词经常出现在这种生物的图片附近，但在我们的隐喻性森林中的树木获得了更广泛的关联感。一棵能够识别猫图片的树可能有根连接到其他识别猫咪模因或猫床的树。它可能与那些能够识别猫喜欢的玩具以及能够识别它们的疾病和人类粉丝的树相连。研究者们正在努力创建更多的“多模态”人工智能模型，意味着图像、文本和电影可以在单一工具中被关联。这使人工智能成为了一种协调，展现了人类如何注意到不同事物之间的联系——至少是那些已经进入训练数据的事物。在这样一个森林的其他地方，树木可能专注于滚石音乐，或者运行漫画书粉丝网站的代码，或者肺部肿瘤的放射学图像。一个足够大的森林理论上可以分类几乎任何以数字形式表现的事物，只要有足够的那个事物的例子。

  

种植一片大森林是一项惊人的工程。这需要很长时间，并且涉及到惊人的资源。当一个“GPT”旁边的数字上升：比如从3到4，这标志着一个新的“训练周期”。在这个周期中，一个新的森林被种植，能够以更高的可靠性识别更多的事物。这些森林有多大？会包括哪些事物？我们事先不知道。

这些树不是显式的；我们得不到它们的列表。它们是隐式存在的，在一个巨大的混合中。在我们的卡通中，它们在空间中展开，因为人类是时间和空间的生物。无论如何，如果你愿意看到树，那么有数以十亿计的潜在树木。整体结果的大小是难以传达的。

  

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhygkib45ictLQN0cpo628Yu0pKOrZ6aWzpYNv2icBfJCZZWIx9SCTDbHXLAsGXNgrFibxgaywbBF8Kcw/640?wx_fmt=png&from=appmsg)

  

**III.****森林产品**

想象一下，你有一棵能够识别猫的树，但你手头上没有猫的图片。这就是所谓的“生成式”人工智能开始发挥作用的时刻。

我们可以反过来操作，利用能够识别猫的树来生成一张猫的图片。从一片随机像素开始——想象一片雪花覆盖的矩形。现在，把这个矩形放到一棵能识别猫的树下，看看它是否能识别出猫。因为图像只是随机的像素，所以它识别不出来。但现在，让这些随机像素再次随机化。结果在你眼里可能仍旧像雪，但在树的“视角”中，可能会引起一丝丝的认识。如果你看到树的认识程度在提高，就保留这个结果。如果认识程度降低了，就放弃这次改变。不断重复这个过程。最终，从一片“雪地”中，一只猫的形象将逐渐显现。（顺便说一句，通常的解释与这里给出的稍有不同，通常涉及到不断地对图像增加和去除噪声，但那只是用一种更复杂的方式来描述同一个过程。我之所以谈论丢弃图像，虽然实际上我们并不删除任何文件，是因为许多人更容易理解像丢弃某样东西这样的具体行为，而不是添加和移除噪声这样的抽象过程。）

你生成的猫是什么样的？它并不是一只真正的猫。它会是一些对我们旅程一开始就参与到猫识别树训练过程中的猫的随机插值。这些数据源自于上传到网络上的猫的图片，但新生成的图像通常并不完全相同于其中任何一张。它只是一张能够被识别为猫的图片。如果你重复这个过程，你会得到一个新的混合图像。训练一个人工智能以生成这类图像，不仅仅是猫，还有许多其他事物。你就构建了一种基础的生成式人工智能。

  

**IV.****幻影树**

现在，我们已经准备好以一种比喻的方式来理解，当我们与生成式人工智能系统交互时，究竟发生了什么。我们通过使用提示——一系列描述我们所需内容的词汇组合，来与这些系统进行交流。我们的提示词被森林里的树木所识别。你可以想象这些树木在我们的提示下点亮。但是，单个树木的激活并不如它们之间所发生的互动那么关键。

比方说，你请求一个生成式人工智能系统制作“一幅画，描绘一只在优胜美地即将着陆、跳伞时吹奏大号的猫的水彩画。”森林里没有哪一棵单独的树能完全匹配这一特别的要求，因为网络上从未有过与这组具体词汇直接关联的图片。从某种意义上讲，对于“水彩画”、“猫”、“跳伞”、“大号”以及“优胜美地”这些词语，它们之间存在着一片开阔的空地。但通过汲取这些概念的树木，生成一个所有这些树木都能认出的东西，人工智能能够填补这一空白。它能在这片空地上创造出一个幻影树，这是一个为了响应你的提示而特别定制的树。

“一幅即将在优胜美地着陆、跳伞时吹奏大号的猫的水彩画”构成了一个引人入胜的“树”。创造它似乎需要一种创造性的行为。猫如何准确地适应跳伞装置？它如何准确地握住大号？这些都是没有确切答案的问题。然而，通过综合所有由提示激活的树木，人工智能将找到一个方案。这是一个统计学的过程——寻找同时充当多个角色的方法。你可以想象人工智能程序在所有匹配提示的树木中循环，只选出一个同时匹配所有条件的成形图像。在网络上，我们通常看到使用降落伞的都是人类，而不是猫。但是，让猫采取一个与人类类似的姿势更可能使得“使用中的降落伞”这一树木得到满足。这一过程产生了一个貌似合理的结果。其输出虽然不完美，但通常足够适用于正式场合，或至少显得很可爱。

  

生成文本与生成图像的方式有所不同，主要是因为文本由一连串的词组成。与生成一个确定的图像不同，处理文字的人工智能在与提示以及之前选定的词汇相关的基础上，需要一次又一次地选择下一个词汇。当然，还有许多其他方面的差异。即便如此，当生成式人工智能模型选择下一个词时，可以把这个词视为解决一个单一的不确定性点——噪声——变成一个词汇选择，仿佛它是一个极其微小且简单的图像。这就是为什么一个与生成超现实猫图像的过程极为相似的方法可以用来生成任意文档的摘要。人工智能的训练数据中包含了众多摘要及其对应源文档的实例；人工智能过程生成的文本段落之所以能被认作摘要，是因为它在比喻意义上激活了那些最初学会识别摘要的“树”，即便摘要的主题与训练时的并不相同。（这种方法能如此成功，是出乎很多人预料的。）

对非编程人士而言，人工智能能够编写代码的能力可能显得非常惊人。然而，计算机程序本质上是一种文本，而且训练数据非常充足。编码通常是一项极其单调的工作，因为编写一个程序涉及到许多令人烦恼的细节问题，这些问题需要在着手解决最终目标之前被处理。但是，程序员们已经创造了数以百万计处理这些细节的程序，每一个都略有不同，并把这些代码发布到了网上。正如一只猫的身体可以被调整以适配跳伞装置一样，这些已有的程序也可以通过生成式人工智能进行微调，以符合特定提示的需求。据一些估计，生成式人工智能能够将程序员的工作效率提高20%至30%甚至更多。

某些类型的输出在经济上可能非常有价值。举个例子，这个森林有能力识别靠近较长文本版本的文档摘要——比如，一份详尽报告旁边发布的执行摘要——接着，对一个提示做出反应，创造出它之前从未见过的文档摘要。这是怎么做到的？值得一提的是，文字与图像有所不同，处理它们的人工智能技术通常也有所区别：文本通常由被称为大型语言模型的技术生成，而图像则通常由扩散模型生成。但是，这两种过程在很大程度上是相似的。单词往往出现在其他单词的附近；这样一来，单词之间的接近性与单词与图片之间的接近性相似。单词之间的接近性模式可能很能说明问题。如果有足够多的例子，一个比喻性的识别单词的树木森林应该能本质上识别出一连串单词是否语法正确，以及可能是哪位作者所写。这段话听起来像是简·奥斯汀的作品吗？像是海盗用语？还是似乎出自一个十三岁孩子之手？

  

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhygkib45ictLQN0cpo628Yu0JODo2K0TIU5tbSdec3egvAibyf5dN6kibMXibRQe31YDO3dIKZXypufDQ/640?wx_fmt=png&from=appmsg)

如果说文本是由一系列词汇组成的一维线串，而图像是二维的像素格网，那么视频则是三维的，因为它们随着时间展开。然而，用于生成文本和图像的原则同样适用于视频。最近，OpenAI推出了Sora，这是一个能够根据文本提示生成逼真视频片段的生成式视频系统。在现实世界中，制作电影通常需要一个连续性监督者——一个确保从一个镜头到下一个镜头中道具、发型以及阳光角度等不会突然改变的人。连续性之所以重要，是因为它保证了现实的一致性，从某种角度来说，定义了“真实”；重要的是，即便物体离开镜头又重新进入，它看起来仍应该与之前一致。直到现在，连续性的错误一直是阻碍人工智能制作令人信服视频的障碍。如果生成式图像系统试图制作电影的各个帧，那些帧最终可能会出现不连贯，随着时间的流逝细节不一致。

Sora 通过一个简单的原则模拟连续性。回想一下，树的最底层可能是一个网格，用来测量如颜色或图像某个区域的清晰度等简单属性吗？Sora
采用了一个不同的基础理念来捕捉连续性。在一部电影中，一个特定的图像区域在一个画面（帧）中出现，通常也会出现在下一个画面中，虽然它通常会有所变化；比如，猫眼中的一闪光可能会持续存在于多个画面中，但它不会保持在完全相同的位置。计算如猫眼中的高光这样的小元素从一个位置移动到下一个位置，在一系列画面中是相对容易的。一旦对一部电影进行了这样的分析，你就能得到一系列画面中、随时间延续的图像部分的扫过效果。（我所称的“扫过”在大部分学术文献中被称为“片段”，但因为“片段”给人的感觉是静止的，而“扫过”则含有移动的意味，所以我在这里选择使用“扫过”这个词。）

通过库尔特·冯内古特的小说《第五屠宰场》中的一段话，我们可以从另一个角度理解这个概念，其中描述了特拉法马多星人如何看待世界：

对特拉法马多来的生物而言，宇宙并不呈现为众多闪亮的小点。这些生物能够看到每一颗星星的过去位置及其将要去向，使得天空中充满了稀薄且发光的意大利面条形状。同样，特拉法马多人也不把人类看作是双腿生物。在他们眼中，人类像是一种两头是腿的长长的蜈蚣，一端是婴儿的腿，另一端是老人的腿。

对Sora而言，这些“扫过”的效果是构建基础，而不是构成静态图像的像素点。随时间演变的视觉特征的“扫过”与文本描述相结合，用户通过输入文本提示，能够以全新的方式重新组合这些“扫过”。使用这类模型来生成电影的过程，自然而然地捕捉到了现实中物体运动的许多细节，比如摄影机移动时视角的变化，以及身体的摆动。它能确保在一个假人吃掉假汉堡一部分之后，那部分的缺失仍然保持。与此同时，我们也开始理解为什么在这个过程中手部更可能变形。手部具有自己的内部结构和运动规律，这意味着，对整个场景的运动“扫过”方式的组合，很容易忽略手部微观世界的动态。

  

**林木界限**

这类技术是否会导致设计师和程序员失业？我认为不会。对于程序员来说，对新程序及其更新的需求非常巨大。但同样可以认为，人工智能并不总能完全替代创意设计人员的工作。原因何在？

要回答这个问题，我们需要考虑这项技术的能力及其局限性。当你让人工智能应对一个提示来创造一个全新的幻影树时，的确会有一种新事物出现在这个世界上。这包含了一种创造性。然而，我们的类比也强烈表明，这种创造性是有限的。它能够填充树木之间的空隙，但不能超越这些树木的高度。

人类的思维是否也存在这样的局限？或者我们能够思考出超越我们已知的“树线”之上的事物呢？人工智能能够超越其自身的树线吗？对于这些关键问题，研究者们意见不一；现在，对人类和人工智能的过程了解还太少，不能确切地做出太多结论。但是，在实践中，随着我们把机器引入人类世界，我们必须对人和机器做出一些假设。我认为，假设人类能够达到比人工智能所能想象的隐喻性树更高的地方，是一种更好的出发点。这样的假设将帮助我们避免为文明设定一个较低的上限。人工智能的一个危险是，我们可能会开始认为，未来所有可能的事物与过去已经做过的事物足够相似，以至于人工智能能够完成所有任务。我认为，我们应该反对这种看法。

通常关于人工智能的拟人化叙述存在一个问题：它们未能增强我们对人工智能弱点的直觉理解。因此，我们对这项技术的讨论往往围绕极端对立展开：一方面是那些认为我们正在创造一个能解决所有问题或者毁灭我们的宇宙级大脑的热情支持者，另一方面是对人工智能价值看法不高的怀疑者。怀疑者通常只关注我们的第三步——反向生成可以被我们比喻中的树识别的新内容。专注于这一点，计算语言学家Emily
Bender及其同事们将某些模型描述为利用统计学回收既有信息的“随机鹦鹉”。类似地，Ted
Chiang在本杂志的一篇文章中争辩说，生成式AI仅仅产生了对其训练数据的“模糊”重复。

我对这些工作持有极大的尊重，并在一定程度上认同它们。但这种观点忽视了我们的第四步，在这一步中，在我们比喻的森林里召唤出了一棵新的树。通过召唤这些树，生成式人工智能使训练数据中原本隐含的对应关系变得显式。这些潜在组合的多样性是无法提前列出的，因此我们可以认为这个过程具有创造性。但同时，我们也能看到它的局限性。

我认为，一棵新树朝着由其他树定义的树冠高度伸展，但通常不超过这个高度的形象，是一个既实用又平衡的比喻。它提供了一种视角，既非人工智能仅仅是重复旧信息，也表达了对人工智能将成为一种超越、无界限智慧形态的怀疑。填充树木间的空隙固然重要，但这不应与提升上限混为一谈。其实质作用在于最大化训练数据的价值。仅这一点，就足以让我们对最新的人工智能进展保持热情。

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhygkib45ictLQN0cpo628Yu0MPX0pJcQ5G9BKkHAxEsTOcIibvaDP0INq5fgNP91VmZdLFye1lhxjww/640?wx_fmt=png&from=appmsg)

**森林的价值**

大模型人工智能依靠现有数据发展。它的森林通过吸取人们过去执行的重复任务中的相似性来成长。通过人工智能，我们能够重新利用他们创造的价值。这不仅适用于编程、文档总结、课程创建、猫图绘制等，我们可以把人工智能看作是一种让过去在今日人类努力中更有存在感、更加充实的方法。

在新的、更佳的方式中利用人类努力，实质上定义了经济价值。这是管理者、投资者和消费者需要记住的一个重要原则。如果你想知道生成式人工智能在哪些领域能带来最大的价值，那么问自己：有哪些人类活动曾经多次进行，但每次都不尽相同？在这些领域，生成式人工智能很可能会改善现状。

  

**探索森林**

人们对人工智能有着合理的担忧——涉及到安全、质量、公平以及经济影响等问题。我们的比喻也可以帮助我们理解那些正尝试应对这些担忧的人的努力。从远处观察，我们的比喻形成了一个三联画：在一侧的训练数据和另一侧的生成输出之间，展开了一片广阔而奇异的森林。训练数据和输出是可以被理解的，这意味着人们能够理解它们。而中间部分——即森林——在可预见的将来，大多数仍将难以被理解。

研究人员已经采取了一些积极步骤，开始监控那些可以理解的部分——即提示和输出。现代的人工智能系统中包括了“护栏”，旨在阻止用户以开发者认为可能造成伤害的方式进行提示。同时，也在努力淘汰训练数据中最差的部分。通过反对犯罪、虚假、恶意或带有偏见的训练数据，我们可以培育出一个更为健康的森林。

我们能否使森林本身：中心的画面，更容易被导航呢？在《没有人工智能》一文中，我提出我们需要找出一种方法，以追踪在大型人工智能模型中特定输入与输出之间的联系。这就好比在森林成长的过程中铺设面包屑小径。理论上，这是可行的，但实践中尚未实现；我认为找出如何做到这一点非常重要。假设一群坏蛋想利用人工智能帮助他们制造炸弹。他们可能足够狡猾，避免在提示中直接使用“炸弹”这个词。他们甚至可能能够要求一个伪装的输出——比如，有没有可能诱导人工智能创造一个偶然能制成爆炸物的蛋糕食谱。但如果森林里有面包屑，他们的任务就会变得更加困难。在某个时刻，这些小径将会指向训练数据中与炸弹相关的文档。

一些人工智能的开发者和用户可能会认为我对这项技术评价过低，但我不这么认为。能够确切地陈述某事物的具体、有限价值可能会对无限潜力的幻想构成伤害，但这最终会让我们对该事物的价值有一个更加精确和可行的理解。还有人会指出，技术总是在进步的；我这里描述的人工智能版本可能很快就会被某种不同的东西所替代，从而使我们的比喻变得过时。或许会这样。研究者们每天都在发表论文，试图突破新的领域，而且总有一波又一波充满希望的创业公司。

尽管如此，这里给出的比喻对于当下存在的情况是一个合理的表述。这正是它的价值所在。它捕捉到了人工智能技术当前的能力与限制——不是某些研究者希望它成为的样子。如果这里描述的人工智能版本变得过时——如果森林被烧毁——那么下一位接手的人将需要创造一个新的、切实可行的比喻，以及所有其他必要的人类元素，使得这项新技术成为真正的技术。

科幻作家亚瑟·C·克拉克曾著名地说过， _**足够先进的技术与魔法无异。**_

但这只有在技术没有被足够解释的情况下才会发生。技术专家有责任确保他们的创新不被误认为是魔法。

  

原文链接：https://www.newyorker.com/science/annals-of-artificial-intelligence/how-
to-picture-ai

AI知识和技能无限分享  
欢迎点击“分享、点赞、在看”

