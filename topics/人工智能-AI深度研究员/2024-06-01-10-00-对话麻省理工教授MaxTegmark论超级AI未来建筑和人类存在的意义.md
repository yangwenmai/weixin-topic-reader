# 对话麻省理工教授Max Tegmark： 论超级AI、未来建筑和人类存在的意义

文章作者: AI深度研究员
发布时间: 2024-06-01 10:00
发布地: 广东
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247490772&idx=1&sn=a5a74cec36dad92f7c771cd7ffe1d5ff&chksm=c00bae31f77c272750ba9c6cbb53ffaf6a143b2a7b2d1bf33532fdffc75075784caa3359f4f4#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAhvB2CGqelibiaWbITwAjiaXicCw3hGfQCD72CCokeOKTEdgicictpvKrrsrZA67sgKwLmwcEnG1AAnTQgA/300

在麻省理工学院充满激情的校园氛围中，Joel Hellermark 访问了 Max Tegmark 教授的办公室。Tegmark
是该校人工智能和基础交互研究所的杰出成员，同时也是大脑、思维和机器中心的核心研究人员。他的研究领域涵盖了人工智能和物理学，而在学术界之外，Tegmark
教授更以其非传统的思考方式闻名于世，赢得了“疯狂麦克斯”的昵称。

此外，Tegmark
还担任生命未来研究所的所长，致力于推动科技和生命未来的界限。他的两本作品《生命3.0》和《我们的数学宇宙》均为《纽约时报》的畅销书，这些著作不仅广受读者喜爱，也极大地影响了公众对科技未来的认识和讨论。在这次采访中，它们探索
Tegmark 的独特见解及其对人工智能未来的展望。

# 视频时间轴

**从宇宙到人工智能** 00:00

**创造超人人工智能** 05:00

**取代人类** 09:32

**人工智能现状** 12:15

**自我完善模型** 16:17

**人与机器** 18:49

**汇聚顶尖人才** 19:37

**“香蕉”盒子** 24:20

**未来建筑** 26:50

**AI 评估 AI** 29:17

**处理人工智能安全** 35:41

**人工智能愚弄人类？** 40:11

**乌托邦** 42:17

**生命的意义** 43:40

# 视频文稿整理

## 从宇宙到人工智能

**嘉宾Max Tegmark:**
我记得当我还是个少年的时候,住在布罗姆玛的古利塔大道上,躺在两棵苹果树之间的吊床上,我意识到我喜欢思考关于宇宙和大问题的事情,我总是觉得最大的两个谜团就是我们外面的宇宙和内在的宇宙智慧和思想。

所以在我整个职业生涯中,我从外部宇宙开始研究,然后我对人工智能和神经科学充满了激情,这就是我在麻省理工学院研究的方向。这真是一个激动人心的时代,你知道四年前,我的大多数同行都认为我们距离像ChatGPT-4这样聪明的东西还有几十年的时间,因为他们认为在我们弄清楚我们的大脑如何工作之前,我们永远无法制造出能掌握语言和人类知识的机器。而我们离它还差得远呢。

结果发现有一种更容易让机器思考的方法。这让我想起飞行的情况,你知道,在1900年,有人可能会说,哦,直到我们弄明白机械鸟,我们都不会弄清楚如何制造飞行器。这是完全错误的,因为有一种更容易的方法能够制造比鸟飞得更快的飞行器,我觉得这正是我们今天看到的LMS动力转换器与大脑相比非常简单,我认为我们应该很谦卑,永远不要过于自信认为某事很快就无法实现,因为也许我们并没有意识到的更容易的方法。我们可能意识不到有更容易的方法。

**主持人 Joel Hellermark:** 宇宙学的这些理念是如何影响你的人工智能研究的?

**Max Tegmark:**
它们让我一直寻找更广阔的视角。我认为今天,特别是年轻人几乎将人工智能和人工神经网络划等号。一些人甚至将人工智能和变形金刚放在一起,这种特殊类型的神经网络驱动着ChatGPT,我认为这太狭隘了。我认为变形金刚会被人们记作人工智能的真空管。真空管是第一个真正让我们建造电子计算机的技术,但后来我们找到了更好的。我相当确信,不久的将来我们会找到更好的。比我们现在所拥有的AI架构更先进,可以用更少的数据、更少的能量、更少的电力来做同样的事情。

**Joel Hellermark:** 你认为大脑的功能与下一个标记或下一个单词的预测有所不同吗?

**Max Tegmark:**
当然有。例如,我们的大脑是所谓的循环神经网络,信息在其中循环传递。在变压器中没有循环,而这其实非常有趣,因为有一种更详细的理论认为意识、主观的颜色和声音体验以及爱等都需要循环,但我们当然也可以训练循环神经网络,我怀疑新的AI架构将会最终会比今天的变压器可能会结合一些额外的成分,比如大脑使用的那些变压器没有的。人脑经常从更少的例子中学习。我们需要的训练数据比今天的大型人工智能系统少得多。你看到这些数据中心使用数以百万瓦特,你知道,你的大脑只有20瓦特。显然,我们可以从大脑中获得更多的想法,但我们不必完全了解大脑是如何工作的。当大脑被进化优化时,它被限制只能发展出一种可以自组装的生物计算机。而且他们只能使用周期表中最常见的原子来做到这一点,你知道,工程师们根本不在乎这些奇怪的限制。然而,这并没有限制,也没有必要简单易懂,而这正是我们作为工程师所受到的限制。

**Joel Hellermark:** 你认为缺少的是什么成分?你提到了重复。你认为需要什么来让这些模型进行更多的推理?

**Max Tegmark:**
我不会给你一个肤浅的回答,因为我认为我不知道,也没有人确切地知道。但是如果粗略地将AI的历史分为两个阶段,第一阶段是追求传统的人工智能,在那个阶段你拥有基于符号逻辑的系统。然后第二阶段是基本上击败了旧技术的自学习神经网络。这使我们认为神经网络就像更好、更酷的。但如果你看看我们周围的动物世界,情况似乎恰好相反。猫、狗和鹰通常比我们有更好的视力系统或嗅觉系统等。人类的特别之处不在于我们能比鹰看得更好,而是我们还可以用符号推理、用人类语言、数学语言和编程语言进行交流,并且我们可以以某种方式无缝地将旧人工智能和新人工智能结合起来。这也是我看待超级人工智能的发展之路。但人们想出了如何将这些强大的新系统与许多这些更符号化的技术结合起来,以便在某种程度上更像我们人类所做的方式。而真正令人着迷的是模型能够进行的类比推理。

所以你在模型上进行训练,它在处理人类语言方面变得更加优秀,因此它能够从中得出一些更高的抽象,让它在两个完全不同的领域之间进行迁移学习,这对某种程度上来说是很重要的。类比是多么重要,不仅对人类大脑,似乎是我们推理的主要方式,而且对这些模型也同样重要。

**Joel Hellermark:** 你认为在研究这些模型时遇到的一些最有趣的类比是什么?它是如何能够根据来自不同领域的派生见解得出这些结论的?

**Max Tegmark:**
是的,这是我在我的人工智能研究小组中经常研究的课题,因为八年前,我们从物理学转向了机器学习,我们经常在这个办公室里讨论这个问题。这些类比是如何被发现的?机器学习系统是如何从一个领域学到的东西推广到其他领域的?
我们最近发表了一些关于这个问题的论文,我觉得真的很酷。这一切都是关于发现模式,而神经网络非常擅长这一点。你给它大量的数据,然后它开始看到模式。就像,等一下。比如,你让一个大型语言模型阅读互联网上的所有文本。然后它发现实际上所有这些地方如果它选择用二维空间来表示它们,甚至从来没有见过地图的图片,我们写了一篇论文,看里面的llama
2,那里真的有一张地图,斯德哥尔摩在这里,身体在那里,一旦它意识到它可以表示这样的事情,它现在可以开始回答从来没有在训练数据中看到的问题,比如如果你问它你是否在身体的西边加德满都的西边。它可能从来没见过那个问题,但它有一张地图。它以这种方式表示它来回答其他一些问题。现在,它可以解决这些问题。

在翻译时我们看到了相同的东西,例如,如果你看它如何表示单词,它会把它们放在一个种高维度的地图中,词嵌入。如果你拿出最近有人发表的一篇好的论文,这篇论文中的英语单词的词嵌入是从大量的英文文本中获得的,而意大利语单词的词嵌入是从阅读许多不同的意大利文本中获得的,然后找出如何旋转和移动这些单词嵌入,使它们相互匹配得很好。他们从这些模式的匹配中得出了一个相当不错的英语-
意大利语词典。

所以我认为这些人工智能系统正在学习很多这些几何模式。这就是它们通常能够概括并实际回答从未接受过训练的全新问题的关键原因之一。因为这似乎是这些模型能够超越当前人类知识的方式,它们能够绘制出非常不同学科之间的类比,这对人类来说是不可行的。也许你足够聪明,可以掌握所有人类知识,但看起来今天这是相当困难的事情。但这些模型不仅能做到这一点,而且还能很快地将其适应到它们的短期记忆中,甚至包括上下文窗口。

## 创造超人人工智能

**Joel Hellermark:** 那么你对这些模型超越当前人类知识的能力有什么看法?能够远远超越它?

**Max Tegmark:**
是的,我认为这绝对会发生,毫无疑问。而且我是说,如果你我能够阅读所有的互联网和我用所有语言写的一切,并将这些记在我们的脑海里,我很抱歉,我不行。我们也会看到很多模式。当我和我那些正在训练这些模型的同事交谈时,他们都非常震惊,哦天啊,这个东西居然可以翻译英语到中文?我们从来没有教它做到这一点。天啊,它居然可以用Python编程。它是怎么找出来的?而我认为我们可能会在2024年看到很多模式和联系事物的能力,不仅仅是基本知识方面,还有使用工具方面。

所以现在,这些LLM倾向于输出标记,新词或词片,但人们正在意识到,你也可以给它们输出命令,以便计算出非常好的数学,或者输出到字典或各种其他工具,或者输出到数据库。这是我们人类当然经常做的事情。如果你在开车,发送信息几乎就像你身体的延伸。这可以开始弥合,克服大型语言模型中很多固有的弱点,因为我们有所有这些旧式的人工智能系统,可以制作非常强大的工具。所以如果LLM学会使用它们,他们就可以充分利用两者之长,这对于构建机器人也非常强大,无论是像自动驾驶汽车那样的轮式机器人,还是更像人类的机器人,它们基本上可以被一个大型语言模型控制,在某种程度上,一些token和输出只是运动命令之类的。

**Joel Hellermark:**
你认为以什么方式来看待这些模型是正确的呢?因为最初它们是语言模型,但现在它们越来越多元化了。你会说它们是世界知识的一种压缩吗?它们是token预测者吗?对于这些模型当前状态的正确看法是什么?

**Max Tegmark:**
这相当多样化。我觉得看这个事情的最终发展比试图精确地分类目前发生的事情更容易一些。存在着巨大的商业压力来构建能够自主行动的系统。传统的LLM更像是一个吉祥者。你问它一个问题,它就给你一个答案。但是拥有能够真正做事情的代理人具有巨大的商业价值,它可以获取信息,找出完成某个目标所需要采取的行动,然后去做。我认为2024年可能也会被认为是代理人的年份,我们将开始看到更多的自主系统,首先是纯软件的系统,然后逐渐地我们也将看到越来越多的实体代理人。这当然对很多方面都有好处,但显然我们也要小心,因为如果我们有很多自主系统在世界上行动,它开始感觉不再只是一种新技术,比如电力,更像是一种新物种。

**Joel Hellermark:** 你认为我们能够大大加快我们发现新科学的速度吗?如果我们这样做,那对世界意味着什么呢?

**Max Tegmark:**
这可能是令人惊讶的。我的意思是,我真的很喜欢你们公司加快知识增长并让其广泛可及的愿景。对我来说,这是地球生命史上最酷的事情之一,我们已经从以前的无力为主,30年的寿命,对所发生的事知之甚少,经过数千年的科学发展,首先对实际情况有更多了解。然后透过这些知识,也开发出让我们更加掌控并控制我们命运的技术,成为我们自己船长。我非常赞同这一点。

我认为如果你能拥有能够深入洞察和广泛知识的AI系统。显然,这可以彻底改革教育。我的工作不仅仅是研究员,尽管我在这个办公室大部分时间都在从事研究,但也非常重视作为一名教育者。对我来说,每次在开始教授某个知识之前,我总是要确保自己对这个知识有着非常深入的理解,要比学生后来需要的理解更深入。然后我还需要了解学生。他们在哪里?这也是人工智能可以不断改善的地方,可以了解那些试图学习的人已经知道什么,不知道什么,以及他们存在什么误解。最后,我可以着手处理这个问题。

我应该用什么方式来传达这个知识,这是最有帮助的方式?我应该从哪里开始?什么比喻和类比能够起到作用?我应该如何呈现这个问题,让他们保持对学习更多知识的动力和好奇心?我认为人工智能真的可以彻底改变教育的广义意义。我当然喜欢和某个真正的专家交谈,他愿意给我一些时间并回答我的问题。以一种对我有意义的方式。这是在这所大学工作的一大乐事。如果有人工智能系统也能扮演那样的角色并以我真正能理解的方式教我东西,我一定会喜欢。我会喜欢的。

这种历史推理的一种假设是它们是自我完善的。这些模型目前的状态是,你知道,你必须购买大量的计算资源。你需要花六个月的时间来训练它们。当你运行这些集群时,会有很多小问题出现。因为它们现在并不真的自我改进。

**Joel Hellermark:** 所以你的直觉是什么呢?那么,鉴于它们当前的趋势,我们如何才能达到逃逸速度呢?

**Max Tegmark:**
我认为认为现在的技术不会自我改进,然后突然间就会自我改进并且迎来奇点是一个错误的想法。这是一个渐进的过渡。科技一直在自我改进。我们总是使用今天的技术来构建明天的技术,这就是为什么我们在大多数指标上看到了技术和生产力的指数增长,但我们也看到随着时间推移,世界GDP或大多数技术指标所需要的时间成倍提高,所以实际上增长速度比指数还要快。而今天你们公司肯定有很多人在编程,他们在使用某种形式的自动驾驶。我不知道这是否使他们的生产力提高了一倍,还是1.5倍还是3倍,但这已经是人工智能如何加速AI发展的一个例子。所以这是一种递归的自我改进,但仍然有人类参与其中。只是随着时间的推移,我们在其中的人越来越少。以前我们有农耕,瑞典几乎所有人都在种地。现在只有大约1%在种地。同样,在软件开发方面,他们会逐渐变少。如果你看今天的汽车工厂,每生产一辆汽车的员工比50年前要少得多。

所以我认为事情将是这样发展的。我们会发现,在环节中所需的人越来越少。在某个时候,可能不再需要人类参与,然后事情会变得更快。但你会开始注意到这一趋势。

## 取代人类

**Joel Hellermark:** 为什么你对人类相比人工智能模型有如此强烈的偏见?

**Max Tegmark:**
因为我是人类。我有一个可爱的一岁小孩,Leo。当我看着他的眼睛,我感到他是我的儿子。当然,我应该对他更忠诚,而不是对某个随机的机器,是吗?我感觉我们人类已经共同想出如何开始建造人工智能。所以我认为我们有权利对我们建造的未来产生一些影响。我在这里是支持人类团队,而不是机器团队。我认为我们希望让机器为我们工作,而不是相反。

**Joel Hellermark:** 我看了你组织的2015年AI安全会议的精彩照片。你能告诉我们更多有关谁在那里以及你们谈论了什么吗?

**Max Tegmark:**
噢是的,那挺有趣的。快要迎来十周年了。所以,由于我喜欢大型活动,我觉得与所有主要参与者就如何使人工智能用于积极用途而不是消极用途进行对话非常重要。我觉得2014年的情况是完全不正常的,因为一方面,有一小群人担心建造比人类更聪明的人工智能而失去控制。另一方面,实际上在大公司和学术界推动人工智能发展的人从未真正与那些担心的人交谈过,他们认为那些人只是一群怪人,也许我们应该忽略他们,因为这可能对资金有害。所以我有这个愿景,我们应该试着把他们聚在一起。而你知道,瑞典擅长的一件事是,奇怪地擅长于举办好派对,从诺贝尔庆典到更非正式的派对。所以我尽一切努力诱使人们来参加这次会议,将其安排在2015年1月的波多黎各而不是在瑞典。我发出了一份邀请函,上面有一张男子在酒店旁边海滩旁把车从一米高的雪堆里挖出的照片,并写道,在2015年1月你更愿意在哪里?然后我首先接触了,我认为也许我能说服的最知名的人。当你得到他们时,你可以开始打造一个滚下山的瑞典雪球,你会得到更多人。

最终,我们得到了一些令人惊叹的人。我们邀请了德米斯·哈萨比斯,DeepMind的首席执行官,我们邀请到了埃隆·马斯克。我们邀请到了一些来自学术界的顶尖教授,以及所有曾经感到担忧的顶尖人物,来自Eliezer
Yudkowsky,尼克·博斯特罗姆和很多其他人。为了确保他们不会互相残杀,我们准备了很多葡萄酒,这很愉快。

我对最后的结果感到非常满意。每个人都聚在一起,签署了一份声明,你知道的,是的。为了确保他们不会互相挑衅对方,我们准备了很多葡萄酒,而且也在于如何使其安全、透明并且可控。埃隆·马斯克说,好的,我愿意给你一千万,来做一个资助项目,开始让一群书呆子来做这个。所以我们启动了这个项目,很快这个领域就开始发展起来。讨论AI安全问题已经不再是禁忌,技术AI会议开始就这些话题举行"书呆子专题"。

所以这也让我意识到,即使少数人经常能产生重大影响。很多时候,需要发生的事情却没有发生,仅仅因为旁观者效应的存在。我认为这对任何听到这番话的人都是一个警示。如果他们有一个新创业的想法,或者一些新的社会运动,或者任何事情,然后他们会想,啊,这一定是不可能的,否则其他人早就已经做了。不。很可能是因为没有其他人真正努力尝试过。

**Joel Hellermark:** 在会议上,人们最不同意的是哪些事情?

**Max Tegmark:**
人们对人工智能变得比人类更聪明需要多长时间有着很大的分歧。人们对此也有着很大的分歧,有人认为可能会很好,也有人认为可能会很糟糕。但所有人几乎都认为这可能会发生,而且可能会很快发生。所以,你知道,怀着这种谦逊,采取一些预防措施是有道理的。即使那些认为人类灭绝的可能性非常低的人,你知道,他们还是买了房子火灾保险。这并不意味着他们认为他们的房子可能会烧毁。只是以防万一,为什么不做一点准备呢?也许也安装一个烟雾报警器,并备有灭火器,鉴于我们目前正在花费大量资金进行培训越来越大的模型,并使其更加强大,即使是对于那些对风险持怀疑态度的人来说,至少在想一些巨大的投资可能也许有些理智化解这些系统的危险。

## “香蕉”盒子

**Joel Hellermark:** 你办公室里最好的盒子之一是香蕉盒。你认为哪些疯狂的想法可能会奏效,但我们并未给予足够关注?

**Max Tegmark:**
对于人工智能?一般来说。我认为对于人工智能来说,如果有什么真的很疯狂的事情我们没有足够重视,那可能就是我们在架构设计方面想得太小了。我们看着Transformer,考虑着微小的调整,但它们也可以很容易地成为完全不同类型的架构。甚至只需看看计算机的历史。我们在架构方面进行了多少次飞跃?首先是艾伦·图灵和查尔斯·巴贝奇等人,他们在思考机械计算机。然后从那一点开始转向开始做像ENIAC这样的电子计算机,这是一个相当大的转变。而那些计算机,就像我十几岁时学习编程时一样,那时候,计算方式完全不同,你要将所有东西都编程进去,然后将其编译成机器码,而神经网络只是教会自己。我们的大脑,生物学所提出的解决方案又是非常非常不同的。

如果你仅仅是退一步想,我要给你一大团的原子,你知道最聪明的排列方式是什么,它可能是我们根本没想过的一些东西,而且如果我们开始得到更加强大的人工智能,可以使用人工智能来发现如何制造更好的人工智能,它可能会发现那些非常聪明的东西,所以我的预测实际上是,即使现在我们正在建造越来越大的数据中心,其大小相当于飞机机库,几乎需要很快放置核反应堆来为整个系统供电。那只是暂时的。我怀疑我们正在通过这些荒谬数量的硬件和训练数据来弥补我们非常糟糕的软件架构。等到我们克服了困难,我们就会意识到其实可以用更少的硬件、更少的能源和更少的训练数据来完成所有的工作。我们一直没有充分利用混合专家等技术来设计一些模型,也没有充分筛选数据集,这真是荒唐。

**Joel Hellermark:** 你认为你看到的最有前途的新架构是什么,你认为我们应该进一步探索?

**Max Tegmark:**
所以我提到了LLM的工具使用。我认为更一般地,很有前途的是脚手架,你可以把LLM看作更大体系结构中的一个组成部分。可惜已故的卡内曼大约在90岁左右,不久前曾谈到我们人类大脑中的系统一和系统二,系统一是快速思维、直觉思维,很像神经网络,而系统二则更多基于逻辑的符号推理,让我们能说瑞典语、英语、数学、Python,以及属于我们的那些东西。

如果你想象一下未来,神经网络、变压器等可以看作是系统一,你可以想象它只是更大体系结构中的一部分,可以实现更聪明的数据库结构、各种工具、循环和其他各种技术。神经网络、Transformer这些可以看作是系统一,你可以想象它只是更大体系结构中的一部分,可以实现更聪明的数据库结构、各种工具、循环和其他各种技术。我完全可以看到这种类型的神经网络的支撑结构比今天的系统更加强大。

**Joel Hellermark:** 你认为有必要改变基本模型结构,还是可以在其上进行启发式处理?

**Max Tegmark:**
我的意思是,我们已经看到了这种思维链和类似方法,有点像在当前模型之上进行推理。所以,你不是在它们开始输出标记的时候就停止它们,而是让它们制定一个计划,然后以这种方式进行递归推理。我认为我们已经看到了更多类似的东西,比如刚出来的Quiet
Star论文,一个激进的解释是,强迫神经网络只输出一个标记来表达它的一切是愚蠢的。这不是你的工作方式。当你说话时,有时会在决定下一个词之前有几个想法,对吧?因此,Quiet
Star架构具有更多的自由度,并且性能要好得多。但这只是一个小小的例子,稍微改变架构就能带来很大的改进。而且我非常有信心,我们将在未来一两年看到巨大的改进。

**Joel Hellermark:** Max,你在符号回归研究中做了一些非常有趣的工作。最新进展是什么?

**Max Tegmark:**
最新的进展是什么?所以,我们的技术研究非常侧重于采取一个黑盒人工智能系统,该系统正在执行某种智能操作,并自动化地解决如何运作的过程,这样我们就可以看到它有多可靠,希望能使其更加可靠。

这种情况最简单的例子是,如果你有一个神经网络,它只是从数据中某种方式学习到一些函数的计算。弄清楚它实际学到的公式是什么,这个任务被称为符号回归。如果是听众中的书呆子,如果是一个线性公式,那就是线性回归,这很容易。但如果是一些复杂的公式,比如我窗外的一些物理公式,通常被认为是NP难题。这可能需要的时间甚至比宇宙的寿命还要长,因为长度为n的公式是以指数方式增长的。但是其中一个,我们设法实现了最先进的性能。我们借鉴了很多物理学的思想,从中我们能够自动发现这个神经网络实际上是模块化的,可以分解成不同部分。而且我们实际上能够从数据中重新发现许多著名的物理公式。因此,如果我们能够坐上时光机,我们就有机会在一些很酷的事情上赶超爱因斯坦等人。而且我们甚至最近成功地发现了一个有关臭氧的气候化学新物理结果,而且我们还发表了相关论文。所以这是我们第一次利用这些工具来推动科学的发展。

但更广泛地说,我们想做的就是最终能够对任何黑盒人工智能系统进行分析,并弄清楚它学到了什么算法,以及它真正学到了什么知识。我们最后一篇关于这个话题的论文中,我们使用了大约60种不同的算法,并训练了一个神经网络来学习执行这些任务。

**Joel Hellermark:** 所以现在你有了一个黑盒子,但它到底做了什么?

**Max Tegmark:**
然后我们使用了一个自动化人工智能系统,它能够完全弄清楚它在做什么,并将其转化为Python代码。她就像这样,啊,我们对此感到非常兴奋。我们正在大力扩大规模,看看是否能够应用到更大的系统中。

我在这里的愿景是,如果你有一个系统,一个人工智能系统,它将以某种方式影响人们的生活,你真的希望拥有高度信任,那么如果让机器学习去学习,这是一个非常好的主意。我们没有比这更好的方法。但是可以将它所学到的知识转化为Python或其他东西,在那里你实际上可以证明代码符合你的规范。我基本上相信这是可能的,因为我们人类可以做到。

当你还是个小孩的时候,如果你爸爸向你扔一个网球,你能接住,因为你的大脑已经学会了如何计算抛物线轨迹,但当你长大后,你会觉得,哦,这是一个抛物线,y等于x的平方公式。这就是科学家通常如何直观地找出问题的方法,即使他们不知道他们的大脑是如何工作的。然后他们学会以一种能够被编程到月球火箭中的方式提炼知识。已经取得了这么大的进展,这个领域正在迅速发展,我在麻省理工学院组织了迄今为止最大的会议。这个领域被称为机械解释能力。这实际上让我感到很有希望,我们不必对我们永远无法理解人工智能系统的想法感到无奈。那些我们真正想要理解的系统,我认为我们可以利用其他人工智能系统来帮助我们理解它们。

通过模型,像推导这些方程式还是它们会有一个更简单的启发式吗?如果以我扔球给你做例子,然后你并不需要进行精确计算。你只需根据风向、球的大小等简单的启发式来判断。

**Joel Hellermark:** 你认为这些模型会怎么样?它们会有那个简单的启发式,还是它们会实际包含精确的方程式?

**Max Tegmark:**
我们的系统实际上两者兼具。因此它实际上找到了很多公式。我们将它们放在一个图表中,一个坐标轴表示它们的复杂程度,另一个坐标轴表示它们的不准确程度,它会发现。就像在这种情况下一样,最简单的情况,就是抛物线,这里完全没有空气阻力。但随后它可能会找到更复杂的,更精确的路径。这非常像我们人类的做法。有时候你只需要一个简单的。

但从整体来看,我认为在这个问题上有太多悲观情绪了,关于我们是否能够建立我们实际可信赖甚至证明事物的系统。因为人们犯了一个错误,就是假定所有的解释和证明工作都必须由人来完成。但AI系统现在在这方面变得非常优秀,它们能帮助我们。而且你可能会想,哦,我怎么能信任一个由AI制作的系统,其证明又是由AI产生的,如果我无法理解,如果证明和代码都太长而无法阅读?没关系。因为实际上,很难在一堆草里找到一根针,但一旦找到了,证明它是一根针就比较容易了。找到正确的代码和证明它符合规格要困难得多,但一旦找到了,验证它是否有效就比较容易了。所以你只需要真正理解你的证明检查器,它可能是300行Python代码。现在你可以完全信任一些由AI制作的非常强大的系统了。

而且你在大学里遇到了很多很棒的人。还有这么一个故事,道格拉斯·恩格尔巴特遇到了马文·明斯基。马文·明斯基告诉恩格尔巴特关于计算机将来会做的一切。它们将会推理,它们将会有意识,等等。恩格尔巴特回答说,你们要让计算机做所有这些吗?你们要为人类做些什么?还有其他类似的故事吗?

## AI 评估 AI

**Joel Hellermark:** 您是否与明斯基或其他人工智能领域的先驱者有过交流?你是如何看待他们对人工智能的看法随着领域的进步而发生的变化的?

**Max Tegmark:**
我知道,我认识的顶尖人工智能思想家和商业领袖们可能没有那么多时间来反思,正如他们所希望的那样。例如,经营公司是很艰难的。许多人认为,首先只需让这个东西运行起来,然后再想好如何确保对社会有益。然后许多人都对聊天GPT和稳定扩散等技术提前几十年出现感到吃惊。我的天,这下该怎么办?

我希望最终能够让这些人有时间来解决这个问题,以确保我们能够迎接美好的未来。对于所有其他可能带来危害的技术,我们都有方法来解决,无论是飞机还是药物,我们总是有安全标准。如果阿斯利康公司推出了一种新奇药物,声称能治愈癌症,并且明天就在伊卡开始销售,美国药品管理局会问,好的,你们的临床试验在哪?哦,你们懒得去做,没时间做试验?是的,我会在你们做完临床试验后再过来,看看你们是否符合标准,对吧?这样一来,就给所有相关方争取了时间。公司现在有责任去弄清楚对社会的影响,有多少人会出现副作用,他们用一种非常书呆子的方式来量化一切。这样我们才能信任我们的生物技术公司。这就是为什么阿斯利康最终在很大程度上有很好的声誉。飞机也是一样,汽车也是一样,基本上任何可能导致伤害的技术也是一样,除了人工智能,在美国基本上没有监管。如果有人明天想发布GPT-5,他可以吗?所以我认为我们越快地改变对待人工智能的方式,就像我们对待其他所有强大技术一样,越好。

**Joel Hellermark:** 我认为一个非常普遍的误解是,我们在快速享受人工智能的各种好处和避免灭绝之间必须做出选择。

**Max Tegmark:**
事实上,我与之交谈的人们对99%的事情都很兴奋,我认为包括你在内,对人工智能也是如此。这些事情大多是无害的,与我们不知道如何控制的比人类更聪明的人工智能无关。我们可以帮助传播知识。我们可以帮助公司更有效率。我们可以在科学和医学等方面取得巨大进步,等等。因此,如果我们建立安全标准,只是稍微减缓一下我们可能失控的最后1%,那么在未来的一段时间里,我们可以享受医疗保健和教育等领域的革命,而不必为此失眠。这一切都可能会失控。然后,如果我们最终能够看到更强大的系统符合安全标准,那太好了。如果需要更长的时间,也可以。我们并不急于求成。如果我们做对了,生命可以在数十亿年里繁荣。因此,冒着浪费一切的风险只是为了早一年到达目标是没有意义的。

**Joel Hellermark:** 你是一个历史迷。你觉得历史上最类似的是什么事情?有没有我们可以从中汲取教训的历史发明,它们的行为会相当类似?

**Max Tegmark:** 对。所以在1942年,恩里科·费米在芝加哥一个足球场下建造了世界上第一座核反应堆。物理学家们一知道这个消息就完全吓坏了。

**Joel Hellermark:** 为什么?是因为他们认为这个反应堆真的很危险吗?

**Max Tegmark:**
不是,它的体积很小,能量输出也很低。他们意识到现在离炸弹只有几年的时间。而三年后,广岛和长崎发生了,对吧?这里有个很好的类比,因为大约在1951年,艾伦·图灵曾说过,有一天机器会变得和人一样聪明,然后很快它们将变得比人类聪明得多,因为我们是生物计算机,没有理由机器做不得更好。然后,默认情况是我们失去对机器的控制。但我会给你一个小小的警告,让你知道你已经接近了。图灵测试。一旦机器在语言和知识方面变得足够出色,可以愚弄很多人认为它们是人类,那就是你已经接近的时候了。那就是你可能还有几年时间的时刻。

**Joel Hellermark:** 去年,世界上引用次数最多的人工智能研究者之一约书亚·本吉奥声称GPT-4通过了图灵测试。

**Max Tegmark:**
你可以争论它是否通过了图灵测试,或者我们明年会通过它。但是我们大致已经到达了人工智能的恩里科·费米反应器的那一刻,是时候认真对待即将发生的重大事件了。让我们开始准备迎接它们吧。

## 生命的意义

**Joel Hellermark:** 那么,最后一个问题。我们现在在你们的校园里。你知道,二十年后你认为最好的情况是什么?

**Max Tegmark:**
最好的情况是,我们仍然活着并感到快乐,而且人类仍然掌控着这个星球。除了再也没有饥荒,不再有战争。气候都很好,我们有基本上解决了困扰人们数代的最大难题。那就是我所追求的成功案例。

**Joel Hellermark:** 那么,你认为一旦我们解决了所有问题,会发生什么呢?我们已经找到了所有疾病的治疗方法?那个世界看起来是什么样子的?

**Max Tegmark:**
尼克·博斯特罗姆刚刚出版了一本关于这个问题的书,他称之为"解决世界"。我现在还没有花太多时间去思考这个问题。我宁愿等我们对这个问题有了更接近解决的进展之后再去考虑。现在,有太多令人兴奋的事情要做,无论是从技术上去想出如何使系统更加值得信赖,还是从社会角度上确保我们的政治家制定良好的安全标准。这就是我花费精力的地方。

**Joel Hellermark:** 那我们来谈一些更简单的问题吧。你现在认为生命的意义是什么?

**Max Tegmark:**
啊,简单的问题。你知道,通过找到所有这些物理基本方程式,我们发现的事情是,这些方程式中没有明确提到任何意义。所以我认为创造意义其实在于我们这些有意识的生命。我认为意识和积极的体验是这一切的核心,因为美丽、爱、激情、善良和希望都是有意识的体验。我认为我的书桌没有这些体验。换句话说,我认为我们的宇宙并没有赋予我们意义。是我们赋予我们的宇宙意义。

# 往期回顾

[1、[李飞飞演讲：只有计算机和机器人具备空间智能，人工智能的潜力才能得到充分发挥]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhvB2CGqelibiaWbITwAjiaXicCWl1FBsZWBcjldyhPsX2JQhsS5fMUteoFfan9ENbwPgyUICazOb5GOA/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247490369&idx=1&sn=9a76969dcc87b57bd946778ab7e4d543&chksm=c00ba9a4f77c20b23b8266cab39434ef27c1fcf9fc8980d7c8730506a81dc968b45ec99a4117&scene=21#wechat_redirect)

[2、[对话节目：AI之父Geoffrey
Hinton为什么坚信模型越大，AI越能够像人一样更有创造力？]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhvB2CGqelibiaWbITwAjiaXicCeHTUsxAzvp4bO9ar3okdQqKJ2kG7H1GaCZvuVhl5n8zSqz8WmQT3vg/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247490393&idx=1&sn=1f326befbceb9f158ed0a0af4b2500f8&chksm=c00ba9bcf77c20aacd95c53dac49ddb0766d6ac03c00d394a228d32d496d2ed6e8831eb468b8&scene=21#wechat_redirect)

[3、[李飞飞领衔Stanford
HAI发布全新500页2024人工智能报告，显示超过30%的工作岗位或被AI取代]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhvB2CGqelibiaWbITwAjiaXicCdLosKMSVnlUvAODiarkC28GAQaRdia5IS6j7llBlRIB6fFwRUSB62S1Q/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247489438&idx=1&sn=4c305a310a5ef39c01be3594fcc45cb7&chksm=c00ba57bf77c2c6d6acdd569f613ee158303ec78fe3c49f3ea39cffcb697e8673f17213eae51&scene=21#wechat_redirect)

* * *

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhtRhTOjz2QwH4dIlC3YUcYbaicMEwjqQqh06Yhdd7EH3r9wiaMRArLz0a6Zhx6uiaUD7hguPfbY0nAg/640?wx_fmt=png&from=appmsg)

****

**我们的AI团队现向外界开放服务，旨在助力每个企业与个人引领时代潮流，将先进科技与创新想法完美融合!**

#  告别昂贵服务费和缺人烦恼,再见漫长交付周期

# 无限创意风格,分分钟生成专业级作品

# 感受 AI 带来的全新工作体验！

 _**欢迎各大品牌方、媒体、科技企业、知名IP等合作**_

 _**合作请联系负责人微信：Milo-1101**_

 _**\--END--**_

