# 在联合国AI for Good峰会上，Sam Altman展示了AI如何快速有效地提高个人工作效率

文章作者: AI深度研究员
发布时间: 2024-06-03 10:00
发布地: 未知地区
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247490807&idx=1&sn=5dcc8b6aa690d81f231ea76c7607956e&chksm=c00bae12f77c270461818a7bb372941a1e4db56ad41f7d3e84d37fe67791385569bb6f137cbb#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAjhmskic41SCOu742DvxRTVicCaGlr9D0s5TUdxPq24xwdicuRLYBFPZrQVOMT5ZOHMAm2RKQr474ticA/300

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAjhmskic41SCOu742DvxRTVicIAqCgqwnoDiaHUbh4vibhBWI98UPQYoYSbzXapZVpWCe1AsdacnJbYKA/640?wx_fmt=png&from=appmsg)

在日内瓦举行的AI for
Good全球峰会上，众多来自世界各地的思想领袖、政策制定者、科技先锋汇聚一堂，共同探讨如何利用人工智能技术推动全球发展的关键领域，包括健康、气候变化、性别平等、社会包容以及可持续基础设施建设。此次峰会由联合国信息和通信技术专门机构——国际电信联盟（ITU）主办，得到了40个联合国姐妹机构的协作支持，并与瑞士政府共同召开，旨在将人工智能的创新潜力转化为具体行动，解决一些最为紧迫的全球挑战。

在这一行动为导向的平台上，Sam
Altman——作为OpenAI的首席执行官，他在会议中分享了他对于人工智能未来发展的深刻见解，并讨论了AI技术如何在尊重个体自主性的同时，提升全球福祉。Sam强调了人工智能面临的双重挑战：一方面是其巨大的潜力能够为世界带来前所未有的益处，另一方面则需要我们谨慎地解决伴随而来的安全和伦理问题。他提出，与其在理论上过度推测AI的长远影响，不如通过实际应用中的反馈和调整，更加科学地塑造AI的发展方向。

# Sam Altman发言整理

## 提高生产力提高

**主持人：** 非常高兴能与OpenAI的CEO Sam Altman进行交流，谢谢Sam在线加入我们。

你好，Sam。感谢你的耐心等待。你现在正对着一个坐满了的人大厅发言，很高兴你能来，今天我想谈论广泛的话题，包括AI的当前进展、未来方向、重大问题以及治理问题。现在，让我们开始这次对话。当前，人工智能已经显现出巨大的潜力和能力，但它还未真正地改变世界或实现我们讨论的可持续发展目标。我不会问你这会在何时实现，但我想知道，哪些好的或坏的重大事件可能首先发生？

**Sam Altman：**
目前我们已经看到的是在提高生产力方面的影响。以软件开发者为例，他们能更快更有效地完成任务，专注于他们更喜欢的工作部分。像其他技术工具一样，这些工具很快就成为了工作流的一部分，很难想象没有它们的工作环境。我预计这种模式将逐步扩展到其他领域，使得各行各业因使用这些工具而变得更加高效。这将首先带来显著的正面影响，从编程到教育、学习和医疗保健的方式都将改善。至于负面影响，尽管现有工具已经带来了一些问题，我特别关注的是网络安全问题，这可能成为一个严重的挑战。我们正在努力改进将来的模型，使其支持更多语言。据我们公布的数据，已经很好地支持了97%的人使用他们的母语。这是我们向前迈出的一大步，大家对此反应非常热烈，我们会继续在这方面做更多工作。对于你提到的下一代模型，你觉得我们可能会看到什么样的进步？是线性的、渐进的，还是可能出现一些意想不到的指数级进步？

我们并不认为我们已经接近任何技术的极限，这是一个全球性的讨论话题。我们的策略是通过实际展示而非空谈来解决问题。很多人做出了各种预测，我们会尽力进行最优质的研究，并找到负责任的方式来发布我们的成果。我预计在某些方面我们将看到巨大的改进，在其他方面可能不会有太多改善，这与以前每个模型的情况都相似。但这也是第一次，我们将有一个主要基于合成数据训练的模型。现在网络上有很多由其他语言模型生成的数据。你担心基于这些模型生成的数据训练新模型会导致系统出现问题吗？

**主持人：**
关键在于我们需要高质量的数据。无论是合成数据还是人类数据，低质量的都不少。只要我们能找到足够的高质量数据或提高数据利用效率的方法，学习如何从较少的数据中获取更多信息，我认为这是可行的。我们认为，为下一个模型，我们已经具备了必要的资源。你们是否创造了大量的合成数据来进行训练？你们是否自行生成了用于训练的数据？

**Sam Altman：**
我们当然做了很多实验，包括生成了大量的合成数据。我希望不会出现只通过生成海量的合成数据来训练模型的情况，因为那样效率太低了。理想情况是我们可以在训练过程中从数据中学到更多。我们还有很多需要探索的地方，但当然，我们已经生成了大量的合成数据进行实验。但你真正关心的核心问题是，如何从更少的数据中学到更多。我们可以通过不同的方式理解一个系统，不必非得逐个神经元分析。这些系统的行为和特性已经被非常详尽地描述了。令我和许多同行惊讶的是，这些系统很快就被普遍认为是安全可靠的。我的妻子有时也说她不完全理解我的大脑在做什么，所以这方面我们有共同之处。在理解这种复杂性方面，我们有什么进展或者突破吗？Anthropic最近的一个发布展示了一个以金门大桥为模型的研究，这展示了系统的一个有趣特性。好的，转到Tristan
Harris今天早上提出的关于安全的建议。Tristan说，每当大型语言模型公司增强模型的能力时，他们也应该投入同等金额于安全性。你觉得这个想法怎么样？

我不确定这意味着什么。人们倾向于把世界分为能力和安全两部分，并可能制定很多听起来不错的政策。但如果你关注我们实际上是如何让像gp4这样的模型安全地服务于数亿用户，完成越来越多重要任务的，你会发现很难区分很多工作到底属于哪个领域。如果你在实际操作中使用模型，你希望它能完成任务，而不是引发任何问题，但这很难确定。作为用户，你可能想知道，这是因为模型的能力还是安全性设计，或者是两者的结合，让模型按用户的需求行动。这是一个综合体。比如你乘坐飞机，虽然最近有些不好的例子，但让我继续用这个比喻。你希望飞机能安全抵达目的地，也希望它不会在途中出现问题。但在飞机设计中，虽然有些部分明显是关于能力的提升，有些明显是关于安全的设计，但大体上，你是在试图构建一个能安全快速地带你到达目的地的综合系统，这里的界限并不总是那么明显。

这些系统使用自然语言进行操作，这对我们来说非常重要，因为这似乎是正确的方向，并且围绕这一点，未来可能会有许多安全优势。我们的目标是使AI尽可能与人类兼容，为人类设计，以一种能够用语言与我们甚至彼此沟通的方式工作。还有其他的想法，例如我个人认为，相比其他形状或结构的机器人，人类更应该倾向于使用人形机器人，以保持以人为本的方向。因此，对人类友好的使用包括将语言作为可能的主要交互界面，但不试图在此基础上过度赋予它们人类的特性。因此，我们没有给AI取一个人类的名字。我认为ChatGPT这个名字虽然有些笨拙，但它很好地解释了它是什么，并且三个字母听起来像是机器人，这很明确地表明它不是人类。关于这个方向，我们还能做更多什么呢？例如，我们可以规定ChatGPT永远不使用“我”来增强其人类兼容性。我们试验过这样的版本，通常会让用户感到更加挫败而非帮助。我们习惯了在语言交流中使用一些固定表达方式。那么，使用你的声音呢？比如说，你有一个语音模型，可以在其前加一个提示音来表明这不是一个人。我们即将进入选举期，大家都在关注深度伪造和误导信息的问题，你如何验证哪些是真实的？你能在设计的核心层面做些什么来减少这些问题？

# 斯嘉丽·约翰逊的事件

**主持人：**
我们来讨论一下斯嘉丽·约翰逊的事件，因为有些东西我不太明白。在你们展示这些声音之后，她发表了一个声明，引起了广泛关注，大家可能都看到了。她说，他们问我是否愿意使用我的声音，我拒绝了，他们在产品发布前两天又问了一次，我再次拒绝，但他们还是发布了。随后OpenAI发表声明，说实际情况并不完全是那样，我们邀请了很多演员试镜，选出了五个声音。之后我们又邀请她，她本可以成为第六个声音。我不明白的是，为什么其中一个五个声音听起来极像斯嘉丽·约翰逊，这让人觉得你们好像是想要两个声音听起来像她，我很好奇你怎么解释这一点。

**Sam Altman：**
那不是她的声音，我们也没有意图让它听起来像她的声音。对于这种混淆，我感到抱歉。显然，你认为那是她的声音，但事实上，人们对声音相似程度的感觉不同，但我们并不认为那是她的声音，不知道还能说什么。

**主持人：**
好的，我们来谈谈真实性，因为这与我们之前的讨论密切相关。你在视频中，我在现场，我是真实的。我问GPT-40在通过视频采访某人时如何证明他们是真实的，它建议询问一些在最近几小时内发生的事情，看看他们是否能回答。

**Sam Altman：** 刚才发生在马格努斯·卡尔森身上的事我不知道。

**主持人：** 好的，我还有几个问题，我们会找到一个。现在Twitter上讨论的哪家科技公司的财报？

**Sam Altman：** 哦，是Salesforce。

**主持人：**
它还说你可以让那个人做一个复杂的动作，比如能不能用右手举起来同时用左手摸鼻子。好的，这个人是真实的。让我们稍微谈谈AI的全球化，因为这是会议中经常提到的话题。显然，对你们来说，有一个或几个大型语言模型是有利的，但你如何看待未来的发展？三年后，会有许多基于大型语言模型的应用还是很少？重要的是，中国、尼日利亚、印度会有各自不同的大型语言模型吗？

**Sam Altman：**
说实话，我们和其他人一样，不知道未来会怎样。显然有很多模型正在被开发，这个趋势将持续。虽然我们不确定，但我预计中国将有自己的大型语言模型，与世界其他地方有所不同。我猜测不会有成百上千个大型语言模型，但可能有10到20个使用最多资源的模型将获得大部分使用率。我认为我们还处在这个领域的早期，还有很多未知和科学突破即将到来，因此现在做出任何肯定的预测都是非常困难的我认为我们使用互联网的方式可能会有所改变，虽然这需要一段很长的时间。但我并不担心它会变得无法理解。通过使用ChatGPT的方式，我们已经能看到一些初步变化，比如在某些情况下，使用它获取信息比传统的搜索和点击更为高效。我认为AI的发展带来的一大优势就是可以直接将互联网内容有效地呈现给用户。所以我认为我们使用互联网的方式可能会有这样的改变，但我并不担心它会变得充满垃圾邮件或自动生成的内容而变得无法理解。你提到的那种情况，我能想象一个互联网几乎崩溃的世界，只有那十几二十个大型语言模型作为用户的主要界面，但这并不是我所看到的。

  

## 对低收入工人的帮助

**主持人：**
可以想象在未来，整个网络变成了各种组件，有一个AI根据你的需要实时组合出完美的网页。但我无法想象所有事情都仅仅局限于网站，这违反了我的直觉。我们来谈谈一个我自去年11月以来一直关注的问题，这个问题在AI领域的很多聪明人之间存在分歧，那就是AI是否会加剧收入不平等。我听了很多次你的播客，这个话题偶尔会被提及，你有时会提到它可能会加剧收入不平等，以及需要普遍基础收入来应对这一问题。但今天早上Azar在这里引用了一些经济研究，这些研究表明，实际上AI工具在呼叫中心等场合的应用对低收入工人的帮助大于高收入工人。AI的推广是否改变了你对全球和各国内部收入不平等未来走向的看法？例如，我们今天刚刚推出了面向非营利组织的OpenAI计划，这是一个使我们的工具对非营利组织更加便宜和广泛可用的新倡议。我们提供了折扣，分享了最佳实践方法。人们已经开始用这些工具做出了惊人的成绩。例如，国际救援委员会就利用我们的工具取得了显著的成效，支持那些在真正危机区域压力巨大的教师和学习者。这证明了这些工具能够自动化一些以往难以处理的任务，并使智能技术更广泛地普及，真正帮助到那些最需要帮助的人，而不仅仅是那些已经处于较为富裕环境中的人。

**Sam Altman：**
我们对推出这个计划感到非常兴奋，这正是你所描述的那样，AI有很多方式可以在不需要太多想象力的情况下，帮助最贫困的人超过富人。我们对此深信不疑，并对此充满热情。这是我们想要开发这些工具的一个重要原因，而且我认为这也是技术历史和发展趋势的一部分，这种变化肯定会发生。我认为技术极大地提升了世界的丰富性、高度和繁荣，我对此持乐观态度，认为这不需要任何特别的干预。虽然我不确定将来会发生什么，这不是一年或两年内就能看到的事情，但长远来看，我预计随着这项技术的强大潜力，社会契约将需要一些变化。我不认为未来没有工作，我相信我们总能找到新事物，但我确实认为社会结构本身将需要进行一些讨论和重新配置，这种重新配置不仅仅是由大型语言模型公司来引领，而是整个经济系统的运作方式，以及社会决定我们想要做什么。这种变化已经持续了很长时间，随着世界变得更富裕，社会安全网就是这种变化的一个例子，我期待我们将决定在这方面做更多工作。

  

## AI监管

**主持人：**
：那么，对于这个房间里的许多国家的政府领导人来说，过去一年半讨论过的哪些规则，你认为有助于重新配置社会契约以适应AI的大规模采用？又有哪些规则可能会阻碍这一进程？

**Sam Altman：**
我认为当前关于规则的讨论并未集中在这些问题上，而是关注我们有选举，我们该怎么办等问题。你可以看到其他一些非常重要的短期AI问题。我认为还没有讨论到我们将制造AGI，它将会像科幻小说中的那样，我认为现在讨论这些问题为时尚早，因为我们还不知道社会和这项技术将如何共同进化。我认为这些值得辩论，但我不认为这应该是当前的焦点，目前显然还没有成为焦点。

**主持人：**
那么，你认为有没有现有的监管框架，比如经常被讨论的核武器监管框架，你觉得在我们进入这个新时代时，有哪些监管框架是有用的？你是在谈论长期影响，比如AI成为一个巨大的经济力量，还是谈论短期问题？

**Sam Altman：**
如果我们有一个强烈的建议，我们当然会意识到这不是我们的决定，但我们会提出强烈的建议，并指出，基于我们认为最可能发生的情况和我们对未来的预期，这里是我们认为应该重点考虑的地方。理论上提前处理这些事情非常困难，你必须观察事物如何发展。我们相信逐步部署策略的一个原因是将这些系统安全地推向世界，意识到它们将得到改善，你将在这个过程中学到很多。我们认为这很重要，因为社会不是在理论白板上的静态存在，当你推出技术时，社会和技术都在变化，这是一种真正的共同进化。因此，我认为我们共同弄清楚这将会是什么的正确方式是基于实际经验的。自从发布ChatGPT以来，你已经可以看到它开始小规模地但确实开始改变经济的某些部分和人们的工作方式。我认为我们不是某一天坐下来说，好吧，我们现在要一次性设计新的社会契约，这将是非常糟糕的，非常难以正确实现。但通过迭代的方式来达到这一目标似乎更有可能成功。

**主持人：**
让我们谈谈OpenAI的治理。我最喜欢的一句话是你八年前在《纽约客》的一次采访中说的，当时我在那里工作，你谈到了OpenAI的治理。你说我们正在计划一种方式，允许世界各地的人选举代表到公司的新治理委员会，因为如果我不在这个过程中，我会问为什么这些人可以决定我的命运。告诉我关于那个引述和你现在的想法。

**Sam Altman：**
类似那样的东西仍然是我认为值得做的事情。我们继续讨论如何实施治理。我可能不应该说太多，但我仍然对那个方向的事情感到兴奋。再多说一点，我将选择保留意见，对此表示歉意。

**主持人：** 让我问你关于现在治理的批评。你的两位前董事会成员Tasha McAu和Helen
Toner最近在《经济学人》上发表了评论，他们说在OpenAI的经历令人失望，这些是在你被解雇之前投票解雇你的董事会成员，在你回来并重新担任CEO后，他们说你不能信任AI公司的自我治理。本周早些时候，Toner在Ted
AI播客的一次采访中说得很严厉，她说监督完全是功能失调的，事实上，她和董事会是从Twitter上得知ChatGPT发布的，这准确吗？

**Sam Altman：** 我尊重地但非常明显地不同意她对事件的回忆，但我会说，我认为Toner女士真正关心一个好的AGI结果，我对此表示赞赏。

是的，我认为这将是一个很好的项目，让联合国开始讨论我们如何收集人类的一致性数据集，以及在此过程中如何确定默认设置、边界，以及人们如何在其中进行调整。我认为这将是联合国应该做的事情。所以你认为我们真的可以达到那里，为了建立一个能够使AI帮助使治理系统更加协作、更具雅典风格的治理系统，需要采取哪些中间步骤，而不是相反？

我们最近发布了一些东西，大概一个月前，称为规范，这是朝这个方向迈出的第一步。我们说，基于我们所学到的，这里是我们将如何尝试设定规则，模型将尝试做什么。这一点很重要，因为它至少解释了什么是bug，什么是按设计行为。因此我们可以修复bug或讨论原则。我们现在正试图就这个规范进行大量讨论，以及为什么我们做某些事情，这涉及到相当高的细节水平，比如模型在回应某些可能有问题的请求时不应该说什么，但如果你要求它将某事从英语翻译成法语，它应该遵守翻译请求，试图达到这种具体性是重要的。

是的，我认为其他要做的事情是现在将这推广到更广泛的范围，你可以想象一个世界，最终人们可以与ChatGPT交谈关于他们的个人偏好，并将这些偏好考虑进更大的系统中，当然也包括它仅对他们的行为方式。在这个世界中，我们的系统消息使人们做出了非常有创意的工作，使模型按照他们希望的方式行事。你认为人类大脑中有什么是机器无法复制的吗？

也许是主观体验，我不确定，我不想深入AI和意识的辩论，因为我认为我没有什么可以补充的。我在最后问你这个问题，因为你基本上只能对AI或意识给出是或否的回答。让我问你另一个问题，这是我孩子之一提出的，我觉得很有趣。我有三个儿子，最大的一个，我和他谈论他对AI的恐惧，他的回答很有趣。他在辩论准备中使用AI，他在学校中将其作为辅导工具，我一直在向他展示不同的模型，他说他担心的是他将进入一个重新学习变得极为重要的未来。我想我们都同意，世界将以戏剧性的方式改变，为了繁荣，我们必须学习，他担心我们将变得过于依赖，不再学习如何学习，他对此感到担心。你是否也担心这一点？

在一个变化迅速的世界中，我们必须弄清楚如何适应这种快速移动的新事物，我担心很多其他事情，但学习如何学习似乎是如此根深蒂固的人类技能。显然，这似乎在人生早期比晚期更强，但它从未消失。我认为未来将更加重视培养这种技能，我们将有更多的动力去精通它，但它看起来深刻且与生俱来，我们的大脑为此设定得很好。我同意他的看法，这将变得越来越重要，但我乐观地认为我们将会非常擅长它。好的，我会告诉他可以使用ChatGPT来完成他的下一篇论文。

**主持人：**
这是最后一个问题，因为我们快结束了。这个房间里聚集了很多非常聪明的人，他们将会帮助监管AI和塑造它的未来。你想对他们说的最重要的信息是什么，或者你希望他们从这次讨论中带走什么，以便他们在努力使用AI、监管AI并将AI用于善良的目的时可以参考？

**Sam Altman：**
你们面临的挑战是，存在着巨大的上升潜力和将这种潜力带给世界的道德责任，同时也有严重的安全问题和社会层面的关切需要缓解。我们本周成立了一个新的安全与安保委员会以及一些团队成员，帮助我们为下一个模型做准备。全球各地有许多关于AI安全问题的优秀论坛，并且现在对准备工作框架的讨论也很多。但如果我们预计改进的轨迹将保持陡峭，那么弄清楚公司和国家应实施什么样的结构和政策，以及整个国际社会，以确保世界获得这些巨大的好处——这是全世界都将要求的，并且我认为这是非常有道德价值的，同时避免各种时间尺度上的风险，这是非常重要的。因此，不要只关注短期或只关注长期。我建议全面考虑这个问题，这是极具挑战性的。我认为可以从目前正在发生的事情中学到很多，还有很多新的问题需要解决。但我想说的是，不要忽视长期问题，也不要假设我们会突然停滞不前。

**主持人：**
好的，当我问GPT-40如何判断某人是否是人类时，它实际上提供了三种方法：手臂测试、新闻测试和第三种，提出一个开放性问题，看看他们是否能给出一个复杂的答案而不需要停顿。非常感谢你，Sam
Altman。

# 往期回顾

[1、[视频访谈节目：OpenAI创始人Sam
Altman亲述GPT-4o细节,展望科技浪潮下新生存模式!]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAjhmskic41SCOu742DvxRTVicy5ibgHmuhG8U3AsfGEZaN3665pSPlFQFLju6pd7dx4bSbPOFq9hH41Q/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247490338&idx=1&sn=56ad0861af3bd36997324913c95cebc8&chksm=c00ba9c7f77c20d12f9b7ecd19e07cc34934a430ce7bcb7206ff939efd5a4382eedcded9b1ec&scene=21#wechat_redirect)

[2、[视频+万字实录：Sam Altman 在斯坦福创业者思维领导研讨会完整对话首次公开，涵盖你想了解的全部 AI
内容]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAjhmskic41SCOu742DvxRTVicbMe322eia2T21gyic9L72z0gzv20BBUmbQiaBZdPjeuVYTYGl7PUJzvibA/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247489850&idx=1&sn=2bc2c34cc2b759bbf4de214b0383f79e&chksm=c00babdff77c22c947ddfcb8a6bcbcc0adc35d466ad9f38a2b4fa17629c6cd0759973fef1834&scene=21#wechat_redirect)

[3、[从观望者到行动者的转变，红杉资本2024年AI大会指明普通人抓住AI机遇的路径]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAjhmskic41SCOu742DvxRTVicDiajciasmPWR2mKdia3mK7wvSiaBh3HEHGRMZic8qeazDgDIryV27JMtyJg/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247489090&idx=1&sn=35b4df58a275f7ed62074ec183e28f3c&chksm=c00ba4a7f77c2db193fc8efcd78a3327f3cb92db6b595b26d1bbb9cdbaee0a0d717a2f6f860e&scene=21#wechat_redirect)

* * *

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhtRhTOjz2QwH4dIlC3YUcYbaicMEwjqQqh06Yhdd7EH3r9wiaMRArLz0a6Zhx6uiaUD7hguPfbY0nAg/640?wx_fmt=png&from=appmsg)

**我们的AI团队现向外界开放服务，旨在助力每个企业与个人引领时代潮流，将先进科技与创新想法完美融合!**

##  告别昂贵服务费和缺人烦恼,再见漫长交付周期

## 无限创意风格,分分钟生成专业级作品

## 感受 AI 带来的全新工作体验！

**_欢迎各大品牌方、媒体、科技企业、知名IP等合作_**

** _合作请联系负责人微信：Milo-1101_**

** _\--END-_**

  

