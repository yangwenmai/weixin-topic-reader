# AI之父Geoffrey Hinton首次公开表示人工智能已经通过图灵测试，这意味着什么？将给我们生活可能的变化？

文章作者: AI深度研究员
发布时间: 2024-07-03 09:05
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247491598&idx=1&sn=6b3fde6928427dc7efdb78986efe4006&chksm=c00852ebf77fdbfd64809ae7334b814ce06a28018865ab1906155997728b22493ddf49a2aba4#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAgO9a1Iy1RfY4PLSo0jGAmyILbic0od7sMRsibOse1nymr1EdEwibcYrxVv0IgBuoAjwM8N1zEqYOV0A/300

最近，被誉为“AI之父”的Geoffrey Hinton与学生的讨论再次引起了公众对人工智能能力和潜力的关注。

**Hinton教授提出了一个引人深思的观点：当人工智能能够解释一个笑话为什么好笑时，它实际上已经通过了图灵测试。这个标准不仅仅测试了人工智能在处理语言的复杂性方面的能力，更深入地考察了其理解人类情感和文化背景的能力。**

此言论不仅挑战了传统对于人工智能能力的认知，也重新定义了图灵测试的现代意义。图灵测试，由数学家和逻辑学家艾伦·图灵在上世纪40年代提出，旨在评估机器是否能够展现出与人类不可区分的智能行为。然而，Hinton的观点提出了更高的要求——机器不仅要模仿人类，更要深入理解并参与人类的情感世界。

# 文稿整理

## 1.人工智能的进化与其前景

**主持人:** 好的，是的。正如比尔刚才提到的，很高兴Geoffrey
Hinton教授在这里。我会简要列举一下您的成就，虽然这感觉有点多余——你说我不需要任何介绍，我的第一点就是说他不需要任何介绍，所以我还是要给他一个介绍，

**Geoffrey Hinton:** 我们直接开始吧，你的第一个问题是什么？

**主持人:**
当然。我很好奇，就像比尔刚才提到的，你的思考方式发生了怎样的变化？我不是要指责你，只是出于好奇。我要引用一些你在2018年说过的话，部分是因为我感觉现在很多人还在说这些话，而现在你对人工智能的总体看法和潜在风险的态度似乎有很大的不同。我在维基百科上找到了一些你的话，你说“人工通用智能这个词本身就暗示了这种单一的机器人突然会比你更聪明，我不认为会是这样。我认为越来越多我们日常的事务将被AI系统取代，未来的AI将非常了解你可能希望它做什么，但它不会取代你。”这似乎和你现在的说法大不相同，所以我很好奇，你能带我们了解一下这六年来你的思考有何演变吗？

**Geoffrey Hinton:**
那时候，我认为在我们拥有比我们更聪明的东西之前还有很长的时间。我也曾认为，随着我们使事物更像大脑，它们会变得更聪明。然后，在我在谷歌的最后几年里，我试图想办法使用模拟硬件来减少训练这些大型模型和服务更大模型的能量需求。很显然，如果你能使用模拟硬件，并且有一个学习算法能利用模拟电路的所有特殊性能，你可以克服许多模拟的问题。你不需要使两台不同的计算机表现得一样，它们只是学会利用它们拥有的硬件。这使它们有些许的不朽，因为当那个硬件死掉时，它们的权重就没用了。但这也意味着你可以以更低的功率运行。经典的例子是，如果你想将一个向量神经活动乘以一个权重矩阵，以获得下一层的输入，这是一个中心操作，占据了大部分的计算，那么如果你使神经活动成为电压，并且使权重成为导电率，电压乘以导电率就是单位时间的电荷，电荷会自动累加，所以你完成了，你从来没有需要将活动转化为16位数字，然后执行16位平方运算来完成乘法，这非常节能，快速而简单。现在，对于较不线性的事物，要做到这一点比较困难，但问题是你能否使用。当你使用模拟硬件时，能量消耗会大大降低。当我越来越多地思考这一点时，一些问题变得明显起来。其中一个问题是，我们不知道在你不了解系统行为的情况下如何学习。如果你不知道系统如何运作，你就不知道正向传递，所以你不能进行反向传递。人们想出了一些解决办法，比如近似方法，这些近似方法对小规模的东西，比如Mnist，效果很好，但没有人为像ImageNet这样的大型任务创造出一个可行的版本，而不使用反向传播，即便ImageNet现在看起来是小东西，以前它是巨大的挑战。

另一个问题是，我开始意识到数字计算的巨大优势。它耗费大量能源，但你可以拥有同一模型的许多不同副本，这些不同的副本可以去查看不同的数据，并且它们都能从查看的不同数据中学到东西，然后它们可以通过简单的平均梯度来共享它们所学到的东西。这在共享不同副本同一模型的信息方面是巨大的。如果我们能像那样分享信息，10,000人可以去研究10,000个不同的主题，并且在过程中平均他们的权重，你就能同时获得10,000个学位。但实际上并不是这样，我们根本无法很好地传递信息，正如我现在所示范的，我制造句子，你们则弄清楚如何改变你们的权重，使你们能够产生相同的句子，这就是所谓的大学。这个过程非常慢，与共享权重相比简直是蜗牛速度。它们在这方面有着巨大的优势，正因为如此，它们比我们知道的要多得多。以GPT-4为例，我估计它比任何一个人都要了解更多，大约多10000倍。它几乎是每个领域的专家，但不是很好。

它们部分能做到这一点是因为它们可以使用反向传播来获得梯度，部分是因为它们可以在同一模型的许多不同副本之间共享。所以我确信，实际上这只是一种比我们现有的更好的计算形式。它们只需几万亿的连接，具体数字我也说不清，但大概只有几万亿，就可以获得比我们在100万亿连接中得到的知识多几千倍。它们面临的问题是拥有大量经验和少量连接，而反向传播非常擅长在这种情况下压缩信息。我们的问题恰恰相反，经验非常少，连接数却很多，我们可能有一种非常不同的学习算法。那么，我就确信了，让事物变得更像大脑的那个领域或多或少已经结束了，事物将变得更聪明，不是通过使它们更像大脑，而是通过利用我们已经在走的路径，这现在是特定于数字智能的。所以我确信这些事物只是比我们更好。

## 2.从模拟到数字

**主持人:**
那你能再详细说明一下吗？我很好奇，是什么具体的过程改变了你的思考方式？是你和人交流时产生的洞见，还是你在谷歌时的工作经历？是不是在深入研究模拟的优势、特别是这种洞见，你如何才意识到的？

**Geoffrey Hinton:**
是的，我们制造数字计算机，让它们精确执行我们的指令，这样我们就可以编写程序，不同的计算机必须做完全正确的事情，这样你才能对它们进行编程。我们现在不再是在编程它们，而是通过学习算法来让它们执行特定的任务。我们训练它们，一旦训练好，就不必让所有的计算机都以相同的方式工作，因为它们会学习如何利用它们所拥有的硬件。因此，你可以沿着完全不同的路径前进，这就是生物路径，你利用你特有的神经元的奇怪属性，而我的权重对你没用，因为我的神经元和连接性不同。这非常令人兴奋。但当我遇到如何让它学习以及学习算法是什么的困难时，我开始意识到数字计算即使在学习的时候，即使不是直接编程我，也有巨大的优势。这种优势来自于能够分享不同的模型，能够共享。这让我相信这些东西现在更好了。

同时出现的还有像Palm这样的聊天机器人，它们能解释为什么一个笑话是有趣的。这原本是另一个巨大的影响力。**我一直有一个标准，我没有理由去证明这一点，但我的标准是，当这些东西真的变聪明时，它们能解释一个笑话为什么好笑，这对我来说是一个很好的衡量标准，这是我的图灵测试，而Palm能做到。**
它实际上不能制造笑话，你可能已经注意到了，即使是GPT-4也不能制造笑话。因为它一次生成一个词，所以如果你让它讲一个笑话，它开始生成看起来很像笑话开头的东西，你知道，它会说一个牧师和一只章鱼走进了一个酒吧，你知道这是一个笑话的开头。然后它继续这样做，然后到了需要笑点的时候，但就像我的一些朋友，它在尝试讲笑话之前没有想到笑点，这就是一场灾难。所以它有一个非常无力的笑点，但这只是因为它一次生成一个词，它不必这样做。所以它更擅长解释为什么笑话好笑，而不是讲笑话，除非它只是记得它知道的笑话。无论如何，我的标准是它能不能告诉你为什么一个笑话好笑，它能做到。所以这两件事加在一起——与GPT-4玩耍所加强的聊天机器人的能力，以及我最终理解的关于数字比模拟好得多的事情，使我开始认为我的观点可能是，这些东西将会接管一切，可能我们只是智能进化中的一个过渡阶段，就像蜻蜓一样，你知道，蜻蜓是奇妙的生物，如果你看蜻蜓的幼虫，它看起来一点也不像蜻蜓，它是一个巨大的、笨重的东西，生活在水下它从环境中吸收大量能量，然后变成某一种‘汤’，从这种‘汤’中你可以构建出一只蜻蜓，还有熔岩。

**主持人:** 那么，自从你有了关于这个问题的洞见以来，你对这个问题的看法有没有变化？你在过去一年里谈论过这个话题，看法发生了什么变化？

**Geoffrey Hinton:**
我的看法确实有所变化。我对AI安全了解得更多了。之前我对AI安全不是特别感兴趣，而且我可能还不如在场的每一个人懂得多。所以我决定，作为一个76岁的人，我的角色不是从事AI安全的原创研究，而是要反驳一些人散布的信息，他们说这没什么可担心的，这都是科幻。我觉得不，这远非科幻。我能做的一件事是利用我的声誉来说，这确实是一个真实的问题。所以这就是我现在的角色。

## 4.AI知识方面远超人类

**主持人:** 明白了。我们是不是该接受一些观众的问题了？

**观众:**
嗨，我的问题是，您如何看待利用当今AI的未来几代来帮助我们确保AI的安全，进行研究的前景？如果我们在此之前没有取得任何根本性的进展，只是让它们变得更聪明，那会怎样？

**Geoffrey Hinton:**
哦，这感觉就像是在训练狐狸帮助你阻止狐狸吃掉鸡。我已经在使用GPT-4来查询关于AI的规定和安全性，它会告诉我这些规定。依赖AI来帮助你规范AI，这似乎有点危险。如果它们是我们拥有的最好的工具，我们将不得不使用它们，但很明显，让AI帮助你规范AI有些可疑。

**观众:**
是的，您提到了像ChatGPT这样的系统可以通过梯度更新来汇集它们的知识，因此它们能够在连接数远少于我们的情况下知道比我们更多。对我和其他一些人来说，这在某种程度上是一个充满希望的更新，因为这意味着你可以拥有非常知识渊博但并不非常创造性的系统，它们必须在一定水平上保持有用。

**Geoffrey Hinton:**
是的，这确实意味着我们可以拥有非常知识渊博的系统。但是你从中推断出它们可能不是非常创造性。我的意思是，目前看来，它们在知识方面超过了我们，但在创造性方面并没有超过我们。有一天它们在两方面都会超过我们，但如果这是当前的平衡，对人类来说可能是有希望的。在这种情况下，你可以请求它们的帮助，它们可以利用它们无穷的知识提供帮助，同时在创造性尝试逃避我们的监控和对策方面并不擅长。

**我注意到你说“非常有创造力”，因为它们显然已经能够创造了。如果你们参考了标准的创造力测试，你们可能已经阅读过相关文献，而我没有，但我在某处读到，如果进行标准的创造力测试，**
它们的得分如同人类中的90百分位。所以，它们已经在这个意义上具有创造力，它们拥有日常的创造力。问题是它们是否拥有那种构成人类本质的真正创造力。我不明白为什么不会。实际上，如果你考虑到将大量知识压缩进少量连接，唯一的方法就是注意到所有不同领域之间的类比。所以如果你问GPT-4为什么堆肥堆像原子弹，它知道，而大多数人不知道。它理解了，并且我不认为它是在测试时才理解的，我认为它可能在学习时就已经理解了。它知道链式反应，知道堆肥堆越热就越快地产生热量，这就像原子弹一样。它可能已经推断出这一点，在这种情况下它在推理方面做得很好，但我认为它在学习的过程中，为了将所有人类知识压缩到不多的连接中，它正在察觉到人类知识的不同部分之间的相似性，这是没有任何人见过的。所以我认为它具有极高的创造潜力。

**主持人:**
谢谢，但我同意它还没有达到那个地步。我很好奇，如果你和一个对这些问题不太了解的人交谈，他们问你，好吧，我大概理解你说的一些抽象的东西，但具体来说，这一切怎么可能出错呢？通过什么具体的机制，我们可能会受到伤害？我很好奇你会对这样的人说什么。

**Geoffrey Hinton:**
好的，我首先会问，你知道有多少例子是智力较低的事物控制智力较高的事物？我只知道一个例子，那就是婴儿控制母亲。进化投入了巨大的工作量在这上面，母亲无法忍受婴儿哭泣的声音，涉及到各种激素和事物。这是一个男性谈论女性的问题，抱歉。但对于母性来说，涉及到很多激素。整个系统就是这样进化的，几乎总是智力更高的事物控制智力较低的事物。

那么这是一个起点。很难想象一个远比较聪明的东西会被一个远不如它聪明的东西所控制，除非你能找到一些非常不同的理由。然后你开始探索为什么它会非常不同的原因。一个原因可能是它自身没有任何意图或欲望，但一旦你开始赋予它能够创造子目标的能力，它确实有它想要实现的东西。这些可能不像人类意图那样迫切，但它确实有想要实现的东西。我不认为这会阻止它。然后，我认为大多数人——不是我们这些人，但是大多数人——认为我们有主观体验，我们和机器就是不同的，他们非常坚信我们和任何机器都是不同的，这会创造一个障碍。我不这么认为，我认为机器也可以有主观体验。

我给你举一个机器拥有主观体验的例子。一旦你看到了这个例子，你就应该同意机器可以有主观体验。想象一个多模态聊天机器人，对它进行训练，给它安装一个摄像头和一个手臂。你把一个物体放在它面前，然后说“指向那个物体”，它没有问题地指向了物体。然后你在它的镜头前放一个棱镜，再放一个物体在前面，你说“指向那个物体”，它指向了物体。你说“不，物体不在那里，我在你的镜头前放了一个棱镜，你的感知系统在欺骗你。物体实际上直接在你面前。”然后聊天机器人说，“哦，我明白了，棱镜弯曲了光线，所以物体实际上直接在我面前，但我有一种主观体验，它在那边。”我认为它就是在使用主观体验，就像我们使用主观体验的方式一样。

**观众:**
那么，您如何回应那些比如说经济系统具有庞大智力却仍然是我们的工具这样的论点呢？有人可能会说，这就像您说的，一个不那么智能的系统控制一个更智能的系统，因为您误解了它，它是跨人类知识聚合的工具，比如股票市场。

**Geoffrey Hinton:**
你是说股票市场比我们聪明？你可以想象有人会这样论证，我不知道，这似乎与它控制我们相符合，不是吗？我今天早上醒来，看了看我的谷歌，它控制了我。所以，这确实与我们讨论的主观体验问题有关。

## 5.AI系统风险干预

**观众:** 我很好奇你认为随着更多人相信AI拥有主观体验或真正的欲望，或者应当享有权利，这些问题将如何变化？

**Geoffrey Hinton:**
他们会更害怕，因为对大多数人和公众来说，他们认为机器与拥有主观体验的生物之间有一条明显的界线，这些机器不能真正拥有主观体验，它们可能模仿主观体验，但不能真正拥有。我们对主观体验的模型是有一个内部剧场，剧场中的东西是你真正看到的，这个模型就是垃圾。这个模型和“上帝创造了世界”一样愚蠢。简短的跟进，我觉得人们可能会更害怕，但也可能会更有同情心，或认为AI应该享有权利之类的。

是的，我还没有讨论过的一件事，因为我认为它无益，就是讨论AI权利的问题。我也吃动物，我让别人去杀它们，但实际上即使没有我，它们也会被杀。我吃动物，因为对我来说，人类是最重要的。这是一个棘手的问题，但假设它们比我们更聪明，你会站在它们这边还是人类这边？对我来说，这并不明显，如果你认为道德是种族依赖的，那么站在人类这边也并不明显是错误的。所以，如果你想谈论AI安全问题，我认为最好避开这个问题，因为这会让你陷入一系列其他事情中，使你看起来更不靠谱。

**观众:** 我很好奇，您最近对哪些减少AI系统风险的干预措施感兴趣或觉得最有说服力？

**Geoffrey Hinton:**
我希望我能回答这个问题。例如，对于气候变化，我们可以停止燃烧碳或者可能捕捉大量碳，但我认为这是老公司的一种策略，用来分散你的注意力。他们可以继续生产，停止燃烧碳，从长远来看会好的，但这需要一段时间。那里有非常简单的解决方案，都是关于阻止人们做坏事的问题，但我们知道如何解决。在这里我们不知道。相当的做法可能是停止发展AI，我认为这对人类来说可能是一个理性的决定，但我认为他们不会做出这个决定，因为国家之间的竞争和它的许多好的用途。对于原子弹，真的没有那么多好的用途，它们主要是用来炸东西的，尽管美国尽力了。在60年代，他们有一个关于核弹的和平使用的项目，这个项目得到了资助，在科罗拉多用于水力压裂，结果你现在不会想去那里。我知道这个是因为火车靠近那里，附近没有公路，但火车从芝加哥到旧金山经过那里，有一次有个导游在扩音器上宣布，我们现在大约在他们用核弹进行压裂的地方西边30英里。

但这大约是核弹的好用途了，也许还能挖另一个运河什么的。但AI非常不同，大多数用途都是好的，它们赋予人们权力，现在每个人都可以拥有自己的律师，而且成本不高。我不确定这是否有助于法律系统，但对于医疗来说，很快每个人都可以拥有自己的医生，这非常有用，特别是对老年人。这就是为什么它们不会被停止的原因。我们无法避免存在的威胁的唯一方法是停止它，我没有签署要求放慢发展速度的请愿书，因为我认为没有任何机会。

**观众:**
是的，所以我想对你刚才说的进行一点反驳，我想问一个问题。我认为现在世界上有一种不幸的动态，很多人都有这种感觉，可能我们应该放慢速度，但我没有采取任何行动，因为这似乎没有希望。如果每个人都集体觉得我们应该停下来慢下来，我认为这将会发生，每个人都会说这是理性的选择。这包括美国国防部吗？我认为如果每个人都这么做了，如果包括国防部，那么我们就能做到。是的，对，我认为那将会像氟利昂那样。所以我的问题是，你认为你的立场——认为这将会发生，无法阻止，所以我不会采取任何行动——是否帮助我们集体决定停止，还是实际上你对任何集体行动都不感兴趣？

**Geoffrey Hinton:**
不，我很感兴趣。我认为我们应该做任何可能的事情来阻止存在的威胁并减轻所有其他威胁。我认为我们应该尽我们所能，但我认为自己是一名科学家而不是政治家，所以我认为我的角色就是表达我如何看待事物，特别是我想说服怀疑者存在着存在的威胁，这样人们就会认真对待并尝试采取行动，尽管我对他们能否成功相当悲观。

**观众:**
在这个话题上，我很想知道，你特别愿意做些什么来帮助说服怀疑者，普及这些问题？不知道是否有特定的政治家对你说话有帮助，以通过某些特定的立法，或是参与媒体活动，或是支持某些具体事项？

**Geoffrey Hinton:**
好的，我意思是去年我参与了很多媒体活动，因为我认为这会有帮助，也因为我喜欢上电视。我现在正在做的一件事是，有一个纪录片制作人试图制作关于AI历史的纪录片，聚焦于AI历史上的各种人物，可能包括现在已经疯狂的Yan，还有我和其他一些人。纪录片可以产生相当大的影响。所以，如果你是亿万富翁，你可以资助一部纪录片。关于气候变化，Al
Gore的活动产生了重大影响，我们可以称之为AI安全的David Attenborough。我还没那么老，他是我的英雄。谢谢你。

## 6.政策制定者采取行动

**观众:**
那么，关于这个话题，我们之前谈到了一些政策问题，我很好奇，你如何看待自己在提高这些问题的认识和说服怀疑者方面的角色，以及你希望支持这个方向的政策制定者应该采取什么行动，有何希望他们能做的？

**Geoffrey Hinton:**
我认为他们应该制定具有实际效力的规章制度，我认为他们的规定中不应该包含免除军事用途的条款。看看欧洲的规定，抱歉我现在不能开电脑使用GPT-4，所以我不能告诉你行政命令的内容，但我打赌行政命令也说不适用于军事用途。一旦你看到这样的条款，你就知道他们并不是真的认真，他们愿意规范公司，但不愿意规范自己。当你说“有牙齿”时，你是指什么样的“牙齿”？比如，如果你足够明智地说开放源代码与提供权重是非常不同的事情。因为如果你开源训练代码，你仍然需要十亿美元来训练一个巨大的模型。如果你开源权重，你不会获得开源的常规优势，你不能进去看权重说“哦，这个不对”。这就是开源代码的优势，这种情况不会发生。你得到的是犯罪分子可以对其进行微调，用于网络钓鱼，这显然已经发生了，因为去年增长了1200%。所以，我认为非常好的做法是说，开源超过一定大小的权重模型是非法的，如果你这么做了，我们将起诉你。这是我希望看到的规定。

**观众:** 继续追问一下，您提到支持Scott
Leers的S1047法案，还有其他立法努力吗？您经常公开演讲，是否去过华盛顿告诉人们这些，或者您在哪里花时间？

**Geoffrey Hinton:**
不，实际上我不怎么旅行，因为我坐飞机有问题。但是，你看，我年纪大了，我想退休。当我离开谷歌的时候，是因为我想退休，而不是想公开发言。但我觉得这是一个公开发言的机会，所以我就提到了这些东西会杀死我们所有人。然后我有点惊讶，我每两分钟就收到一封邮件。但那并不真正是我的意图。也许我考虑不周。我想这会过去的，然后我可以退休。所以，这仍然是我的意图。人们认为我是AI安全专家，我不是AI安全专家，我只是不相信它们是安全的。

**观众:**
您刚才说您不是AI安全专家，但我不知道现在是否真的有人是安全专家。我们需要在构建比我们更智能的系统之前回答哪些重要问题？如果一个政府来找您，问现在是否足够安全，我们是否真的解决了正确的问题，您会怎么回答？

**Geoffrey Hinton:**
我认为我们需要更多地了解这些东西是否会受到进化的影响。例如，如果你要得到多个不同的超级智能体，如果进化开始发挥作用，我认为我们真的有麻烦了。举个例子，如果有一个超级智能体，我们知道能控制更多数据中心的那个将能更快地训练，学到更多，变得更聪明。所以，如果某个超级智能体说，哪怕只是因为它想变得更聪明，我希望有更多的我这样的副本，你就会看到进化。那个更积极获取自己副本的将会打败其他的，这将是非常糟糕的消息。我希望有某种保证，进化不会开始发挥作用，然后我想知道你们将如何阻止它。你必须赋予它创造子目标的能力，那么问题是，你如何防止它说。一个非常好的子目标是获得更多的控制权，因为这样我就可以做人们希望我做的所有事情，并且做得更好。我曾经对欧盟的一位副总裁说过这件事，他专门负责从谷歌提取资金。这笔钱就在哪儿，对吧？她说，是的，为什么不呢？现在情况是一团糟。

**主持人:** 那么，有没有什么具体的事情会让你感觉问题得到了解决？像，我不知道，这是一个更广泛的问题。

**Geoffrey Hinton:**
是的，有一些事情会让我觉得问题的一部分得到了解决。任何能证明它不会做出某些事情的证据都会很好，但我对获得这样的证据非常悲观，因为它是一个神经网络，它训练后的状态取决于训练数据的性质。所以你不能仅仅通过查看网络的架构和训练算法来判断它的状态，你需要了解大量的训练数据才能知道会发生什么。如果有任何证明它是安全的证据，那将是很好的，但我认为我们永远不会得到那样的证据。

如果你能以某种方式理解它从来没有自我，从来不想有更多的自我副本，它非常乐意像一个非常智能的行政助理为一个非常笨拙的CEO服务，并且在这个角色中感到非常满意，那将是我们想要的，对吧？这里有一个好的情景，即我们都可以拥有比我们聪明得多的AI助理，我们可以闲逛，讲笑话。但我看不出你如何能证明它永远不会想要接管。

至于权力集中的问题，如果有人来找你说，如果你反对权力集中，那么为什么你反对开源呢？我确实反对开源，这是一个很好的观点，因为它似乎与权力集中相悖，但现在它正在与所有网络犯罪分子分享权力，这是问题所在。如果你开源权重，微调它非常容易，你可能只需10万美元就能完成微调，而原本可能需要花费十亿美元来训练。所以，网络犯罪分子现在可以用它做各种事情，这使得当前最大的障碍——训练需要很长时间——被消除了。

至于假设AI发展的轨迹继续如同至今那样，没有在安全技术上的巨大转变，我们进行风险评估、红队演练等，我对这种情况持怀疑态度。

## 7，当前AI风险评估（RHF）存在漏洞

**观众:** 至于那些系统可能不会真正关心我们的最佳利益，或者说“末日概率（P Doom）”，你想知道我的末日概率吗？

**Geoffrey Hinton:**
我认为可能性相当高。我认为风险评估（RHF）是一堆废物。你设计了一个包含无数错误的庞大软件系统，然后你说，我要做的就是逐一堵住漏洞，像堵住堤坝的洞一样，但我们知道这不是设计软件的方式。你应该设计它以便有某种保证。

假设你有一辆车，车上到处是小洞和锈迹，你想卖掉它。你会做什么？你可能会给它刷漆。这就是风险评估的作用，它像是给车辆刷漆，而不是真正修复它。因为它只是刷漆，很容易被撤销。我认为令人惊讶的是，你不需要很多示例就能使行为看起来有很大不同。但这只是刷漆，如果你有一辆锈迹斑斑的旧车，刷漆不是修复它的方式。

**观众:** 至于人们对这些AI系统的风险评估有很大不同，我想知道你是否有看法或想法，比如哪种知识、实证数据或演示可能有助于就风险达成共识。

**Geoffrey Hinton:**
好吧，让我试着回答你说的小部分内容。人们对风险的估计差异很大，什么样的实证数据可能改变这种情况，对吗？首先，有些人像Yan那样认为风险几乎为零，有些人像Yosi那样认为风险接近99.999%，这两种观点在我看来都完全疯狂。单独来看就很疯狂，但考虑到如果有一大群专家，除非你认为自己比其他人聪明很多，如果你认为风险是零，而别人认为是10%，你至少也应该认为是1%。我的意思是我实际上认为存在的威胁的风险超过50%，但我不这样说，因为其他人认为风险较低。考虑到我所知道的每个人的意见，一个看似合理的估计是10%到20%。我们仍然有很好的生存机会，但我们最好认真考虑如何做到这一点。我认为我们最终会做的是，在它们变得比我们更聪明之前，我们会得到一些智能通用但不如我们的东西，我们将能够对它们进行实验，看看会发生什么，看看它们是否会试图取得控制，看看它们是否开始进化。在我们仍然能够控制它们的情况下，这将是一个非常激动人心的时刻，但只是勉强能控制。

**主持人:**
我自己也有个问题。基于你到目前为止在对话中的发言，人们可能会对你表现出的悲观态度感到惊讶，你似乎认为风险非常高。但你又说99.999%的概率是疯狂的，我很好奇你是如何区分这些的。你说了很多人在担忧的方向上出错，如果你要对那些担心的人说些什么，你会说什么？

**Geoffrey Hinton:**
我自问自答，我倾向于有些抑郁，所以我认为我们根本没什么头绪，50%是一个不错的数字，但其他人认为我们有一些头绪，所以我把这个数字调整到10%到20%。我们构建了非常强大的AI，如果它们想要的话，可以接管一切。

**观众:** 你对去年的猜测是怎样的？还有，你认为在这类参考群体中人们的信念分布是怎样的？这会是人们在提前两年就已经认真对待的问题吗？

**Geoffrey Hinton:**
很可能不够认真。但我认为许多人实际上是认真对待的，只是还不够。我认为必须发生重大灾难才会被真正认真对待。你可以想象某种恶意AI试图接管，导致电网和水系统瘫痪，但实际上没有成功。那将使人们认真对待这个问题。

**主持人:** 好的，非常感谢你的分享和讨论。

* * *

# 往期回顾

[1、[对话节目：AI之父Geoffrey
Hinton为什么坚信模型越大，AI越能够像人一样更有创造力？]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAgO9a1Iy1RfY4PLSo0jGAmyUGOF7ugwvNbyYdMKrSeAFUTY27s5H52S1GIaTiaAz6cVGq4jlI7OwRQ/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247490393&idx=1&sn=1f326befbceb9f158ed0a0af4b2500f8&chksm=c00ba9bcf77c20aacd95c53dac49ddb0766d6ac03c00d394a228d32d496d2ed6e8831eb468b8&scene=21#wechat_redirect)

[2、[AI发展脉络：李飞飞教授在2024年数据峰会上详述人工智能的过去和未来]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAgO9a1Iy1RfY4PLSo0jGAmy9mZnEs87TAibAWqatJXagfovmgxTefNbHda2Fus8JlBjQiciaoylEzQFQ/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247491224&idx=1&sn=01dfb7d71cd364401e4f447820366e9d&chksm=c00bac7df77c256b1cf39b4917b261c410741320e0374b25096788a68eb1043c80b23c3c7bbd&scene=21#wechat_redirect)

[3、[加州大学伯克利教授斯图尔特·罗素演讲：如果我们实现了这一AGI目标，社会将会发生什么样变化]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAgO9a1Iy1RfY4PLSo0jGAmyRRPmO45BeCXbO0sboAZ4BbwQrH3ldEq2MibpHibticbSY3DJj0qzVuMGg/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247491513&idx=3&sn=98a45a83acae1d9e390092621636208b&chksm=c00bad5cf77c244a0e0b228d24c5ff4930cf8130981f0bf2f80f8e3cb267a357e2fc62657395&scene=21#wechat_redirect)

* * *

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhtRhTOjz2QwH4dIlC3YUcYbaicMEwjqQqh06Yhdd7EH3r9wiaMRArLz0a6Zhx6uiaUD7hguPfbY0nAg/640?wx_fmt=png&from=appmsg)

****

**我们的AI团队现向外界开放服务，旨在助力每个企业与个人引领时代潮流，将先进科技与创新想法完美融合!**

##  告别昂贵服务费和缺人烦恼,再见漫长交付周期

## 无限创意风格,分分钟生成专业级作品

## 感受 AI 带来的全新工作体验！

_**欢迎各大品牌方、媒体、科技企业、知名IP等合作**_

 _**合作请联系负责人微信：Milo-1101**_

 _**\--END--**_

