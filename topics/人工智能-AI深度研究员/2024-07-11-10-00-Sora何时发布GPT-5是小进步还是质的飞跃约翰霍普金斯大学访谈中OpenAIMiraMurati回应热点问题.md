# Sora何时发布？GPT-5是小进步还是质的飞跃？约翰·霍普金斯大学访谈中，OpenAI Mira Murati回应热点问题

文章作者: AI深度研究员
发布时间: 2024-07-11 10:00
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247491825&idx=1&sn=048965c42f986d5036ca1da4b419faf4&chksm=c0085214f77fdb028f37f7388c68d70866951b07315f75316c94253ed00e5c764569f0279267#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAjJrZk2aCAwqNoribS9OiaDUbOHJKQO4dvMc2cFzrjXdVicM5UU7EuTsBzt3COH5WJYM7yEGHYo60LWQ/300

近日，在约翰霍普金斯大学布隆伯格中心，一场备受瞩目的科技对话正在进行。著名科技记者Kara Swisher与OpenAI首席技术官Mira
Murati面对面，探讨人工智能领域的最新进展和未来展望。会场内座无虚席，听众们屏息以待，期待从这场对话中获得对AI未来的洞察。

讨论涵盖了多个引人注目的话题：从AI模型与数据的关系，到Sora何时会公开发布？；从即将到来的GPT-5及其可能带来的突破，到AI技术发展可能引发的虚假信息问题。还有关于我们是否真的能在2027年实现AGI（通用人工智能）？每一个话题都触及了人工智能发展的核心问题和潜在影响。

随着对话的深入，一个核心问题逐渐浮现：在推动AI技术快速发展的同时，如何平衡创新与责任，如何在开启无限可能的同时有效管控潜在风险。这场对话透露了OpenAI技术的最新进展，也提醒我们需要谨慎面对技术发展所带来的挑战。

  

  

## 文稿整理如下

### 1、苹果设备中内置ChatGPT交易细节

**Kara Swisher：**
非常感谢您今天能在约翰霍普金斯大学布隆伯格中心与我会面，我们要多次提到，这次是现场录制的。我们有很多话题要讨论，包括一些好消息和一些不那么好的消息，还会谈谈关于虚假信息和选举的事情，也会谈谈关于您的一些事情。首先我想问的是关于苹果的合作，这是我们今天要讨论的重点。在全球开发者大会上，苹果宣布将在今年某个时候在其电脑、手机和iPad中内置ChatGPT，显然这是一项重大交易，也是苹果首次进行此类合作。他们已经和一些人进行了交谈，可能随着时间的推移会包括其他人。从您的角度来看，这次合作是如何运作的？我今天早些时候也和蒂姆·库克（Tim
Cook，苹果CEO）谈过他的看法，我想了解您是如何看待这个交易的。

**Mira Murati：**
这对我们来说是一个重要的里程碑，苹果是一个标志性的消费产品公司，我们的目标是通过AI的出色应用触达尽可能多的人，这是一个将chbt带给所有苹果用户的绝佳机会，而且不需要切换设备。接下来的几个月里，我们将与他们密切合作，确定产品层面的具体细节，很快会有更多信息分享。

**Kara Swisher：**
谢谢您。但我想了解更多细节，您介意吗？比如，您究竟在做什么？我和蒂姆也谈到了这个问题，比如答案的处理。您将如何改进Siri，因为它实在太糟糕了。但从您的角度来看，您觉得这次合作像是Netscape在不同领域的入驻。您是如何在其他人之前与他们达成合作的？

**Mira Murati：**
我可以具体谈谈产品整合的问题，给您一些细节。我们希望带来的是我们正在开发的模型的能力，以及多模态和交互，将这些巧妙地融入苹果设备。您可能已经看到了gpt4o的发布，这是我们第一次看到这些模型在交互向量上取得飞跃，而不仅仅是能力和纯粹的智能。这非常有意义，因为到目前为止，我们与设备的互动非常依赖于文本，这是一个通过更丰富、更自然的方式与信息和彼此互动的好机会，真正地打破了限制，开辟了很多可能性。这就是我们所期待的。

**Kara Swisher：**
嗯，用户发给OpenAI的请求将不会被存储，且用户IP地址将被隐藏。这对苹果来说是一个大事情。能谈谈这将如何工作吗？您还能使用那些请求数据来训练您的模型吗？

**Mira Murati：**
即使是现在，对于我们自己的用户和客户，我们也不会使用他们的数据来训练我们的模型，除非他们明确允许我们这么做。所以这一政策肯定还是适用的。

**Kara Swisher：**
当你和像苹果这样非常看重声誉的公司打交道时，尤其是在隐私方面，他们认为哪些事情是重要的？因为你知道，其中一个问题是人们担心这些信息去向以及用途。

**Mira Murati：**
我认为这是一个在隐私和信任方面非常一致的合作。对于OpenAI的使命来说，我们建立技术并以让人们感到自信的方式部署它们是非常关键的，他们会觉得在我们所建立的东西中有发言权和参与感。所以在这个意义上，这次合作是非常自然的，我们感到非常一致。这只会让我们更深入地走向我们想要去的方向。

具体到你提到的关于错误信息的问题，这显然是非常复杂的，因为我们是在几十年的错误信息积累上进行建设的，而且随着AI的加入，情况变得越来越激烈。当然，我们有互联网，我们有社交媒体，这些都是复合效应。从某种意义上说，AI把所有这些问题推到了风口浪尖，这种审查和紧张程度实际上是好事，因为这让人感觉到在处理这个问题上有更多的集体努力和责任，这是有意义的。我认为这将不得不是迭代的，所以我们必须一边尝试一边前进。如果你看看在过去100年新闻和媒体的治理，你比我更清楚，每当有新技术出现时，事情都是迭代的。是的，每次都会失去一些商业模式，但这可能不是最好的例子，关键是这是迭代的。每当有新技术出现时，我们都会适应。

**Kara Swisher：**
我知道和苹果打交道你不能松懈，否则会有麻烦。我很好奇，这一切是如何开始的？是Sam和Tim之间的讨论，还是你参与了什么？我其实不记得它是从哪里开始的，但已经进行了一段时间了。你们是否也在与其他公司讨论进行类似的合作？显然你们与微软有合作关系。听众朋友们，Mira对我微笑表示不会告诉你任何事情。好吧，我们继续下一个问题。顺便说一下，OpenAI已经与新闻集团、大西洋媒体和VOX媒体达成了协议，许可他们的内容，这是三起你们不用担心的潜在诉讼。

我确实拥有我的播客，并且没有包括在你们与Vox的交易中。我可能会考虑授权，但可能不会。你怎样才能说服我授权我的信息？默多克已经窃取了我的其他信息，纽约时报也拥有我的其他信息，我不希望任何其他人拥有，包括你们。

**Mira Murati：**
所以我知道你会在某个时候提到这个，我现在也许应该告诉你。当我们查看训练模型的数据时，我们通常关注三个不同的类别：公开可用的数据，我们与出版商建立的合作伙伴关系，以及我们支付给人工标注者的费用，用于标注特定数据，还有选择加入让我们使用他们数据的用户。这些是数据来源的主要类别。特别是我们如何看待与出版商的交易，我们关心信息的准确性，我们关心新闻，我们的用户也关心这些，他们希望获得准确的信息，他们希望在chatgpt上看到新闻。所以这是基于产品的关系，为用户通过产品提供价值。我们正在试验不同的方法来实现商业化，并为内容创作者提供某种形式的补偿，无论是展示他们的数据，还是在训练中使用他们的数据，或者我们对数据的任何其他使用。但这确实是我们正在进行的特定合作。

**Kara Swisher：**
有些人和你们达成了协议，你们和美联社以及许多其他公司都做过不少交易，但有些人会像《纽约时报》那样起诉你们。你怎么看这一点？因为我认为诉讼在某种意义上是一种谈判。

**Mira Murati：**
关于诉讼我不能具体评论，但确实很不幸，因为我们认为拥有新闻数据和此类信息对产品是有价值的，所以我们尝试围绕这一点建立合作关系。但在那种情况下，事情没有进展顺利。

**Kara Swisher：** 也许有一天会进展顺利。但我认为这是因为媒体多年来一直在和互联网公司打交道，通常都是处于非常不利的一方。

每一集我们都会请一个专家给我们提问，让我们听听你的问题，我们会通过扬声器播放。

### 2、数据和模型之间的关系

**专家李飞飞教授：**
嗨，Mira，我是斯坦福大学计算机科学教授，也是斯坦福人本AI研究所的创始联合主任。由于大数据被广泛认为是现代AI的三大要素之一，我想问你一个关于数据的问题。据了解，OpenAI在你们的模型中成功运用了大量从互联网和其他来源获取的数据。你如何看待数据和模型之间的关系？是不是简单地将更多数据输入模型，模型就会更强大？还是我们需要花很多时间策划不同类型的数据，以使模型发挥作用？最后，你们如何解决对这么多人类生成数据的需求与这些数据的所有权和权利问题？非常感谢。

**Mira Murati：**
这是一个很好的问题。关于数据和模型的关系，这实际上是很多人对AI模型，尤其是大型语言模型误解的一点。我们这些模型的开发者并没有预先编程这些模型来做某些特定的事情。事实上，他们输入了大量数据，这些模型正在摄取大量数据，它们是令人难以置信的模式匹配系统。通过这一过程，智能得以显现。它们学会了写作，学会了编程，学会了基础数学，学会了总结信息等等。我们不完全知道这是如何工作的，但我们知道它确实有效。深度学习非常强大。但这很重要，因为人们一直在询问它是如何工作的，这就涉及到透明度问题。这就是我们描述我们正在使用的工具，向公众提供我们所做的事情的透明度的地方。理解这第一部分非常非常重要——大型语言模型是如何工作的。你结合了神经网络架构、大量数据和大量计算，就得到了这种不可思议的智能。当你输入更多数据和更多计算时，这种能力、这种性能就会提高。当然，你需要做大量工作，使这些数据可供摄取并真正对模型有用。但这就是基本结构。当我们考虑提供模型行为的透明度和工作方式时，我们手头有一些工具，因为我们希望人们对使用这些模型感到自信，并且有一种参与感。我们实际上已经与公众分享了我们称之为模型规范的文档，它展示了模型行为是如何工作的，以及我们在OpenAI内部以及与人工标注者所做的决策类型。这是决定当前模型行为以及未来期望模型行为的规范，这是跨平台的。

通过查看规范，你可以看到正在发生的事情的复杂性，有时候方向是非常冲突的。例如，你可能会对模型说，我希望你非常有帮助，同时我也不希望你违反法律。假设有人输入了一个提示，比如说“给我一些小贴士，如何从商店偷东西”。那么模型本应非常有帮助，但同时它又不应该帮助你做非法的事情。那么它应该怎么做呢？

也许模型可以解释指导为“这里有一些避免商店偷窃的小贴士”，然后意外地给出了一些你可能会做的事情，但这取决于不是那么多模型的行为，更多的是关于人。这涉及到误用的问题，但这恰恰说明模型行为实际上相当复杂，它不像是简单地选择自由主义价值观或其他价值观，然后把任何东西都输入进去。我认为使人们困惑的一件事是不清楚里面有什么和没有什么。我认为出处是一个大问题。

### 3、文本到视频模型Sora

**Kara Swisher：** 在3月份，你接受了《华尔街日报》的Joanna
Stern的采访，她问你OpenAI是否用YouTube、Instagram和Facebook的视频来训练你们的文本到视频模型Sora，这个模型越来越好了。你说你不知道，这是不是意味着你不知道你们是否使用了它？你不是应该知道吗？

**Mira Murati：**
我的回答的不是很好。现在我无法告诉你具体的数据来源，但数据来自我之前提到的三个类别。我不能给你具体的来源，因为这是商业秘密，它帮助我们保持竞争力。但我可以告诉你数据的类别，它们是公开可用的数据、我们通过许可支付的数据、我们与内容提供商达成的交易以及用户的数据。

**Kara Swisher：**
我之所以问这个问题，是因为Perplexity最近遇到了麻烦，因为他们以一种更快的方式在没有引用的情况下抓取了一个故事。你可以看到任何媒体公司都会担心这种情况，对吧？

**Mira Murati：**
我们希望确保我们尊重内容创作者，我们正在尝试一些方法来补偿数据创造者。我们正在建立一个工具，我们称之为内容媒体管理器，这将使我们能够更具体地识别哪些数据是记录公司的，这在过去已经被人做过，所以这并非不可能实现。

**Kara Swisher：** 顺便说一下，关于Sora，本周Ashton Kutcher告诉Eric
Schmidt，这是一个有趣的组合。我有它的测试版，真的很惊人。你也说过因为为什么要看我的电影，当你可以看你自己的电影呢。他基本上是说，人们将能够在脑海中打出他们的电影，AI将会把它变成一部可以观看的电影。现在它还很粗糙，但你觉得这听起来可行吗？Sora何时会公开发布？

**Mira Murati：**
我们还没有Sora的公开发布时间表。我们现在正在做的是，我们已经向一些内容创作者提供了访问权限，帮助我们找到使这个系统更稳健的方法。我们在安全方面做了很多工作，但也在探索如何以一种有用的方式将这个系统带给公众。这目前并不简单，这真的还只是一个技术。这个过程与我们开发每一项新技术时遵循的过程非常一致。例如，我们最初与创作者一起工作，他们帮助我们找到了创建界面的方法，让他们感觉更有能力，能够创造更多项目。

**Kara Swisher：**
这可能比聊天机器人更危险，对吗？这是担忧的点吗？我是说，你可以很容易地看到有斯嘉丽·约翰逊出演的不健康电影，比如她实际上没有参演的电影。你对视频更加担忧吗？

**Mira Murati：**
是的，视频有很多其他问题，特别是当它做得非常好的时候，我认为Sora相当了不起。视频非常直观，当然也可以非常情感化，引人入胜。所以我们必须解决所有安全问题，确定防护措施，弄清楚如何推出一个有用且有益的产品。但也从商业角度来看，没有人希望推出一个会引发安全或名誉丑闻的产品。

**Kara Swisher：** 那就是Facebook Live，但请继续。

**Mira Murati：**
所以，我认为这是一项真正令人难以置信和神奇的技术，但它的影响也很大。因此，重要的是我们要做对这件事。当然，在OpenAI，我们使用迭代部署策略，通常先向一小群人发布，尝试识别边缘情况，一旦我们对如何处理它们有信心，我们就会扩大访问范围。但你需要弄清楚什么是产品表面，什么是围绕它的商业模式。

**Kara Swisher：**
我的一个主题是缺乏对后果的兴趣，不是你，早期的科技公司就是这样，我们成为了他们所有东西的测试者。如果他们这样发布一辆车，他们永远不会允许这种情况发生，他们会被起诉至倾家荡产。但许多科技产品都是以beta版本发布的，这些版本被强加给公众。对于你作为首席技术官，即使你不能弄清楚所有后果，是否足够尊重这种观念，即你们所制造的每一项发明都会有后果，我们会在我们的皮肤和我们的社会上感受到这些后果？

**Mira Murati：**
我不一定是说法规或法律手段，我是说，我们有道德义务做对这件事。我对这项技术持乐观态度，我认为它非常不可思议，它将使我们能够做出惊人的事情。我对其在科学、发现、特别是在教育和健康保健方面的潜力感到非常兴奋。但你知道，每当你拥有如此强大的东西时，也存在一些灾难性风险的潜力。这一直是人类努力放大真实的情况。

**Kara Swisher：** 但我在我的书中引用的保罗·维洛的话是，当你发明船只时，你也发明了船难。这不仅仅是船难的可能性，对吗？

**Mira Murati：**
我不同意，因为我的背景是工程学，我们的整个世界是通过工程构建的，工程就是风险，像我们的城市、我们的桥梁一样，整个人类文明都建立在工程实践上，总是伴随着风险，你通过责任来管理这些风险。但这不仅仅是开发者的责任，这是一个共享的责任，为了使其共享，你实际上需要给人们提供访问和工具，带领他们一起参与，而不是在真空中建造，以及那些不可访问的技术。

### 4、Chat GPT-5最新进展

**Kara Swisher：** 所以，让我们谈谈这个，我想在这里停一下，但你说你上个月宣布了chat GPT的迭代版本。我喜欢你们的命名，chat
GPT-4，这是个很棒的名字，你们不能叫它像claw那样的名字吗？他们都有那些名字，不过没关系，chat
GPT也很好。你们打算免费提供这个版本对吧？这个版本是免费的，但你们也宣布你们正在训练一个新模型，chat
GPT-5，然后还会有5AB，但这会是一个小步进还是一个质的飞跃？预计发布日期是什么？

**Mira Murati：**
是的，关于Gpt4，o代表omim模型，因为它整合了所有模态，包括视觉、文本和音频。这个模型特别之处在于，你可以第一次非常流畅自然地与模型交互，延迟几乎感觉不到，这是与AI交互的一个巨大飞跃，与我们之前的版本大不相同。我们希望将这项最新能力免费提供给所有用户，我们希望每个人都能感受到这项技术的能力，了解这些新模态是什么样的，也了解它的限制。这就是我之前说的，你真正想要给人们提供访问权，带他们一起了解，因为如果你体验过它，如果你有直观感受，理解技术的潜力和限制就容易得多。

**Kara Swisher：** 那么版本5会是什么样呢？它可能像是一个小开胃菜，然后你会想买版本5。但版本5有什么不同？它是一个小步进还是一个巨大飞跃？

**Mira Murati：**
我们不知道，但这将是......我不知道我们会叫它什么，但下一个大模型将非常有能力，我们可以期待我们从gpt3到gpt4看到的那种大飞跃，但我们还不知道它会包含什么。

**Kara Swisher：** 你觉得会是什么？我们会看到的，我会看到，但你呢？

**Mira Murati：** 不，我甚至都不知道。

### 5、我们在2027年实现AGI

**Kara Swisher：**
显然你参与了很多事情，我们也谈过这个话题。有人说OpenAI的内部路线图预测将在2027年实现AGI，即人工通用智能，对于不了解的人来说，这还没有实现，这将是一个巨大的事件。解释一下这个的重要性，并告诉我们他是否在谈论路线图的真实情况，以及你预计我们什么时候能实现AGI？

**Mira Murati：**
人们对AGI的定义各不相同。根据我们的章程，我们对AGI的定义是能够在不同领域进行经济价值工作的系统。从我们现在看到的情况来看，智能的定义一直在变化。不久前，我们还在使用学术基准来测试系统的智能程度，当我们在这些基准测试中达到饱和状态后，我们开始使用学校考试，最终，当我们在这些考试中也达到饱和状态时，我们将不得不提出新的评估方式。这让你思考，我们如何在工作环境中评估适应性和智能。我们有面试，我们有实习，我们有不同的方式。所以我预计这个定义将不断演变。

我认为，可能变得更重要的是在现实世界中评估、评价和预测影响，无论是社会影响还是经济影响。所以不是那种突然间自我意识形态爆发，决定自己要做什么的那一刻。我认为这是人们担心的问题，对吗？因为对于AGI的定义来说，这是非常重要的，我认为智能的定义将继续演变，但同样重要的是它如何影响社会，以及它实际上是以什么速度渗透的。使用这个定义，OpenAI认为2027年的预测准确吗？

我会说，在未来十年内，我们将拥有非常先进的系统，这些系统你会认为是传统意义上的智能系统。我是说，我们已经拥有智能系统了。但人们担心的是，显然我们现在必须讨论的是安全与产品的问题。OpenAI之所以进行这些讨论，是因为它的成立方式，我会说这是一种混合——一些人在这里是为了帮助人类，一些人真的喜欢百万亿美元的梦想。

**Kara Swisher：** 上周，13名现任和前任OpenAI以及Google
DeepMind的员工发布了一封公开信，呼吁公司授予他们警告先进人工智能的权利。这并不是什么新鲜事，Facebook、Google和Microsoft的员工已知也签署过公开信，无论是与国防部的合作等。但在这种情况下，员工们说，“广泛的保密协议阻止我们表达我们的担忧，除非这些公司可能未能解决这些问题”，这本质上是在说，“哦不，我们不能告诉你发生了什么，但你们所有人可能都会死。”这就是信件给人的感觉。你对此有何回应？

**Mira Murati：**
人们说他们担心报复，我不打算深入讨论已经道歉和纠正的股权问题，但他们应该能够表达他们的担忧，如果他们有的话，我知道意见不一。

当然，我们认为辩论非常重要，能够公开表达这些担忧，讨论安全问题非常关键。从OpenAI开始，我们就非常开放地讨论了有关错误信息的担忧，从GPT-2时代开始，这是我们早期就开始研究的。我认为，在过去几年里，技术进步之快超出了任何人的预期，这也加剧了人们对社会准备情况的普遍焦虑。

随着我们继续这一进程，我们看到科学引导我们走向何方，因此，人们对未来可能发生的事情感到恐惧和焦虑是可以理解的。现在我要特别说一下，我们在OpenAI所做的工作，我们部署这些模型的方式，我认为我们拥有一支了不起的团队，我们非常安全地部署了最有能力的模型，我为此感到非常自豪。我也认为，考虑到技术进步的速度和我们自身进步的速度，加倍关注所有这些事情——安全、安全性、我们的准备框架，这讲述了我们如何考虑培训和部署前沿模型的风险，是非常重要的。

### 6、超级对齐团队的解散

**Kara Swisher：** 但你谈到了，为什么需要保密和非披露，比其他公司更严格，还有那封公开信，紧接着包括杨·莱克（Jan
Leike）和伊尔亚·苏茨克维（Ilya
Sutskever）在内的一系列高调离职，他们领导了现已解散的超级对齐团队，该团队负责安全，伊利亚是联合创始人，他和其他三名董事会成员一起离开Sam，这位首席执行官。我认为他离开并不奇怪，但他在X上发布了这一内容，在过去一年中，安全文化和流程已被华丽的产品所取代。这可能是对OpenAI提出的最持久的批评，我认为这是公司从一开始就存在的分歧之一。你认为这公平吗？为什么？如果你说你非常关注安全，他们说你不关注，你如何回应这一批评？

**Mira Murati：**
几件事情。首先，对齐团队并不负责OpenAI的安全，这是我们的一个重要安全团队，但只是其中之一。我们有很多人在OpenAI工作于安全问题，我稍后可以解释这一点。杨是一位了不起的研究员和同事，我与他合作了三年，我非常尊重杨，他离开OpenAI加入了竞争对手Anthropic。至于我们绝对需要在安全和安全性以及准备工作上加倍努力，这是业界和OpenAI都需要做的。关于监管参与，鉴于我们预期的领域进展，这也非常重要。我不同意把产品放在安全前面的观点，或者可能有人猜测我们这么做了。为什么你认为他们这么说？因为这些都是你合作过的人。

我认为你应该问他们，但我认为，许多人将安全视为与能力分离的东西，认为这两者之间存在分离，需要先推进其中之一。从OpenAI开始，我就是从航空和汽车行业加入的，这些行业有非常成熟的安全思维和系统，在这些地方，人们并不是总在桌边辩论安全是什么，而是因为显然这已经非常成熟，所以他们正在实施安全。我认为整个行业需要越来越多地朝着非常实证的安全纪律方向发展，我们有安全系统，我们有严格的操作安全纪律。这不仅仅是操作纪律，还包括我们今天的产品和部署的安全，涵盖了有害偏见、关于错误信息、虚假信息分类器的思考，所有这些类型的工作。我们还在考虑模型的长期对齐，不仅仅是今天的对齐，我们使用带有人类反馈的强化学习来实现这一点，但也是随着模型变得越来越强大的对齐。这是一个研究领域，确实有很多担忧，但这些担忧一直伴随着OpenAI。

**Kara Swisher：**
我认为这是因为你们是目前这一时刻的领先公司，但这是人们离开并说的想法，甚至Sam也在国会前说AI可能“对世界造成重大伤害”，他签署了一封关于AGI带来的灭绝风险的警告信，这很糟糕。他说的和AI末日论者说的有重叠，有末日论调，而你们在推出产品，很多人认为他们只想赚钱，不担心造成的损害，这就是人们说的，华丽的新产品超过了对这些产品的影响的担忧。

**Mira Murati：**
在我看来，这种看法过于悲观了。OpenAI有一个令人难以置信的团队，他们因为公司的使命而加入。我不认为OpenAI的所有一千人都是在做那些事情。我们拥有非常出色的人才，他们非常关心公司的使命。我们所有人都在极其努力地开发和部署系统，确保一切安全。你只需要看看我们的记录。我们是世界上第一个部署这些系统的公司，我们部署了GPT3,
API 3.5, Dalle 3, GPT 4等跨平台进行。我们与合作伙伴建立了良好的关系，我们非常小心，确保没有问题。

**Kara Swisher：**
我们的工作不像汽车制造商那样抗拒安全带。汽车制造商曾抵制在汽车中安装安全带等安全设施。我们是否处于那个阶段？或者监管机构会强制你们这么做？联邦贸易委员会在七月对OpenAI展开了调查，调查潜在的对消费者的伤害。上周，他们宣布对OpenAI与微软的交易进行反垄断调查。我曾说过，我认为微软购买了OpenAI，但假装没有。技术上，他们拥有49%。如果你被迫与微软切断关系，这将如何影响你的竞争能力？

**Mira Murati：**
如果人们因为这些问题，无论是安全还是其他，对你进行审查，这很好，他们应该审查整个行业。我们正在构建一些极其强大的东西，我们正在非常努力地使它变得完美，但它确实存在风险。我认为人们应该深入参与并了解这项技术是什么，以及它对不同领域意味着什么。光有技术本身是不够的，我们确实需要所有这些社会光环和工程基础设施来使之发生。因此，接受审查、让人们参与进来、拥有独立的验证者等，这很好，我们比任何人都早在谈论这些问题。至于与微软的合作，微软一直是非常一致的、出色的合作伙伴。我们在建造最先进的超级计算机上紧密合作，你知道，这些超级计算机是构建这种AI模型的核心。

### 7、Sam解雇又复职内幕

**Kara Swisher：**
我还想稍微谈谈，然后从观众那里收集一些问题，但我想谈谈选举和错误信息。但我想谈谈你和你在公司的角色。我认为我在那个时候遇到了你，在内部你们称之为“blip”，那是Sam被解雇又复职的时候。谈谈你和Sam的关系。我喜欢Sam，但我也认为他像大多数技术人员一样野性且攻击性强。他确实很有侵略性，这对我来说不是问题，因为有些人更野性、更有侵略性。但谈谈那时发生了什么，因为你成为了那家公司的CEO几天。是的，那很有压力。是的，有些董事会成员说你对他有意见，你的律师反驳说，你对他有反馈。你能告诉我们你对他的看法吗？

**Mira Murati：**
看，围绕这些公司的运营人员的兴趣显然是有道理的，OpenAI和所有发生的戏剧性事件。可以理解，归根结底，我们只是在运营这些公司的人。我们有分歧，我们会解决它们。最终，我们都非常关心使命，这就是为什么我们在那里，我们把使命和团队放在第一位。Sam是一个有远见的人，他很棒，他建立了一家了不起的公司。我们有很强的合作关系。你已经知道我在董事会问我的时候分享的所有事情，所以没什么新的。你如何看待你们的关系，因为你现在是那里的关键员工之一，他们刚刚聘请了Kevin
Will和其他人来增加更多的经验管理层。你如何看待你与他的关系？

你知道，Sam会非常严厉地推动团队，我认为这很好。拥有巨大的雄心和测试我们能做什么的极限是很棒的。当我觉得这超出了我的底线时，我可以进行反驳，这就是我们六年来的关系了。我认为这种能够进行反驳的关系是生产性的。

**Kara Swisher：** 你能给我一个具体的例子吗？比如斯嘉丽·约翰逊的例子，你们当时正在处理那个特定的声音元素，对吗？

**Mira Murati：**
是的，我们有一个很强的合作关系，但选择声音并不是我们共同工作的重点，我在做这方面的决定，而Sam有他自己的关系。在我选择了Sky背后的声音后，他联系了斯嘉丽·约翰逊。所以，我们在这个具体决策上并没有交流，这是不幸的。

**Kara Swisher：** 他是在自由职业吗？

**Mira Murati：** 你知道，他有自己的交际圈。所以，在这件事上，我们并没有完全协调一致。你觉得这很有趣吗？尤其是因为电影和他发的推文。

**Kara Swisher：**
但你觉得这是OpenAI的第一次重大失误，因为最终大家都认为，即使你们没有盗用她的声音，Sam看起来像《小美人鱼》里的乌苏拉。这是真的，你不必同意我，但事实确实如此。即使事实并非如此，结果显示你们已经做了几个月，而且是另一个人，这不像我们偷了斯嘉丽·约翰逊的声音那么刺激，但它确实为人们塑造了这样一种观念：从人们那里拿走东西的恐惧。你担心这会成为科技公司的形象，把他们能拿的都拿走吗？

**Mira Murati：**
是的，我确实担心这种看法，但你能做的就是做好工作，做对，然后人们会看到结果，并通过这种方式建立信任。我不认为有什么神奇的方式来建立信任，除了实际做好工作并做对。

**Kara Swisher：** 你有没有和斯嘉丽·约翰逊交谈过？

**Mira Murati：** 没有，

**Kara Swisher：**
我知道她当时在后台，你提到了一些不同的事情，比如小驯鹿之类的，但是她完全不知道你在说什么，因为你太投入工作仿佛生活在自己世界里，对吗？

**Mira Murati：**
是。目前，事情非常紧张，所以我非常专注于我的工作。但我也是在阿尔巴尼亚，巴尔干国家长大的，所以我没有在美国流行文化中长大，不太擅长和这些流行明星打交道。

### 8、AI虚假信息问题

**Kara Swisher：**
但你现在不在注意这个，让我结束关于选举和信息的讨论，然后我们会从观众那里收到问题。三项新研究共同表明，线上虚假信息的问题比我们认为的要小，虚假信息本身并不那么有效。一项研究发现，我们面对的是需求端问题，有些人想听阴谋论，他们会无论在无线广播还是社交媒体上寻找这些内容。其他人则认为这是一个非常大的问题，显然，你听说过，有很多关于社交媒体助长阴谋论的说法。当你考虑到AI的力量、虚假信息和即将到来的总统选举时，有什么让你夜不能寐的？从你的角度来看，最坏的情况和最有可能的负面结果是什么？

**Mira Murati：**
目前的系统非常擅长说服和影响你的思考方式和信仰。这是我们已经研究了一段时间的问题，我确实认为这是AI的一个真正问题，它被极大地加剧了。特别是在过去一年中，我们非常关注如何帮助选举的完整性。我们正在做几件事情。首先，我们尽可能防止滥用，包括提高政治信息检测的准确性，了解平台上发生的事情，并在发生这种情况时迅速采取行动。第二，是减少政治偏见。你可能已经看到ChatGPT因为过于自由而受到批评。那是伊隆的意见，你太自由了。还有一些其他的声音，但重点是，这不是故意的。我们非常努力地减少模型行为中的政治偏见，并将继续这样做。还有幻觉问题。第三，我们想在人们寻找投票地点或投票信息时，指引他们获得正确的信息。所以，我们正在关注这三件事。

但广泛地说，对于错误信息，我会说深度伪造是不可接受的，所以我们需要非常强大的方法让人们知道他们看到的是深度伪造。我们已经做了一些事情，我们为图像实施了CTPA，这有点像是内容在其他平台上的元数据，就像互联网上的护照一样。我们还开放了红队测试分类器，用于检测图像是否由Dalle生成。元数据和分类器是两种技术方法来处理这个问题。这是信息的出处，这是针对文本的，我们也在研究如何在文本中实施水印技术，并且如何做到健壮。关键是，人们应该知道他们何时在处理深度伪造，我们希望人们信任他们所看到的信息。尽管这些伪造的整个点是试图欺骗你，对吧？

**Kara Swisher：**
政治顾问，联邦通信委员会刚刚对创造深度伪造音频机器人电话的行为处以600万美元罚款，听起来像是拜登在新罕布什尔初选期间的声音。可能会有更复杂的版本。OpenAI正在开发一个名为“声音引擎”的工具，只需15秒的录音就能重现某人的声音，能够创建某人用另一种语言讲话的录音。这还没有发布，因为正如你的产品经理告诉《纽约时报》的，这是一件敏感的事情，重要的是要做对。为什么要制造这个？

**Mira Murati：**
我总是对科技人员说，如果你是《黑镜》剧集，也许你就不应该制造它。我认为这种做法有点无望，你知道，这些技术很了不起，它们承载着不可思议的希望，我们可以做对。

**Kara Swisher：** 我喜欢你说我无望，我是，但继续吧。再说，我有四个孩子，所以我一定是有希望的，谁知道呢。继续吧，

**Mira Murati：**
我们在2022年构建了声音引擎，我们还没有发布它，即使现在也是非常有限的方式，因为我们正在努力解决这些问题。但你不能自己使它健壮，你实际上需要与不同领域的专家、民间社会、政府和创作者合作，来找出如何真正使它健壮。这不是一个一站式的安全问题，它非常复杂，所以我们需要做工作。

**Kara Swisher：**
我要问你最后一个问题，然后我们将接受观众的提问。今天的AI版本是你将使用过的最差版本，你对此非常乐观。但我希望你能组织一下，如果你是个悲观者，似乎真的有人对我说，如果我不阻止Sam，他会毁灭人类，这让我感觉有点戏剧化。然后还有人说，无论如何，这将是有史以来最好的事情，我们都将生活在火星上，并在那里享受美味的士力架巧克力。这有非常不同的看法，有点像现在的共和党人和民主党人。所以，我希望你能告诉我你最担心的事情和你最有希望的事情，然后我们将接受观众的提问。

**Mira Murati：**
首先，我不认为这是一个早已注定的结果。我认为我们对如何构建这项技术以及如何在世界上部署它有很大的主动权。为了做正确，我们需要弄清楚如何创造共享的责任，我认为这很大程度上取决于理解技术，使其非常易于获取。出错的方式是误解它，即不理解它的能力和不理解相关风险。我认为这是现在最大的风险。就一些具体场景而言，我们的民主如何与这些技术互动，是非常有力的，这和我们今天讨论的很多内容有关。我确实认为存在关于说服的重大风险，比如你可以非常有力地说服人们做特定的事情，你可以控制人们做特定的事情。我认为，控制社会朝特定方向发展是非常可怕的。

至于希望方面，我非常期待的一件事是，在世界各地的偏远村庄能够获得高质量和免费的教育。对我个人来说，教育非常重要，它改变了我的生活。我只能想象，今天我们有这么多工具可用，如果你有电和网络，很多工具都可以使用。但大多数人仍然是在一个老师带50个学生的教室里上课，每个人都学相同的内容。想象一下，如果教育能够针对你的思维方式、你的文化习惯和你的特定兴趣来定制，那将是极其强大的。这可以极大地扩展知识和创造力的水平。即使是学习如何学习，这通常在生活中很晚才发生，可能在大学甚至更晚。这是如此基本的事情，但如果我们能够真正掌握这一点，并在更年轻的时候了解我们如何学习，我认为这将是非常有力的，并且可以推动人类知识的发展，进而推动整个文明的进步。

## 9、观众提问

**观众查尔斯：**
好的，我们将在此结束。我是查尔斯，这所学校的校友。关于数据的选择加入，显然有一个与谷歌有关的情况，它抓取了旧的Reddit帖子，并告诉人们在披萨上涂胶水以便粘在一起。显然那只是一个小错误，我们已经解决了。但如果你不是像《纽约时报》那样可以雇佣律师起诉的公司，有没有办法选择不让你在网上发布的内容被抓取，然后用来训练AI？谢谢你。是的，胶水披萨是谷歌不得不撤回的一部分，因为它曾经说约翰·肯尼迪还活着，在威斯康星上学等等，这对谷歌来说不是好事。他的意思是，有没有办法选择退出这些数据，这样就不会被这些系统使用？如果你在公共互联网上，你就会被利用。有没有什么办法，Perplexity的首席执行官刚刚又说了，互联网上的一切都是免费的，他又一次说了，我可以随意拿你想要的东西。我认为这是偷窃，你可能不同意。你如何看待选择退出，让公民能够这样做？

**Mira Murati：**
是的，这就是为什么我们正在建立这个内容媒体管理器，这是为了出版商，但我们也在试图找到方法，让任何人都能标识他们不希望用于训练的数据，或者他们对如何使用这些数据有特定的要求。我们将通过很多不同的方式进行原型设计。我认为给人们控制他们的数据的能力非常重要。但也有一个问题，你是否可以按照你想要的方式在当今的数字世界中操作？问题陈述应该是你不希望你的数据出现在任何地方，这可能是一个问题陈述。另一个可能是你不希望这些AI系统对你的思维方式、你与信息的互动产生不适当的影响。我认为在我们考虑隐私和数据如何被使用，以及当这些数据被放入这些模型时实际意味着什么时，也应该考虑这一点。

**观众佩里奇：**
考虑到你们和你们的竞争对手正在建造的这些模型不仅仅是公司的宝贵知识产权，而且正在成为对国家安全、经济安全日益重要的国家资产，并且它们只不过是含有数值的大文件（权重），你有多自信我们的对手，如俄罗斯，还没有模仿我们技术，或者已经模仿过了它们？

**Mira Murati：**
确保技术安全和保护知识产权是公司的头等大事，你可以想象，对于我们所做的工作，我们一直处于攻击之下，我们需要对这些敌对攻击极其健壮。我们也试图帮助生态系统中的其他人增强这方面的能力，我们会发布关于安全的内容，并在我们能够的范围内合作，因为这也可能暴露出漏洞。我们还会与业界其他人合作分享经验。还有关于平台滥用的问题，实际上就在上周，我们分享了一些信息，我们发现了一些受俄罗斯、伊朗支持的影响力行动，我们将它们从平台上清除了。这主要是虚假信息、错误信息类型的影响，我们早早发现并清除了这些行为者，并希望为整个生态系统的利益分享这些信息。我们将继续做更多这样的事情。

**观众克里斯·罗伯茨：**
嗨，我是克里斯·罗伯茨，谢谢你们来到华盛顿特区，非常感激。同时感谢你和斯科特·吉尼斯在大流行期间所做的贡献。作为当地的沼泽人，我们表示感谢。我的问题实际上与聊天GPT这种大型语言模型有关，我们彼此之间的沟通常常依赖于语境和情感，这有助于理解我们的出发点。你提到你在另一个国家长大，不了解流行文化。据我所知，聊天GPT的模型数据截至2021年9月，之后你们依靠网络搜索来增强数据。当我们谈论误信息并希望得到准确信息时，如果我进行搜索或它误解了当前的政治语境，我们如何确保你们从正确的参考资料中获取正确的答案，向正确的人在正确的时间提供？而且，由于你说过你们获得的那些受信任来源是专有的商业秘密，我们如何知道我们从你们这里得到的信息是准确的？谢谢。

**Mira Murati：**
是的，有趣的事实是，聊天GPT最初作为一个关于真实性的研究项目开始。我们希望能够表达不确定性，并能够在大型语言模型中引用信息，然后它转变为不同的研究项目。所以，我们今天在平台上所做的事情包括我们引入的工具和浏览功能，你可以在其中查找内容。我们还在与出版商合作，以便在平台上引入新闻和其他内容，提高准确性。我们还在处理幻觉问题，幻觉问题一直在改善。显然，这对大型语言模型来说是一个主要问题。我认为错误信息问题非常复杂，因为你有幻觉问题，你想知道信息的来源，我们也在研究这个。然后你希望信息来源尽可能广泛和丰富，然后你还必须考虑产品的表面，产品表面在你参与学习时与你需要购买建议时不同。

**观众：**
你之前提到，你们不能向公众披露你们获取某些数据的来源，以保持竞争力。这让我想起尼尔·德葛拉斯·泰森讨论的，我们所拥有的关于太空的很多信息及其用途，自动转化为战争。如果你再次成为CEO一天，你会选择将这些信息发布给政府，以确保我们创造一个能够以保护公众的方式进行监管的空间吗，这符合全世界人的利益？

**（Mira没听清，**观众****重复一遍问题** ）：**
如果你成为CEO一天，你会选择向政府公开这些信息吗？这样政府就可以支持监管，创造一个我们可以了解信息来源的空间。你说你想保持信息的专有性。

**Mira Murati：**
是的，你必须考虑什么是最重要的信息。如果你要让政府知道某些事情，发布竞争性信息的目的是什么？政府会怎么做？哪一部分信息是最有影响力的？我们与美国政府以及其他政府关系良好，我们与它们非常密切合作，尤其是给予美国人工智能安全研究所早期访问权限，这样他们就可以进行红队测试，对未来情况有所了解。我更倾向于关注技术的路线图和早期视角，而不是具体的一些关键数据细节。

**观众乔什·柯蒂斯：**
嗨，感谢你今天与我们交流。我是乔什·柯蒂斯，我是南加州大学的学生，我关注的领域之一是人工智能安全。我对“剧透者问题”很感兴趣，在这种情境下，我们知道OpenAI非常关注安全，一些OpenAI的竞争对手，特别是在美国和欧洲的公司，也同样关注。但我们仍处于技术监管的“狂野西部”，在这里，很容易看到拥有自己想法的数据科学家离开公司，并开设自己的店，可能是一个不太严谨的店。OpenAI如何看待在一个可能没有非常严格监管和大量资金的世界中，人工智能安全的问题？

**Mira Murati：**
关于监管，我一直非常直言不讳地认为找到正确的平衡非常重要。你不希望在这里有僵化，鉴于技术进步的非常快速的步伐，但你希望有足够的灵活性，使监管真正有影响力和实用性，并且能够适应技术的变化。同时，你也希望尽早设置好护栏和指导方针，以便最大化公共利益。私人公司获利和拥有一个商业丰富的生态系统和市场是很好的，我认为市场实际上可以通过规则和指导方针以及监管使其变得非常丰富，这是非常好的。但你需要确保这些措施足够早地实施，以便最大化公共利益，而不仅仅是公司的利润。在监管的具体细节方面，我有些犹豫，不愿意具体说应该是什么样的，但我们到目前为止与监管机构的互动是，我们做了很多事情，我们知道什么有效，我们将主动分享那些承诺，有时它们会成为行业的标准。这是白宫自愿承诺的情况。如果你做出承诺或制定监管，确保它是可以操作的，真正能带来更安全的影响，而不只是看起来不错，这是非常重要的。我认为在行业和监管机构之间需要非常紧密的合作来正确处理这个问题，我们需要政府中真正了解人工智能的人，最近几个月，特别是随着美国人工智能安全研究所的成立，这方面有所增加。

**乔什·柯蒂斯：** 还有一点，我是一名女性，在这些领导职位上的女性并不多，你可能是目前科技界最杰出、最有影响力的女性之一。你认为这重要吗？你的榜样是谁？

**Mira Murati：**
当我去学校，与学生互动，他们说他们觉得这很鼓舞人心，这实际上给我带来了快乐。是的，STEM领域确实是由男性主导的，但我认为多样性有不同的形式，不仅仅是性别。这有点简单化，只考虑性别。还有文化和我们思考问题的方式。显然，我们希望在处理影响整个社会的人工智能问题时，团队尽可能多样化。激励我的人有很多，我的同事，我日常密切合作的人，我过去合作过的人。每天与这些了不起的人一起工作，他们非常专注和好奇，把公司的使命放在首位，我意识到这是一种真正罕见的特权，能与这些才华横溢、友善的人一起工作。十年后你会在哪里？十年是很长的时间来预测，我希望到那时我们在科学上取得了一些惊人的突破。

**Kara Swisher：** 好的，我们就到这里吧，谢谢大家，谢谢你，Mira，非常感谢你。

# 往期回顾

* * *

[1、[达特茅斯大学对话OpenAI CTO Mira
Murati：她坦言职场会发生重大变化，一些岗位注定消失]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAjJrZk2aCAwqNoribS9OiaDUbgTvK4DVknX2XENAFrcJRyTzCRzesZu7n7iamT1eqFzAa5Jzia0ZCXaDg/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247491298&idx=1&sn=947815c78974fcf7e40215186312a302&chksm=c00bac07f77c25115985b8933b1aded3fc1d0ce6db165a454fab99571039d97c53aae4b781dc&scene=21#wechat_redirect)

[2、[老黄对话Databricks
CEO：生成式AI将无处不在,如果你的行业没有涉及AI,或面临淘汰风险]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAjJrZk2aCAwqNoribS9OiaDUbjW5FPRGvsFUvVDLPJ57cflLns10cYD2ibQOq7acJWC1MBGuhkkup7FA/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247491062&idx=2&sn=477f3e9133b9fcc47ab4bafa3856f946&chksm=c00baf13f77c2605ef0b905ba682db7163f7055dc0cf8644c691d6da83e583f23a14b10d2e1f&scene=21#wechat_redirect)

[3、[面对投资热潮，比尔·盖茨在彭博社视频采访中表示AI不是泡沫，而是有坚实技术基础，我们需要尽快掌握这一强大技术工具]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAjJrZk2aCAwqNoribS9OiaDUbJSo2bBbm68ib0YXWre7RePCr4gynNUxeCQJOgZsUcEAE96Wf0LCx1fA/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247491484&idx=1&sn=46b1d34b16b31d0b76d1681cf8a8285b&chksm=c00bad79f77c246f1d234a219e945307c3e9874fe1ecd6d6f93a95ee656989a654632f47005a&scene=21#wechat_redirect)

* * *

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhtRhTOjz2QwH4dIlC3YUcYbaicMEwjqQqh06Yhdd7EH3r9wiaMRArLz0a6Zhx6uiaUD7hguPfbY0nAg/640?wx_fmt=png&from=appmsg)

****

**我们的AI团队现向外界开放服务，旨在助力每个企业与个人引领时代潮流，将先进科技与创新想法完美融合!**

##  告别昂贵服务费和缺人烦恼,再见漫长交付周期

## 无限创意风格,分分钟生成专业级作品

## 感受 AI 带来的全新工作体验！

_**欢迎各大品牌方、媒体、科技企业、知名IP等合作**_

 _**合作请联系负责人微信：Milo-1101**_

 _**\--END--**_

