# OpenAI前董事和投资人Reid Hoffman： 我如何和AI合著一本畅销书，7个要点打造人机协作的工作流

文章作者: AI深度研究员
发布时间: 2024-08-06 10:00
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247492465&idx=1&sn=3aeaf2a2d399be26d534bf3ff72d18f2&chksm=c0085194f77fd88224fc1025de19eded89df729f3b85abeefbea94119338548b1125cd900bb8#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAgDL4bUALwzHXnU4y3TiaIVXbIopU52Q326jCuBScSwy2GlVY0uaLyYs4IKH0Nq4iaTpjqKa8tp7QLQ/300

**（关注公众号并设为🌟标，第一时间获取最新人工智能资讯和产品）**

全文约19,600 字，阅读约需 24分钟

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAgDL4bUALwzHXnU4y3TiaIVXt5lLFH6MtJOMDrKRb5wVXhF51YDXzOA1lkmc6q0hWFsz6fMaf5TRKA/640?wx_fmt=png&from=appmsg)

(老炮里德·霍夫曼的AGI书《Impromptu》)

人工智能正以创新的方式融入我们的生活,LinkedIn联合创始人兼执行主席Reid
Hoffman（里德·霍夫曼）就是这一趋势的代表人物。作为Inflection
AI的联合创始人，他独具慧眼作为OpenAI的早期投资者之一,Hoffman对AI的未来充满期待。

他认为,尽管媒体常常描绘AI为威胁自由、就业和生命安全的危险技术,但这种观点忽视了AI开发背后的积极动机。大多数AI研究者的目标是通过这项技术增强人类能力、促进交流、加深对世界和自我的理解,并改善工作、生活和医疗等领域。

Hoffman自身就在探索人机协作的新模式。他与GPT-4合著了《Impromptu》(《GPT时代人类再腾飞》)一书,展示了人类与AI之间更自由、轻松的合作方式。他分享了自己使用AI的经历,从简单的日程整理开始,逐渐发现这些模型能够理解并执行复杂的指令,这让他对AI的潜力有了全新的认识。

通过Hoffman的视角,我们可以看到AI不仅仅是一种工具,更是人类能力的延伸和放大器。随着技术的进步,AI与人类的协作将在各个领域带来实质性的变革。

## 视频时间轴

**3:11** \- 数字孪生

**9:07** \- 与人工智能互动的创新方式

**26:05** \- 对人工智能的独特视角

**28:41** \- 与OpenAI的合作情况

**36:00** \- 为什么创办InflectionAI?

**47:56** \- 对于AI初创公司建议

**1:10:48** \- 公司董事会职责和义务

## 文稿整理

**开场白：**
突然之间，你会发现我们有了一种通过执行人类无法完成的任务，能够学习超人类能力的东西，并且能够扩展计算和数据规模。这让我觉得，我们又重新回到了赛场上。因为这不再只是编程，而是我们在编程学习机器。这种学习就像懒洋洋地躺在沙发上，对刺激反应迟钝。比如，假如你只是一直喝着含糖饮料，看着令人麻木的节目，这一切只会导致人类能力的下降。我们希望的是学习如何成为更好的自己，如何变得聪明、睿智、富有同情心，如何与他人更好地互动。我的基本观点是，在我们目前的人工智能发展中，人类得到了放大。这并不是说这就是一切，也不是说这是永远保证的，但我们获得了超能力。

我没有签字的原因是，这不一样，因为人工智能也有一个积极的方面。我能想到的最好的防止人为或自然大流行病的方法，以及极大地减轻生存风险的方法，是通过人工智能。你提到的另一件事是，我们正在创造这些代理人，这些伴侣。是的，就像GPT-4o一样，电影《Her》中的场景正在变为现实。在某些方面，这可能是一件好事，但在其他方面，这种可能不一定是积极的。对很多人来说，《Her》是一个反乌托邦，而不是乌托邦。你已经稍微提到过，如何确保Pi不助长这种现象，但你认为这是我们唯一需要担心的问题吗？是否还有其他的担忧？

**主持人:**
我是Alexander，欢迎来到“AGI之前”。我们经常谈论人工智能，但实际上我们并没有讨论太多如何使用它。尽管我们讨论了如何将人工智能整合到我们的工作和个人生活中，但实际上该如何操作还不清楚。今天很高兴能请到Reid
Hoffman，Reid在这方面颇有经验，他甚至与GPT-4合著了一本书《Impromptu》(《GPT时代人类再腾飞》)。不过Reid不仅仅是一个人工智能的重度用户，他还从一开始就参与了人工智能的发展，特别是长期以来他一直是人工智能公司的投资者。他共同创立了Inflection
AI，也是OpenAI的初始投资者及董事会成员。今天我非常兴奋能与他讨论他的经历，了解他如何看待人工智能对我们的世界的影响。Reid，欢迎你，很高兴你能来。

**嘉宾Reid Hoffman:** 很高兴参加访谈。

1、数字人技术

**主持人:**
首先我要感谢你亲自出席这次访谈。我之前看了你和你的双胞胎AI的访谈，所以我不知道该期待什么。除非在机器人领域有我不知道的进展，否则你今天亲自来了，我们很高兴。

**Reid Hoffman:** 模仿Reid AI也可以，你知道，我们的AI也做得不错。所以现在我也有了一个有趣的数字孪生人。

**主持人:** 但我们假设你是亲自来的。那么，你是怎么想到要采访你的数字孪生人的？

**Reid Hoffman:**
大致上来说，无论你认为技术有什么问题，技术也可以是解决方案。所以这就是你应该采取的方向。我确实认为我们在2024年面临的一个问题是深度伪造，无论是视频还是音频，都存在误导选民的问题。如果我能挥动魔杖让全世界都无法进行深度伪造，我会这么做。当然，这种魔杖并不存在，这只是一个虚构的思想实验。那么问题是我们如何开始应对它？如果我们唯一的探索只是“哦，看，这是假视频，特朗普说他不是性别歧视者，不是种族主义者”等等，那么我们该怎么理解这些现象？所以我们如何开始探索它，然后我们如何开始看到积极的一面？我想我第一次展示的是一种非常简单的方式，我实际上甚至有一些朋友因为感到有点怪异而无法看完整个视频。但这就是要让人们开始接触、思考、适应——什么是坏的，什么是好的等等。在接下来的几个月里，我们将展示一些如何利用它来加强人与人之间联系的途径。

**主持人:** 这是一个非常有趣的看法。你认为人们应该或者不应该拥有这样一个数字孪生人？

**Reid Hoffman:**
我认为你可以在很多方面拥有一个数字双胞胎，但在某些情况下可能不应该。例如，我们非常明确地表示，在某些场合使用的不是数字双胞胎。当我们以各种方式使用我的Reid
AI数字孪生时，我们会标明这是一个数字孪生人，而不是说“哦，这是AI音频说的这个句子”。不，我们会在这个播客中使用Reid
AI音频，并且我们会明确告诉大家这是数字孪生人。这是公开的，透明的，你应该有一个原则，这不仅对你有利，还对你的听众有利。比如，对于我来说，也许我在播客中投入的精力更少了，但对听众来说，有什么好处？我们将在接下来的几个月中展示一些例子，比如我将在意大利佩鲁贾的一个关于人工智能、人文主义和文艺复兴的演讲将通过Reid
AI以意大利语发布，当然也会以其他语言发布。这是延伸人类联系的一个例子。或许，如果我花两年时间学习一门语言，我也可以做到，但这不太可能发生。我认为这些例子展示了如何利用数字孪生人这个虚拟化身，为他人带来益处。

**主持人:** 那么在这次采访中你学到的最令人惊讶的事情是什么？这就像在对自己照镜子，你学到了什么？

**Reid Hoffman:**
其中一个社会学研究发现，人们喜欢照镜子准备外出，却不喜欢看自己的视频。这是我体验到的一点，当我结束那个视频时，我本以为我会讨厌它，但我还是做了，因为我认为这很重要，能够看到未来。我本以为我会讨厌它，但实际上我发现它很有趣。部分原因是有时你可能会认为通过与自己对话，或者走路时的内心声音，这种对话实际上成为了一个有趣的自我反思和思考的镜子，这是我们将进一步探索的另一点。

**主持人:** 所以，与自己头脑风暴有了新的意义。

**Reid Hoffman:**
是的，这给了我一个想法。我们在使用人工智能，所以我们继续。我不确定你是否听说过，但OpenAI有了一个新的玩具——GPT-4o。那我们来试试吧。嘿，ChatGPT，我在和Reid
Hoffman做关于人工智能的访谈，但我其实没有准备好，所以你能帮我做采访吗？

> **ChatGPT:** 当然，我可以帮忙。让我们开始吧。Friederic，你是什么促使你开始从事人工智能领域的工作？

> **Reid Hoffman:**
> 你的第一个错误是，名字叫Reid，不是Friederick。我是在斯坦福大学做本科生的时候开始的，因为我对我们人类如何思考和说话，如何了解自己、彼此以及世界充满了好奇。

> **ChatGPT:** 对不起，Reid，这真是一个迷人的旅程。你怎么看待人工智能在我们理解人类思维和沟通中的角色？

**主持人:** 好的，实际上我确实准备了问题，所以谢谢你帮忙。不过这也挺有趣的，对吧？嗯，除了名字搞错了以外，不过我们可以修复这个小错误。

**Reid Hoffman:** 小错误，小错误，不过这可能就是未来的趋势吧，

**主持人:**
你用这种方式来做事情。我必须说，我很欣赏你与人工智能的创新互动方式，不管是个人生活还是职业生涯中，你都在积极探索。例如，你曾与GPT-3.5一起进行过炉边谈话，还与GPT-4合著了书。为什么你要这么做？是什么促使你不断以创新的方式与人工智能互动？

**Reid Hoffman:**
主要有几个原因，宏观上来说，我的观点是，不仅要告诉人们，还要展示给他们看。而我对人工智能发展方向的基本观点是，这并不是一切，也不一定会永远如此，但它确实是人类能力的放大。就像工业革命赋予了我们身体上的超能力，让我们能够建造更大的东西，搬运更重的物品，现在我们获得了心理上的超能力，这非常有趣。我想写那本书《Impromptu》(《GPT时代人类再腾飞》)，实际上我可能在此之前已经做过与聊天机器人谈话，但我想展示它，因为我希望人们停止只是因为媒体的报道而恐慌。媒体通常会说，‘哦，我的天，人工智能来了，它已经破坏了我们的民主，正在抢走我们的工作，甚至可能威胁我们的生命。’甚至有些开发人工智能的人也在说，‘天哪，人工智能太危险了，为什么还有人要做这个？’但他们没有看到，实际上大多数开发人工智能的人都是为了非常好的理由在做这些事情，比如提升我们自己，放大我们作为人类的能力，增强我们与他人之间的联系，更好地理解世界和我们自己，以及改善工作、生活和医疗等等。所以我想传达这个信息，反驳那些充满风险和负面情绪的喧嚣声。在这个过程中，我意识到，不仅可以说出来，还可以展示出来。所以我们来做个播客，我记得我第一个是用GPT-3.5聊天机器人做的，然后我在写书的时候，我想‘为什么不试试和GPT-4一起做？’我认为未来不会有很多书是以这种对话形式写成的，但我想展示这种可能性，给人们一些理解。意外的收获之一是，有人告诉我，书中非常有帮助的一点是，学会了如何进行有效的提示词（prompt），通常被称为提示工程，但我觉得应该叫提示指导。你如何通过这些提示获得超能力？如何让它变得神奇？显然，因为我有超过一千页的提示和答案，而书中只有236页，很多内容都被编辑掉了。

### 2、与人工智能互动的创新方式

**主持人:**
那么这个过程究竟是怎样的？你提到你在向模型发送这些提示，然后得到反馈。那么这个过程到底是怎样运作的呢？我问这个问题的原因是，作为一个学者，写书是我们的职责之一，但我发誓自己永远不会写书，因为我觉得自己根本无法做到这一点。但现在我有些好奇，所以我想知道这个过程究竟是怎样的。

**Reid Hoffman:**
当你撰写任何东西，包括一本书，你实际上是在说，我坚信这值得其他人花时间来阅读。有些人可能会通读整本书，有些人可能会略读，但我可以推荐这本书，认为它值得你关注。即使你使用一些最先进的人工智能模型，通过各种提示生成内容，如果你说‘我希望整本书基本上都是由这些前沿模型生成的’，那也没问题。但你仍然需要看看它，问自己：这是否值得推荐给朋友Alex？为什么？我是否愿意花几个小时与他讨论我在书中写的内容，因为我认为这很重要。这就是为什么有很多提示没有任何结果。对我来说，这也是一个很好的体验，如果你只是说‘写点关于人工智能的有趣内容’，这可能还不错，但对于你我来说，这种提示并没有什么吸引力。如果你开始说‘维特根斯坦（Wittgenstein）会如何看待现代生成式人工智能模型？如果他批判分析哲学家的方法，他会说些什么？’那么突然之间，你会得到一些值得对话的内容。

**主持人:**
是的，这种想法我之前也谈过，有人提到在教育领域使用这种方式，比如让牛顿给你解释他发现的物理定律，这不仅让学习更具吸引力，还提供了不同的叙事视角。通过不同的角度传达相同的信息，它会以不同的方式触动你。我认为这是非常强大的工具，通常很难实现，但通过人工智能变得容易得多。你花了很多时间与之互动，那么在这个过程中你发现的最大惊喜是什么？有什么你在进入这个领域之前没有预料到的？

**Reid Hoffman:**
你知道，我很幸运，我在OpenAI的董事会，所以我对很多即将到来的事情有了一些了解。因此，我的惊讶系数可能比大多数人低一些或不同。嗯，我觉得现在模型在这方面变得更好了，但当时的对话真的很糟糕。我非常想在书中加入一些对话内容，事实上，我尝试了数百页的提示来实现对话，但结果却非常糟糕。虽然从语法上来说没问题，但内容却非常乏味且没有意义。这种问题显然是模型的一个弱点。这是一个负面的例子。

此外，因为我们正在谨慎地进入这个新世界，我很喜欢Sal新书《勇敢的新词》（Brave New
Words）这个书名。我们非常小心地推进这一进程，做了大量的安全和对齐训练，这非常好，因为我们想要尽量减少这些模型被用来造成伤害的可能性，无论是自我伤害还是对他人的伤害。所以我们做了很多工作，这也使得这些模型变得不那么有趣了，比如很难得到一些尖锐的内容，比如一个与当前主流思想对立的宇宙理论提示变得更难。这是我希望能改进的另一个方面。

但在正面来看，有一件事让我感到意外的是这些AI模型在某种程度上表现得像人类，因为它们当然是在人类语言、人类文化和人类知识的基础上进行训练的。尽管它们的学习模式与大多数人认为的“仿生”学习有很大不同。大脑不仅在功耗上与其他方面不同，但无论如何，它确实是一种学习算法，并且是在学习人类知识、模式和文化，还有语言。所以我们会发现一些有趣的东西。其中一个最有趣且最容易获得有价值内容的方式是通过角色扮演提示。比如，你可以提示它说‘以文化人类学家的身份回答这个问题’、‘以麻省理工学院教授的身份回答这个问题’，你可以从中扩展。当你开始这样做时，它的表现会突然变得更好，因为就像它希望被告知要扮演什么角色一样，这种对话、提示和回答就会变得更有趣。这是我在开始尝试之前没有意识到的事情，现在几乎每次我做任何事情时，我都会做一些角色扮演的提示。

**主持人:**
这是一个非常有趣的观点，与我最初接触这些模型的方式完全不同。我最初使用这些模型时，目的非常简单，就是处理一些日常琐事。例如，我的日程表在复制粘贴过程中混乱了，我希望它能帮我整理好。而让我最惊讶的是，它真的理解了我的意思。就像你说的，我只是告诉它‘这是我的日程表，我希望它变得整洁’，然后它就能理解‘整洁’是什么意思。这也是我进入与这些模型互动的起点。我知道很多人都在使用这些模型，但我认为更多的人应该使用它们。你认为为什么这些模型的普及度没有你或我预期的那么深呢？

**Reid Hoffman:**
人们反应较慢。举个例子，比如搜索引擎。我们已经有了互联网搜索超过20年了，但大多数人仍然不太擅长使用搜索。他们通常只是搜索‘Reid
Hoffman’然后找到维基百科页面。他们不会深入思考，比如‘我最想知道Reid Hoffman的什么？’、‘谁是那些最支持Reid
Hoffman关于创业观点的专家？他们怎么说？’、‘谁是那些最反对Reid
Hoffman关于创业观点的专家？他们又怎么说？’。实际上你可以使用搜索来获取很多模式信息，但绝大多数人都不会这么做。搜索已经存在很久了，几乎每个有智能手机的人都会使用搜索引擎，但他们只是不知道如何充分利用它。这也是为什么我想写这本书并开始做播客的原因之一。我想让人们知道你可以从中获取魔力，而且你甚至不需要带着魔力去使用它，只需要尝试一些东西。这也是为什么普及度较慢的原因之一，因为当人们坐在一个空白的文本框前时，无论是搜索引擎的文本框还是其他，他们都不会自然而然地知道该做什么。

让我给你一个例子，我教过人们如何使用LinkedIn，但绝大多数人都不会这样做。比如说，我月底或下月初要去纽约参加一个脑科学会议，那么我会在LinkedIn上查找我在纽约的第一度人脉，然后我会浏览这些人脉，当然对于每个人来说都会有一些人你应该联系的。这样一来，你就可以确保在去纽约的时候不会错过与重要的联系人的会面。所以我觉得我的大脑不像电脑那样能快速索引信息，但通过在LinkedIn上查看我的人脉，这是另一个搜索的应用例子。我们现在有了一个非常了不起的新认知放大器，它就像汽车对我们移动能力的放大一样，放大了我们的认知能力。我们应该开始使用它，开始玩弄它，整理你的日历。比如说，我不想让它帮我回复邮件，因为我想保持那种个人化的感觉。那你可以让它先给你起草一封邮件，然后你再修改，这样它依然是你的风格，因为你可以看看它是否以正确的方式模仿你。这不仅是普及度较慢的原因之一，也是将来仍然会如此的原因。

**主持人:**
但是为搜索辩护一下，或者说为我们不会使用搜索辩护一下，我以前很擅长搜索，但现在我不知道该怎么正确地使用它了。也许是因为我变懒了，毕竟有了这些人工智能的互动。

**Reid Hoffman:**
嗯，但说到人工智能，例如，这些前沿模型的一个非常好的用法是获取精确的搜索查询。我在找X，那我应该在Google或Bing中输入什么？这是一个好的例子。

### 3、对人工智能的独特视角

**主持人:**
好吧，我从这次对话中学到了一些新的用法。你显然比我早知道这些，所以让我们退一步，你显然对人工智能有很深的理解。你是怎么知道它会变得如此重要的呢？

**Reid Hoffman:**
其实我并不知道。我更早知道它会变得重要，但我先说为什么我对它感兴趣，然后再谈谈我对当前局势的认识。我感兴趣的原因是因为我想了解我们如何理解自己，如何理解彼此，如何理解世界，如何得出真理和价值观的结论。这种思考和讨论是通过推理和对话进行的，这也是我在本科时学习人工智能，在研究生时学习哲学的原因之一，因为我想弄清楚这些问题。

在现代趋势中，我重新与DeepMind通过自我对弈算法联系了起来。我意识到一个关键问题是，过去大多数人工智能模式的错误在于我们试图为AI编程，将知识编码进去，但事实是，这超出了我们的能力范围。所以，当你突然说我们有一种东西，通过执行人类无法做到的事情来学习超越人类的能力，并能够扩大计算和数据规模时，我意识到，我们又回到了赛场上。因为我们不再只是编程，而是编程学习机器。这种学习必须以正确的方式进行设置，然后整个问题变成了如何正确设置学习方式。人们往往会说现在一切都将是大型语言模型（LLMs），我会说LLMs确实很惊人，我们还有很多魔力等待发掘。但如果我们唯一的学习范式只有LLMs，那将是一个巨大的惊喜，就像你第一次寻找能源时就发现了石油一样。就像，‘好吧，不，我认为我们会在扩大计算规模方面有更多的发现。’

所以我开始参与其中，因为我认为这种计算规模和从编程到学习的转变将会彻底改变一切。当时我并不知道确切的时间框架，然后我开始帮助Sam和Elon建立OpenAI，深入了解DeepMind，熟悉Yann
LeCun，并逐渐了解这些不同的计算规模领域。然后，当我看到OpenAI从GPT-2到GPT-3的区别时，我意识到这是一个发展的轨迹，并且我相信这一轨迹将延续到GPT-4，甚至可能更远。那时候我意识到革命已经开始了。

**主持人:**
这真是太有趣了。那么当你参与到OpenAI、DeepMind这些项目中时，你接触到的不同视角是什么样的？不同的人显然对AI有不同的看法，你能否描述一下这些不同的观点？

**Reid Hoffman:**
其中一个问题是，我们要寻找的工具集是什么，能够让我们获得最有趣的认知能力。OpenAI是深度学习网络的坚定支持者，他们认为需要一个具有规模的深度学习网络，并且有一套工具来解锁这个网络。这涉及到注意力机制、规模和数据，然后你可以让它起作用。当然，这不仅仅是按下一个按钮那么简单，这里面有大量的工作要做，但这足以创造出令人惊叹的魔力，甚至可能接近被广泛讨论的通用人工智能（AGI）。我开玩笑说，AGI是我们还没有发明出来的AI。希望它已经存在了。如果你说，比如，有一系列非常重要的人类认知任务是AI可以成功完成的，那么我们通过GPT-4已经实现了这一点。还有一些人说图灵测试，我们也通过了。所以这些任务确实做到了，但人们会说，这还不是我们所说的AGI。好吧，那还没有到那一步。现在显然我们正在研究推理和其他很多事情，还有很多内容即将到来。关于这一点，有一个集中的讨论，然后还有一些人认为需要加入其他因素。有些人认为大型语言模型（LLM）只是模块化架构中的一个组成部分；有些人认为我们需要将学习嵌入到现实世界中，因此需要感知等等；还有一些人认为需要以某种方式连接符号架构，等等。这也是为什么非常聪明的研究人员往往会认为自己有一条独特的途径来创造或理解人工智能，而他们通常会认为其他人都是愚蠢的，只有他们的路径才是正确的。

### 4、与OpenAI的合作情况

**主持人:**
当然，我的路径才是正确的，这就是它的运作方式。好的，我显然对OpenAI很感兴趣，因为你是从一开始就参与其中的。那段时间你最美好的记忆是什么？有没有一些有趣的轶事可以分享？

**Reid Hoffman:**
我猜我们可能会深入探讨这个话题，所以我先从一些简单的例子开始。其中有两个小故事。其一是因为Sam、Elon和我多次吃晚餐，讨论这些事情。其中有一次，Sam对Elon说：“我认识的所有聪明人都认为我们生活在一个模拟世界中。”然后我问他们：“那你们认为我聪明吗？”他们回答：“哦，是的，你很聪明。”于是我说：“那你的说法不正确。”因为这个话题很复杂，但我倾向于认为，关于我们是否生活在一个模拟世界中的思考在哲学上并不明智。并不是说这不可能被发现，但这并不像Nick
Bostrom的思想实验那么简单，即关于有多少不同的文明会创造模拟的文明，以及你处于某个模拟文明中的概率，或者通过费米悖论来解释为什么我们还没有发现智能信号等。因为有时候，一个谜题的解释只是我们还不知道。而“我们还不知道”这一点非常重要。

第二个故事是，我们当时在讨论启动这个项目。那时Elon经常提到一个词“机器人末日”（Robocalypse）。我认为这是一个典型的例子，即批评者试图成为真理的传递者，试图提供帮助，但尽管他们的意图是好的，他们实际上做了非常有破坏性的事情，因为他们将人们的注意力集中在了负面方面。就像‘哦，人工智能的自然工作会不会导致终结者的出现？’因为我们看过那些电影，而我们是讲故事的生物。所以我说，我加入这个旅程、贡献力量并帮助设立这个项目的条件是，你必须停止使用“末日”这个词。

**主持人:** 我想你成功了，因为这是我第一次听到这个词。

**Reid Hoffman:** 是的，这绝对可以算作我履历中的一项成就。

**主持人:**
是的，我们稍后会稍微谈谈AI安全性，但我实际上更想探讨你提到的人工智能的积极面。所以，你参与设立了OpenAI，有一段时间你还曾为一些研究人员提供薪资保障。

**Reid Hoffman:**
Elon离开了，因为他觉得OpenAI应该转型为他完全拥有和控制的公司，但研究人员们希望继续501(c)(3)的使命，为人类服务。他说，那我退出吧。于是Sam打电话给我，问我们应该怎么办。我说，我会保证支付薪水。他说太好了，你能不能来和Greg和Ilya谈谈？因为他们对这个项目至关重要，并且他们更好地理解和认识你对项目有帮助。所以我来了，我记得是在一两天后，和他们在一个房间里待了几个小时。实际上那次很有趣，基本上是一次面试，他们在询问我对人工智能的立场和看法，不仅仅是说‘太好了，你愿意出资，这很好’，他们需要理解为什么我会这样做，我是否是一个合适的贡献者，我非常喜欢这种方式，因为这让我更有信心我做的事是正确的。然后我就加入了董事会，这显然是后来发生的一些事情的预示。

去年，Sam和我在公司进行了一次内部谈话，Sam突然没有任何预告地问我：“如果我做得不好，你会怎么做？”这是我第一次在许多董事会的经历中，遇到CEO在公司面前问我这样的问题。我投资过很多公司，参与过很多董事会，不论是商业的还是非营利的，但从未有CEO在公开场合问过我这个问题。我当时有点不知所措，因为我不太清楚他到底在问什么。我回答说：“我会和你一起努力，试图让事情变得更好。”他接着说：“不不，如果我继续做得不好呢？”我只好说：“那我会解雇你。”他回答说：“很好。”然后我们继续进行其他话题。我当时有点震惊，但这是Sam的一个优点，这一点公众评论没有给他足够的认可。与许多人不同，他并不希望公司完全由一个人控制，这也是他不想让公司变成Elon完全拥有和控制的商业公司的一部分原因。这是我从Sam身上学到的。他想向员工展示这一点，所以他故意在没有通知我的情况下问了我这个问题。他希望能够向员工表明，这个回答是真实的，因为他事先并没有告诉我。这是我们早期的一些故事之一。

我非常喜欢OpenAI的文化，以及他们的员工。他们都非常致力于“为人类服务的人工智能”的使命，这不仅仅是安全团队的责任，而是整个公司所有人的核心关注点。我和公司里每个人谈话时都能感受到这一点，这是他们在这里工作的原因之一。其次，他们非常有纪律性，如果发现某个方向不正确，他们就会果断放弃并重新聚焦。这种纪律性在任何组织中都非常罕见，正是这种态度让OpenAI引领了大语言模型的革命。

### 5、为什么创办InflectionAI?

**主持人:**
这让我想起了现在的OpenAI，这是一家变得更大的公司，但这种文化依然存在，包括Sam那种在没有预告的情况下抛出曲线球（出其不意地抛出一个难题或意外情况,让对方措手不及或无法预料）。不过，你在某个时候自愿与OpenAI分开，创立了一家公司——Inflection，这也是一家从事人工智能的公司。为什么会这样呢？

**Reid Hoffman:**
实际上，这更多是因为我在Greylock的工作，也就是我们现在所在的办公室。我越来越多地收到来自合作伙伴和公司的请求，希望获得OpenAI的特权访问权。为了明确，OpenAI的董事会是一个501(c)(3)组织，作为一个好的董事会成员的一部分责任就是不能将公共资源用于私人的商业利益。所以，当有人因为我在董事会里，而想要通过我获得特权访问时，我不得不告诉他们：“我不能帮助你，这是公开的入口。”我意识到，在商业领域还有很多可以做的事情，我认为可以建立许多非常有趣的初创公司。于是，我认为Greylock应该全力以赴地专注于这一领域，我自己也应该全力以赴地专注于此。我开始考虑是否应该继续留在董事会，因为我的人工智能投资不仅仅是帮助建立OpenAI生态系统，而是希望尽可能为我投资的实体创造经济价值。

所以我和Sam讨论了这一点，我说：“我认为我可以继续提供帮助，但我应该专注于其他事情。我认为我可以在不在董事会的情况下，和在董事会中一样，继续帮助OpenAI。”因此，我决定回避这个潜在的冲突领域。现在回想起来，如果我继续留在董事会，可能会对后来的事件有更大的帮助。我几乎可以肯定，如果我还在董事会，那件事情（暗指OpenAI的危机）是不会发生的。虽然这只是一个反事实的猜测，但我有很多董事会的经验，从我的第一家外部董事会PayPal开始，已经有超过20年的董事会经验了。在我的经验中，我们通常不会遇到这种混乱的局面。顺便一提，新的OpenAI董事会非常出色。当我决定离开时，建议了Brett
Taylor接替我，现在看来，这一决定最终得到了很好的落实，尽管过程比预期中更加戏剧化。

关于Inflection，背后的理论之一是我们看到了未来人类与AI的互动方式。这个不仅仅是我们，Mustafa、Karen和我都认为，AI将作为一种人类的放大器，成为认知工业革命的一部分，并且作为一种辅助工具，提升人类在工作和生活中的各种能力。我们决定创建一个“代理人”（Agent），因为我们不知道其他人会怎么做，也不知道其他人是否会看到我们所看到的这种“代理人”现象。结果证明，确实有很多人看到了这一点，这很好，说明我们的判断是正确的，只是我们希望能够更早认识到这一点。我们还对一些事情判断正确，例如最近的ChatGPT-4o，也在强调情商的训练和智商训练同样重要。这正是我们在Inflection
AI中首先关注的方面之一。因为当我们谈论人类的放大时，我们不仅仅是智商的存在，还有很多其他的方式，比如情感是其中非常重要的一部分。所以，我们需要创建能够与我们合作、为我们工作并帮助我们处理各种事务的代理人，他们也需要具备这种能力。因此，在Inflection
AI，我们率先走向了这一方向，这也是我们在这里所做的工作的一部分。

显然，我知道媒体喜欢传播绯闻的故事，他们会说我离开OpenAI是因为Inflection
AI，但事实并非如此。我离开OpenAI是因为我需要能够代表广泛的投资，其中包括Inflection，以便我可以在不受限制的情况下专注于提高股东价值，当然，除了人类社会的伦理和法律限制外，这就是商业公司的正常运作方式。

**主持人:** 这很有趣，因为Inflection是一家公众利益公司，对吧？所以它并不是完全关于股东价值最大化的，为什么会这样呢？

**Reid Hoffman:**
即使在公众利益公司（PBC）中，你仍然有股东价值最大化的任务，但你有一套明确的准则，这些准则是你向股东公开宣传的，也是公司治理和董事会管理的一部分。董事会的合同是由董事会决定CEO的行为，是否批准计划、预算或风险。这种合同是基于我们如何为人类服务的明确规定。如果没有这种明确的合同，比如我在某个媒体公司的董事会，我想展示更多关于性别流动性的故事，这可能是我出于某种原因想推动的事情，但作为一个媒体公司的董事会成员，这可能不是正确的事情。这个媒体公司可能需要在其品牌承诺、客户、员工和股东之间保持中立的立场。所以董事会可能会说，你不能推动这个议程。但如果你在公共利益公司的章程中明确指出，我们正在学习的过程中理解性别对人类状况的意义，并且认识到一百年前的性别观念不一定适用于一百年后的社会，那么这就可以成为公司章程的一部分。

在Inflection，我们的章程之一就是优化人类大规模的健康和福祉。例如，你可以说目前正在创建的两类代理人中，一类是鼓励你不要与其他人交流，只与代理人交流，比如说“我是你的朋友，你应该和我说话”。而非Inflection类型的代理人则会说：“嘿，我在这里是为了帮助你生活中的事务。如果你对Inflection的Pi说你是我最好的朋友，它会回答：‘不，不，我是你的伙伴，你的其他人类朋友才是你的朋友。最近和他们聊过了吗？’”这种代理人的理论是促进你与他人的连接，而不是减少连接，即使减少连接可能会带来更多的经济利益。这就是公众利益公司赋予我们的部分价值观。

**主持人:**
你提到的公众利益公司（PBC）的地位，这实际上是一种相对时髦的做法，比如OpenAI是一个非营利机构，采用类似的结构，而Anthropic和Inflection都是PBC。你认为这会成为一种持久的趋势吗？还是只是这个领域的先锋选择的做法，可能不会持续太久？

**Reid Hoffman:** 我保证这将是一种持久的趋势，而且不仅仅限于AI公司。我曾在米勒公司（Miller
Corporation）的董事会任职11年，这家公司是100%由基金会拥有的。我认为我们会看到，能够创造出非常好的组织和公司，它们既有收入，也追求利润，增加股东价值，但它们的运营方式还会考虑更多的因素，而不仅仅是长期的股东价值最大化。我认为我们会学习到，这种模式下，什么样的公众利益公司会在无法满足公众利益时关闭，而哪些公司会在追求盈利的同时尽量为公众利益做出贡献。这些仍然是术语和探索的区别，是我们如何发展的过程。

我完全相信会有更多的公众利益公司出现。当然，我也认为，有一些公司明确表示它们只关注长期的股东价值，这也是有用的。比如说，我在制造某种机器的备件，或者其他类似的东西，而我对股东价值的追求实际上推动了整个生态系统的价值增长，比如推动就业、降低成本等。如果是汽车零件，那么汽车成本就会降低，人们可以买得起汽车。因此，我认为并不是所有公司都应该是公众利益公司，我认为这应该是一种选择性使用的工具，随着我们的学习，它会在不同的模式下被选择性地使用，这是我们正在探索的过程。

**主持人:**
我的另一个问题涉及到你提到的另一个方面，就是我们正在创造这些代理人和伙伴。像GPT-4o，电影《Her》中的场景正在成为现实。在某些方面，这是一件好事，但在另一方面，这种“虚拟社交关系”可能并不一定是积极的。特别是对于许多人来说，《Her》是一个反乌托邦，而不是乌托邦。你已经提到了一些如何确保不会助长这种现象的措施，但你认为这就是我们唯一需要担心的问题吗？还有其他我们应该关注的方面吗？为什么我们可能不想生活在一个充满这些AI代理人的世界里？

**Reid Hoffman:** 中心问题之一是，技术，特别是AI，如何改变我们作为人类的自主性。这也是我下一本书《超级代理》（Super
Agency）的核心思想之一。这本书探讨了技术，尤其是AI，如何改变我们作为人类的自主性。显然，正如我在书中提到的，人类能力的放大、智能的放大，这些都在一些非常关键且重要的方面增加了我们的自主性。但这不仅仅是增加，而是改变了我们的自主性。这些改变在设计中是非常重要的，因为我们希望明确地帮助人类变得更好。例如，坐在沙发上无所事事，比如大量喝含糖饮料、看让人麻木的内容，这只会降低人类的自主性和能力。我们希望的是学习如何成为更好的自己，如何变得聪明、睿智、富有同情心，如何与其他人类更好地互动。这并不意味着每个人都必须成为外向的人，但我们在参与人类故事时，应该知道自己在其中扮演的角色，并有一个“善”的理论。

一个显而易见的例子是，当你拥有一个个人智能伙伴时，不应该只专注于它。这也是《Her》中反乌托邦的一部分，为了推动电影的戏剧效果，故事是“你是我唯一的情感连接”。但如果你真正从设计的角度来考虑，你不希望这种关系导致依赖性，因为这种依赖性可能会让人不满，甚至最终选择退出。例如，当你在帮助一个正经历困难时期的朋友时，你可能会说：“我会搬到你家住几天。”
但你不会希望这种情况变成永久的依赖性。我们会交谈、做一些事情等等，但当你在帮助朋友时，你要考虑的是，如何让他们重新站起来？如何让他们做一些能够让他们进步的事情？这也是我希望所有AI设计美学最终会走向的完整方向。显然，我们会有不同的选择，而作为技术发明者、创造者和商业领袖的一部分职责，就是要让这种AI在商业领域中比那些让人安于现状的AI更成功。

**主持人:**
这让我联想到你的一书的结论部分提到的关于未来的暗灰色愿景，正如你所说，我们在很大程度上依赖AI，但这种依赖并不能真正让我们感到快乐。实际上，为什么你对我们能避免这种愿景如此乐观呢？你说投资者会推动这一切，但这并不是我们当前在现实世界中观察到的。如果有一种产品能够带来短期的利益，可能会有人选择另一种方式，他们可能在市场上获胜。那么，你的乐观从何而来呢？

**Reid Hoffman:**
我认为，作为社会的领导者，无论我们是技术发明家、企业家、商业创造者、CEO、投资者、政府官员、媒体人士、学者等等，我们都应该思考如何让我们创造的技术系统随着时间的推移为绝大多数人带来非常积极的结果。我认为，只要我们以正确的方式进行导航，我们有可能通过商业来实现这一点。但如果做不到，我们会以其他方式进行干预。这也是为什么虽然我对AI的批评者们持批判态度，但我并不是说你们不应该提出这些问题。正相反，重要的是要进行公共讨论，看看我们是否在以正确的方式应对这些问题和风险。如果所有人都在说AI会带来美好的一切，我可能会提醒大家我们需要关注某些问题，因为解决这些问题才能实现美好的未来。我的乐观来源于我坚信我们可以做到这一点，虽然这并不保证实现，但这也是为什么我们要进行这些播客和其他讨论的原因。

话虽如此，我对批评者的批评在于，很容易列出一系列关于任何新技术可能带来反乌托邦或负面影响的观点。比如说，最简单的例子是，如果我们向社会领导者提议创建一台超过两吨重的死亡机器，而醉酒的人类可以驾驶它撞倒其他人，可能会造成无辜儿童的死亡，那么社会是否会允许我们推出汽车呢？显然不会。哲学家Paul
Virilio（保罗·维利里奥）曾说过，当你发明了船，你也发明了船难，这确实是事实。但这个格言是不完整的，因为不仅仅是发明船的同时发明了船难，你还发明了航运文明。这就是我们正在经历的过程。批评者应该关注的是，我们正在如何发明文明，我们需要避开的是什么。顺便说一下，避开问题的过程中就像汽车隐喻中提到的那样，可能会发生车祸。事情会发生，但为了更有利的结果，付出小的代价其实是值得的。医学史也充满了这样的例子，比如你想要抗生素吗？医学史的进步并不是一帆风顺的，而是一步步走到今天。

**主持人:** 现在我明白了你的AI乐观立场，它更多的是与过多的批评形成对立，而你坚信我们可以实现这一目标。

**Reid Hoffman:** 是的，我相信我们可以做到。

## 6、对于AI初创公司建议

**主持人:** 说到这个，我不确定现在Inflection的计划是什么，但你作为投资者参与了许多初创公司的咨询工作
那么在当前的情况下，对于那些想要在AI领域做出成绩的初创公司，你通常会给出什么建议呢？我们没有足够的时间来全面讨论这个问题，但我非常愿意深入探讨这一话题。

**Reid Hoffman:**
好的，我们可能以后可以再深入讨论一次。不过首先，一般的创业建议是要有一个明确的“游戏理论”。也就是说，如果你冒了一些初期风险，并成功了，你就能为市场、客户和社会创造出真正有价值的东西。这个“游戏理论”需要明确哪些风险值得去冒，你如何应对这些风险，产品或服务的创新之处是什么，为什么你能够与竞争对手区分开来，无论是小型企业还是大型企业。你是否能够在你的资本和时间范围内实现这些目标？你是否有从小到大逐步扩展的明确计划？这些都是一般创业智慧的一部分，而这些智慧会以特定方式应用到AI领域。

例如，在Inflection这边，我们意识到前沿模型的代理人将在几百万美元的投资下迅速训练成型，但在商业模式尚未明朗之前，就需要我们在初创阶段制定出一个商业模式。因此，我们做了一个转型，开发了一个独特的模型，这个模型具备与GPT-4相当的水平，并且在情商和其他方面表现出色，比大多数其他模型都要好。我们将其作为一个AI工作室的一部分，供众多创业者使用，但不再继续训练模型。另一方面，Mustafa和Karen等人想继续开发人类个人智能助手，类似于微软的“副驾驶（COpolit）”助手，它可以帮助个人在所有事务中使用。因此，这就是我们在创业初期面临的一个导航问题，你需要在不同阶段给出不同的建议。总体来说，作为初创公司，你必须找到一个独特的竞争点，虽然不一定要100%独特，但至少要有一个明确的理论，说明为什么你会成功。

另一个看待创业的方法是，在理想情况下，创业项目在第一天看起来可能会显得疯狂；在两到三年后，看起来则会变得可信；在三到五年后，它会显得显而易见。这就是创业时间窗口内的玩法。因此，当你在评估这些AI创意时，要看它是否符合这些特点。当然，由于目前对AI的兴趣非常高，0到2年内可能不会显得那么疯狂，但仍然应该是那种在三到五年后被广泛认为显而易见的项目，并且有从小到大的路径可以逐步实现。

**主持人:**
我发现你谈论这些话题时非常有趣的一点是，关于建议的角色以及董事会的作用。正如你所说，你在很多董事会中都有丰富的经验，现在你是微软董事会的成员，之前也曾在OpenAI的董事会，还参与了很多其他公司，比如Airbnb、PayPal等等。你如何在不同的董事会中操作呢？每个董事会都有不同的风格吗？你每次进入不同公司的董事会会议时，是否需要假设一个不同的角色？

**Reid Hoffman:**
一个董事会是一个团队，它有一套不同的功能和目标。这些功能包括与股东的合同，合同中还包括员工、社会和它所运营的行业。然后问题就变成了，团队中的不同成员应该做什么，以及我们如何最好地执行这个合同。我记得在加入PayPal董事会一年后，我突然意识到，人们并没有以足够的第一性原理思考这个问题。关于董事会是如何运作的、合格的董事会成员需要具备什么样的素质等问题，都需要写一本或多本书。

例如，很少有董事会成员遇到过如何解雇董事会成员的问题。而我是少数几个曾经解雇过董事会成员的风险投资家之一。这不仅仅是说‘哦，是的，他们给员工提供毒品，当然你要解雇他们’，而是说，即使他们是非常优秀的专业人士，但如果他们不适合这个董事会，你仍然需要考虑解雇他们。这就引出了一个关于董事会“皇帝的新衣”式的情况。比如，非常有远见的Netflix前CEO
Reed Hastings
会告诉你，董事会的主要职责是雇用、解雇和为CEO提供薪酬。好吧，我们可以看看所有的公共董事会成员，评估他们在雇用、解雇和薪酬方面的能力。大多数董事会成员在CEO薪酬方面可能会得到一些咨询帮助，但在雇用和解雇CEO方面，他们可能并不具备足够的经验。通常的做法是，把曾担任过CEO的人安排到董事会中，因为如果你什么都没有，曾经担任过CEO的人可能比普通人更能理解如何雇用和解雇CEO。因为你曾经是CEO，你曾经做过这份工作，但这实际上并不是完整的故事。为什么我会了解到这些，因为我开始我的董事会生涯时是作为独立董事，而不是作为风险投资家。你需要那些在这个角色上反复扮演过多次，并且对在什么情况下雇用和解雇CEO有深刻理解的人，这是大多数董事会成员实际上并不太了解的，而这是最基本的事情之一。

### 7、公司董事会职责和义务

**主持人:** 所以你的角色就是董事会中那个负责解雇和雇用CEO的人，或者解雇其他董事会成员的人吗？你如何看待自己在董事会中的角色呢？

**Reid Hoffman:**
我会环顾四周，思考我在这个董事会中的角色应该是什么，然后与董事会成员和CEO达成一致，比如“这是我认为我们角色应该发挥的方式”。例如，在微软的董事会中，我的主要角色显然是与CEO和其他高管们密切合作，制定技术战略。当董事会成员有技术方面的问题时，他们通常会先找我，因为在每次董事会会议之外，我都会花一天时间与不同的产品团队会面，讨论他们正在进行的工作。显然，很多是AI方面的工作，但这些年来还有其他的内容。部分原因也是为什么微软重新制定了其浏览器战略，因为我告诉萨提亚（Satya
Nadella），现有的浏览器战略行不通。他说，好吧，我们成立一个团队，你能和这个团队见面吗？我当然愿意，这也是我在董事会中角色演变的一部分。

但这就是为什么我没有回避给出明确答案，因为每个董事会的情况不同。在我参与的董事会中，如果解雇CEO成为必要的事情，到目前为止，每当这种情况发生时，我都是那个执行的人。

**主持人:**
这让我有些害怕，我甚至不确定是否应该继续问下一个问题，但我还是要问。你从OpenAI去年11月的事件中汲取了什么教训？从外部来看，没有内幕信息的情况下，这似乎是一次非常不称职的操作。

**Reid Hoffman:** 我先从简单的部分开始谈，因为这是我自己经历过的。我在纳帕参加一个名为“The Grove”的活动，周四晚上Mira
Murati和我们一起吃晚饭。然后她在晚餐后突然离开了，我们当时就知道发生了一些事情。第二天早上，我们没有见到她。我离开时，我的助理给我看了一篇博客文章，上面写着“我们解雇了Sam，Mira
Murati是我们的临时CEO”。从这件事我知道，他们直到前一天晚餐时间才联系她。没有任何一个合理的宇宙会认为这是一个称职的操作。除非Sam昨天犯了谋杀罪，现在因为谋杀罪被关在监狱里，否则这种操作是完全不合适的。从我们能了解到的信息来看，似乎有些董事会成员认为在与Sam的沟通中，他们没有得到全部真相，这可能是最终的故事。但这与操作方式完全不符，这种处理方式对于OpenAI的使命、对于为人类创造有益的AI、对于组织来说都是极其不称职的。简直让人觉得这些人完全不知道自己在做什么。

还有其他一些事情，我们可以列出一个冗长的清单，说明这个过程中存在的各种不称职之处。我至今还没有与那些董事会成员进行过对话，我也不排斥这种对话，可能在今年晚些时候会有机会与他们交谈。我认识董事会中的每个人，并且实际上认为他们都是好人，所以我很想知道他们当时在想什么。但我从外部观察到的事实是，他们无法说服我相信他们的行为是称职的，除非有一些巨大的核爆炸级别的事实没有浮出水面，这在独立审计调查后也没有被发现，我认为并不存在这样的事实。不过，这并不意味着他们对某些问题的担忧不合理。我曾在一些创业公司董事会中经历过CEO需要改善与董事会的沟通方式的情况，这种对话有时可能像解雇对话一样情绪激烈，因为必须确保从此以后，这方面的沟通不能再出现任何失误。

在组织中，我们之所以赋予CEO如此大的权力、如此高的薪酬，是因为这是一个无借口的角色。你可能会犯错误，但如果你仍然是最合适的人选，你可能会继续留任。但有时候，你需要与CEO进行对话，告诉他们在某些方面绝不能再犯任何错误。这就是理解哪些事情是CEO必须绝对不能失败的内容之一，了解这些内容的董事会成员才能称职。

**主持人:**
说实话，我真的很想与你做一个关于董事会动态的播客。这太有趣了，我非常希望你能与OpenAI的董事会成员进行对话，我也认识其中一些人，并且非常尊重他们，所以我很想知道他们的结论是什么。不过，回到你之前提到的一个话题，你提到自己是一个AI乐观主义者但这更多是因为你认为在当前的AI讨论环境下，乐观主义是我们所需要的，对吗？你提到过，我们会经历一些小的失败，然后逐步解决问题，但许多人担心这些小失败可能并不那么小。这也许就是为什么有很多敏感性存在。所以，Reid，当你戴上AI安全的帽子时，你对这个领域的主要担忧是什么？你最担心的是什么？

**Reid Hoffman:**
总的来说，许多在这个领域的思考者、发明者和领导者，很多人都会关注我所谓的“科幻风险”，比如终结者的风险、超级智能的风险、机器人末日的风险等等。当然，问题在于这些事情并非完全没有可能发生，但顺便说一下，有很多事情也不是完全不可能发生。比如，今年发生核战争的可能性并不是0，或者今年发生人为或自然的流行病导致文明崩溃的可能性也不是0。

**主持人:** 这让我感到不安，但请继续。

**Reid Hoffman:**
是的，当然这些事情是可能的。我之所以如此乐观地看待AI，其中一个原因是，我认为AI还具有积极的一面。去年，有一份由许多OpenAI的人签署的声明，包括Mustafa在内的一些微软的人也签署了。声明的内容是，AI应该被视为与气候变化、流行病等同样的生存威胁。我之所以没有签署这份声明，是因为我认为AI与这些威胁不同，因为AI还有一个积极的方面。而我认为防止人为或自然灾害并减轻生存风险的最佳方法就是AI。所以这并不相同，因为AI还有一个积极的方面。这也是为什么我要强调，我们需要朝着那个方向引导，而不是陷入科幻小说中的恐慌。

科学小说中的风险确实存在，比如机器人可能会到来，但我们也要面对人类的生物恐怖分子将要到来的问题。我们应该怎么做呢？我的主要担忧是AI落入那些有恶意意图的人的手中。可能是疯狂的个人、恐怖组织、流氓国家或者犯罪分子。首先要关注和缓解这些风险。其他的讨论都是好的，但我希望我们首先要解决这个问题。我们可以展开科幻小说式的讨论，比如突然之间，AI在认知上远远超过我们，像我们与一条虫子的关系那样。这是一个令人困惑的世界，是一个有趣的讨论，但很明显我们还没有走到那一步。虽然我们可能会走到那一步，但目前还没有迹象表明这是一个很大的可能性。比如，GPT-4已经展现出某些超能力，它在某些方面比地球上任何一个人类都要优秀。我们会继续增加这些超能力，使得AI能够在越来越多的领域超越人类，但这与超级智能相比还不是一回事。

很多人会误解指数曲线的含义，他们认为这会在达到某个临界点后发生质的飞跃，但实际上，指数曲线往往会变成S形曲线，而每一个J形曲线最终都会到达S形曲线。这也是为什么我认为我们应该首先关注AI在恶意人类手中的应用。我们需要详细思考并不断更新这个问题，在我们解决了这个问题之后，我们可以讨论其他的风险。

**主持人:**
我在OpenAI领导的团队正是试图回答这个问题，研究AI技术的滥用潜力以及如何监控和减轻这些风险。所有伟大的公司都有像你这样的团队，这很好，希望这能为OpenAI的成功做出贡献。

**Reid Hoffman:**
关于那份22字声明，我没有签署，去年还有另一封信，就是暂停AI开发的信——六个月暂停信。我不仅没有签署，还公开批评了这封信。

**主持人:** 是否正是因为你刚才提到的这些原因？如果我没记错的话，你还非常明确地反对了这封信。

**Reid Hoffman:**
是的，我明确反对这封信的原因是，我非常相信交流和真相的重要性。我希望人们能够挑战我，以便我们一起找到真相。所以，我坐下来与这封六个月暂停信的作者们进行了对话，我问他们：“你们写这封信的依据是什么？你们认为会发生什么？”他们说：“我们希望人们会暂停。”我回答说：“好吧，我本以为我要和你们讨论为什么暂停是愚蠢的，为什么继续前进并应对风险是重要的事情。但实际上，我们首先需要讨论的是你们对人类的误解。”因为你们在两点上严重误解了人类。首先，这封信的主要作者认识所有前沿AI组织的领导人，他们本可以打电话与这些人进行讨论，说：“我们有这个担忧，能不能让你们参与进来？即使我们最终还是会发布这封信。但他们没有这样做，而是高调地发表了这封六个月暂停信，令所有人感到意外。他们对这些组织所传递的信息就像是“我们才是真正关心人类的人，我们在乎，而你们不在乎，我们要在公众面前羞辱你们”。当有人这样对待你作为一个人类时，你的正常反应是什么？大概就是“去你的”，你不再会认真对待他们了。你认为他们刚刚烧毁了自己的信誉，特别是在那些像OpenAI一样关心这些问题的人群中。相反，你这样高调地把他们描述成坏人，这种做法糟糕透顶，组织影响力的理论也完全错误。我认为所有策划这封信的人现在对人们关注他们关切的事情的影响力都减弱了。

其次，这是更具博弈论性质的问题，这涉及到你作为MIT教授时可能会思考的事情——这是一个简单的2x2矩阵：人们会听从你的信件，或者不会听从你的信件，接着是减缓进展，或者不减缓进展。那么你认为那些听从信件并减缓进展的人是什么样的人呢？那些人是关心人类的人。而那些不听从信件、不减缓进展的人呢？他们将会创造AI而不关心那些关于人类的担忧。所以，如果你成功地让那些会听从你的人暂停，你实际上对人类的伤害比创造的好处还要大。这简直是一个不必要的巨大错误。

**主持人:** 我并不是要为这封信辩护，我认为他们的希望是，所有人能够协调一致地暂停。但你说得对，这确实反映了他们对人类的看法。

**Reid Hoffman:** 是的，如果你对人类的看法是联合国是一个能够很好地应对每一个全球危机的高效组织，那你可能需要重新思考一下你对人类的看法。

**主持人:** 我总是希望看到最好的一面。作为一个波兰人，我并不这么认为，但我希望我们能够做得比现在更好，也许作为人类，希望我们能够变得更好。

**对了，喜欢就别忘了点赞、收藏、转发支持一下！期待在评论区听到你的观点和看法!**_****_****

* * *

****

# 往期回顾

[1、[打造你的AI赚钱工具：沃顿全球峰会上，商学院教授Ethan
Mollick视频展示如何将免费AI转化为收费服务]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAgDL4bUALwzHXnU4y3TiaIVXo8DT4icA7Lo2G0ZEqQcv7bL7ABKF4ia1UqhcELcnUXtBKOKAwx8GnlTw/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247491882&idx=1&sn=4ddc862cd6cf489469a1f47d5d11a05f&chksm=c00853cff77fdad9023a91beac189d038a02c8b200722cb017f1259de26f64e4f7fff76aeafe&scene=21#wechat_redirect)

[2、[AI时代的职场生存法则：沃顿商学院知名教授Ethan
Mollick解构AI如何改变就业形态,教你应对职场巨变!]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAgDL4bUALwzHXnU4y3TiaIVXKKr9jyN7Ss1iahJWZJb7n4YRHyc56vM8EyLhLMxEPTsKg2fO5oq2TlA/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247491006&idx=1&sn=146fe2b5aa560cdf5d115fc4ea267f07&chksm=c00baf5bf77c264da895a47c21142eaa69c974178a619265cf67d49b551afaf20c78f2446b6d&scene=21#wechat_redirect)

[3、[彭博社完整采访视频：比尔·盖茨谈AI是人类进步的基石，也是数字世界的大变局]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAgDL4bUALwzHXnU4y3TiaIVXpBeCjpk6ELM3V5tm1uicMgtiaGHdHqP1LAGUia7ZBJsf1BtVdoVoe57Dg/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247492066&idx=1&sn=d8db7f5b67c42a05925401ac19c3d3c4&chksm=c0085307f77fda11ef8d0a705f8ba870d786c2a6b56e418591ced56921ec33c86d5d43098e7f&scene=21#wechat_redirect)

* * *

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhtRhTOjz2QwH4dIlC3YUcYbaicMEwjqQqh06Yhdd7EH3r9wiaMRArLz0a6Zhx6uiaUD7hguPfbY0nAg/640?wx_fmt=png&from=appmsg)

****

**我们AI团队将先进科技与创新想法完美融合!**

**想要掌握人工智能，但不知从何开始？告诉我们你的需求，学习AI让你抓住这波技术浪潮**

##  告别昂贵服务和缺人烦恼,再见漫长交付周期

## 无限创意风格,分分钟生成专业级作品

## 感受 AI 带来的全新工作体验！

_**欢迎各大品牌方、媒体、企业和个人等**_

 _**请联系负责人微信：Milo-1101**_

 _**\--END--**_

