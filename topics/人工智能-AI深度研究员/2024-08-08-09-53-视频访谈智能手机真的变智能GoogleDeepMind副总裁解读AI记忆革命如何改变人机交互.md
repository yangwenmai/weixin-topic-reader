# 视频访谈：智能手机真的变"智能"，Google DeepMind副总裁解读AI记忆革命如何改变人机交互

文章作者: AI深度研究员
发布时间: 2024-08-08 09:53
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247492517&idx=1&sn=8190dc15cffae0037d8b46ec43d964a2&chksm=c0085140f77fd856b9c06db845651b11438d607a537e163e2bdf8175ec85c262e7da8fb1d85b#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAialZmcqlzkC1RyqdbKwLdVyCYCNI1I1oSbo1uTMnyemP25Q0311WDFjHvgdjuaJX8u1kiboRp5abYQ/300

**（关注公众号并设为🌟标，获取最新人工智能资讯和产品）**

全文约12,900 字，阅读约需22分钟

在这场人工智能技术革命的前沿，Google DeepMind的研究副总裁Oriol
Vinyals正引领着一支精英团队，推动着AI的边界。作为深度学习团队的负责人和Gemini项目的技术联合负责人，Vinyals最近接受了一次深度专访，分享了他对AI未来的洞察。

Vinyals描绘了一幅令人振奋的未来图景，其中AI的能力已经达到了"超人"的水平。"你只需要对准摄像头，提出问题，就能得到答案，"他解释道。"把几个小时的视频放进去，然后问任何问题，感觉非常超人化。经过短短10到30秒的处理，你就可以询问任何内容。"

这种先进的视觉处理能力只是即将推出的AI模型众多惊人特性中的一个。Vinyals强调，记忆将成为下一代AI的关键组成部分。"你拿起手机，和它互动，就像它是一个具有记忆的智能体一样，"他预测道。这种持续学习和适应的能力将彻底改变我们与技术的交互方式。

在谈到个人职业发展时，Vinyals建议年轻人要有前瞻性思维。"你要思考一下这项事物如何随着AI的发展而变化，并利用这一点，"他建议道。这个观点不仅适用于技术领域，更是对所有行业的警示：适应并拥抱AI带来的变革至关重要。

## 视频时间轴

00:55 Gemini计划及其影响

08:29 无限上下文长度及其应用

14:42 扩展人工智能和奖励功能

31:55 通用模型和专业化的未来

38:14 对 AGI 的思考和个人见解

43:09 下一代会学习计算机科学吗？

## 文稿整理

**主持人：** 大家好，这里是《No Priors》。今天我们邀请到了Google
DeepMind的研究副总裁兼Gemini项目的技术联合负责人——Oriol
Vinyals。他在机器学习领域有着辉煌的职业生涯，包括领导AlphaStar团队，开发出具有专业竞争力并且开创性的《星际争霸》智能体。今天我们非常期待他为我们分享对当前机器学习领域的历史性视角。欢迎来到节目，Oriol。

**嘉宾Oriol Vinyals：** 是的，非常感谢你，Sarah，谢谢你的邀请，也非常感谢你主持我。

### 1、Gemini计划及其影响

**主持人：** 去年对Google和DeepMind来说是充满事件的一年。你能和我们分享一下目前研究工作的组织方式以及你对内部使命的看法吗？

**Oriol Vinyals：**
当然，我很乐意讨论过去这些年研究机构所经历的不同阶段。对于去年，发生了两个重大事件。其一是Gemini项目的成立，这源于Google
Brain和我们现在称之为Legacy
DeepMind的两条并行的大模型（LLMs）开发路径。因此，在去年早些时候，这两个项目进行了合并，由此Jeff和我携手，将两个团队联合起来，创造了第一个Gemini模型，并在年底发布。第二个重大事件是，将所有从事AI研究的组织整合在一起，形成了今天称之为Google
DeepMind的组织，这来自Google Brain和Legacy
DeepMind的再次融合，显然，Gemini是这个组织中一个非常大且非常重要的项目。Gemini的真正目标是创建一个出色的核心模型，以支持当今全球各地的LLMs技术应用，并且我们预期这将显著提升这一领域的发展。

**主持人：** 你如何与公司内部的其他团队进行互动？Google作为一家商业公司，我不得不问一下，你认为AI会取代传统的搜索方式吗？

**Oriol Vinyals：**
从研究的角度来看，这非常有趣。目前有两个主要的研究中心，一个在加州，一个在伦敦，这与我们的团队背景有关。以这种方式运作项目是非常有趣的，因为它让我们能够24/7全天候运行项目，这在训练这些大型模型时非常有帮助。我们需要做一些重要的事情，首先当然是尝试构建最先进的技术，从研究的角度，了解该领域的来源及其未来方向，真正展示我们的直觉和雄心，预测未来的发展。例如，今年早些时候我们发布了长文本处理的技术，现在我们的模型能够处理数百万的token。

但当然，我们也考虑到了不同产品的需求。Google有很多产品领域，因此我们在项目的初期，特别是形成项目时，主要专注于关键项目，这一点可以从Gemini最初如何向用户或企业展示中明显看出。显然，云计算和企业市场非常重要，开发者也是如此，将这些模型交到创意者手中是非常酷的，他们会做出我们未曾预料到的事情。然后，非常重要的一个部分就是曾被称为“Now”或“Jini”应用的产品，它是我们模型的聊天机器人界面。最后，一个非常重要的部分是搜索，它正在尝试将这些技术集成到其产品中，并且拥有大量用户。因此，想到我们在建模时所做的决定，可能只需要几个月的时间就能传递给可能报名测试版的用户，这真是非常令人兴奋。显然，这与公司的核心密切相关，尤其是对于那些需要非常智能的AI系统的产品而言，比如我们今天正在创造的系统。

**主持人：**
你如何看待基于聊天的模型与基于搜索的模型的各种用例？我记得多年前我在Google的时候，许多不同类型的搜索查询被分成了不同的类别，比如导航查询，它们帮助用户找到目标网站；还有强意图的商业查询，你可以将它们分类；以及医疗查询，这样你可以绘制出用户通过搜索界面真正试图完成的各种任务的世界图景。你认为什么会更趋向于聊天，什么仍然属于传统搜索方式的领域？

**Oriol Vinyals：**
我们可能不知道确切的答案，我们有点在尝试中探索。你可以把它看作是一种“LLM优先”的体验，比如聊天机器人。在这个领域中，搜索也有它的角色。因为它可以被视为一种工具，能够增强聊天体验中的答案质量，提供引用，增强可信度。当然，我们知道语言模型有时会出现“幻觉”，所以我们正在从这种“LLM优先”的视角出发来构建新产品。而搜索本身则在拥抱并增强各种查询类型的功能，比如AI总结。不过，我认为今年的Google
I/O已经展示了许多关于搜索和语言模型结合的愿景，其中一些还在测试阶段，反馈也非常重要。不过现在很难说这两者是否会融合，或者其中一个会主导另一个。我觉得目前两者在不同的方式下都显得很有用。作为一个用户，你肯定会同时使用两者。不过，如果搜索是你最初查询并想要研究某些内容的起点，那么这种体验将会因为这些模型而得到极大的增强。所以搜索产品本身也在努力探索如何整合LLM的答案和推理能力等特性。我认为我们会看到很多这样的尝试。我把这种趋势称为从搜索到LLM的整合，当然反之亦然，这也是显而易见的。

作为像Gemini项目这样的核心模型项目，我们保持开放的心态，并不急于选择一个方式或另一个。Google在大规模运营时的一个优势是，我们是构建模型的研究团队，但最终的产品和策略会由其他团队推动，当然也会受到模型能力的影响，并且会从我们这些长期梦想这一世界的人那里得到反馈。不过，有经验的团队与用户和用例反复迭代的过程也很酷，这非常有意义。我认为Google的一个被低估或被遗忘的地方是，它实际上是全球首个AI优先或机器学习优先的公司。无论是在搜索还是广告中，Google的整个产品在最早的日子里都是由AI驱动的。这其中的一部分也是通过用户行为推断用户意图，然后通过算法得出结果。因此，正如你所说的，用户仍然可以继续使用搜索作为主要的用户界面或入口点，而如果它导向更类似于聊天的体验，或弹出一个聊天窗口，那也可以根据用户表现出的意图自然而然地发生。

### 2、无限上下文长度及其应用

**主持人：** 你提到了Google的能力和其他方面的内容，我想问问，与此相关的，你觉得用户或公司与Google AI的互动中，最让你感到意外的是什么？

**Oriol Vinyals：**
有很多例子让我感到意外。也许最让我惊讶的是，最初我认为这只是一个可以报告的数字——无限上下文长度即将到来。我当时想，这很有趣，我们来自一个使用循环神经网络和LSTM的世界，它们实际上拥有无限的记忆，尽管实际效果并不显著。模型在实践中通常只能记住几百个单词左右。因此，首先，我们能够将上下文长度变得如此之长，然后在我们内部首次试用模型时，看到这些用例自然地涌现出来。在事后看来，这似乎非常平凡，但你知道，把一个小时的视频放进去，然后问任何问题，感觉非常超人化。你只需要把视频放进去，经过10秒钟或30秒钟的处理，你就可以问任何问题。

当我们想到计算机视觉领域或视频问答数据集时，它们与我们手中的能力相比显得微不足道。然后我们把它交给开发者，他们展示了令人惊叹的演示和一些人们可以做的事情。即使是你把相机直接对准屏幕，甚至不需要查看代码，只是屏幕上显示的文字，你就可以进行调试。你可以想象未来的界面将是多么轻松。你只需要指向相机，提出问题，就能得到答案。这是一个有趣的研究问题，但也许现在还无法判断它是否有用。我们还在尝试探索这将带来什么，我们展示了Aster计划，在这个项目中，记忆非常重要，你拿起手机，和它互动，就像它是一个具有记忆的智能体一样。不过在未来几年内，这种技术的实际应用仍然不太明朗。你可以想象整个网络都在上下文中，或者你所有的个人数据都保存在设备中，因为这是模型的工作记忆，而不是应用在很多场景中的权重数据。但目前仍处于早期阶段，这让我感到惊讶，尽管它在某种程度上还没有完全普及或进入主流。然而，当你开始与它互动并意识到你可以随时提出任何问题并得到答案时，确实感觉非常神奇，你不需要观看这些电影或阅读大量的书籍，你可以上传这些内容，然后直接得到答案。

**主持人：**
你认为非常长的上下文窗口在广泛应用中的时间框架是什么？这不仅仅是针对Google的问题，看起来有很多公司正在努力实现这种大规模应用，而且你还看到它出现在生物模型和其他类似领域。所以我有点好奇，这项技术何时能够进入大型企业或消费者的实际用例。比如你提到的，企业可以将所有来自用户设备或交互的上下文数据添加到上下文窗口中，或者企业上传包含大量法律文件的大型文件夹，然后这些文件被纳入查询或其他操作中。如果有类似的对比用例，技术在不久的将来就能大规模部署。当然，硬件也在根据研究进展不断更新。

**Oriol Vinyals：**
当然了，可能需要一到两年时间，这种上下文窗口可能会成为一种常见的商品，并且会在各个方面得到显著增强，可能是10倍左右。然后，极长的上下文窗口，我认为将会是一个从研究角度推动的动力，最终大规模部署。一些技术，比如层次化记忆等，已经被探索过了，甚至像缓存（rack）这样的技术也很常见。所以我们将会结合这些技术，利用实际用例。我预计在一到两年内，你会看到我们从当前的最先进技术迈上另一个数量级，当然这也将成为一种常见的技术。我非常确信这一点，这当然需要找到合适的用例来服务于需要更多记忆的模型。当然，这其中也有一些技术上的限制，但如果有足够的动机，这些问题很快就会得到解决。

**主持人：** 在即将到来的无限上下文时代，检索架构和更层次化的记忆结构的相关性如何？从效率的角度来看，这显然仍然是非常相关的，你怎么看待这个问题？

**Oriol Vinyals：**
我认为，效率这个观点无疑是支持层次化记忆的理由之一，这可以让上下文变得更长，这非常有意义。甚至仅仅从学习和记忆检索的效率来看，这种粗略到精细的方式，就像我们人类这样智能的生物可能会做的事情，也很有道理。因此，我认为即使从质量的角度来看，这种解决方案也是有动机的。不管怎么说，我们在检索方法方面有很多经验，特别是在Google，我们也将它们与基于神经网络的方法结合在一起。我认为这只是时间问题，我们需要完善细节和用例。当然，检索方法的问题在于它们往往会简化问题，比如把整本书简化为一个向量，而如果你只是把整本书上传到Gemini模型中，并提出问题，它实际上可以对每个单词进行推理。所以，可能需要为不同的用例找到中间地带。不过在我看来，这更像是一种功能，而不是缺点。我们未来可能会有一个混合模式，而研究将会以这种方式推动发展。

**主持人：** 你如何看待当前的这个时间节点，就目前最先进的大模型（LLM）所面临的最大限制是什么，以及未来值得研究的方向是什么？

**Oriol Vinyals：**
有一点我之前就和一些早期参与者讨论过的反思是，他们说，准备好吧，当这个领域进入主流时，数以亿计的人将涌入这个领域。你现在确实能看到这种情况，开源和一些随机搜索等现象出现。这不是选择偏差，而是有人做了某些随机的事情，但人们却真正需要它，然后它就以某种方式变得病毒式传播。我认为这个领域的庞大规模是我们早就预料到的一个方面，但对我来说，这是我看到的最大的变化之一，有更多的人才、更多不同背景的人涌入这个领域。这与数据和计算规模的扩大以及算法进步密切相关，当然这些方面在过去的10到20年里确实发生了一些重要的变化。然后是软件的可访问性，以及开源的努力。这些因素对于创造我们现在在对数尺度上看到的指数或线性趋势起到了非常关键的作用。回到我对这个领域的看法，也许我把2010到2020年称为“深度学习时代”。在那个时代，所做的一件正确的事情是利用了一组通用的算法，比如随机梯度下降（SGD）、深度学习神经网络、强化学习等。你可以把这些看作是一些通用的配料，这些算法随着时间的推移在不同领域得到了扩展，但它们本质上是相同的。你只需将它们应用到某个领域，你就能在那个领域取得非常好的效果。

例如，我们在围棋上取得了突破，赢得了ImageNet挑战，达到了语音识别的最先进水平，图像生成技术也达到了最先进的水平。所以在那个十年中，模型本身不是通用的，但算法是通用的。你可以采用相同的算法，然后更改数据集，并做一些调整，最终你会在例如蛋白质折叠问题上取得很大的提升。这一伟大的洞见来自于我们意识到——这对我们来说是一个幸运的因素——建模语言竟然是一个如此强大的通用抽象工具。当然，特别是在GPT-2论文发布后，摘要中提到，通过建模语言，你可以解决每一个任务，而不仅仅是一个任务。然后通过不断完善这一点，整个领域积累了多年的研究成果，创造了不仅算法可重用，模型本身也变得通用了。这就是为什么我认为AGI（通用人工智能）正在逐渐接近。我们首先在2010到2020年间拥有了强大的模型，现在我们有了通用模型。我认为，多模态能力的最近突破也非常令人惊叹，这些技术不仅扩展到语言，还扩展到视觉、声音、视频等领域。

这意味着我们拥有了非常强大的通用模型，从AGI定义的角度来看，这些模型已经开始具备许多必要的特征。模型的推理能力已经存在，但我认为我们还没有完全做到让推理非常清晰和准确，以至于这些模型不会出现“幻觉”或错误。例如，模型可能能够解决一个奥林匹克数学问题，但在处理一个非常简单的谜题时却会失败。我认为模型的推理步骤，还有很多想法、经验和算法进展需要进一步完善。尽管在过去几年中，我们在搜索等领域取得了一些进展，但还没有完全达到完美。当然，接下来的问题是，在某些领域继续推进前沿研究，至少我们已经走了很长一段路。我认为投资是必要的，幸运的是，这些模型正在变得有用，所以现在用于训练模型的资源有了良性的反馈循环，特别是来自最大的企业。作为研究人员，我们当然欢迎这种情况。

### 3、大模型的推理能力

**主持人：** 拥有推理能力和拥有清晰准确的推理能力之间的区别是什么？

**Oriol Vinyals：**
有时这种区别在于概率地解决问题。当前的模型会对每个词序列分配一个概率质量，简化来说，不考虑多模态，仅考虑词序列。模型会为每一个词序列分配一个概率分布，因此你当然会吸收互联网上的所有知识，然后围绕如何遵循指令、与人类对齐来优化这些模型。但你仍然有一个概率分布会为某些不正确的东西分配非零概率，尽管在语言中，有很多种正确表达同一个意思的方法，这也是为什么这些模型如此出色。

最终，这些模型是非常高效的方式来整合所有可能的词序列。现在，假设你在面对一个难题时，比如一个需要深入知识的问题，你可能达到95%的准确率，但当然，尽管错误率很小，如果这些模型被部署到全球范围内使用，你仍然会看到这些错误。因此，有一种想法是，你只需不断扩大模型规模，继续改进算法，直到错误的概率消失为止。我们显然会继续探索这些问题，但为了加速进展，你需要开始真正探索模型的推理过程，并通过使其更加冗余、更具逻辑性来迭代这些想法。你可以想象生成一个非常小的程序，这个程序由语言模型作为核心，虽然运行速度较慢，但最终能够达到99.9%甚至更高的精度。当然，作为一个有雄心的实验室，我们会同时进行这些尝试。不过，清晰准确的推理意味着错误概率的减少。我们可以投入更多的计算资源，人类会犯错误，会感到疲劳等等，但这些模型非常强大，我们可以投入更多的硬件资源进行推理。因此，希望在这个意义上，这些模型至少可以和人类一样好。

**主持人：**
一个理解这个问题的方法是，即使是DeepMind或任何大型实验室，或者说整个世界，能用于解决这个问题的计算资源都是有限的。似乎在训练阶段和推理阶段的计算资源分配上，尤其是在测试时搜索或你提到的一些技术方面，发生了显著的变化。你对未来两三年内，训练和推理阶段的计算资源分配比例有什么预测？

**Oriol Vinyals：** 我们都希望能够验证并实现Richard
Sutton的“痛苦的教训”。“痛苦的教训”指出，作为计算机科学家，你只需要扩展学习和搜索的规模就行了。这虽然具有争议性，但我作为一个深度学习者，内心对此并不反对。最近，我们已经在学习的可扩展性方面进行了大量测试，并取得了显著进展。而在没有完美奖励的情况下进行搜索，这是我们在语言领域面临的一个关键问题之一，也是当前的一个研究领域。如何为某些陈述分配适当的奖励？这甚至是你我之间可能无法达成一致的问题。

例如，天空是蓝色的吗？我不知道，晚上它不是蓝色的。这是一个很有趣的点。在游戏中，我们需要为某些行为赋予真或假的值，这在这里并不适用。历史上，如果你看AlphaGo，它实际上非常紧密地遵循了这样的配方：你先在所有人类数据上预训练模型，然后使用强化学习来提升模型，最后在推理时进行一些搜索。在这个过程中，大部分的计算资源都用于中间的强化学习阶段，即我们当时称之为自我提升循环的训练。如果你看今天的情况，这显然不是这样。现在，大部分计算资源用于预训练。实际上，你会发现模型在某些情况下会过拟合，所以你不得不停止强化学习过程，以避免模型对不完美的奖励函数进行对抗性搜索。因为你有一个人类偏好的数据集，模型可能会突然发现“嘿，你可以发很多表情符号，这个奖励函数认为这很好”，显然我们面临的一个问题是奖励函数不如围棋或国际象棋中的那么准确。

然后还有第三个组件：现在你已经训练好了模型，你会允许它在推理阶段进行多少推理？以AlphaGo为例，当然规则规定了一局棋大约需要四个小时的计算时间，所以我们知道推理时间是有限的。当然，我们使用了并行计算等技术，但用于推理的计算资源显然没有训练时那么大。所以对我来说，这种平衡是正确的：在预训练上花费一些资源，在学习每个任务时，这可能高达50%，而不是像今天那样超过90%，然后剩下的大部分资源用于强化学习或如果我们能够获得好的奖励函数，这将是下一个可能需要更多计算资源的部分。推理阶段的计算资源较少，虽然不至于非常慢，除非你要求模型解决蛋白质折叠问题，那可能需要一个月的时间才能得到结果。不过几秒钟的推理时间对于大多数应用来说是可以接受的。这可能只是相对于训练阶段计算资源的一小部分，当然你需要为数十亿用户提供查询服务。这意味着研究尤其需要在强化学习的中间步骤上进行深入探索，因为目前这个领域仍然处于相对早期的研究阶段。

### 4、扩展人工智能和奖励功能

**主持人：** 你如何看待将奖励函数扩展到游戏之外的其他领域，一旦模型达到了超越人类的表现，我想到的是一些像Med-Palm
2这样的旧模型，它们在输出结果上已经超越了人类医生的专家小组，那么显然可以通过与医生专家的后期训练来继续改进，但在某个时刻，机器将比人类更优秀，那么你如何继续扩展奖励函数呢？

**Oriol Vinyals：**
传统上，奖励函数就是监督学习，对吧？奖励函数意味着好或坏，所以我们可以像以前一样扩大这一过程。当然，许多玩家都意识到了人类标注的力量，实际上，深度学习之所以能够取得进展，得益于类似于FA和Lab这样的团队努力标注了上百万的样本数据。所以，这种扩展方式是一种，但我强烈相信，可能会有一种自举效应，即模型自己变得更擅长评估它们的输出。这实际上可能是强化学习的主要假设之一，至少在我看来是这样。我不是强化学习的专家，但如果检查某件事是否正确比创造解决方案更容易，那么我们就进入了一个有利的局面，因为语言模型将能够更准确地评估自己的样本，然后我们就有了一个强化学习循环，因为我们可以强化那些看起来更有前途的样本，然后模型就会变得更好。因此，使用模型本身作为奖励，这实际上利用了语言的模糊性，这是一个我非常感兴趣的领域。

目前有一个奖励模型的排行榜，其中一些模型使用的名字可能叫生成性奖励模型。我认为这个领域超越了对特定任务的标注需求。当然，我们仍然可能需要特定任务的标注，问题是我们需要多少标签？希望在极限情况下，我们只需要系统从用户那里获得的标签，当用户想要教系统一些新东西时，而不是滥用它。

**主持人：**
我有一个朋友曾经用奈奎斯特取样定理作为一个代理，用来解释一个聪明的人或机器实际上能够推断出比它自己更聪明的东西的智能程度。你知道，这感觉就像你几乎陷入了某种版本的推断之中，定理基本上指出，如果你有一个波的频率，你需要在一定的速率以上进行取样，才能够实际重建这个波。你可以说这是一种学习或智能的形式。因此，你需要足够聪明，才能真正判断自己能有多聪明，对吗？

**Oriol Vinyals：**
是的，我喜欢这个类比。在我本科期间，我深入研究过奈奎斯特定理，这很有趣，因为我们违反了它很多次（笑）。让我们稍微聊一下奈奎斯特定理吧，它大致说的是，如果你想输出某种分辨率或频率，在频域中，你需要以至少该频率的一半进行取样，否则信息就不存在了。你可以看到，如果你进行不足够的取样，你将无法恢复原始频率。然而，看看这些超分辨率生成模型，你输入一个32x32像素的图像，它以某种方式填充了细节，这完全违反了这个原则。我曾与我的信号处理老师讨论过这个问题，当然，这确实是违反了定理，并且它是在“幻想”，但这实际上是在“作弊”，因为事实证明，世界上有某种结构可以被学习，这基本上就是所有这些图像生成模型所做的事情。

回到你的观点，我同意这有点像是一个渐进的过程，在某个时刻，模型可能具备了自我修正的能力。一旦具备了这种能力，你会看到，自举效应就变得微不足道了。当然，这不会在所有领域都普遍适用，但我们肯定会看到其中的一些表现。它不会是非常戏剧性的，而更像是“嘿，这个能力现在出现了”，等等。不过，一旦这种能力出现，你需要有算法来利用它，尤其是那些主要由模型本身驱动的奖励模型。那么，你如何纠正它可能仍然存在的错误？这些都是非常有趣的问题，甚至从产品的角度来看也非常酷。我们都在与这些模型互动，如果它们出错了，你可以说“我不喜欢这个”，模型应该适应。而这也是长上下文在其中起作用的一部分。你有了更长的互动，你可以微调模型为你执行的任务。

**主持人：**
这听起来很有前景，所以你如何实现这些能力，以及其他相关的事情，是该领域许多令人兴奋的未来方向之一。我们在这个领域看到了一种从通用算法到越来越通用模型的进展。我们会看到这种趋势走到多远？DeepMind在特定领域也做了非常出色的工作，比如蛋白质折叠、材料科学等等。我们现在完全进入了通用模型的时代了吗？还是说从语言到音频、视频的进展能够解决剩下的所有问题？你认为还有哪些数据或领域在当前的语料库中没有得到很好地代表？

**Oriol Vinyals：**
你解释得很到位，不过我认为这里涉及到时间和性能层次的问题。当前的模型在蛋白质折叠方面能做得很好吗？也许可以，它们可能会利用网络工具，下载一些软件并解决问题。所以我对通用模型的描述是，它们的性能水平可能不高，但它们在所有领域都能达到大约20%的水平。这种通用性是非常强大的，你希望这20%的水平能够在各个方面相对均匀地提升，因此你不想过度专注于某个特定领域的模型或研究。不过，世界上有许多值得通过专门化来解决的重要挑战。所以我告诉团队和我周围的人，如果问题足够重要，那么我们就应该专门化。我们可能会看到越来越多的从Gemini和这些模型中启动，然后为特定问题找到解决方案的情况。这个模型可能会被专门用于解决蛋白质折叠、核聚变或天气建模等问题。这些都是DeepMind目前正在进行的一些项目。我们最好选择那些对世界重要的领域进行专门化，因为这样我们会更快地取得进展。

当然，可能最终通用模型会超过专门化模型，但那可能还需要一段时间。所以，如果某个问题值得去解决，那就专门化去做吧。我认为我们仍然会看到这种混合模式，虽然越来越多地会从Gemini入手，然后在更狭窄的领域内做出一些惊人的成果。在我看来，这是一种很好的局面，因为将通用模型用于专门领域会形成一个反馈循环。比如说，我们最近在数学领域取得了很大进展，接下来模型可能会利用这些数据或作为奖励模型的一部分，帮助主模型变得更好。所以这是一个非常有协同效应的过程。

**主持人：**
在数学和计算机科学领域，尤其是在游戏或其他受限领域中，有人批评说这些领域的发展可能是个“死胡同”，而不是推动通用推理的进展。尽管这些领域有许多吸引人的属性，比如生成能力和自我验证的能力。你如何回应这种批评？

**Oriol Vinyals：**
这种批评是有道理的，这又回到了奖励函数的问题上。如果你想创造最通用的模型或智能体，事实证明，奖励从来不会由环境完美定义。即使你认为“生存”是一个完美的目标，计算奖励也是极其复杂的。有人可能会说，当你在一些人为的、有趣但不自然的领域中获得这些奖励时，它们可能无法泛化到实际问题。在这种情况下，它确实可能是一个“死胡同”。然而，研究的方式也很重要。以数学为例，我们确实可以获得奖励，但即便如此，也不是那么简单。如果我进行一个简单的计算，比如4+4等于8，这是可以检查的。但当你开始思考“证明这个定理”时，虽然证明要么正确要么错误，但获得一个清晰的奖励信号变得更加复杂，除非你能将其形式化。但在形式化过程中或者在验证数学的引擎中可能会出现问题。

此外，如果我说4+4而不是说8，而是说4+4等于8，这是否正确？你如何检查正确性？你开始引入语言解释。因此，通过尝试解决这些问题，而不是严格地看奖励是否明确，比如你是否赢了，而是说奖励模型需要理解什么是正确的或者大致正确的，看看你写了什么并进行评估。这可能会让你开始走出“死胡同”，进入一个更广泛的领域，即从奖励完全明确的世界走向“什么是真理，什么不是”的问题。这确实相当复杂，所以我认为在这个意义上，取决于你如何解决问题，这绝对不是死胡同。我认为，即使在语言中很难有完美的奖励函数，但随着我们逐渐发现这些更通用的奖励函数，并更好地训练它们，这个领域也会在无意中向前发展。然后这些奖励函数本身将推动模型的发展，并希望某种自我改进循环会出现，比现在更多。

### 5、 对 AGI 的思考和个人见解

**主持人：**
我想你已经提到过，你感觉AGI（通用人工智能）在未来几年内触手可及。关于这一点，或者关于AI的一些其他话题，你是否有一些与主流观点相悖的看法？或者你是否有一些不太被讨论的看法？

**Oriol Vinyals：**
我其实不太喜欢“AGI”这个术语，这有点有趣，因为Shane是公司的联合创始人，他有着非常卓越的远见。最近我和他讨论了AGI的时间线问题。早在2009年，他预测AGI将在2028年实现，这听起来好像很久远，但取决于你如何定义AGI，以及测试的标准是什么。我认为他的预测在当时确实很有前瞻性，虽然从当前的元分析等方面来看，世界似乎也有些认同这一预测，尽管可能还略显悲观。世界的普遍估计是2030年左右。

相反的观点是，我不确定我们是否真的需要达到AGI。我认为它可能不会完全像我们所想象的那样，能够执行与人类认知任务完全相同的工作并达到同等水平。这更可能是一种分布式的能力，这些模型有些可以做到，有些则不行。对我来说，这仍然是值得追求的目标。我们可以看到许多例子，正如我之前提到的，模型可能会破解一个在数学上看似不可能的难题，但随后在某些非常简单的问题上自相矛盾。所以我认为我们需要准备好，不要过于执着于AGI的概念，仍然要解决显而易见的问题，这非常重要，因为这些问题反映了模型中存在的一些深层次问题。然而，我认为AGI可能不是我们追求的最终目标。可能更重要的是理解这些能力的分布，而不是认为某个时刻AGI实现了，而之前没有。

而且，说实话，想要让所有人达成一致也几乎是不可能的。可能会有一些时刻，人们会觉得“现在AGI实现了”，但这并不重要，因为这些模型可以用于许多令人惊叹的事情、产品和研究。自举研究和科学发展是我们当然感到兴奋的事情之一。Google
DeepMind的使命声明中明确包含了科学，这也是至少激励我继续前进的原因。所以我并不特别在意是否严格按照定义来构建AGI，但我理解这是一个很好的目标。我很欣赏有一个明确的目标可以追求，但我认为和往常一样，要与每个人达成一致是很难的。

### 6、2028年AGI实现，你给我们什么建议

**主持人：** 也许最后一个问题，你在相信2028年AGI实现的情况下，是否会以不同的方式生活？

**Oriol Vinyals：**
我在反思这个问题时有点像思考智能手机的普及。比如，孩子们如何面对智能手机的选择？我们没有太多样本或数据点，但很明显，智能手机已经过时了，因为这些技术的更新速度非常快。我的孩子还很小，所以还没到可以尝试像ChatGPT这样的技术的时候。但我认为，这让我们在更人性化的层面上反思自己。在这种意义上，我认为你也会随着环境的变化而适应，就像职业发展中的“扩大规模（指在职业发展中扩大自己的职业领域、能力范围和职责范围）”一样。你知道，随着职业生涯的进展，从个人贡献者写代码到帮助他人找到自己的发展路径，这种转变是非常重要的。所以我认为，借助这项技术，“扩大规模”是一个巨大的机会。

当然，我一直在尝试使用这些工具来弄清楚我在无数个聊天群中发现了什么。我现在在伦敦，所以当我醒来时，加州已经给我留下了大量的消息和需要处理的长文本。因此，当然，从个人角度来说，你也需要弄清楚如何最好地利用这些技术来增强自己。我和一些不太接触技术的人聊过天，我对他们说的是，试着找出如何与这些技术合作，或者将其作为工具来使用，因为我认为这种变化肯定会到来，无论是否有AI。而且我可能会用它，但从创造智能的角度来看，不幸的是，这有点像零样本学习（zero-
shot learning）。所以我们拭目以待吧，下次播客节目时我可能会告诉你进展如何。

**主持人：**
我可以再问你一个问题吗？如果你今天要给有孩子的父母一些建议，你认为他们的孩子应该学习什么？他们10年后上大学时应该专攻什么？他们应该做些什么来为未来的世界做好准备？

**Oriol Vinyals：**
老实说，从学习的角度来看，我觉得总是有你个人激情不能被忽略。很多时候，在早期阶段，你学习深度学习并不是因为它是流行的选择，而是因为我们很多人喜欢做这件事。我个人觉得，我不能给出那种建议，比如找到最热门的职业并基于此做出选择。所以我会调整我的回答，首先肯定要找到你真正热爱的领域，或者你敬佩的人、榜样等等。现在，我要说的是，我其实已经说了好几年了，思考一下这项事物如何随着AI的发展而变化，并利用这一点。当然，并不是每个人都需要了解技术的基础知识，但老实说，就像我之前说的，语言是推动力，所以要理解它的工作原理并不难。我和我姐姐聊过，她是一名老师。我告诉她，她可以用AI来为孩子们的作业创建摘要，比如将所有作业上传，然后生成总结。这种思维方式需要进入许多职业领域。

所以，我的第一个建议是找到你的激情并追随它。其次，真正拥抱今天存在的一些工具。当然，如果你对技术感兴趣，计算机科学是一个很好的方向。另一个非常有前景的方向是找到AI尚未涉足的领域，可能你会训练一些专门的模型，因为这样做可能值得。还有很多机会，我刚刚和一个人聊过关于气候建模的问题。天气建模已经通过深度学习取得了突破，但气候是完全不同的领域，我们只有一个样本，那就是地球，所以这相当棘手。但你可以考虑这些领域，以及如何增强它们。当然，如果你喜欢技术，我认为在未来5到10年内，仍然有很多关于大模型（LLM）及相关研究的工作要做，所以这可能仍然是一个值得研究的方向。如果你进入研究领域，肯定有很多事情可以做。

**主持人：** 非常感谢你参与这次访谈，Vinyals，这次对话非常棒。

**Oriol Vinyals：** 是的，谢谢你的邀请，也感谢你提出的精彩问题。希望下次我在湾区时，我们可以进行一次面对面的访谈。

  

* * *

**喜欢这篇文章吗?别忘了点赞、收藏、转发支持一下!期待在评论区听到您的看法!**

#  往期回顾

[1、[加州大学伯克利教授斯图尔特·罗素演讲：如果我们实现了这一AGI目标，社会将会发生什么样变化？]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAialZmcqlzkC1RyqdbKwLdVy8dPp4kYELN4soJORf3e2hP959ScHOxhSsM0Z9AEQpGWfwTejpBIkHw/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247491513&idx=3&sn=98a45a83acae1d9e390092621636208b&chksm=c00bad5cf77c244a0e0b228d24c5ff4930cf8130981f0bf2f80f8e3cb267a357e2fc62657395&scene=21#wechat_redirect)

[2、[AI之父Geoffrey
Hinton首次公开表示人工智能已经通过图灵测试，这意味着什么？将给我们生活可能的变化？]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAialZmcqlzkC1RyqdbKwLdVyhicUK7kP52wicGBMvwxptXDzLib0h2MkrLia8xo2bydsxF3UIkOeTKOhIQ/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247491598&idx=1&sn=6b3fde6928427dc7efdb78986efe4006&chksm=c00852ebf77fdbfd64809ae7334b814ce06a28018865ab1906155997728b22493ddf49a2aba4&scene=21#wechat_redirect)

[3、[杂志《连线》连载报道：人工智能取代你的岗位？游戏巨头暴雪娱乐已经大量裁员，改用AI进行游戏开发]![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAialZmcqlzkC1RyqdbKwLdVyYFfIzzBEYj8GqkXdHnq8oD9KMsHqI1en9gXzhm2GfV7YLC3o9auItA/640?wx_fmt=png&from=appmsg)](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247492252&idx=1&sn=fbf7e3f98f4c74b0c658325a0f882633&chksm=c0085079f77fd96f3aacfdc8132f19cdea06e9a16f7923c2e5b6babbb5da285dc2271730835b&scene=21#wechat_redirect)

* * *

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhtRhTOjz2QwH4dIlC3YUcYbaicMEwjqQqh06Yhdd7EH3r9wiaMRArLz0a6Zhx6uiaUD7hguPfbY0nAg/640?wx_fmt=png&from=appmsg)

****

**我们AI团队将先进科技与创新想法完美融合!**

**想要掌握人工智能，但不知从何开始？告诉我们您的需求，零成本学习AI让你抓住这波技术浪潮**

##  告别昂贵服务和缺人烦恼,再见漫长交付周期

## 无限创意风格,分分钟生成专业级作品

## 感受 AI 带来的全新工作体验！

 _**欢迎各大品牌方、媒体、企业和个人等**_

 _**请联系负责人微信：Milo-1101**_

 _**\--END--**_

