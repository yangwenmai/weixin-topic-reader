# Nvidia科学家访谈：AI将彻底改变我们的日常生活 - 从智能冰箱帮你网上订菜到自动驾驶汽车接送孩子

文章作者: AI深度研究员
发布时间: 2024-09-19 10:00
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247493214&idx=1&sn=f171958a17a1c72c6fcf08f02a01c1b4&chksm=c00854bbf77fddad54ca27ca011dc3f4903fd33d89bf542d3b1167b5133b38acbeb7c2b203ef#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAgrR2RAjFlfR9JOmFhYf0iag3kEscqOvY8n0RicFFvB2GOFU8MnibnSZhujlpDC4MtLLBFYHLT8r9UkA/300

**（关注公众号并设为🌟标，获取最新人工智能资讯和产品）**

全文约12,000 字，阅读约需28分钟

## 金句摘录

> 未来这些东西都会实现自动化，能够自主决定如何行动

> 我们的世界围绕人类形态设计，先进的人形机器人将能够完成任何人类能做的任务。

> 通用型AI模型将比专用模型更具优势，不仅更强大，而且更易于维护和使用。

想象一下，周一早晨，你不是被刺耳的闹铃叫醒，而是听到智能家居系统温柔的提醒：“早安，李先生。今天晴朗，气温22度。您的第一个会议在9点，考虑到当前交通状况，建议您7点50分出发。”

走进厨房，咖啡已煮好，吐司烤得金黄酥脆。打开冰箱，一个温和的声音提示：“鸡蛋和牛奶快用完了，我已经帮您添加到网上购物清单。您喜欢的有机农场今天有特价，需要订购吗？”

这不是科幻电影的场景，而是英伟达高级科学家Jim Fan描绘的即将成为现实的日常生活。曾在OpenAI实习、师从“人工智能教母”李飞飞的斯坦福博士Jim
Fan，如今在英伟达领导具身智能研究小组GEAR，他的职业生涯堪称传奇。

在接受红杉资本独家采访时，Jim解释道：“人工智能正以惊人的速度融入我们的生活。未来5到10年内，我们将看到智能系统接管大量日常琐事，从家务管理到个人助理服务，甚至交通出行。这不仅是为了方便，更是为了让人们能够将时间和精力专注于真正重要的事情。”

那么，我们的生活具体会发生哪些变化？AI将如何改变我们处理日常事务的方式？Jim提出了机器人技术的“三管齐下”数据策略：结合互联网规模的数据、模拟数据和现实世界的机器人数据。他坚信，在不远的将来，我们有望创造出能够泛化技能、适应各种环境的“基础代理”。

## 核心观点

  1. Jim预计在未来两到三年内，人形机器人领域将迎来类似于语言模型GPT-3的突破性时刻。
  2. 我们的世界本就是围绕人类形态设计的，因此具备足够先进的人形硬件理论上可以完成任何人类能做的任务。他预测我们将看到价格亲民的人形机器人硬件问世，接下来的挑战将集中在开发能够驱动这些硬件的AI"大脑"上。
  3. 机器人的经济价值：从家庭助手到医疗辅助，再到工业生产，人形机器人有望在未来十年内彻底改变我们的生活和工作方式。

  

  

# 视频时间轴

**04:53** 英伟达“GEAR”智能小组

**10:32** 机器人技术的 GPT-3 时刻

**21:59** GR00T拥有自己的芯片

**25:23** 为什么现在选择机器人技术？

**36:28** 对游戏的影响

**42:10** Transformers 的替代架构

# 文稿整理

**主持人:** 从芯片级别的 J 和 Thor 系列，到基础模型项目
Gro，再到我们沿途构建的仿真和实用工具，它们将成为类人机器人以及智能机器人领域的计算平台。因此，他相信说过：“一切能够移动的东西，最终都将实现自主化”，Jim
Fan 的团队负责项目 Groot，也就是你可能在今年 GTC 上和黄仁勋一起看到的类人机器人。我们非常期待向 Jim
询问关于机器人技术的一切，为什么是现在，为什么是类人机器人，以及要解锁机器人领域的 GPT-3 时刻需要哪些条件。

**Jim Fan：******感谢邀请。

##  1、实习生到Nvidia高级科学家

******主持人:****** 我们非常兴奋，今天能够深入了解你在机器人技术和具身智能方面的所有见解。在开始之前，你的个人经历非常吸引人。我记得你是
OpenAI 的第一位实习生？可以和我们分享一下你的个人故事以及你是如何走到今天的这一步吗？

****Jim Fan：**** 当然，我非常愿意与大家分享我的经历。2016
年夏天，有朋友告诉我镇上有一家新创公司，你应该去看看。我心想，反正我也没有别的事做，因为我已经被博士项目录取，那年夏天我很空闲。于是我决定加入这家公司，结果它就是
OpenAI。在 OpenAI 的那段时间里，我们已经在讨论通用人工智能（AGI）的问题了，那是在 2016 年。我当时的导师是 Andrej
Karpathy 和 Ilya Sutskever，我们共同探讨了一个项目，叫做 "World of Bits"。这个项目的想法很简单，我们想构建一个 AI
代理，它可以读取计算机屏幕上的像素，然后控制键盘和鼠标。你可以想象，这个界面是非常通用的——无论是回复邮件、玩游戏还是浏览网页，都可以通过这种方式来完成。这是我在
OpenAI 的第一次尝试 AGI，也是我在 AI 代理领域的第一个篇章。

**主持人:** 我记得 World of Bits 项目，我没想到你也参与了这个项目，真是太有趣了。

******Jim Fan：****** 是的，这是一个非常有趣的项目，它也是一个更大计划的一部分，叫做 OB
Universe。这个平台将各种应用程序和游戏整合到了一个框架中。

**主持人:** 你认为当时的一些突破点是什么？同时，当时在 AI 代理领域面临的挑战又有哪些呢？

******Jim Fan：****** 当时我们主要使用的方法是强化学习（Reinforcement Learning），2016 年还没有出现
Transformer
模型。强化学习在特定任务上是有效的，但它无法推广，我们无法给代理人任何自然语言指令并让它执行各种任务。它可以在我们设计的任务上起作用，但无法广泛适应其他任务。因此，这也引导我进入了我的下一个阶段。我去了斯坦福大学，开始跟随李飞飞教授攻读博士学位。我们开始研究计算机视觉以及具身智能。在我
2016 年到 2021
年的斯坦福时期，我见证了由李飞飞教授领导的斯坦福视觉实验室的转变，从传统的静态计算机视觉（如识别图片和视频）到更具互动性的具身计算机视觉，也就是在交互式环境中，代理人通过学习感知并采取行动。这些环境既可以是虚拟仿真，也可以是物理世界。因此，这便是我博士研究的方向——转向具身智能。博士毕业后，我加入了
Nvidia，并一直工作至今。我将博士论文中的研究带到了 Nvidia，继续在具身智能领域进行探索。

**主持人:** 你目前负责 Nvidia 的具身智能项目 "GEAR" 团队。能否简单介绍一下这个项目的意义以及你们希望达成的目标？

******Jim Fan：****** 好的，我现在共同领导的团队叫做 GEAR，字母是 G A R，代表的是
“生成式具身代理研究”（Generative Embodied Agent
Research）。简单来说，我们团队的工作可以用三个词概括：生成动作。因为我们构建具身智能代理，这些代理会在不同的环境中采取行动。如果这些动作发生在虚拟世界，那就是游戏
AI 和仿真；如果这些动作发生在物理世界，那就是机器人技术。实际上，今年三月的 GTC 上，黄仁勋 在他的主题演讲中发布了一个项目，叫做 “Groot
项目”，这是 Nvidia 对类人机器人基础模型的一个大胆尝试。而这正是 GEAR 团队现在的重点：我们想为类人机器人甚至更广泛的领域构建 AI 大脑。

**主持人:** 你认为 Nvidia 在构建这一技术时的竞争优势是什么？

******Jim Fan：******
这是个很好的问题。首先当然是计算资源。这些基础模型需要大量的计算资源来进行扩展，而我们相信扩展规律的有效性。过去的模型，比如
LLM（大型语言模型）有其扩展规律，但具身智能和机器人技术的扩展规律还没有被充分研究，因此我们正在致力于此。Nvidia 的第二个优势在于仿真技术。在成为
AI 公司之前，Nvidia 是一家图形公司，因此 Nvidia 在物理仿真、渲染和 GPU
实时加速方面有着多年的经验。我们在机器人技术的开发过程中大量使用仿真技术。

**主持人:** 仿真策略确实非常有趣。为什么你认为大多数行业仍然非常注重使用真实世界的数据，而你们采取了相反的策略？

******Jim Fan：****** 我认为我们需要所有类型的数据。单靠仿真数据或真实世界的数据都是不够的。在 GEAR
团队，我们将数据策略大致分为三个部分。第一个是互联网规模的数据，比如所有线上文本和视频；第二是仿真数据，我们利用 Nvidia
的仿真工具生成大量的合成数据；第三是真实机器人数据，我们通过远程操作机器人来收集这些数据。我相信，一个成功的机器人战略将涉及到三种数据的有效结合与利用，并提供一个统一的解决方案。

## 2、机器人发展阻碍

**主持人:** 你提到数据是机器人基础模型发展的关键瓶颈，能否再详细谈谈这个想法？要打破这个瓶颈，打造优质数据需要做些什么？

******Jim Fan：******
正如我之前提到的三种数据，它们各有优劣。互联网数据是最具多样性的，包含了大量的常识。比如，网上的大多数视频都是以人为中心的，因为我们人类喜欢自拍，喜欢记录自己进行各种活动。还有许多教学视频可以帮助我们学习人类如何与物体互动，以及物体在不同情况下的表现。这为机器人基础模型提供了常识性前提。但是，互联网数据并不包含行动信息，我们无法从网上下载机器人的运动控制信号。

因此，接下来就是仿真数据。在仿真中，你可以拥有所有的动作，并观察这些动作在特定环境中的后果。仿真的优势在于它的数据是无限的，随着计算资源的增加，数据量也随之增加。此外，仿真数据可以实时加速，如果仅从真实机器人收集数据，那你每天只能收集24小时的数据，而仿真则可以通过
GPU 加速，实际收集速度可以达到 10,000
倍。因此，仿真能够以更高的吞吐量收集数据。不过仿真的缺点在于，无论图形管线多么先进，仿真数据始终存在“仿真-现实差距”（sim-to-real
gap），仿真的物理效果和现实世界总会有不同，视觉效果也无法完全逼真，同时仿真内容的多样性也无法匹敌现实世界中的各种场景。接下来是来自真实机器人的数据。真实数据没有仿真与现实的差距，因为它们是在真实机器人上收集的。但它们的收集成本更高，因为你需要雇人来操作机器人，收集速度也受限于现实时间（一天24小时）和人力资源。因此，我们认为这三类数据各有长处和短处，成功的策略在于将它们的优势结合起来，同时消除各自的缺点。

**主持人:** 在今年 GTC 的舞台上展示的那些可爱的 Groot
机器人真的让人印象深刻。如果要设想你们团队在接下来一到五年、甚至十年内的梦想成就，你认为你们会达成什么目标？你对机器人基础模型的未来发展有什么期望？你认为我们多久能看到突破？

******Jim Fan：******
这是纯粹的猜测，但我希望我们可以在未来两到三年内看到机器人基础模型的研究突破。这就是我们所说的“GPT-3时刻”在机器人技术中的体现。不过之后的情况有些不确定，因为要让机器人真正进入人们的日常生活，除了技术之外，还有很多其他的因素需要解决。机器人需要价格实惠且能够大规模生产，我们还需要考虑硬件的安全性、隐私保护以及相关的法规。这些因素的实现将需要更长的时间，才能让机器人进入大众市场，所以这个时间点难以预测。但我确实希望在未来两到三年内能够看到研究上的突破。

**主持人:** 你认为什么能定义机器人领域的 GPT-3 时刻？

******Jim Fan：******
这是个好问题。我喜欢将机器人技术分为两套系统，系统一和系统二。这是来自《思考，快与慢》这本书中的概念，系统一指的是无意识的、快速的低级别运动控制，比如当我抓起这杯水时，我不会每毫秒都去思考如何移动手指尖，这就是系统一。而系统二则是缓慢且有意识的推理和规划，它更多使用我们的大脑能力。我认为
GPT-3
时刻会出现在系统一领域。我最喜欢的例子是“打开”这个动词。想象一下“打开”这个词的复杂性：打开门和打开窗户不同，打开瓶子和打开手机也不同，但对于人类来说，我们很容易理解“打开”在不同情况下的含义以及相应的动作。然而，目前还没有看到能够在低级别运动控制上对这些动词进行泛化的机器人模型。所以我希望能看到一个模型，能够理解这些动词的抽象意义，并能在各种场景下进行泛化——这对人类来说是理所当然的，但我们还没有看到类似的机器人模型。我希望这种突破能够在未来两到三年内实现。

**主持人:** 那么系统二的推理呢？你认为我们如何才能实现这一步？你觉得 LLM 世界中的推理努力在机器人世界中也有相关性吗？

******Jim Fan：******
绝对有相关性。我认为对于系统二，我们已经看到了非常强大的模型，能够进行推理、规划，甚至编程。我们已经看到了一些先进的 LLM
模型在这方面的表现。但如何将系统二模型与系统一整合，是另一个研究挑战。问题在于，机器人基础模型是采用一个单一的整体模型，还是采用某种级联方法，其中系统二和系统一模型是分开的，并通过某种方式进行通信？我认为这是一个开放性的问题。两者各有优缺点，比如单一模型的优点是简洁，仅需维护一个模型和一个
API，但同时也更难控制，因为系统二模型的控制频率较低，比如每秒做一次决策（1Hz），而系统一，比如我抓起水杯时的运动控制，可能需要每秒进行上千次的微小肌肉决策（1000Hz）。要在同一个模型中同时编码这两种行为非常困难。因此，或许采用级联方法会更好。但问题是系统一和系统二之间如何通信？是通过文本，还是通过某些潜在变量？这仍不清楚，我认为这是一个非常令人兴奋的研究方向。

**主持人:** 你觉得系统一的突破会通过扩展和 Transformer 实现吗？还是更多地依赖希望与尝试？

******Jim Fan：****** 我当然希望我之前提到的数据策略能够让我们实现突破。因为我觉得我们还没有完全挖掘出 Transformer
的潜力。Transformer 的本质是接收输入的 token，输出 token，最终这些 token
的质量决定了模型的质量。而对于机器人技术来说，正如我之前提到的，数据策略非常复杂。我们不仅需要互联网数据，还需要仿真数据和真实机器人的数据。一旦我们能够扩大数据管道，收集到高质量的动作数据，我们就可以将这些数据进行
token 化，然后传递给 Transformer 模型进行压缩和处理。我觉得我们还没有真正将 Transformer
推到极限。一旦我们弄清楚数据策略，并能够在数据量和模型规模上进行扩展，我们可能会看到一些涌现的特性。对此，我称之为具身智能的扩展规律，而这才刚刚开始。我对未来充满乐观，相信我们终会达到目标。

**主持人:** 我很好奇，当我们实现这个目标时，您个人最兴奋的是什么？您认为在哪些行业或应用场景中，机器人技术会彻底改变世界？

******Jim Fan：******
有几个原因促使我们选择类人机器人作为主要的研究方向。首先，世界是围绕着人类的形态设计的。无论是餐厅、工厂、医院，还是各种设备和工具，都是为了人类的身体形态和双手设计的。因此，理论上，只要类人硬件足够好，它应该能够完成任何普通人类可以做到的任务。虽然今天的类人硬件还不够成熟，但我相信在未来两到三年内，类人硬件生态系统将会完善，我们将拥有价格实惠的类人机器人硬件。而接下来的问题将是
AI 大脑的开发，也就是如何让这些类人硬件运作。一旦我们能够构建一个 Groot
基础模型，可以接受任何语言指令并完成任何普通人类可以做到的任务，我们就能释放大量的经济价值。我们可以在家中拥有机器人，帮助我们完成日常家务，比如洗衣、洗碗、做饭，或者照顾老人。我们也可以在餐厅、医院和工厂中使用它们，协助完成各种任务。我希望这一切能在未来十年内实现，但正如我之前提到的，这不仅仅是技术问题，还有很多技术之外的因素需要解决。

## 3、机器人行业的前景

**主持人:** 除了这些原因，你们还选择专攻类人机器人的其他原因是什么？

******Jim Fan：******
确实还有一些更实际的原因，特别是在训练流程方面。网上有大量关于人类的中心化数据，所有视频都围绕着人类展开，比如人们日常的任务和娱乐活动。类人机器人形态最接近人类形态，这意味着我们利用这些数据训练的模型能够更容易地迁移到类人形态的机器人上，而不是其他形态的机器人。比如，关于机械臂和夹持器的视频相对较少，而关于人类用五指双手操作物体的视频则非常多。因此，对于类人机器人来说，训练可能会更容易。一旦我们完成这一步，我们就能更好地将其专门化到机器人手臂等具体的机器人形态上。这就是我们首先瞄准通用性的原因。

**主持人:** 我之前不知道这一点，所以你们现在主要专注于训练类人机器人，而不是机器人手臂或机器人狗之类的吗？

******Jim Fan：****** 是的，对于 Groot
项目，我们目前主要聚焦于类人机器人。不过，我们正在构建的训练流程，包括仿真工具和真实机器人的工具，这些工具是具有普遍适用性的，未来也可以适应其他平台。

**主持人:**
你刚才多次提到“通用性”这个词。我知道一些机器人领域的专家认为，通用方法行不通，必须要针对特定领域或环境进行优化。你为什么选择追求通用方法？你觉得
Richard Sutton 的“苦涩的教训”（bitter lesson）在机器人领域是否同样适用？

******Jim Fan：****** 绝对适用。首先，我想谈谈我们在自然语言处理（NLP）领域看到的成功案例。在 ChatGPT 和 GPT-3
之前，NLP 世界有很多不同的模型和流程，分别应用于不同的任务，比如翻译、编程、数学运算和创意写作。它们各自使用不同的模型和完全不同的训练流程。但
ChatGPT 出现后，一切都被统一到了一个模型里。在 ChatGPT 之前，我们称这些为“专家模型”，而 GPT-3 和 ChatGPT
则是“通才模型”。有了通才模型之后，我们可以通过提示它们、提炼它们，并将它们微调到具体的任务上。我们称这些为“专才通才”。历史趋势几乎总是显示，专才通才远比原来的专家模型强大得多，而且它们更容易维护，因为只需要一个输入输出文本的
API。

我认为我们可以从 NLP 领域的成功经验中汲取教训，机器人领域也会遵循同样的路径。目前在 2024
年，我们所看到的大多数机器人和应用程序仍处于“专家阶段”，它们有专门的机器人硬件，用于特定任务，收集特定的数据，并使用特定的流程。但是，Groot
项目旨在构建一个通用的基础模型，首先应用于类人机器人，之后可以泛化到各种不同形式或结构的机器人上。这就是我们所追求的“通才时刻”（generalist
moment）。一旦我们拥有了通才模型，就可以通过提示它、微调它、精炼它，进而将其应用于具体的机器人任务上，也就是所谓的“专才通才”。但这只有在我们拥有通才模型之后才会发生。在短期内，专注于专家模型更容易，因为它们专注于非常狭窄的一组任务，因此可以更快看到成果。但在
Nvidia，我们相信未来属于通才模型。虽然开发通才模型需要更长时间，并且需要解决更多复杂的研究问题，但这是我们首先要追求的方向。

**主持人:** Nvidia 构建 Groot 项目的另一个有趣之处是你之前提到的，Nvidia 同时拥有芯片和模型本身。你认为 Nvidia 在优化
Groot 项目时，利用自己芯片的优势有哪些值得关注的地方？

******Jim Fan：****** 是的，在三月的 GTC 大会上，Jensen 还发布了下一代边缘计算芯片，叫做 Jetson
Thor，这款芯片实际上是与 Groot 项目共同发布的。我们的想法是向客户提供一个全栈的统一解决方案——从芯片层面的 Jetson 和 Thor
系列，到基础模型 Groot
项目，以及我们在此过程中构建的仿真和实用工具。它将成为类人机器人以及智能机器人整体的计算平台。我想引用黄仁勋的一句话，这是我最喜欢的，他说：“一切能够移动的东西，最终都将实现自主化。”我也相信这一点。虽然现在还未完全实现，但如果我们相信十年或更长时间后，智能机器人会像
iPhone 一样普及，那么我们现在就得开始构建这一切。

**主持人:** 你们的研究中是否有一些特别的成果想要分享？有什么成果让你们对所采用的方式充满乐观或信心吗？

******Jim Fan：****** 当然可以提到我们之前的一些工作。其中一个让我非常满意的工作叫做
Eureka。在这个项目中，我们展示了一个五指机器人手如何进行“转笔”的演示，这对我来说是超人级别的，因为我早就放弃了转笔这个技能（笑）。我自己做不到，但这个机器人手却可以做到。我们训练这个机器人的方法是通过提示
LLM 来编写 Nvidia 的仿真 API 代码，称为 Isaac Sim API。LLM
输出的代码用于奖励函数。奖励函数基本上是对我们希望机器人执行的理想行为进行规范。当机器人执行正确时会获得奖励，执行错误时则会受到惩罚。通常情况下，奖励函数是由人类专家设计的，通常是对
API 非常了解的机器人学家。这是一项非常专业化的工作，设计奖励函数本身就是一项非常繁琐且手动的任务。而 Eureka 项目通过 LLM
自动化了奖励函数的设计，能够指导机器人执行非常复杂的任务，比如转笔。这个技术是通用的，我们计划将其扩展到不仅仅是转笔，还可以为各种任务设计奖励函数，甚至生成新的任务。这为我们未来的发展提供了很大的空间。

**主持人:**
为什么你认为现在是机器人技术的关键时刻？我记得五年前，有些研究人员在尝试让机器人手解决魔方等任务，似乎那时的机器人技术进入了低潮。而在过去的一年左右，这个领域似乎再次升温。你认为现在有什么不同吗？是什么让大家重新投入机器人技术？

******Jim Fan：******
我认为现在有几个关键因素有所不同。首先是机器人硬件。自去年底以来，我们看到了机器人硬件生态系统中的爆发式增长。有公司像 Tesla 开发的
Optimus，还有 Boston
Dynamics，以及很多初创公司。我们看到越来越多的硬件变得更加可靠，比如更好的手指灵活性、全身稳定性等。第二个因素是价格。我们还看到类人机器人的价格和制造成本显著下降。早在
2001 年，NASA 开发了一个名为 Robonaut 的类人机器人。如果我没记错的话，当时每个机器人造价超过 150
万美元。而最近有一些公司能够将全功能类人机器人的价格定在大约 3
万美元左右，这个价格大致相当于一辆汽车的价格。同时，制造业中有一个趋势，即成熟产品的价格会趋向于原材料成本。对于类人机器人来说，其原材料成本通常只占汽车原材料成本的
4%，所以我们可能会看到类人机器人的成本进一步下降，在接下来的几年里价格甚至可能呈指数下降。这使得这些先进的硬件越来越便宜，这是我认为类人机器人开始获得动力的第二个原因。

第三个原因是基础模型的发展。我们现在看到 GPT、Claude 和 LLaMA 等前沿模型很好地解决了系统二的问题，即推理和规划部分。这些 LLM
模型能够泛化到新的场景中，并且可以编写代码。实际上，我之前提到的 Eureka 项目就利用了这些 LLM
的编码能力来帮助开发新的机器人解决方案。此外，还有大量多模态模型的兴起，它们提高了计算机视觉和感知能力。这些成功鼓励我们继续追求机器人基础模型，因为我们认为可以利用这些前沿模型的泛化能力，然后在此基础上加入动作部分，生成能够驱动类人机器人的动作
token。

**主持人:** 我完全同意。我们一直在努力解决的问题之一是如何解锁构建这些模型所需的大规模数据。你自己也做出了许多贡献，比如关于仿真到现实（sim-to-
real）转换的研究，以及 Nvidia 构建的工具如 Isaac Sim
等，这些都极大地推动了这一领域的发展。同时，远程操作设备的成本也在下降，使得这一领域变得更加激动人心。

## 4、虚拟世界

**主持人:**
我们可以转到谈论虚拟世界的话题吗？我记得你最初的研究更多是在虚拟世界领域，能否谈谈是什么让你对《Minecraft》以及机器人技术感兴趣？在你的世界观中，它们是如何相关的？

******Jim Fan：****** 这是个很好的问题。对我来说，我的个人使命是解决 embodied AI 的问题。对于虚拟世界中的 AI
代理，这涉及到游戏和仿真技术，这也是为什么我对游戏情有独钟。我自己也喜欢玩游戏。

**主持人:** 你玩什么游戏？

******Jim Fan：****** 我玩《Minecraft》，不过我不是一个很好的玩家（笑）。这也是为什么我希望我的 AI
能够为我“复仇”，弥补我的拙劣技能。所以，我之前参与了一些与游戏相关的项目。第一个项目叫做 Mind
Dojo，我们开发了一个平台，用于在《Minecraft》游戏中训练通用 AI 代理。对于不熟悉《Minecraft》的观众来说，这是一款 3D
方块世界游戏，你可以在其中随心所欲地进行冒险，制作各种工具和配方。这是一款开放式游戏，没有特定的分数，也没有固定的剧情线。我们从互联网上收集了大量数据，包括人们玩《Minecraft》的视频，还有解释游戏中每个概念和机制的
Wiki 页面，这些都是多模态文档。此外还有 Reddit
的《Minecraft》子版块，那里有许多人用自然语言讨论游戏。我们利用这些多模态数据集，训练模型来玩《Minecraft》。这是第一个项目，名为 Mind
Dojo。

后来，我们开发了第二个项目，叫做 Voyager。这个项目的灵感来自 GPT-4
的出现，当时它是最强的编程模型。我们想到：如果把编码作为行动会怎么样？基于这个想法，我们开发了 Voyager
代理，它通过编写代码与《Minecraft》世界互动。我们首先将 3D 的《Minecraft》世界转换为文本表示，然后让代理通过 API
编写代码进行操作。就像人类开发者一样，代理并不总是能一次性正确编写代码，因此我们为它设计了一个自我反思循环：如果遇到错误或在《Minecraft》世界中犯错，它会获得反馈并修正程序。一旦它编写了正确的代码，我们称之为“技能”，并将其保存到技能库中。以后，代理遇到类似的情况时，它无需再经历试错过程，可以直接从技能库中提取技能。你可以将技能库想象成一个完全由
Voyager 代理自己编写的代码库，没有任何人类干预。第三个机制是我们称之为自动化课程设置（automated
curriculum）。代理知道它已经掌握了哪些知识，也知道自己尚未掌握什么。它能够提出下一个既不太难也不太简单的任务，并沿着这条路径不断发现新的技能和工具，同时在《Minecraft》的广阔世界中进行探索。因为它会不断旅行，因此我们称它为
Voyager。

**主持人:** 我觉得课程设置的这个概念非常有趣，因为这似乎是 LLM
推理世界中未解决的问题之一——如何让这些模型自我意识到它们下一步该如何改进。你能再详细谈谈你在课程设置和推理方面的构建工作吗？

******Jim Fan：******
当然，我认为这些前沿模型展现出一个非常有趣的特性，那就是它们能够反思自己的行为，并且知道自己知道什么，不知道什么，能够据此提出任务。在 Voyager
中，我们给了代理一个高层次的指令，那就是发现尽可能多的新物品。这是一句非常简单的目标指令，我们没有指明应该先发现哪些物品，先解锁哪些工具，代理能够自主发现这些内容，通过编码、提示和技能库完成任务。整个系统能够正常运行，真的令人惊叹。我认为这是涌现特性的一种体现——当你有一个非常强大的推理引擎，它可以进行广泛的泛化。为什么那么多虚拟世界的研究都是在虚拟环境中进行的？我相信这不仅仅是因为很多深度学习研究人员喜欢玩电子游戏，虽然这也可能是其中一个因素（笑）。你认为解决虚拟世界中的问题和现实世界中的问题有什么联系？这两者之间是如何相互影响的？

**主持人:**
尽管游戏和机器人技术看起来非常不同，但我发现它们之间有许多相似的原则。对于具身代理来说，它们的输入是感知信息，可以是视频流加上一些传感器输入，输出则是动作。在游戏中，这些动作可以是键盘和鼠标的操作，而在机器人中，这些动作则是低级别的运动控制。最终的
API 看起来是相似的。这些代理需要在世界中进行探索，并在某种程度上自行收集数据，这就是所谓的强化学习和自我探索。这一原则在物理代理和虚拟代理之间是共享的。

******Jim Fan：******
但两者的区别在于，机器人技术更难，因为还需要解决仿真到现实的差距。在仿真中，物理和渲染永远不会是完美的，因此很难将仿真中的学习转移到现实世界中，这是一个尚未完全解决的研究难题。而在游戏中，你是在相同的环境中进行训练和测试，所以不存在这样的差距。因此，这就是两者之间的主要区别。去年我提出了一个叫做“基础代理”（Foundation
Agent）的概念，我相信最终我们会有一个模型，它既能在虚拟代理中工作，也能在物理代理中工作。对于基础代理，有三个维度的泛化：第一个是它可以执行的技能；第二个是它可以控制的不同形态或身体；第三个是它可以掌握的世界——虚拟世界或现实世界。我认为未来的某个单一模型将能够在各种不同的机器人或代理形态上执行各种技能，并在许多不同的世界中进行泛化，无论是虚拟世界还是现实世界。这就是我们
GEAR 团队希望追求的最终愿景。

## 5、游戏中的AI应用

**主持人:**
在虚拟世界和游戏领域，你们已经解锁了一些推理和涌现行为，特别是在开放性环境中。你个人对游戏领域的未来有哪些梦想？你希望在今天的游戏世界中看到 AI
代理在哪些方面进行创新？

******Jim Fan：****** 我对两个方面非常感兴趣。首先是游戏中的智能代理。现在的
NPC（非玩家角色）都是有固定脚本的，完全由人工编写。如果我们有真正“活着”的 NPC
呢？你可以与他们互动，他们可以记住你之前告诉他们的话，并在游戏世界中采取行动，改变故事情节和叙事。这是我们目前还没有看到的，但我觉得这个领域有巨大的潜力。当每个人玩同一款游戏时，每个人的体验都将不同，甚至对于同一个人来说，玩两次游戏也不会是相同的故事情节。这样每款游戏将具有无限的重玩价值。第二个方面是游戏本身可以被生成。我们已经看到很多不同的工具实现了这个宏大愿景的某些子集，比如从文本生成
3D
资产的工具、从文本生成视频的模型，当然还有能够生成故事情节的语言代理。如果我们能将这些工具结合在一起，那么游戏世界就可以在玩家玩耍和互动时实时生成，这将是一次真正令人惊叹的开放式体验。

**主持人:** 关于代理的愿景，你认为我们需要 GPT-4 级别的能力吗？还是仅仅依靠 LLaMA 8B 就能实现？

******Jim Fan：******
我认为代理需要具备以下能力：首先，它需要能够进行有趣的对话，保持一致的性格，并拥有长期记忆，能够在世界中采取行动。目前来看，LLaMA
模型在这些方面表现相当不错，但仍然不足以产生非常多样化和高度引人入胜的行为。我认为目前仍然有一些差距需要填补。另一个问题是推理成本。如果我们希望将这些代理部署给游戏玩家，那么要么它们的成本非常低，能够在云端托管，要么它们可以在本地设备上运行，否则从成本上来说是无法扩展的。这是另一个需要优化的因素。

**主持人:**
你认为在虚拟世界中进行的所有研究，是否是为了服务于现实世界？换句话说，虚拟世界的研究成果是否是为了帮助解决现实世界中的问题，或者虚拟世界本身是否也足够有价值？你如何在虚拟世界和现实世界之间平衡你的工作优先级？

******Jim Fan：****** 我认为虚拟世界和现实世界最终只是同一轴上的不同现实。让我举个例子，有一种技术叫做“域随机化”（domain
randomization），它的工作原理是你在仿真环境中训练一个机器人，但你会在 10,000
个不同的仿真环境中并行训练，每个仿真的物理参数都有所不同，比如重力、摩擦力、重量等都略有差异。因此，这实际上是 10,000
个不同的世界。假设我们有一个代理，能够同时掌握这 10,000 种不同配置的现实，那么我们现实中的物理世界就只是第 10,001
个虚拟仿真。在这种情况下，我们可以直接从仿真转移到现实。这正是我们在 Eureka
项目的后续工作中所做的，我们在仿真中使用各种随机化进行训练，之后无需进一步微调，代理就能够直接在现实世界中进行迁移。因此，我确实相信，如果我们拥有各种虚拟世界（包括游戏中的虚拟世界），并且有一个代理能够在所有世界中掌握各种技能，那么现实世界也只是这个更大分布的一部分。

**主持人:** 你能为观众介绍一下 Dr. Eureka 的工作吗？

******Jim Fan：****** 当然可以。在 Dr. Eureka 的工作中，我们基于 Eureka 项目，仍然使用 LLM
作为机器人的开发者。LLM
编写代码，这些代码用来指定仿真参数，比如随机化参数。经过几次迭代后，我们在仿真中训练的策略能够泛化到现实世界。我们展示的一个具体演示是让一个机器狗在瑜伽球上行走，它能够保持平衡，甚至还能前进。我看到有趣的评论，有人尝试让他的真实狗做这个任务，但他的狗做不到。从某种意义上说，我们的神经网络在这个任务上的表现已经超越了真实的狗（笑）。

**主持人:** 在虚拟世界领域，最近我们看到了很多基于 Transformer 的令人惊叹的 3D
和视频模型。你认为我们已经找到了通向成功的架构了吗？还是在模型架构方面仍然需要一些根本性的突破？

******Jim Fan：******
我认为在机器人基础模型领域，我们还没有真正推动架构的极限。目前数据是最大的瓶颈，正如我之前提到的，我们无法从互联网上下载这些动作数据，因为它们不包含运动控制数据。我们必须在仿真或真实机器人上收集这些数据。一旦我们建立了一个成熟的数据管道，就可以将这些
token 输入 Transformer，让它们进行压缩，就像 Transformer
预测维基百科中的下一个单词一样。我们仍在测试这些假设，但我认为我们还没有将 Transformer 推到极限。现在也有很多关于替代 Transformer
的研究，我个人对这些替代方案非常感兴趣，比如 Mamba 和最近的 Test-time Training
研究。有些替代方案有非常有前景的想法，虽然它们还没有达到前沿模型的表现，但我期待看到它们的进展。

**主持人:** 有没有哪些特别吸引你的替代架构？为什么？

******Jim Fan：****** 我提到了 Mamba 和 Test-time Training，这些模型在推理时更加高效。与
Transformer 需要关注所有过去的 token
不同，这些模型有更高效的机制。因此，我认为它们非常有潜力。但我们需要将它们扩展到与前沿模型同等的规模，才能真正看到它们与 Transformer
的正面对比。

## 6、快问快答环节

**主持人:** 我们结束前来个快问快答怎么样？除了具身智能之外，你还对人工智能哪些领域感兴趣？

********Jim Fan：**** 我对视频生成非常兴奋，因为我认为视频生成是一种世界模拟器。我们可以仅从数据中学习物理和渲染。我们已经看到像
OpenAI 的 SORA，以及后来许多新模型在追赶 SORA。所以，这仍然是一个正在进行的研究课题。

**主持人:** 世界模拟器能带来什么好处？

********Jim Fan：**** 我认为它将带来数据驱动的仿真环境，在这个环境中我们可以训练 具身智能，那将会非常棒。

**主持人:** 在更长远的未来，10 年或更久，你对 AI 最期待的是什么？

********Jim Fan：****
有几个方面让我非常期待。首先是在推理方面，我对能够编写代码的模型非常感兴趣。编程是一个非常基础的推理任务，同时也具有巨大的经济价值。我认为，或许 10
年后，我们将会有像人类软件工程师一样优秀的编程代理，它们可以通过自我编程加速许多开发进程。第二个方面当然是机器人技术。我相信 10
年后我们将拥有与人类一样可靠和敏捷的类人机器人，甚至超越人类。我希望到那时，Groot
项目会取得成功，类人机器人能够在日常生活中帮助我们。我一直梦想着有机器人帮我洗衣服。

**主持人:** 你认为哪一年机器人会帮我们洗衣服？

******Jim Fan：****** 越快越好，我已经等不及了。

**主持人:** 在 AI 领域中，你最钦佩的人是谁？你曾有机会与一些伟大的人物共事，回到你实习的时候，但如今你最钦佩的人是谁？

******Jim Fan：****** 在 AI
领域，我有太多英雄，难以一一列举。我非常钦佩我的博士导师李飞飞，我觉得她教会了我如何培养良好的研究品味。有时候关键不在于如何解决问题，而是识别出哪些问题值得解决。实际上，找到“什么问题”比“如何解决问题”要难得多。在我攻读博士期间，她帮助我转向了具身智能领域，回过头来看，我觉得这是正确的方向。我相信未来的
AI 代理将会是具身的，无论是用于机器人技术还是虚拟世界。我也非常敬佩 Andrej
Karpathy，他是一位伟大的教育家，我觉得他编写代码像是在写诗，我非常仰慕他。还有 黄仁勋，他非常关心 AI
研究，并且对模型的技术细节也非常了解，这让我印象深刻，我非常敬佩他。

**主持人:** 说到拥有良好的研究品味，你对那些从事 AI 创业的创始人有什么建议，帮助他们找到正确的问题去解决？

******Jim Fan：******
我觉得最近的研究论文变得越来越易于理解，并且充满了非常好的想法。这些论文也越来越实用，而不仅仅是理论性的机器学习研究。所以，我建议大家紧跟最新的文献，并尝试所有开源工具。例如在
Nvidia，我们开发了一些仿真工具，任何人都可以免费下载并使用这些工具，在仿真中训练自己的机器人。动手实践很重要。

**主持人:** 黄仁勋是一个偶像。你觉得对那些从事 AI 创业的创始人来说，他的哪些实际建议是值得学习的？

********Jim Fan：**** 我觉得最重要的是识别出正确的问题去解决。Nvidia
押注类人机器人，是因为我们相信这是未来的方向。还有具身智能，因为如果我们相信 10 年后，世界上将会有与 iPhone
数量相当的智能机器人，那么我们现在就应该开始着手这个方向。

**主持人:** 这是一个很好的结束语。Jim，非常感谢你加入我们，我们很高兴了解你们团队的工作，也迫不及待地想看到未来的叠衣服机器人。

******Jim Fan：****** 非常感谢你们邀请我，谢谢！

  

* * *

原视频链接：https://www.youtube.com/watch?v=yMGGpMyW_vw&t=1s  

 _**对了，喜欢就别忘了点赞、收藏、转发支持一下！期待在评论区听到你的观点和看法!**_

#  往期回顾

[1、[演讲视频：2024年第65届国际奥数大会上，陶哲轩再次表示当前AI进展惊人，智能水平已与人类相当]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247492830&idx=1&sn=72ae1cffdfc56f212d4b5fdbd3b37120&chksm=c008563bf77fdf2db99c1b71f962e897567f2e2380bdde257b06c0715a093e3fdfb6c881d978&scene=21#wechat_redirect)

[2、[万字整理一小时采访：谷歌AI首席科学家 Jeff
Dean详解AI的前生今世，并预测AGI实现时间表]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247493161&idx=1&sn=4464a9e508667fa3a45689e56e45b304&chksm=c00854ccf77fddda8e8b021b5cebf185f9462ce0ec0cdc92fd381971f4037d0acd3eedc7bf95&scene=21#wechat_redirect)

[3、[OpenAI 刚刚发布全新系列模型的第一款 OpenAI
o1，AI也学会思考了，离'真正的智能'更近一步！]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247493144&idx=1&sn=db462126b7c38a79161df1c4482c7ee9&chksm=c00854fdf77fddeb6b46cdcbd8fe38a46d41f6af8e3d1bae62294e985bdcc25a3fe0b048e69a&scene=21#wechat_redirect)

* * *

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAhtRhTOjz2QwH4dIlC3YUcYbaicMEwjqQqh06Yhdd7EH3r9wiaMRArLz0a6Zhx6uiaUD7hguPfbY0nAg/640?wx_fmt=png&from=appmsg)

****

**我们旨在将先进科技与创新想法完美融合!**

**想要掌握人工智能，但不知从何开始？告诉我们你的需求，学习AI让你抓住这波浪潮**

##  告别昂贵服务和缺人烦恼,再见漫长交付周期

## 无限创意,快速生成专业级产品

## 感受 AI 带来的全新工作体验！

** _欢迎各大品牌方、媒体、企业和个人等_**

** _请联系负责人微信：Milo-1101_**

** _\--END--_**

****未经许可不得转载，务必保留公众号原文链接和公众号按钮****

