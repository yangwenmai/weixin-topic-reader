# Yann LeCun万字通俗解读：什么是AI、怎么用AI、别被AI焦虑困住(附视频)

文章作者: AI深度研究员
发布时间: 2024-11-29 08:07
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494416&idx=1&sn=9e1f74b70c6039097829d97d5388442f&chksm=c00859f5f77fd0e3e229d63740533e8e1b5d82733ab8e70e38e1b8b93ee542ac0da6c0e33515#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAjib2hmOt5MW0PthfwCqicibWgoWLLtmL2AbfVic3WL238xDcHjv8ZbtXtke3zswJH5jrLPy0IWFASsfg/300

**（关注公众号并设为🌟标，获取最新人工智能资讯和产品）**

全文15,000 字，阅读约需36分钟

金句摘录科学家是试图理解这个世界，而工程师是试图创造新的事物。但如果你想要理解这个世界，往往也需要创造新事物。几乎所有我们面临的问题，其根源都在于人类知识或智慧的缺乏。LLM适用于离散的世界，但它们无法处理连续的高维世界，而视频正是这种连续高维世界的典型案例。我们将把注意力转向其他任务，比如不是'做事'，而是'决定做什么'或者'思考该做什么'。智能是一种由大量简单单元——神经元——互相连接后涌现出来的现象。

昨天，在印度班加罗尔，Meta首席人工智能科学家Yann LeCun与著名科技达人Nikhil
Kamath展开了一场关于AI发展历程、现状和未来图景的深度探讨。

作为人工智能领域的开创者之一，Yann
LeCun从历史视角梳理了AI的发展脉络，揭示了这一领域引人入胜的演变过程。早期的人工智能沿着两条截然不同的路径发展：一条专注于具体问题的规划与解决，如物体堆叠顺序优化或机器人避障等任务；另一条则致力于模仿生物智能机制，试图理解和复制人类大脑的工作原理。这两条路径的交织发展，为今天AI技术的突破奠定了基础。如今，人工智能已经形成了清晰的层级结构：最顶层是人工智能（AI），其下是机器学习，再往下则包括像DeepMind开发的强化学习系统和像ChatGPT这样的自监督生成式模型等不同分支。

他预测，在未来五到十年内，AI系统可能逐步接近人类智能水平，这将给人类社会带来深刻变革。最显著的改变将发生在工作领域，AI系统将承担起大量具体的执行任务，而人类则转向更高层次的决策和创新工作。这种转变不仅仅是工作方式的改变，更是整个社会结构的重塑。传统的知识储备和技能培养方式将面临挑战，教育体系需要重新定位，更加注重培养抽象思维能力和创造力。

未来的AI技术也将释放人类的创造力，让我们能够专注于更具战略性和创新性的工作。这不仅仅是技术的进步，更是人类文明的一次重要跃升。

AI的关键概念人工智能智能构成-解决方案能力-学习能力-感知能力-零样本学习核心架构-神经网络-卷积神经网络-Transformer-大型语言模型记忆类型-
参数记忆-上下文记忆-持久记忆发展趋势-开源平台-分布式训练-新型架构-成本优化

# 对话整理

**主持人：** 主持人：早上好，Yann，非常感谢你参与我们的节目。

**嘉宾Yann LeCun：******很高兴参加，谢谢邀请。

##  1、个人介绍

**主持人：** 我们想了解你更多一些。能否聊聊你的成长经历，比如你在哪里出生和长大？这一切是如何促成了今天的你？

**Yann
LeCun：******我在巴黎郊区长大，我的父亲是一名工程师，很多东西我都是从他那里学到的。从小我就对科学和技术感兴趣，并且一直希望自己能成为一名工程师。我当时完全不知道如何成为一名科学家，但后来对这一领域产生了兴趣。

**主持人：** 工程师和科学家之间的区别是什么？

****Yann LeCun：****
这个问题很难定义。通常你需要兼具两者的特质。科学家是试图理解这个世界，而工程师是试图创造新的事物。但如果你想要理解这个世界，往往也需要创造新事物。科学的进步很大程度上依赖于技术的发展，比如望远镜的发明推动了对行星的发现，以及它们围绕太阳旋转的研究。同样，显微镜也为各种发现打开了大门。对我来说，一直以来让我着迷的问题是揭开智能的奥秘。而作为一名工程师，我认为揭开这个谜题的唯一方式就是创造一台智能的机器。所以这是一个既有科学层面的理解，又有实践层面的探索。而建立智能机器可能对人类产生深远的影响。

**主持人：** 那么你在巴黎上学时学的是什么专业？

******Yann LeCun：******
我学的是电气工程。但随着学习的深入，我对数学、物理和人工智能等更基础的问题产生了兴趣。我并没有学习计算机科学，不过当时学电气工程时计算机技术已经逐渐成为一部分了，特别是在80年代和70年代末我刚开始学习的时候。我还和数学教授一起做了一些关于人工智能问题的独立项目，从此便沉迷于研究。我的最爱就是发明新事物、构建新事物，然后用新的方式理解它们。

**主持人：** 当人们称你为“人工智能教父”时，你有什么感受？

******Yann LeCun：******
坦白说，我不是特别喜欢这个称呼。你知道，我住在新泽西，“教父”这个词在新泽西听起来像是黑手党的意思（笑）。科学从来不是某个人单打独斗的追求。科学进步是多种思想碰撞的结果。我们提出假设，然后通过实验或理论证明这些假设是正确的。这不是孤立的活动，总有许多人为进步作出贡献。但是，由于这个世界的运作方式，我们往往只记住少数几个人。我觉得很多人都应得到更多的认可，但我们往往难以记住每个人的贡献。

**主持人：** 那么，作为一名教师，你现在的感觉如何？在纽约大学（NYU）时，你是否被当成名人？

******Yann LeCun：******
可以说，过去几年里，学生在课后会过来找我拍自拍照（笑）。所以，这确实有点名人效应。不过，我觉得如果和学生在同一个教室里互动是很重要的，否则他们完全可以直接看视频。这就是我尝试去做的事情，真正与学生互动。

## 2、科学中英雄

**主持人：** 在学术界或研究领域成为英雄，是否和在体育或创业中成为英雄类似？还是更难一些？

******Yann LeCun：******
有一点让我感到欣慰，那就是科学中也可以有英雄存在。我们可以说牛顿、爱因斯坦以及其他人都是科学的英雄，对吧？不过，牛顿并不是公众人物，而爱因斯坦绝对是的。而且，在某种程度上，一些其他科学家也成为了小范围的名人。这种现象部分来自于科学成果，但坦白说，有很多科学贡献是完全默默无闻的，我觉得这有些遗憾。很多人之所以在科学和技术领域出名，不仅仅因为他们的科学产出，还因为他们在公众场合的立场。我与一些比较低调的科学家的不同之处，可能在于我在社交网络上的活跃，以及我经常发表公众演讲，并对一些技术和政策问题表达明确的观点。这种做法或许放大了我的知名度，也可能引起了一些争议。在某些圈子里，我可能被看作是个彻底的“傻子”。

**主持人：** 在过去的几周里，我看了很多你的采访。如果你用自己的视角指出当今世界的三个问题，会是什么？

******Yann LeCun：******
作为科学家，我们试图建立世界的因果模型。我们观察到一些现象，然后追问这些现象的原因是什么。而几乎所有我们面临的问题，其根源都在于人类知识或智慧的缺乏。我们犯了错误，因为我们还不够聪明，没有意识到问题的存在，也没有找到解决问题的方法，甚至无法组织起来共同解决问题。比如说，气候变化就是一个巨大的问题。这其中有政治问题，也涉及全球治理的组织问题。但同时，也可能存在技术解决方案。我希望我们更聪明一些，这样可以更快找到解决方案。

我认为我们犯错是因为我们还不够聪明。如果我们对世界的运作有一个更好的心理模型——这也是人工智能的核心问题之一——我们就能更好地解决问题，做出更理性的决策。当今世界的一个大问题是，有些人对寻找事实并不感兴趣，也不愿意提升自己的知识水平，或者即使有兴趣，他们也可能缺乏条件，比如无法获取信息和知识。因此，我认为我们能做的最重要的事情就是让人类变得更聪明。这也是我成为教授的一个原因。某种程度上，这也是从事人工智能工作的最好理由，因为人工智能可以放大人类的智慧，提升整个人类的集体智能。我认为这是解决许多问题的关键。

  

## 3、什么是AI

**主持人：**
我先声明，我在人工智能或技术方面是个“白痴”。我最近才开始试图了解相关内容，虽然对此非常好奇，但仍知之甚少。我想今天可以探讨几个问题：什么是人工智能？我们是如何走到今天的？接下来可能会发生什么？我们是否可以从“什么是人工智能”开始聊起？

******Yann LeCun：******
好，这是个好问题。其实，这也引出了另一个问题：什么是智能？知道那个“盲人摸象”的故事，对吧？第一个盲人摸到了大象的一侧，说：“这听起来像——看起来像是一堵墙。”然后另一个摸到了大象的一条腿，说：“这看起来像是一棵树。”再一个人摸到了象鼻，说：“这是——这是个管子。”没有人能够完全了解大象是什么样子，每个人都只是从不同的角度看到了一部分。所以，将智能看作是为特定问题寻找解决方案的过程，这只是“大象”的一小部分。这是智能的一个方面，但并不是全部。然而，在20世纪50年代，人工智能的一个分支几乎完全关注于这一点。这个分支基本上一直占据主导地位，直到1990年代。

当时的人工智能主要关注的是寻找解决方案或者制定计划。比如，如果你想把一堆物体叠在一起，有些物体比其他物体更大，你需要组织这些物体的堆叠顺序，寻找一系列能够实现目标的动作，这被称为“规划”（planning）。又或者说，你有一个机器人手臂需要抓取一个物体，但前面有障碍物，你需要为机器人手臂规划一个轨迹来抓取这个物体。所以，这一切都与规划有关，这是寻找问题解决方案的一部分。但人工智能的这个分支——从50年代开始，到90年代之前都占据主导地位——完全忽略了感知这类问题，比如我们如何理解世界，如何识别一个物体，如何将一个物体从背景中分离出来以便识别它。

还有，我们如何思考——不是用逻辑或搜索的方式，而是更抽象的方式。这些在当时基本都被忽略了。但人工智能的另一个分支也始于50年代，它尝试复制动物和人类身上的智能机制，而动物和人类拥有大脑。大脑会自我组织并学习，对吧？它们并不是天生聪明的，而智能是一种由大量简单单元——神经元——互相连接后涌现出来的现象。所以在40年代和50年代，人们开始发现，智能和记忆来源于神经元之间连接的强度。从某种程度上，大脑学习的方式就是通过改变这些连接的强度。一些人提出了理论模型，甚至构建了电子电路来再现这一点。

**主持人：** 你是说智能主要是解决特定问题的能力？

******Yann LeCun：******
这是其中一个观点，即解决给定问题的能力。另一个观点是学习的能力。这两个观点分别催生了人工智能的两个分支。以学习能力为核心的分支，在50年代末和60年代初取得了一些成功，但在60年代末基本消亡了，因为当时用于神经网络的学习方法非常有限。这种方法无法构建真正智能的机器，但在工程领域的某些部分，比如模式识别，产生了很大影响。

**主持人：** 所以你是说，现在智能还包括系统学习的能力？

******Yann LeCun：****** 对，学习能力。而机器最基本的学习场景是感知，比如解读图像和声音。

**主持人：** 那么，计算机是如何做到这一点的呢？

******Yann LeCun：******
这实际上促成了我们称之为“经典计算机科学”的出现。基本上，你编写一个程序，这个程序内部会搜索解决方案，并通过某种方式检查它提出的解决方案是否合适。在60年代，人们将这种方法称为“启发式编程”，因为无法穷尽所有可能的解决方案。以国际象棋为例，每一步都有许多可能的走法，而每个对手的回应也有许多可能，这样下来可能的路径或动作序列呈指数级增长。显然，你不可能穷举所有路径并找到最佳策略，所以你需要使用启发式方法，只搜索可能性树的一部分。

  

## 4、卷积神经网络

**主持人：** 人工智能是否从生物学中获得了灵感？

******Yann LeCun：******
确实如此。神经科学家发现，大脑中的学习机制是通过改变神经元之间连接的强度实现的。人们想象这种学习机制可以在机器中再现。在40年代，数学家McCulloch和Pitts等人提出了神经元是简单计算单元的想法。在50年代和60年代初，人们提出了一种非常简单的算法，用于改变神经元之间连接的强度，从而让神经网络可以学习任务。第一台基于这种理念的机器被称为“感知机”，于1957年提出。这是一个非常简单的系统。假设你想训练一个系统识别简单的形状，比如区分“C”和“D”的形状。

对于计算机或人工系统来说，图像是由数字组成的阵列。以黑白摄像头为例，黑色像素表示为0，白色像素表示为1。如果使用50年代的技术，你需要一个光电传感器阵列和一个镜头，将低分辨率图像输入系统，比如20x20像素甚至更低。然后，这些像素的值会被输入计算机。50年代的计算机非常昂贵，所以实际上是用电子电路实现这些操作的。像素会作为电压输入到传感器，系统会根据输入的像素值和权重计算一个加权和。如果加权和大于某个阈值，它就会认为这是“C”；如果低于阈值，则认为是“D”。

**主持人：** 这是哪个年代？您说的是哪一年？

******Yann LeCun：****** 1957年。

**主持人：** 那么，这要如何训练呢？

******Yann LeCun：******
训练的过程就是改变那些权重的值。权重可以是正的，也可以是负的。具体来说，你向系统展示一个“C”，然后系统计算加权和。对于“C”，你希望加权和的值很大，大于零，比如这样设定，对吧？如果加权和的值小于零，那么系统就会犯错。如果你以特定的方式构建神经网络，能够利用这些结构特性，那么它的学习速度会更快，需要的样本也更少。我们在80年代末期开始尝试这种方法，并构建了卷积神经网络（Convolutional
Neural
Networks，简称ConvNets）。这些网络的设计灵感来自视觉皮层的架构，并且具有一定的数学依据。基本思想是，每个卷积网络中的神经元只关注图像的一小部分区域。多个神经元同时关注图像的多个区域，并且它们的权重是相同的。

这个基本概念与一个数学概念——卷积（Convolution）有关，因此这些网络被称为卷积神经网络。卷积具有一个有趣的特性：如果输入发生偏移，输出也会以相同的方式偏移，但其他部分保持不变。这种特性对于处理音频信号、图像以及其他自然信号非常有用。Transformer是一种完全不同的神经元排列方式，其输入是一系列不同的元素，我们称之为token（实际上是一个数值向量的列表）。Transformer层或模块的特点是：如果你对输入项进行置换，输出也会以相同的方式置换，但其他部分保持不变。

**主持人：** 当你说“其他部分保持不变”时，你的意思是什么？

********Yann LeCun：****
我的意思是，如果你给定一组token，并通过Transformer处理后会得到一组输出token，通常输出的数量和输入的数量相同，但它们会是不同的向量。如果你将输入序列的前一半和后一半交换位置，那么输出也会以同样的方式交换位置，但其他特性保持不变。从技术上讲，这被称为“对置换的等变性”（Equivariance
to
Permutation），意思是它将输入视为一个集合，集合中对象的顺序并不重要。相比之下，卷积神经网络将输入视为可以在任意位置出现的对象，这种输入的特性要求输出随着输入的偏移而发生变化，但其他部分保持一致。这种特性被称为“对平移的等变性”（Equivariance
to
Translation）。当你构建神经网络时，你可以将这些不同类型的组件组合起来，以获得整个神经网络的所需特性。例如，你可以组合卷积模块和Transformer模块。

**主持人：** 你能简单解释一下什么是卷积神经网络吗？

******Yann LeCun：******
当然。卷积是卷积神经网络的核心组件。其核心思想是，一个神经元只关注输入的一部分，另一个神经元则关注输入的另一部分，但它们的计算方式是相同的。这种神经元被复制到输入的每个位置上，可以将每个神经元看作是在输入的某个部分检测特定的模式，而所有神经元则在不同位置上检测相同的模式。这样，如果输入发生偏移，输出也会相应偏移，但检测的模式保持一致。这种特性就是“平移等变性”。从数学上讲，卷积是很早以前数学家发明的一个概念，而卷积神经网络实现的功能与其类似。

**主持人：** 你提到“神经元”，在机器学习中这个术语具体指什么？

******Yann LeCun：******
我们在这里使用“神经元”这个词，其实是一种语言上的误用。神经网络中的神经元和大脑中的神经元的关系，就像飞机的机翼和鸟的翅膀。虽然它们的设计理念相似，但并不相同（笑）。在神经网络中，神经元的作用是计算输入的加权和，然后将加权和与一个阈值比较。如果加权和高于阈值，神经元激活并输出一个值；如果低于阈值，则输出为零。这是神经元的基本功能。当然，神经元有不同的变体。在Transformer中，使用的是稍微复杂一些的数学方法，比如比较向量之间的关系，但核心还是通过线性操作和非线性激活函数实现的。

  

## 5、“生成式”由来

**主持人：** 我们在研究时发现，很难找到一个简单的神经网络语言模型定义。你能解释一下吗？

******Yann LeCun：****** 语言模型的概念可以追溯到20世纪40年代。一位名叫Claude
Shannon（克劳德·香农）的数学家提出了这个想法。他是一位非常著名的数学家，曾在贝尔实验室工作，我也在那里工作过，不过他在我加入之前已经离开了。他提出了一种叫做信息论（Information
Theory）的理论，并对从数据中发现结构的想法深感兴趣。他发明了一种方法：给定一段文本，提出问题——“在给定一系列字母后，下一个字母会是什么？”例如，我们可以用一个英文单词或其他类似拉丁字母的语言来说明这个问题。如果有一串字母，而最后一个字母是“Q”，那么下一个字母很可能是“U”。在英语中，几乎不会出现没有“U”跟在“Q”后面的情况，除非这个单词是阿拉伯语的音译词或其他特殊情况。所以，对于你观察到的每一个字母，你都可以建立一个概率表，显示下一个字母是“A”、“B”、“C”、“Q”或“U”的概率是多少。

**主持人：** 这就是“生成式”（Generative）这个词的由来吗？

******Yann LeCun：****** 是的。这被称为生成式模型，因为如果你有这样一个“条件概率”（Conditional
Probability）的表，即给定前一个字母，下一个字母的概率是多少，你就可以用它来生成文本。假设你从一个字母开始，比如“Q”，然后你查找概率表，看看最有可能的下一个字母是什么。选择这个字母，可能是“U”。或者你也可以不总是选择最有可能的字母，而是根据概率随机选择。比如，你可以用抛硬币或在电脑上生成一个随机数，根据真实文本中测量到的概率生成后续字母。然后你继续重复这个过程。这样系统就会生成一串字母。不过，这些字母可能看起来不像单词，甚至可能无法发音。但是，如果你不是只考虑一个字母作为上下文，而是使用两个字母作为上下文，那么生成的内容就会更可读一些。

但如果你使用三个字母作为上下文，结果会更好看一些。随着上下文长度的增加，用来决定下一个字母概率的上下文越来越大，生成的内容会变得越来越可读。不过，这里有一个问题。如果你只看第一个字母，并尝试预测下一个字母的概率，你需要一个包含26行和26列的表格。也就是说，对于每个可能的第一个字母，你需要记录每个可能的第二个字母的概率，这样就形成了一个26×26的表格。如果你使用两个字母作为上下文，那么表格的行数将是26的平方（26²），因为有26²种可能的两个字母组合。而对于每一种组合，你需要记录26个可能的下一个字母的概率。这样表格的大小就是26³。如果继续增加上下文字符数，表格的大小会变成26的n次方（26ⁿ），其中n是序列的长度。这种方法被称为n-
gram模型。这是基于英文字母的模型。如果在单词层面使用这种模型，问题会更复杂，因为可能有十万个单词。因此，表格的规模会变得巨大。

你可以通过训练大量文本语料库来填充这个概率表，从而训练出一个基于单词的语言模型。然而，当上下文长度达到一定程度时，这种方法变得不切实际。原因在于计算需求过高，同时也需要存储这些巨大的表格。此外，这些表格的数据非常稀疏，因为即使你有数十亿单词的文本，大多数单词组合都不会出现。有些组合极为罕见，因此你无法准确地估计它们的概率。

**主持人：** 这是自监督学习的一部分吗？

******Yann LeCun：******
可以将其视为自监督学习的一种实例，因为你只需要符号序列，并不关心它们的来源。如果这些符号不是文本，它们也不一定要来自人类，比如，它们可以是视频帧的序列。你需要将这些帧转换为离散对象，尽管这很困难，但它可以是任何形式的数据。在90年代末，有人提出了一个想法，特别是Yoshua
Bengio提出，你可以使用神经网络来完成这种预测任务。他的想法是，与其用文本测量的条件概率填充表格，不如用神经网络来预测下一个单词。你可以给神经网络一个上下文，训练它生成下一个单词的概率分布。他在当时实验了一些“大的”神经网络（相对于当时的技术），但这些网络在今天看来还是很小的。

一个困难是，你无法准确预测下一个单词是什么，因此你需要生成所有单词的概率分布。在典型的语言中，可能有十万个单词，这意味着你需要输出十万个分数，每个分数表示该单词跟随前一个单词序列的概率。他证明了这种方法是可行的，即使在当时的计算能力下，这仍然是具有挑战性的，但它确实能奏效。这个想法在最近几年得到了复兴，人们发现如果使用Transformer架构（我之前没有详细解释），并将它们训练在互联网上几乎所有公开的文本上，同时构建一个能够利用上下文预测下一个单词的系统，就可以产生非常强大的效果。

如果上下文长度足够大，比如几千、几万甚至一百万个单词，你会得到一些具有“涌现属性”的系统。它们能够回答问题，能够解决一些任务。如果你让这些系统变得非常庞大，比如它们的可调整参数达到数百亿甚至上千亿，这赋予了系统巨大的记忆能力，使其能够存储大量关于训练数据的知识。如果训练数据是文本，它们可以提供难题的解决方案，或者回答你的问题。这主要是检索能力，包含极少量的推理能力，但推理并不多。这是一个重要的局限性。然而，这些系统的表现仍然令人惊讶。人们感到惊讶的是，这些系统能够以非常令人印象深刻的方式操控语言。要知道，人类在操控语言方面其实是有限的，但这些系统似乎在这方面表现得非常优秀。它们能掌握多种语言的语法、句法以及其他语言特性。

**主持人：** 这真的很了不起。

******Yann LeCun：******
如果让我回头描绘一棵“树”的结构，比如说人工智能（AI）在最顶端，下面是机器学习。我想讨论的是今天新闻中常提到的内容，也就是让所有人感到兴奋的领域。机器学习下面有不同的分支，比如像DeepMind这样的强化学习（Reinforcement
Learning），还有像ChatGPT这样的自监督生成式模型。ChatGPT现在是最流行的例子，所以可以用它来作为代表。确切地说，这叫“大型语言模型”（LLM）。LLM（Large
Language Model）。准确地说，应该叫“自回归大型语言模型”（Autoregressive
LLM）。是的，确实应该这么叫。准确的结构是这样的：AI在顶端，机器学习是解决AI问题的一种具体方法。现在的AI基本上都以深度学习为基础，而深度学习实际上是神经网络的多层结构，这个概念可以追溯到20世纪80年代和反向传播算法。这仍然是我们今天所做的一切的基础。在深度学习之下，有几种主要的架构家族，比如卷积神经网络（Convolutional
Neural
Networks）、Transformer，以及它们的组合。在Transformer架构下，又有几种不同的变体，有些可以应用于图像识别或音频处理，有些可以用于表示自然语言，但并不用于生成语言。还有一个子类别是大型语言模型（LLM），它们属于自回归Transformer模型。

Transformer架构的一个特点是，它可以预测下一个单词。然后，你可以用它来生成单词，因为给定一串单词，它会根据训练结果生成下一个单词。给定一段文本，系统预测下一个单词后，将输入向右移动一个单词，然后用生成的单词作为新输入的一部分，接着预测第二个单词，再次移动，预测第三个单词，如此反复。这就是自回归预测（Autoregressive
Prediction）。这个概念与金融学或计量经济学中的自回归模型类似，是同一个原理。

## 6、AI的下一个挑战

**主持人：** 这些模型对于文本最有效，但对图像、视频等其他内容不太适用，对吗？

******Yann LeCun：******
是的。这些模型适用于文本而不适用于其他类型数据的原因在于，文本是离散的。文本中的可能性是有限的，因为字典中单词的数量是有限的。如果你能将信号离散化，那么就可以使用自回归预测系统。但主要的问题是，你永远无法做到精确预测。因此，系统需要学习某种概率分布，或者至少为不同的潜在输出生成不同的评分。如果可能性是有限的（比如语言），你可以输出一个概率列表。但是如果你想预测视频中会发生什么，可能的帧数是几乎无限的，对吧？

比如，你有一百万个像素，一个图像是1000×1000像素，像素是彩色的，你需要为每个像素生成三个值。这意味着你需要生成300万个值，而我们不知道如何对所有可能的300万个像素值的图像集合表示概率分布。

这就是为什么许多人对这一问题感到兴奋。这被许多人视为AI的下一个挑战。总的来说，核心是构建能够通过观察视频来学习世界运作方式的系统。

**主持人：**
如果我们谈到视频和图片，通过这些内容学习，这将是下一阶段的发展。那么，这种学习在整个人工智能的框架中处于什么位置？它属于目前LLM（大型语言模型）的范畴吗？

******Yann LeCun：******
不，这和LLM完全不同。这也是为什么我一直明确表示，LLM并不是通向人类级智能的道路。LLM适用于离散的世界，但它们无法处理连续的高维世界，而视频正是这种连续高维世界的典型案例。这就是为什么LLM无法理解物理世界，也无法以其当前的形式真正理解物理世界。LLM在操控语言方面表现得非常出色，但它们会犯非常愚蠢的错误，这些错误揭示了它们其实并不了解现实世界及其底层逻辑。这也是为什么我们现在有能够通过律师资格考试或为你写文章的系统，但没有能够实现完全自主的家庭机器人，也没有能够完全实现5级自动驾驶的汽车。

我们还没有那些能够真正理解一些非常基础的事情的系统——比如你家的猫都能理解的事情。所以，我一直坚持认为，最聪明的LLM也不如你家的猫聪明，这的确是事实。未来几年最大的挑战是构建能够突破LLM局限的人工智能系统。这些系统需要能够理解物理世界，并具备持久记忆（Persistent
Memory），而这正是目前LLM所缺乏的。

  

## 7、模型记忆能力

**主持人：** LLM现在没有持久记忆吗？

******Yann LeCun：******
对，持久记忆，意思是系统可以记住事物，将事实存储在记忆中，并在需要时检索这些事实。LLM有两种类型的记忆，但它们非常有限。第一种记忆是在参数中，也就是训练过程中调整的系数。这些参数会“学习”一些东西，但并不是存储某条具体的信息。比如，如果你用一堆小说来训练一个LLM，它并不能逐字逐句地“背诵”这些小说的内容。但它会记住一些关于这些小说中单词统计的内容，可能能够回答一些关于故事的概括性问题，但它不会完整记住小说的每一个字。这种记忆有点像人类：你读过一本小说后，不能记住所有的文字，除非你花了大量精力去记忆每个字。这是第一种记忆类型。

第二种记忆是上下文（Context），也就是你输入的提示内容。由于系统能够生成单词，而这些单词会被重新注入到输入中，它可以将这些单词用作某种工作记忆（Working
Memory），但这种记忆形式非常有限。我们真正需要的是一种类似于我们大脑的记忆系统，这种记忆系统在哺乳动物中被称为海马体（Hippocampus）。海马体是大脑中位于大脑皮层中心的一个结构。我们需要人工智能拥有类似的功能结构来实现持久记忆。如果你没有海马体，你就无法记住事情超过大约90秒。

**主持人：** 如果我们从之前描述的“智能”开始画一条路径，一直到自监督学习，您认为这条路径会如何通向从视频、图像中学习以及更接近人类般的智能？

******Yann LeCun：******
我一直尝试绘制的路径是，探索新的架构，不同于用于LLM（大型语言模型）的自回归架构，这些新的架构可以适用于视频，从而能够利用自监督学习来训练这些系统。这种自监督学习的形式基本上是这样的：这里有一段视频，请预测接下来会发生什么。如果一个系统能够很好地预测视频中的下一幕，那么这就意味着它可能已经理解了很多关于世界底层结构的信息。类似于大型语言模型（LLM）通过训练预测下一个单词而学到很多关于语言的知识，尽管这种理解和人类的理解并不完全一样。

**主持人：** 如果要简短地描述一下，这种架构可能是什么样子？

******Yann LeCun：******
问题在于，自回归架构适用于文本，因为文本是离散的，而对于连续高维数据，比如图像和视频，你无法预测接下来的内容。这在数学上是不可行的，或者即使可行，也无法实用化。例如，预测一段视频中的所有像素变化，基本上是不可能的，至少对于我们感兴趣的问题来说没什么用处。我们想要的是一种系统，能够预测世界的未来状态，因为这是一种能够规划行为的好方法。如果我能够计划：当我的手接近玻璃杯时，我握住它并抬起，我就能抓住玻璃杯并喝水。

这种系统需要拥有一个良好的世界模型（World
Model），它能够表示当前世界的状态（比如时间点T，玻璃在桌子上），然后计划我的动作（比如握住玻璃并抬起），预测未来的状态（比如时间点T+3秒，玻璃已经在我的手中）。有了这样的模型，系统就能预测一系列动作的结果，并在“脑海中”模拟这些结果是否能满足某个目标，比如喝一口水。通过搜索（这又联系到了早期的AI方法），系统可以寻找一系列动作来实现这个目标。这种推理和规划是心理学家称之为“系统2”（System
2）的能力。Daniel Kahneman（已故的诺贝尔奖获得者心理学家）提出了“系统1”和“系统2”的概念。

系统1无需思考潜意识的反应式的系统2深思熟虑需要计划复杂行为

  * 系统1：是指无需思考就能采取的行为，潜意识的，反应式的。
  * 系统2：是指需要经过深思熟虑和计划才能完成的行为或一系列行为。

**主持人：** Yann，您认为记忆最终会成为答案吗？因为从生物学角度看，人类正是通过记忆进行学习的，对吧？

******Yann LeCun：******
这取决于记忆的类型。我们也有多种记忆类型，比如海马体（Hippocampus），我刚刚提到过的。海马体用于存储长期记忆，比如你小时候发生的事情，关于世界的基本事实，比如你母亲的生日，或者“你是从哪个方向进入这个房间的，门在哪里”。当然，这也包括较新的短期记忆。

## 8、50年后的AI

**主持人：** 这是否有点像预测明天？比如，如果我用视频记录了我到目前为止的生活，把它输入编码器，是否会得到某种关于明天的抽象表示？

********Yann LeCun：****
是的，但这是在抽象层面上的预测。你可以预测回班加罗尔需要多长时间，但你无法预测回程中所有的细节，比如具体的交通情况可能会让时间有所变化。

**主持人：** 如果我们试图预测50年后的未来，把我们目前的生活视频编程输入一个架构，并用它来预测未来50年，你认为会看到什么？气候变化还是世界大战？

******Yann LeCun：******
我会看到……好吧，现在有一个计划，在未来几年内构建能够通过视频理解世界的系统。这些系统或许能够学习到关于世界的模型，这些模型可以基于动作来推测后果。它们可能能够分层次地计划复杂的动作序列，因为这些世界模型本身是分层的。这些模型能够预测非常短期的事件，非常精确，比如如果我以某种方式移动我的肌肉，我的手臂在毫秒级时间内会出现在某个特定位置。这种预测范围很短，但非常精准。它们也能够做更长期的预测，比如如果我去机场乘坐飞机，我明天早上就能到巴黎；或者如果我努力学习并取得好成绩，我将会拥有一份美好的生活。通过这些预测，系统可以设计出满足某些条件的计划，从而实现目标。

**主持人：** 如果人工智能预测未来，它会是乌托邦还是反乌托邦？

******Yann LeCun：******
它会是乌托邦。因为它只是一种替代我们大脑预测未来的方法，以及用另一种方式规划动作序列以满足某些条件、实现目标。它或许能够积累更多的知识来完成这些任务，并拥有一些人类因为大脑的局限性而无法具备的能力。比如，计算机可以快速计算和处理复杂的任务。如果我们成功地实施这个计划——可能在未来五到十年内实现，那么我们将拥有随着时间推移能够逐渐变得像人类一样智能的系统。或许能够在十年内达到人类智能水平，但这可能是一个乐观的估计。

**主持人：** 五到十年？

******Yann LeCun：******
是的，如果一切顺利，所有的计划都能够成功实现，而且没有遇到意想不到的障碍，这可能会发生。但这种理想情况几乎肯定不会发生，对吧？

**主持人：** 你似乎不太喜欢这个可能性，对吧？像AGI（通用人工智能）和人类级别的智能，你认为这是非常遥远或者不太可能的事情吗？

********Yann LeCun：**** 不，我不认为它那么遥远。我认为我的看法与Sam Altman或Demis
Hassabis等人并没有太大的不同。可能会在十年内实现，但不会是明年，也不会是两年内，它需要更长的时间。所以你不能仅仅通过扩大LLM（大型语言模型）的规模，比如用更大的计算机和更多的数据进行训练，就认为人类级别的智能会自然出现。这种方法行不通。我们需要全新的架构，比如那些JEPAs（Joint
Embedding Predictive Architectures），这些系统能够从真实世界中学习并且能够分层规划。

它们能够规划一系列的动作，而不仅仅是像LLM那样“逐词生成”，几乎没有深度思考。因此，我们需要的是“系统2”（System
2），而不是“系统1”（System 1）。LLM属于系统1，而我描述的架构，也就是目标驱动人工智能（Objective-Driven AI），属于系统2。

  

## 9、LLM的变化

**主持人：**
关于LLM，让我们把这个讨论环节结束一下。因为它现在很热门，所有人都在谈论LLM。通常你会定义一个问题，找到一个大型数据集，大部分时间都花在清洗数据上。然后选择一个模型，训练模型，最后执行模型。在此之前，还需要微调模型。

******Yann LeCun：****** 是的，微调模型是在训练之前完成的。

**主持人：** 那么这里会有什么改变吗？

******Yann LeCun：******
我们仍然需要收集数据和过滤数据，以确保数据的高质量，并剔除无用的内容。这实际上是整个过程中特别昂贵的部分之一。但我认为需要发生的变化是，目前LLM的训练主要使用的是公开可用的数据和授权数据的结合，基本上以公开数据为主，比如互联网上的公开文本。但这些数据存在很多偏差，比如很大一部分是英语内容。虽然像印地语这样的常用语言也有相当数量的数据，但在印度的22种官方语言中，许多语言的数据量并不多，更不用说印度的700多种方言（或者无论具体数目是多少）了。尤其是这些方言大多是口语，而不是书面形式。

未来我们需要的是更加包容的数据集，使得训练出的系统能够理解全世界的语言、文化、价值体系等等。我认为没有任何单一实体能够完成这样的任务。这也是为什么我认为AI的未来将成为一种公共基础设施，成为一个所有人都可以使用的人类知识储备库。这样的系统无法由单一实体建成，它需要成为一个协作项目，训练工作分布在全世界各地。这样我们就可以在全球范围内的数据上训练模型，而不需要将数据集中到某个地方。

**主持人：**
在一次私人交流中，我正在评估一个数据中心业务以进行投资。很多人告诉我，计算能力作为一种商品，很快会在数据中心外部出售，而不再局限于数据中心内部。那您觉得，将精力和时间集中在印度建设数据中心是一个好方向吗？

******Yann LeCun：******
是的，在那种未来里，每个国家都可能更加努力地保留自己的数据，就像我之前提到的模型分布式训练的情况那样，拥有本地的计算基础设施非常重要。所以我认为这非常关键。

这有两个主要原因：

两个主要原因本地训练能力1低成本推理能力2

因为如果你希望AI系统能够服务，比如8亿印度人（我知道印度人口超过8亿，但并不是每个人都会使用AI系统），那么这需要非常庞大的计算基础设施。这实际上比用于训练的基础设施规模要大得多。推理的领域比训练的领域有更多的创新机会。目前，训练领域由NVIDIA主导，未来可能会有其他参与者。但其他玩家很难与之竞争，主要是因为软件栈的问题。他们的硬件可能非常好，但在软件栈方面面临挑战。

然而，在推理领域，有更多的创新正在发生，这些创新正在降低成本。我认为LLM推理的成本在两年内下降了100倍。这真的很惊人，对吧？它的速度远远超过摩尔定律。我认为这里还有很大的改进空间。你需要这种改进，因为你希望AI系统的推理成本能够达到每处理100万个token只需几卢比。如果你想在印度广泛部署AI系统，这将是未来发展的方向。

## 10、年轻人的建议

**主持人：**
Yann，我意识到我们的时间快到了，作为一个20岁的印度年轻人，如果想在人工智能领域创业或建立一份职业生涯，我们该怎么做？以今天的现状来看。

******Yann LeCun：****** 作为一个今天20岁的人，我会祈祷在我22岁毕业时，印度能有很好的博士项目。

**主持人：** 从非学术的角度来说，我是指……

******Yann LeCun：******
但这正是我需要接受的训练，以培养我的创新能力。攻读博士学位或研究生课程可以训练你发明新事物，同时确保你所使用的方法论能够防止自己被误导，以为自己是一个创新者，而实际上并不是。

**主持人：** 如果我是一个企业家呢？

******Yann LeCun：******
一个25岁的企业家？即使你是企业家，你仍然应该考虑攻读博士学位，或者至少是硕士学位。因为你需要真正深入地学习。当然，你也可以自己学习，但攻读学位非常有用。因为这样你可以更多地了解当前的技术水平，知道什么是可能的，什么是不可能的。此外，这还能让你在招聘有才华的人时更具权威性。特别是在像人工智能这样复杂且高度技术化的领域，攻读研究生学位有很多优势。通过语音以自己的语言与AI助手互动，我认为会为农业以及其他各类领域带来许多新的应用。

  

## 11、投资AI的方向

**主持人：**
如果我从企业家的视角切换到投资者的视角，投资AI领域能带来哪些好处？作为投资者，您认为应该投资哪些领域？是NVIDIA、Meta的Llama、ChatGPT还是OpenAI？

******Yann LeCun：****** 好吧，我认为第一步是想象五年后的未来会是什么样子。

**主持人：** 我猜想，Yann，你对未来的想象应该比我更具洞察力。您能描绘一下五年后的世界吗？

**Yann
LeCun：******五年后，世界将由开源平台主导。原因与嵌入式设备和操作系统领域被Linux主导的情况类似。如今，整个世界都在运行Linux，但20年前、25年前并不是这样。之所以如此，是因为开源平台更加可移植、更灵活、更安全，而且部署成本更低。我不应为此归功于自己，但我们有一位名叫Kailash的CTO，他是开源的坚定支持者，我们所做的一切都基于开源。我们还有一个基金会，为开源公司提供资助，类似这样的事情。所以，未来的世界将是开源的。在未来几年内，我们将拥有开源的AI平台。这些平台可能会以分布式的方式进行训练，因此它们不会完全由某家公司控制。目前占主导地位的专有引擎在未来的重要性不会像今天这样高，因为开源平台在性能上正在迅速赶上。而且，我们知道，像Llama这样的开源引擎经过微调后，往往比未微调的顶尖通用模型表现更好。

**主持人：** 但如果一切都开源了，对于投资者来说，这种“民主化”是否会削弱差异化？

****Yann LeCun：****
实际上，开源生态系统反而能激发更多可能性。如果你是初创公司，使用开源引擎并为垂直领域进行微调，比使用API更有优势。因为通过微调，你可以为客户打造更加量身定制的产品，从而更好地满足他们的需求。

**主持人：**
这是一方面。另一方面，如果你真的希望这项技术能够实现民主化，并为每个人所用，比如通过智能眼镜之类的设备——当然一开始可能只是智能手机。你认为技术交互的形式会很快改变吗？从智能手机转向其他设备，比如智能眼镜？

****Yann LeCun：****
是的，我想这几乎是毋庸置疑的。我现在没有戴它们，不过它们就在我的包里。我经常用它们。我发现它们在很多方面都很有用，即使不使用AI，也可以用来拍照、听音乐之类的东西。但有了AI助手后，比如我在餐馆里拿着一份外文菜单，它可以为我实时翻译内容。

## 12、AI技术普及

**主持人：** 随着这些变化，社会中的智能会发生什么变化？在人类世界里，人类智能会变成什么样子？

****Yann LeCun：****
人类的智能将转向一组不同的任务，而不是我们今天正在尝试完成的那些任务。因为我们今天尝试完成的许多任务将由AI系统完成。所以我们将把注意力转向其他任务，比如不是“做事”，而是“决定做什么”或者“思考该做什么”。这是两个不同的事情。想想公司里的一个基层员工，他们只是被告知要做什么并完成任务。再对比公司里的高层管理者，他们需要思考战略、决定该做什么，然后告诉其他人去执行。我们所有人都会成为“老板”。我们都会像那些高层管理者一样，告诉AI系统该做什么，而不必自己亲自去做。

**主持人：** 但相比今天需要很多人来完成这些任务，将来让更高效的系统执行这些任务需要的人会少得多，对吧？

****Yann LeCun：**** 是的。

**主持人：** 那么其他人会怎样？

****Yann LeCun：****
我认为每个人都会处于这样的境地：可以使用AI系统并将大量任务委派给它们，主要是在虚拟世界中，但最终也会扩展到现实世界中。到某个时候，我们会拥有家用机器人、自动驾驶汽车等等，只要我们弄清楚如何通过视频让系统学习真实世界的运作方式。，我们未来能够专注的任务类型将会更加抽象。同样地，现在已经没有人需要做非常快的心算了——我们有计算器。也不需要手动解积分和微分方程了。我们只需要学习这些事情的基础知识，然后可以用计算机工具来完成它们，对吧？所以，这将提升我们所处的抽象层次，从而使我们能够更加富有创造力，更加高效。你和我学习过的许多事情，未来的后代可能都不需要学习，因为这些事情会被机器处理掉。

**主持人：** 比如上学？

******Yann LeCun：**
不，不。我们还是需要去上学的。我们仍然需要接受教育。人类之间的竞争依然存在，比如谁能做得更好、更与众不同，或者更具创造性。这种竞争永远存在，对吧？因为从本性上来说，我们希望与他人竞争。所以我们不会没有工作。和我交流的经济学家告诉我，我们不会没有工作，因为我们不会没有问题需要解决。但借助AI，我们会找到更好的解决方案。

**主持人：**
也许今天我们可以这样结束，Yann，尝试定义一下“智能”到底是什么。我写下了一些定义，比如智能是信息的集合和吸收新技能的能力；是一组技能以及快速学习新技能的能力。

****Yann LeCun：**** 或者是无需学习就能解决问题的能力。在AI领域，这叫零样本学习（Zero-
Shot）。你面对一个新问题，从未接触过类似的问题，但你可以通过思考和运用你对情境的心理模型来解决它。这就叫零样本学习（Zero-
Shot）。你不需要学习新技能，而是从零开始解决问题。

所以，智能是以下三件事情的结合：

  * 1、拥有一系列你已经掌握的技能，以及解决问题和完成任务的经验；
  * 2、能够通过少量尝试快速学习新任务的能力；
  * 3、能够无需学习新知识而解决新问题的能力（零样本）。

这三者的结合就是智能的真正定义。

**主持人：** 谢谢你，Yann，感谢你今天的分享。

****Yann LeCun：**** 谢谢，非常荣幸。

。。

## [往期回顾]

[1、[斯坦福教授吴恩达演讲：6个月项目缩至10天！AI代理如何加速企业创新和应用落地]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494277&idx=1&sn=ca5229dbfdb53108f308359f95b30ee8&chksm=c0085860f77fd1761d16319a1758530758390c143e1307b4ebb7e9fabcc0266ebb5975fb8693&scene=21#wechat_redirect)

[2、[FTT大会上，创新工场李开复发言：我坚信公司只有两种命运—全面拥抱AI或破产出局，没有第三条路！]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247493990&idx=1&sn=7a3c821153687a256e787e4eee9729f6&scene=21#wechat_redirect)

[3、[【5小时视频版】Lex ×
Anthropic核心团队深度访谈：从Claude到AGI的完整对话]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494194&idx=1&sn=44aa7291a1215b432afc0860fb448abf&chksm=c00858d7f77fd1c184b433e5f7d5c7adf4773487445bfe8eaf2c36f9d14dca134fbda67d1c23&scene=21#wechat_redirect)

* * *

### 💡 看到很多读者在问"如何开始AI转型"，我们建了个实战派AI团队（成员来自复旦、浙大、华为、阿里等），专注帮企业做"轻量级"AI落地：

  * 🎯 公司该从哪个环节开始用AI？

  * 🛠️ 具体怎么落地才不会踩坑？

  * 💰 投入产出比怎么才最大？

**我们团队专注企业AI解决方案**

业务流程AI优化提升运营效率降低人力成本定制AI应用开发场景化解决方案快速交付落地AI转型咨询规划专业评估诊断精准转型方案

联系负责人：Milo-1101（仅限企业客户）

原视频链接：https://www.youtube.com/watch?v=UX8uIW9oIZk&ab_channel=CasinaPioIV

素材来源官方媒体/网络新闻

**\--END--**

  

  

