# Meta首席AI科学家LeCun访谈：为什么他一直认为AI还不如一只猫？

文章作者: AI深度研究员
发布时间: 2024-12-31 08:16
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247495092&idx=1&sn=8321e3a99a589af4fd326c3b961c1067&chksm=c0085f51f77fd6477501b3eff52afe8e856cb987ddf4edfeac8d02264907006e363df7254cb0#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAgDAAXvEN5xj7WRnecdMGicsdsjXz5eACYuVkvA94zTsAzH2MJgjutke1WDtU3PTGnuj5zjVGed27A/300

**（关注公众号并设为🌟标，获取最新人工智能资讯和产品）**

全文5,000 字，阅读约需14分钟

> **正如历史反复证明的那样，真正的技术革命往往始于对现状的深刻反思**

当整个科技界都在为大语言模型的惊人表现欢呼时，Meta首席AI科学家、图灵奖得主Yann LeCun却依旧坚持他的观点 ——
最先进的AI系统在真实世界的理解和交互方面，依然处于初级阶段。

在这场深度对话中，这位AI领域的开创者没有沉醉于当前AI的成就，而是直指其根本局限。他不仅挑战了市场对AI能力的普遍认知，更通过JEPA架构等前沿探索，详细阐述了一条不同于主流LLM的技术路径，这可能才是通向真正人工智能的关键突破口。

# 一、猫的智慧

在访谈开端，Yann
LeCun没有直接陷入晦涩的技术讨论，而是选择了一个出人意料却又妙趣横生的切入点——猫的日常行为。这个看似简单的观察，却蕴含着对AI本质的深刻洞察。'你可以看到猫在试图跳上家具时，会先坐下来，摆动头部，规划自己的轨迹。'LeCun以科学家的严谨态度描述了这个日常场景。在他看来，一只猫在跳跃前的每个细微动作都体现着智能的精髓：环境评估、轨迹规划、物理推理，以及实时决策的完美统一。当猫最终'蹦、蹦、蹦'地一跃而上时，展现的是对物理世界的深刻理解和精准预测。更令人惊叹的是，这种智能并非某些特定猫类的特权，而是几乎每只家猫都具备的能力。这种普遍性恰恰说明了某种更深层的智能本质。正如LeCun所说：'猫能够规划、推理，理解物理世界，它们对自己的动态有非常精准的认知，还有关于许多事物的直观物理学。这些都是我们目前无法用计算机再现的能力。'LeCun进一步举例说明，猫的智能不仅体现在物理动作上，还表现在其行为的主动性和探索性上。它们会故意打翻水杯，将水洒在笔记本上；会玩弄死老鼠，这些看似顽皮的行为背后，其实展现了好奇心、探索欲和对环境的主动互动能力。这种自发的探索和学习能力，恰恰是当前AI系统所欠缺的。这个鲜明的对比揭示了当前AI发展的根本性问题：我们不仅在技术路径上可能存在偏差，更重要的是，我们对智能的本质理解可能产生了某种认知盲点。

# 二、大型语言模型的迷思

在深刻剖析了当前AI的认知局限性之后，Yann
LeCun认为最好的大语言模型确实能够以令人惊叹的方式操纵语言，但它们对物理世界几乎没有理解。'在剖析当前AI发展状况时，他一针见血地指出了大型语言模型（LLM）的根本局限。这种局限不仅体现在技术层面，更反映了我们对人工智能本质的理解偏差。

随后他继续指出，LLM的认知完全基于文本训练，它们对世界的理解仅仅来自于人类的文字描述。这种二手知识是高度符号化、近似化和简化的，与真实世界的复杂性相去甚远。他用一个引人深思的对比来说明这一点：我们现在拥有能够通过律师资格考试的AI，却没有能够完成普通家务任务的机器人。这种反差揭示了一个深刻的悖论：在某些专业领域表现出色的AI系统，却可能缺乏最基本的常识理解。

更令人深思的是，Yann LeCun认为这种局限不仅仅是数据量的问题。即便将训练数据扩大十倍，当前的LLM架构也无法实现真正的创新性突破。在与Lex
Friedman的对话中，他提到一个令人震撼的数据：LLM的训练数据大约有20万亿个token，而一个4岁小孩处理的输入量可能是这个的十倍以上。然而，即使如此庞大的数据量，也不足以让AI达到"人工爱因斯坦"的水平。

问题的核心在于LLM的工作方式。这些模型本质上是在进行复杂的文本模式匹配，而非真正的理解和推理。他举例说明，当系统试图预测视频的下一帧时，最好的策略往往是预测所有可能未来的平均值，这导致输出变得模糊不清。这个例子生动地说明了当前AI系统在处理真实世界预测时的根本困境。

特别值得注意的是，Yann
LeCun指出目前最适合科学发现的AI系统其实是一些专门化的模型，而非通用型的LLM。例如，在预测蛋白质结构、研究分子相互作用或者探索新材料特性时，专门设计的模型往往能取得更实质性的突破。这些专门化模型虽然不像LLM那样引人注目，却能在特定领域产生真正的创新性发现。他的观点还揭示了一个更深层的问题：我们是否过于沉迷于语言这个人类特有的高级认知功能，而忽视了更基础的智能形式？他指出，语言能力在人类进化史上是相对晚近的发展，从基因组的差异来看，语言相关的基因可能只占很小的比例。这提醒我们，在追求AI发展时，可能需要重新审视什么才是真正的智能基石。

正如Yann
LeCun所说，真正的突破可能不在于简单地扩大模型规模或增加训练数据，而在于开发能够真正理解和推理物理世界的新型架构。这需要我们跳出当前的思维定式，重新思考AI发展的方向。

# 三、AI时代的商业布局

在评估当前AI发展态势时，Yann
LeCun提出了一个引人深思的类比：现今的AI领域正在重演'修昔底德陷阱'，即当一个新兴势力崛起时，现有的主导力量会将所有注意力集中在它上面。在AI领域，这种现象表现为市场对大语言模型（LLM）的过度关注，以至于挤压了其他创新方向的发展空间，特别是在物理科学领域。

这种现象背后，Yann
LeCun看到了一个更深层的问题：企业正在陷入"沉没成本谬误"。由于已经在LLM技术上投入巨大资源，许多企业不愿承认其局限性，反而试图用这一技术解决所有问题。这种固守既有投资的心态，可能导致企业错失更具突破性的技术机会。

在科学应用领域，他特别强调了专门化AI模型的价值。他指出，当前最适合科学发现的并非通用型的语言模型，而是那些针对特定任务优化的专门系统。例如，在预测蛋白质结构、研究分子相互作用或探索新材料特性等领域，专门设计的模型往往能够取得更实质性的突破。对管理者而言，Yann
LeCun的观点提供了一个重要的决策框架：在AI技术选择上，不应被短期市场热点所主导，而是要从企业的实际需求和长期发展出发。这意味着企业需要建立更加多元化的AI技术组合，而不是将所有资源都押注在当前最热门的技术方向上。

所以。企业与其幻想通过某个单一突破实现质的飞跃，不如踏实地在多个技术方向上稳步推进。这需要企业具备足够的战略耐心，并建立起有效的风险管理机制，以应对技术发展过程中的不确定性。

# 四、企业转型的关键

他认为，企业不应盲目追随大语言模型的热潮，而是要着眼于能真正理解和推理物理世界的AI技术。在他看来，未来AI的突破口在于两个关键技术方向：自监督学习和JEPA（联合嵌入预测架构）。他将自监督学习比作"AI的暗物质"——虽然不那么引人注目，却是AI进步的根本动力。这个比喻源自他对人类和动物学习方式的观察：我们大部分知识并不是通过明确的教导获得的，而是通过感知和互动自然习得的。比如，许多动物在没有父母教导的情况下就能掌握复杂的生存技能。自监督学习正是模仿这种自然的学习方式，让AI系统能够从海量未标注的数据中自主学习。

而JEPA则代表了一种更具突破性的技术路径。这个架构的核心目标是构建世界的"心理模型"，使AI能够理解和预测物理世界的运作方式。Yann
LeCun用木星轨道预测的例子来阐释这一理念：要预测木星未来几个世纪的轨道，实际上只需要六个关键数值——三个位置和三个速度。密度、成分、自转速度等众多参数都不是必需的。这个例子生动地说明了JEPA想要实现的目标：找到现象背后最本质的表达，去除冗余信息，实现真正的理解和预测。

在实际应用中，JEPA展现出独特的优势。不同于传统的监督学习需要大量标注数据，或者当前语言模型仅关注文本层面的关联，JEPA试图理解和预测数据背后的本质关系。这种方法在处理视频、图像等连续性数据时特别有价值，因为它能够捕捉到数据中的不变特征，而不是简单地进行表面模式的匹配。

对决策者而言，这些见解具有重要的战略意义。首先，企业需要重新评估其AI投资方向。与其一味追逐看似显著但实则局限的语言处理能力，不如将目光投向那些虽然需要更长期投入，但可能带来根本性突破的技术方向。其次，企业需要建立起对AI本质的深入理解。正如Yann
LeCun所说，真正的AI不在于简单地扩大模型规模，而在于赋予系统理解和推理世界的能力。此外，企业组织还需要注意建立长期的技术积累。自监督学习和JEPA这样的技术路线，虽然现在可能还不如大语言模型那样炙手可热，但它们可能是通向真正人工智能的必经之路。企业如果能在这些方向上及早布局，就可能在未来的AI竞争中占据先机。

# 五、AI安全问题

在讨论AI安全问题时，Yann
LeCun首先指出了当前AI系统，特别是大语言模型（LLM）在安全机制上的根本性缺陷。虽然这些系统表现出惊人的语言处理能力，但其安全限制往往可以通过巧妙的提示而被绕过。这种情况凸显了现有AI安全设计的不足，也暗示了我们需要从系统的核心架构层面来重新思考AI安全问题。为了解决这个问题，LeCun提出了"目标驱动"架构的概念。这种架构的核心在于构建一个拥有完整世界模型的AI系统，使其能够在"大脑"中模拟行动的后果，并在决策过程中自动整合保护性约束。这些约束不是简单的外部规则，而是系统决策过程中不可分割的组成部分，类似于人类社会中的法律体系。

在解释这种方法的重要性时，Yann
LeCun用"纸夹问题"做了一个生动的说明。这个著名的思想实验描述了一个仅有单一目标（制造纸夹）的AI系统可能带来的灾难性后果。他指出，如果系统缺乏内置的保护机制，它确实可能会不计代价地追求目标实现。但通过目标驱动架构，系统在追求目标的同时，会将安全约束作为决策过程中的必要考量，从而避免出现极端行为。

在实现路径上，Yann
LeCun提出了一个极具启发性的工程类比。他指出，就像我们无法证明涡轮喷气机是绝对安全的，但可以通过持续的工程改进使其变得极其可靠一样，AI的安全性也应该通过不断的工程实践来提升，而不是寄希望于找到一个完美的理论证明。这种观点与一些研究者追求"可证明安全的AI"的路径形成了鲜明对比，展现了他作为科学家和工程师的双重思维。

更进一步，Yann
LeCun强调了系统设计中"保护性目标"的重要性。他提出可以通过硬件层面的设计，比如让GPU的某个电路在系统违背安全约束时烧毁，来模拟"痛苦"的感知，从而在物理层面确保系统的安全行为。这种方法虽然看似激进，但实际上反映了一种深刻的洞察：真正的安全必须建立在系统的根本架构之上，而不是依赖于可能被绕过的表层限制。

他这种务实方案引发了学界的广泛讨论。尽管一些研究者，如Max Tegmark等人，仍在追求更理论化的安全保证，但Yann
LeCun的工程导向方法提供了一个可能更切实可行的解决方案。这种方法不仅考虑了AI系统的技术实现，还充分考虑了现实世界的复杂性，为构建真正安全的AI系统提供了一个可行的路径。

# 六、AI的未来之路

Yann
LeCun的观点不仅是对当前AI技术现状的分析，更是对未来AI发展方向的展望。他认为，AI是社会最需要的资源之一，它能够有效扩展人类的智能，推动社会进步。他将AI的影响力比作15世纪印刷机的发明，认为AI能够像印刷机一样推动启蒙运动、科学、民主的发展，帮助人类摆脱宗教教条，变得更加理性。他坚信，AI能够为人类带来巨大的福祉，但前提是我们能够正确引导AI的发展。他指出，AI的最终目标是帮助人类更好地理解世界，解决人类面临的各种难题，促进人类社会的进步和发展，这才是AI发展的根本意义所在，也是我们追求的最终目标。

AI的发展可能带来一些暂时的负面影响，但他相信，从长远来看，AI将彻底改变社会，使人类更加强大。他强调，我们应该将AI融入其长期战略，建立灵活适应变化的组织结构，积极拥抱AI，充分利用AI带来的机遇，未来，AI
会像虚拟团队的一部分一样支持每个人。这种支持不仅限于商业领袖或教授，而是包括每个人。学生也会被 AI
系统增强，他们的学习过程会因为这些系统而变得更强大。我觉得这是一个很美好的事情，而不是威胁。我们现在处于 AI 发展的初期，这是 AI
最差的状态，只会越来越好。AI 能做的事情越来越快、越来越高效，比如智能眼镜帮助理解物理世界，以及像 Llama 模型这样的新技术为教育提供更多可能性。

此外，Yann
LeCun还对“通用人工智能”（AGI）这个概念进行了重新审视。他认为，“AGI”这个词存在问题，因为它没有反映出人类智能的特殊性。他认为，人类智能具有非常高的特化程度，而“AGI”这个词过于笼统。他更喜欢用“人类水平的AI”或者“AMI”（Advanced
Machine Intelligence，高级机器智能）来描述未来AI的目标，在 Meta，他们把它简称为
“Abbie”，因为这个词在法语中也有“朋友”的意思。他认为，实现“AMI”是一个渐进的过程，而非一夜之间突然发生的事情，我们所有人正在尝试的一些想法成功落地，要构建一个至少在人类看来具有人类水平智能的系统，他觉得这至少需要五到六年的时间。但这是否真的会在五到六年内实现呢？他给出答案是很不确定的，这个分布有一个非常长的尾巴。AI
的历史告诉我们人类，人们总是低估它的难度。

# 七、结语

从对当前AI'不如一只猫'的清醒判断，到JEPA架构这条另辟蹊径的技术路线，Yann
LeCun为我们展现了一位顶尖科学家对AI本质的思考：真正的智能不在于处理更多的文本数据，而在于理解和互动于真实世界的能力。

在当前AI赛道上，大多数玩家仍在语言模型的跑道上竞速。但正如Yann
LeCun所警示，这条路径终会遇到天花板。对我们而言，这场对话的价值不仅在于提供了一个审视AI现状的新视角，更在于为我们指明了一个可能的突破方向：在押注主流赛道的同时，也要关注和布局那些试图突破AI根本局限的新技术路线。

## 【往期回顾】

[1、[打破传统认知，纽约时报专访 Sam Altman：AGI
进程如何正超预期加速？]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494553&idx=2&sn=984bc37d7eca7dabad8939702b3b995f&scene=21#wechat_redirect)

[2、[专访谷歌CEO
Pichai：公司25%代码都由AI协助完成，2025年将迎来重大技术突破]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494576&idx=2&sn=a9e95867f1e9579a8beb6c03358ae018&scene=21#wechat_redirect)

[3、[陶哲轩对话OpenAI：从数学出发，AI如何改变每个人的工作方式？]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494697&idx=2&sn=4baa728bcf666c12949e46920339fa7c&scene=21#wechat_redirect)

* * *

### 💡 看到很多读者在问"如何开始AI转型"，我们建了个实战派AI团队（成员来自复旦、浙大、华为、阿里等），专注帮企业做"轻量级"AI落地：

  * 🎯 公司该从哪个环节开始用AI？

  * 🛠️ 具体怎么落地才不会踩坑？

  * 💰 投入产出比怎么才最大？

**我们团队专注企业AI解决方案**

业务流程AI优化提升运营效率降低人力成本定制AI应用开发场景化解决方案快速交付落地AI转型咨询规划专业评估诊断精准转型方案

联系负责人：Milo-1101（仅限企业客户）

原视频链接：https://www.youtube.com/watch?v=u7e0YUcZYbE&t=243s

素材来源官方媒体/网络新闻

**\--END--**

