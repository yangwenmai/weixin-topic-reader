# 站在AGI前夜的思考

文章作者: AI深度研究员
发布时间: 2024-12-31 08:16
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247495092&idx=2&sn=f1ba7c09bbd66859c1bd5542a7f84556&chksm=c0085f51f77fd6473348afb0d161c10e3bf06fe3988af5601fe85b5b877a67a0d6fc3c1df8d6#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAhf0HK0yIQ30LddtnMHP7p30nsMGQEHgviaYq7e83ATdjuJqglls5vXQPp4mCD0L9YpKvGGqbG5abw/300

**（关注公众号并设为🌟标，获取最新人工智能资讯和产品）**

全文6,000 字，阅读约需18分钟

![](https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAhf0HK0yIQ30LddtnMHP7p37jVia5lkprYavHYOiabtU8th2xOue03LticprXlQqRcuwh6wlicZXPbRog/640?wx_fmt=jpeg&from=appmsg)

当我们回望2024年，就像现在回看90年代的计算机时代一样，会惊叹于AGI发展的起点是如此朴素而充满可能。这是一个值得铭记的开端。

正如硅谷AI搜索公司Exa的CEO Will Bryk所言，o3模型的出现标志着AGI发展的重要里程碑，我们即将迎来巨大的历史性变化。

对于还未"躬身入局"的AI爱好者和轻度使用者来说，这是一个既充满机遇又充满挑战的时代。从技术变革层面，我们看到了AGI在符号处理、数学运算等领域的突破性进展；在创业应用层面，各行各业正在经历深刻变革，从数学家到程序员，专业人士的角色正在重新定义；而在未来幻想层面，无论是职业变革还是人类社会的潜在挑战，都令人既兴奋又深思。

正如有人说"最好的预测未来的方法就是亲手实现它"。在这个AGI前夜，我们不仅需要关注技术突破，更要思考如何在即将到来的变革中，找到自己的位置和方向。本文将从技术变革、创业应用、未来幻想三个层次，为大家展开一张思考地图。

##  _原文如下：_ __

![](https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAgDAAXvEN5xj7WRnecdMGicsP78MRW61SiaTPGnDut7hXMfaQBFFzNLDLt9iatOoGKNvJXklFzUBFZtw/640?wx_fmt=jpeg&from=appmsg)

我一直和几位朋友聊到了
o3。他们的反应可以概括为：“天呐，这真的要成真了吗？”是的，这真的要来了。接下来的几年将会无比疯狂。这是载入史册的大事，甚至可以说是影响全银河系的存在。

###  一、o3 模型的出现

o3 的出现其实并不令人意外。两个月前 OpenAI
就展示了测试扩展曲线，而计算机发展史则告诉我们，无论多难以置信，趋势线终会成真。真正令人震撼的是，这一切只用了两个月。这就是从大学级 AI 到博士级 AI
的飞跃速度。对人类而言，变化总是令人期待，但过于迅速的变化则会让人目瞪口呆。接下来的发展路径已经相当清晰。o3
类模型在任何能够明确奖励函数的任务上表现得非常强大。像数学和编程这样的领域，奖励函数的设计相对简单，而文学创作就更复杂些。因此，在短期内（未来一年），我们可能会看到一些表现极为突出的模型：它们在数学、编程和推理能力上接近
AGI 水平，但在小说创作上却显得平庸。虽然更好的推理能力会让模型看起来整体更聪明，但它们仍会在某些领域出错，尤其是那些没有经过强化学习的领域。长期来看（1
到 3 年），我们将逐步用新的领域数据进行强化学习（例如情感数据和感官数据），弥补盲点。到那时，几乎所有人（除了 Gary Marcus）都会承认它们是
AGI。

到 2025 年，智能代理将正式登场。像 o3
这样的模型完全有能力导航浏览器、操作应用并执行复杂指令。这类任务的奖励模型设计简单，同时，自动化办公也是一个巨大的商业市场，能够为 AI
实验室的高额投入提供合理性。因此，我预测，到 2025 年底，你就可以告诉你的电脑完成任何涉及网页导航或数据整理的工作流。在所有可能被 AI
超越的职业中，数学家或许是最先“出局”的。数学本质上是符号操作，而符号空间正是 LLM
的强项。数学并非真的难，只是人类天生不擅长处理它，类似的还有正则表达式。

一个关键问题是，生成研究级别的合成数据会有多难？我的猜测是并不难。博士级数学和研究级数学对我们而言似乎有本质上的区别，但对 AI
来说可能只是强化学习的训练量问题。我给数学家 700 天的时间。（听起来很疯狂，但认为 o6 不会超越数学家同样疯狂，所以我对这一预测的信心超过
50%。）换句话说，700
天后，人类或许将不再是宇宙中数学领域的王者。至于软件工程师呢？在短期内，我们可以说进入了黄金时代。每个软件工程师都像是刚刚升职为“技术总监”，干得漂亮！对那些全面采用
LLM 的人来说，到 2025 年底，编程将更多是协调一系列小任务，由智能代理去完成。任何有清晰规范的代码需求，都可以由 o4
系统执行，错误率在可接受范围内。当然，也会有挑战，比如目前的上下文窗口可能不足以容纳整个代码库，但像 Sam 这样的领导者对此已经心中有数。

### 二、未来职业种类

AI
会很快淘汰所有软件工程师吗？答案是否定的。软件工程不仅仅是根据超明确的提示完成代码合并请求（PR）。与数学家不同，软件工程师需要与现实世界打交道，尤其是与其他人。工程师需要理解客户的需求，与团队成员沟通协作。当他们设计系统架构或编写代码时，也是在结合大量的组织背景信息进行思考。而这些都是
o4 目前无法做到的。然而，o4 可以帮助那些掌握这些背景的工程师将效率提升 10 倍。

如果工程师的效率提高了 10
倍，是不是意味着需要的工程师数量会减少？对于某些特定公司来说，确实可能如此。通过更小的团队，他们可以达到相同的产出。但从全球来看，对软件工程师的需求可能会反而增加。毕竟，世界完全可以吸纳
10
倍更多的高质量软件。因此，我认为我们即将迎来一个由精简公司推动的应用黄金时代——每个人和每个企业都能拥有定制化的微应用。至于更长远的未来（超过两年在这个领域已经算是长远了），软件工程可能会发生翻天覆地的变化，但具体如何仍难以预测。随着
o6 系统的普及并深度融入我们的应用程序，像“前端工程师”这样的角色可能在三年内消失。这听起来奇怪吗？其实并不，因为 30
年前前端工程师这个职位压根就不存在。

我们应该跳出当前的视角来看待这一切。每一代软件开发方式都会经历一次彻底的转型。软件的核心始终是将需求转化为逻辑，而这个转化过程的抽象层级一直在提升：从最初的二进制到
Python，而现在，它正在向自然语言迈进。将编程语言转变为自然语言的确让非技术人员也能参与编码，但最出色的开发者仍然是那些能在不同抽象层次之间自如切换的人。换句话说，软件工程的本质是通过代码解决组织的需求。如果有一天软件工程完全实现自动化，也就意味着所有组织都已经完全自动化。

我们讨论了一些知识型工作者，但体力劳动者呢？AI 对他们的影响同样不可避免，但速度会更慢，因为需要解决重力和摩擦等物理问题。不过，o
类模型对机器人技术的直接帮助并不大，因为需要花一小时运行的模型对工厂流水线上的机器人毫无意义。虽然更智能的基础模型确实有所助益，o
类模型也能帮助训练这些模型，但这并不能解决机器人技术的核心瓶颈。我认为最大的瓶颈在于硬件的改进，以及快速、可靠的感知与行动模型。这些进步可能需要更长的时间（比如几年）。真正疯狂的机器人技术进展可能要等到机器人开始制造机器人，AI
开始从事 AI 研究时才会发生。这可能与 o 类模型有关，但我觉得还需要几年。

我们总是用“年”来衡量进展，但也许应该改用“算力”作为衡量标准。时间决定了人类的效率，而算力决定了 AI 的效率。在研究机构中，AI
的产出将变得越来越重要。这就是为什么各大机构都在竞相建设超级计算集群，比如 Meta 的 2GW 集群，以及 Xai 计划新增的 10 万张 H100
显卡。

所有实验室都会迅速跟随 OpenAI 的测试时计算模型的脚步，一些实验室甚至可能通过堆叠算力来弥补算法的不足，就像当初他们追赶 GPT-4
那样。开发这些模型需要结合一些共同的知识和实验室特有的“独家秘诀”。目前还不清楚 OpenAI 的 o
类模型中有多少“独家秘诀”，但他们的进步速度表明，这更可能是一种算法上的突破（容易复制），而不是某种独特的数据配比（较难复制）。

在测试时算力主导的时代，我不确定更多的算力和更好的模型哪个更重要。一方面，你可以通过增加测试时的算力弥补模型性能的不足；另一方面，一个稍微优秀一点的模型可能带来指数级的算力节省。

如果 Xai 只是因为更擅长搭建超大算力集群而赶超 OpenAI，这还真是讽刺。

不过，不会有哪个模型护城河能持续超过一年。原因很简单，各实验室之间的研究人员流动频繁，就像棒球卡片一样被“交换”。更重要的是，这些研究人员不仅互相跳槽，甚至一起开派对、相互交往。加上研究者们大多理想主义，如果局面真的失控，信息共享几乎是不可避免的。

现在的 AI 竞赛局势真是有点荒唐，就像冷战时期的核竞赛，但区别是“美国人”和“苏联人”会在周末聚在洛斯阿拉莫斯开派对，同时在推特上互相挑衅：“赌你们
2025 年做不出最大的核武器，哈哈 :)。”

### 三、科技巨头AI竞赛

AI 竞赛将继续以一种自由随性的氛围进行，直到政府介入，或者发生一些重大的负面事件。

o 类模型改变了算力扩展的游戏规则。o
类模型带来了大规模建设的动机，因为每增加一个数量级的算力都会带来明显的性能提升。对算力提供商来说，这种增长规律堪称完美。我猜，这正是 Sam
想要构建万亿美元算力集群时的考量。

但这对 Nvidia 可能不利。o 类模型让推理变得比训练更重要。而推理芯片的优化比训练芯片更容易，这意味着 Nvidia
的技术护城河可能在这一领域不够坚固。

一个很大胆的猜想：如果 o 类模型能够解锁全球的算力资源，用来训练最顶尖的模型会怎样？比如，把全世界的 MacBook Pro
组建成一个巨型推理集群，这会不会让开源项目联合起来击败封闭式的 AI 系统？这听起来真的很酷。

除了算力之外，现在代码本身也成为另一个指数增长的变量。如果某个实验室拥有独占的高级模型访问权限，他们的软件工程师效率比其他实验室高出两倍，就能更快达到下一阶段的生产力倍增。除非代码开发速度触及上限，而实验排起了长队等待算力运行，这时实验室会再次受限于算力。（这种动态其实很难预测。我真的很好奇实验室如何平衡算力与人力投资的分配模型。）即便算力扩展和知识型工作的自动化已经听起来足够颠覆，但当科学家真正开始感受到
AGI 的冲击时，情况才会更加疯狂。我指的是物理学家、化学家和生物学家。

一切都会从理论领域开始，尤其是理论物理学。如果数学真的被彻底解决了（虽然听起来难以置信，但并非不可能），那么理论物理学的突破也不会太远。毕竟，它同样是符号领域，而
LLMs 在符号操作方面已经超越了人类。

想象一下，当我们拥有一百万个 AI 冯·诺伊曼在路易斯安那的数据中心（Meta
即将建成的超算中心）昼夜工作时，会发生什么？它们能以多快的速度阅读过去一百年来成千上万篇物理学论文，然后立即给出更准确、更高效的结论？

当然，这部分最难预测。理论物理学、化学和生物学——如果这些学科在一个 RL 训练的 LLM
面前变成了“小菜一碟”，那会怎样？我们现在还能找到什么理由证明这种情况不会发生？没错，目前这些模型还没有真正带来颠覆性创新，但它们大多停留在高中或大学的认知水平，而这个阶段通常不会诞生新物理学。而当它们达到博士级别时，创造性或许会开始显现。

如果 AI
开始产出新的科学理论，进步的瓶颈将转移到物理实验的验证和执行上。这些瓶颈包括劳动力和材料。届时，如果没有机器人能够制造更多机器人，那反而会让人感到意外。一旦劳动力问题解决，材料开采也可以交给机器人完成。虽然这些物理制造和运输的过程仍需要时间，但时间单位将以“年”而非“十年”计算。以上所有推测的前提是没有新的限制阻碍
AI 和机器人技术的研究与发展，并假设模型可以自由地不断学习。但现实几乎可以确定，这种自由不会发生。AI
进步最大的障碍仍是人类本身，包括监管限制、恐怖主义威胁，以及可能的社会动荡。

### 四、政府的干预

各国政府不会袖手旁观，任由几家旧金山公司的自动化机器人主导地球资源的开采（监管压力）。如果政府无力阻止这种情况，愤怒的失业人群可能会诉诸暴力（恐怖主义）。除非
AI 增强的媒体让人们陷入大规模信息污染，以至于社会功能彻底失灵（社会崩溃）。

如果战争真的爆发，我反而认为它不会成为发展的障碍，而是一个加速器。

未来将变得越来越严肃。2025 可能是 AI 还像旧金山科技推特上的玩笑一般轻松的最后一年，之后，身穿西装的“主流人士”就会介入。所以趁现在还能享受
roon 和 Sama 的时候，好好珍惜吧。

AI 会毁灭所有人吗？我更担心的是人类错误地使用 AI，而不是 AI 自身失控。

人类有 5000 年的历史记录表明，人类会利用最新技术互相残杀。二战后的和平是一种异常状态，随时可能因为美国的一个误判，或对手认为必须通过先发制人来阻止
AI 的快速发展而终结。当武器变得更加致命、更加自主时，局势的危险性会大幅提升。

另一个重大威胁是 AI 引发的社会混乱。AI 生成的媒体可能带来大规模信息混乱、集体恐慌，甚至让整个社会陷入思想麻木。一旦一个专制国家赢得了 AI
竞赛，他们可能会利用新技术剥夺我们数千年的自由。

此外，还有 AI 失控的可能性。它可能会引发我们未能预料到的、导致灭绝的级别灾难。尤其是在强化学习（RL）重新被广泛使用的情况下，AI
不再只是模仿人类数据，而是开始探索自己的优化方式（模仿人类相对更安全）。不过，目前这些模型的核心仍然是 LLM，而 LLM
的“本能”是理解人类。比如，你在提示中明确要求它“不要做任何可能危害我们的事情”，要说它在这种情况下仍可能造成毁灭，那责任就不在 AI
了。当然，我并没有涵盖所有相关论点，但当我梦见 AI 反乌托邦的噩梦时，我脑海中浮现的是中国和俄罗斯的国旗，而不是 OpenAI 的标志。

### 六、是期待，而不是恐惧。

我一直憧憬的科幻世界正在到来，比想象中来得更快。这种速度令人既兴奋又害怕，但在实现这一切的众多路径中，我不确定是否还有更好的方法能大幅优化当前的进程。实际上，这已经是一条相当理想的时间线了。

在接下来的十年中，我希望看到以下令人期待的实现：

  * 颠覆性的物理学突破
  * 由机器人建造的火星和月球基地
  * 具备完美学习和咨询功能的虚拟导师（几乎实现了，只需要更强的检索、记忆能力和个性化）
  * 零副作用的生物增强药物
  * 通过优化无人机实现全自动化的出行方式
  * 以聚变、地热和太阳能为主的超级清洁能源

一些意料之外的重大发现：AI 天文学家在数据中识别出外星信号？AI 化学家设计出室温超导体？AI 物理学家统一物理学理论？AI
数学家解决黎曼猜想？这些目标看起来已经不再是科幻，而是真正触手可及的科学现实。

那么，这一切将通向哪里？最终，我们会迎来超智能的诞生，而那意味着物理定律所允许的一切都将成为可能。我希望借此实现永生，探索其他星系。我也期待人类能彻底升级身体，突破生理局限。不过，对我来说，最令我兴奋的是，我们可能会揭开宇宙起源的谜底。十年前，我开始记录自己对这一答案的渴望，以及如何通过
AI 实现这个目标。而现在，这一切可能真的正在发生，简直令人难以置信。

我们生活在一个前所未有的时代，这些听起来像科幻的目标，已经变得令人信服且可行。每一项新的 AI 突破都让更多人意识到这一点，最近的 o3
是最新的例子。唯一可能让未来不那么美好的，是我们人类自身的阻碍。公众舆论的走向、政策的制定、社会的稳定性，以及国际间的合作——这些都是实现这一壮丽未来的潜在障碍。很多人觉得
AI 实验室的研究人员在掌控我们的未来。我不同意这个观点。他们的研究方向早已注定，无非是执行某些注定会在某个实验室完成的模型架构而已。

真正不确定的是我们的公众舆论、政策方向、社会的稳定性和国际间的合作。这些才是我们需要关注的关键，而我们每一个人共同构成了未来的真正守护者。

在未来的混乱时期，我们都有责任为世界指引方向，确保走向一个美好的未来，而不是陷入悲惨的结局。有很多方式可以做出贡献。比如，开发能够促进社会稳定或让人们变得更智慧的产品（例如，一款帮助用户调节社交媒体使用习惯的应用）；通过高质量的内容和评论帮助公众了解正在发生的事情（例如更优质的社交媒体讨论或更高效的搜索引擎）；参与社区活动或地方政治，清理我们的城市，让它看起来更像未来的乌托邦，而不是反乌托邦。

### 七、新的人生意义

几乎每个人都对 AI
世界中可能失去意义感到担忧，也许你也一样。对此，我想说，这个时代正好相反！你正处在历史上最重要的时刻，并且拥有影响未来的能力。参与拯救世界难道不足以赋予人生意义吗？你真的愿意回到那个只有个人职业进步，而世界停滞不前的时代吗？

也许我们需要的转变，是从通过个人成功寻找意义，转向通过集体成功获取意义。许多我们现在的工作将很快被自动化，我们需要学会适应。如果你的价值感来自某项具体技能，那么可能会在五年内发现这项技能已经不再被需要，让你无所适从。但如果你能从尽力帮助这个世界中找到意义，这种意义将永远不会过时。

对于那些因为 o3 而被给出职业建议的应届毕业生，我的建议是：学会成为
1）一个高主动性的解决问题者，2）一个优秀的团队合作者。你现在学习的具体技能可能并不重要，因为世界变化的速度会让这些技能迅速过时。但积极解决问题的态度和与团队协作的能力将始终重要。同时，你也需要接受一个充满不确定性的生活和世界。未来会变得很奇特。也许你不会住在郊区，养两个孩子和一只狗。但你可能会在星际方舟上，带着两个“赛博孩子”和一只
AI 狗探索宇宙。

我们正处在 AGI 到来的前夜。在这个圣诞前夜，我希望你们能帮助 AGI 的转型顺利进行。这样，我可以在公元 3024
年的圣诞夜，在一个环绕“奥特曼半人马座”（Altman Centauri）的行星上向你们问好。

# 往期回顾

[1、[全文+视频实录:Ilya Sutskever 在NeurIPS
2024的预训练终结演讲（建议收藏）](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494782&idx=2&sn=5c2033d4e97ff318d067940ee36f06f3&scene=21#wechat_redirect)

[2、[福布斯最新预测：2025年AI产业链十大剧变，这些机会别错过](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494994&idx=2&sn=af56f7cc120db9c944a8ea2d58ad42cc&scene=21#wechat_redirect)

[3、[对话首席AI科学家LeCun：大语言模型已触顶，Meta的下一代AI模型可能是新方向](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494948&idx=1&sn=97dd2656c669352cb0a732cb85f3e903&scene=21#wechat_redirect)

原文链接：https://x.com/WilliamBryk/status/1871946968148439260

素材来源官方媒体/网络新闻

**\--END--**

  

