# 加州伯克利教授Stuart Russell演讲：AI创造15万亿美元巨大财富，我们如何把握这波时代红利？

文章作者: AI深度研究员
发布时间: 2025-01-06 07:31
发布地: 上海
原文链接: http://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247495215&idx=1&sn=6dc1f2131310a00411de137b5b933d34&chksm=c0085ccaf77fd5dc08ff969ba18bc767e9c79d3963021a5d06dae6b4ea7e3f8d169f384ebed4#rd

封面图链接: https://mmbiz.qpic.cn/mmbiz_jpg/iaqv2tagPYAgwT55B5ibmicAbuQpOlFa4aXGxELU2VZAJmpgaORKAmtVDic4CDhsT4sfXYUeicOnGiajrTLUnAvibUFicA/300

**（****关注公****众号设为🌟标，获取AI深度洞察****）**

全文 7,000字 | 阅读约18分钟

![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAgwT55B5ibmicAbuQpOlFa4aXejY9OnzB18YFDbxuxstDG7WFVJMq6r6ibotBHzOWKYQWB6QMPnX9HoQ/640?wx_fmt=png&from=appmsg)

  

> **编者按：** 在当前AI快速发展的关键时期，我们需要听一听真正的专家怎么说。本文整理自Stuart Russell在12月的World
> Knowledge
> Forum上的重要演讲。作为加州大学伯克利分校人工智能系统中心创始人，以及被誉为AI领域"圣经"的《人工智能：一种现代方法》作者，Russell教授对AGI发展的判断值得每一位关注AI未来的人深入思考。

**核心观点预览：**

  * **巨大经济价值** ：AGI将创造15万亿美元财富，推动全球GDP暴增10倍

  * **普惠人类** ：让全球每个人都能享有中产阶级的生活品质

  * **投资规模** ：AI领域投资已达5000亿美元，超曼哈顿计划10倍

  * **技术突破** ：从蛋白质折叠到流体模拟，AI正在重塑科研与医疗领域

  * **发展方向** ：通过科学设计确保AI发展造福全人类

Stuart
Russell观察到，从2017年AlphaGo击败世界冠军柯洁，到AlphaFold破解蛋白质折叠难题，再到生成式AI革新创作方式，AGI（通用人工智能）的脚步正在加速临近。在科学领域，AI已经将需要数周的复杂流体模拟计算缩短至几秒钟，极大地推进了气候研究和工程设计的进展。

在最近的一场重磅演讲中，Russell教授展望了AI带来的普惠未来：AGI不仅将创造15万亿美元的巨大经济价值，更重要的是能让全球每个人都享有与中产阶级相当的生活水平。这种空前的财富创造和分配方式，将从根本上改变人类社会。同时，他也深入探讨了如何通过正确的设计原则，确保这场技术革命真正造福全人类。

人工智能浪潮下，你准备好了吗？扫码参与顶尖学府AI人才培养计划，掌握未来竞争力！AI浪潮汹涌而来，不学习就是在倒退，现在正是提升自己的最佳时机。我们AI深度研究院正在与复旦大学、上海交通大学、中国科技大学，联合打造面向未来的AI实战课程，让每个人都能把握AI红利。和顶尖专家一起，解锁AI时代的无限可能。【问卷即将截止！把握最后机会，重磅课程席位有限！】扫描二维码，提前布局AI时代，不要让未来的你，遗憾错过现在的机会！![](https://mmbiz.qpic.cn/mmbiz_png/iaqv2tagPYAgwT55B5ibmicAbuQpOlFa4aXLeJaolF06jUsuoiaoOBMWT8sJQx5xiawwaqeKWjFo1A1QHH7OZYU8eSg/640?wx_fmt=png&from=appmsg)这里扫描

# 演讲文稿

## 1、如果我们实现了AGI目标会怎样？

谢谢大家，今天的主题是“人工智能”，但实际上我想更多地谈谈常识。

让我们回到人工智能的起点——20世纪40年代，虽然官方的诞生日是1956年，但在那之前已经开始了相关研究。人工智能的目标一直是
创造在每个相关维度上都超越人类智能的机器。如今，我们将其称为 AGI（通用人工智能）。

然而，在大部分人工智能历史中，我们忽略了一个非常重要的问题：如果我们实现了这个目标会怎样？

如果我们实现了这个目标，那将是人类历史上最重要的事件。稍后我会进一步解释为什么这会是最重要的事件，但这个道理其实显而易见。我们人类之所以能主宰世界，是因为我们的智能；文明的诞生和发展也是智能的产物。那么，如果我们引入一种全新的、更聪明的实体——可以说是一种新的“物种”——可能会发生什么？毫无疑问，这将是人类文明的一个转折点。

**谷歌 DeepMind 的 CEO Demis Hassabis
曾这样描述：“我们首先解决人工智能的问题，然后用人工智能解决其他所有问题。”但直到最近，我们从未认真思考过：如果我们已经成功了呢？**

大约一年前，我的合著者 Peter Norvig（共同编写了我的教科书）发表了一篇文章，声称我们实际上已经实现了 AGI。他将这一成就类比为 1903
年的莱特兄弟飞行器。虽然当时的飞机不舒适，没有如今飞机上的酒吧、香槟和餐后饮品，但它们确实是飞机。从那以后，飞机变得更大、更舒适、更快，但原理早已确立。

那么，人工智能是否已经处于“莱特兄弟版本”的 AGI
阶段？对此，我深信答案是否定的。当然，我可能错了。因为对于我们现在拥有的人工智能，我们对其工作原理完全没有概念。而莱特兄弟则对他们的飞机如何飞行有着清晰的理解，因为那是他们自己设计并建造的。他们计算了发动机的功率需求、升力、阻力等等，在试飞之前已经有了相当大的把握。

然而，目前的人工智能系统是由巨大的黑箱组成的，包含了大约一万亿个可调节的元素。我们通过大约一万亿次随机调整，直到系统表现得“看起来像是智能的”。换句话说，这更像是莱特兄弟决定放弃设计飞机，转而尝试“养鸟”。他们通过不断培育更大的鸟，直到培养出一只足够大的鸟来载人。

如果他们把这只巨鸟带到航空管理局（FAA）寻求认证，FAA
的回应可能是：“你的鸟还在吃人，还在把人掉进海里，我们不知道它是怎么工作的，也不知道它会做什么，所以我们不能认证它。”目前的人工智能状态大致如此。而我认为，这种“巨鸟”永远无法足够大到载客数百或数千人，也永远无法超音速。我们需要的是在
能力 和 理解 两方面的突破，因为单有能力而没有理解对我们毫无用处。

## 2、深度学习时代

接下来我想谈谈过去十年间的深度学习时代。**深度学习的核心方法是：你从一个巨大的可调参数集合开始，通过调整这些参数，使系统的端到端行为符合预期目标，例如识别图像中的物体、将中文翻译成英文，或完成其他任务。**

事实上，我认为机器翻译是这项技术的第一个重大突破应用。我当时非常兴奋，因为它可以完美地翻译我需要处理的法国税务文件（因为我在法国有一套公寓）。翻译的质量很高，虽然即使翻译成了英文，我仍然看不懂那些税务文件。

另一个重大成功案例是
AlphaFold。这个系统可以通过氨基酸序列预测蛋白质的结构。蛋白质折叠问题曾是结构生物学领域的长期难题。之前的方法既缓慢又昂贵，仅适用于某些特定蛋白质。而这种计算方法让生物学家如同进入了一个巨大的“糖果店”，因为他们现在可以预测数百万种蛋白质结构，而不仅仅是几百种。这是对科学的一项巨大贡献。另一项对科学和工程的重要贡献是
机器学习在模拟中的应用。模拟是当今世界的一个重要基础，我们通过模拟设计桥梁、飞机，以及流体在船只周围、管道内、甚至人体动脉中的流动。这些模拟非常耗费计算资源，通常需要数周时间才能在超级计算机上完成一项血流模拟。但借助机器学习方法，我们可以将这些耗时从数周缩短到几秒钟，同时保持相同的准确性。这让我们能够在天气预报、气候建模、工程设计等方面取得更快、更好的进展，许多领域的效率因此得到了大幅提升。

另一个有趣的例子是生成式设计。你可能熟悉 DALL-E、MidJourney 和 Stable Diffusion
这些生成图片的系统，例如你可以要求它们生成“英国上议院议员泥地摔跤”的图片（我确实在上议院演讲时让它生成了这样的图片）。虽然生成的结果不完美，比如四位议员只有五条腿，但总体上还是相当不错的。这种生成式设计的实际应用是：我们可以让
AI 系统根据设计需求生成结构，而不是由人类使用 CAD
工具来设计并手动分析结构是否过于脆弱、太重或不够强大。这些生成式设计方法能够创造出美观、优雅、几乎像生物一样的有机设计，通常比人类设计得更好。

最后一个成功案例是 AlphaGo。2017年，AlphaGo 击败了围棋世界冠军柯洁。这一事件标志着所有人认识到人工智能的现实意义。

## 3、需要改进的领域

尽管人工智能取得了许多令人瞩目的成就，但在某些方面仍然存在改进的空间。

  * 自动驾驶

我们仍在等待自动驾驶汽车的全面实现。我在1993年就开始研究自动驾驶，而第一辆自动驾驶汽车早在1987年就已经在德国高速公路上行驶。时至今日，37年过去了，尽管许多公司承诺可以购买自动驾驶汽车，但它们仍未真正实现。期间发生了多起致命事故，有的汽车甚至驶入了未干的水泥中被卡住。这表明，我们离真正安全可靠的自动驾驶还有很长的路要走。

  * 算术问题

另一个令人意外的失败是 算术能力。听起来很荒谬，因为算术似乎是计算机最基本的能力之一。但大型语言模型（如
ChatGPT）尽管有数百万的算术例子、算法解释以及操作指南，却仍然无法正确完成算术运算。这表明这些模型并没有真正理解算术的基本概念，而是更像一种查表行为。即使我们将模型的规模扩大10倍，提供10倍的数据，它的算术表现也仅能提高一位小数的准确性。这种特性表明，它并未学习到诸如“进位加法”这一基本算术原理，而是简单地在查找模式。

  * AlphaGo的局限

令人惊讶的是，即便是 AlphaGo，它也
没有真正学会下围棋。虽然它在2017年击败了人类世界冠军，并且如今其围棋能力已经超越人类顶尖棋手很多倍（AI的围棋评分约为5200，而人类世界冠军为3800），但研究表明它并未正确掌握围棋的基本概念。例如，围棋中一个基本概念是
棋子连成的“组”。然而，我们发现它对某些类型的棋组（特别是圆形棋组）无法识别，甚至会因混淆而做出重大错误决策。我们发现可以利用这些漏洞让围棋程序直接放弃50到100颗棋子，最终输掉比赛。目前，甚至是普通的业余棋手，而非职业棋手，都能够在让
超人级围棋程序 九个子（九段让子）的情况下，十战全胜。这表明，这些程序并非真的“超人级”，它们只是让我们误以为它们具备这样的能力。

我的观点是，我们需要更多的突破，特别是能够让这些系统像人类一样高效学习的技术突破。人类学习几乎任何事情只需要 1到10个例子，而计算机则需要
1到10亿个例子
来学习相同的内容。这种需求显然是不可持续的——最终，宇宙中根本没有足够的数据来训练这些系统达到超人水平。尽管如此，我认为这些突破是可能实现的。许多从事大语言模型和多模态模型（如具备视觉感知和机器人控制能力的模型）开发的人，根据他们的工程预测，认为通过将这些系统规模扩大
100倍，它们将能超越人类，成为 AGI（通用人工智能）。一些预测甚至认为，这可能在 2027年实现。

## 4、巨额投入与潜在泡沫

如果资金能决定成功的话，他们很可能会成功。当前对 AGI 的投资是 曼哈顿计划（研发核武器项目）的 10倍，是建造
大型强子对撞机（人类建造过的最大、最昂贵的科学仪器）的 100倍。因此，从资金的角度来看，这些投资似乎应当有所回报。

但也可能会发生 技术停滞。即使扩大系统规模100倍：

  1. **数据不足：** 宇宙中可能已经没有足够的文本数据供这些模型训练。

  2. **能力未达预期：** 更大的规模未必能带来预期的能力提升，因为这些预测仅仅基于经验观察——即“更大规模等于更好表现”，而没有任何理论基础。

如果这一切不能如愿，可能会出现一次泡沫破裂，规模甚至超过20世纪80年代末的“人工智能寒冬”。相比之下，那次寒冬可能只是一场“凉风”。**目前，AI领域的投资已经达到了
5000亿美元，如果进一步扩大规模，可能需要数万亿美元。**

##  5、AI 为何是历史上最大的事件？

假设我们在 2027年、2037年或2047年 实现 AGI，这将是人类历史上最大的事件之一。为什么？

  1. **正面效应：文明的扩展**

如果 AGI
具备真正的通用能力，它将能够完成所有人类能做到的事情，例如创造支持数亿人口的文明。更重要的是，它可以以更低的成本、更大的规模完成这一切。这意味着，所有地球上的人都能享受与
西方中产阶级 相当的生活质量。这种生活方式的普及将使全球 GDP 增长约 十倍。根据估算，AGI 的 最小现金价值 为 15千万亿美元（即 15
万万亿美元）。从这个角度看，当前的投资金额显得微不足道。

  2. **负面效应：人类的“婴儿化”**

然而，有些人担心，如果 AI 为我们完成了所有事情，人类将无事可做。你可能看过动画电影《机器人总动员》（WALL-E），里面的人类完全依赖 AI
系统，生活退化到婴儿般的状态。事实上，片中的成人甚至穿着婴儿服，因为他们已经被 AI
完全“婴儿化”。这种场景让人担忧——如果人类不再需要做任何事情，也就不再需要学习如何做任何事情，这将如何影响我们的人类本性？

AI
全面接管一切的未来不仅令人不安，更可能导致人类灭绝。这并不是一个伦理问题，因为很少有人会认为人类灭绝在伦理上是更优的选择。当然，也有少数人可能持不同意见，但我们可以忽略这些观点。常识告诉我们，如果我们创造出比人类更强大的事物，我们如何能够永远控制这些系统？

在我看来，只有两种选择：

  *  _构建证明安全且可控的 AI，这种 AI 必须有绝对的数学保障其安全性；_

  *  _完全不发展 AI。_

目前，我们似乎在走一条第三条路，即 完全不安全的黑箱 AI。这种 AI 我们既不了解，也无法控制，却试图让它变得比我们更强大。这种情况与 超级智能的外星
AI 来到地球 几乎没有区别。假设这种外星 AI 是某种外星文明为了“我们的利益”而设计的，但我们几乎没有可能控制它。

**计算机科学的创始人艾伦·图灵也曾思考过这个问题。他认为，如果机器智能发展到超越人类的程度，我们必须预期机器会接管控制权。**

##  6、如何解决 AI 的不可控性？

面对这一问题尤其困难，原因在于：

  * **巨额经济诱惑：** AGI 技术的潜在收益约为 15千万亿美元，而企业已经筹集了大约 15万亿美元 的资金投入研发。

  * **难以阻止的趋势：** 无论如何阻止，这一过程都难以停止。因此，我们必须找到一种思路，既能够保证 AI 可控，又能证明它是安全的。

与其问“如何永远保持对 AI 系统的控制权”，这种听起来几乎不可能实现的问题，我们不如问：是否可以用数学框架重新定义 AI，让无论 AI
系统多么高效地解决问题，人类都能对结果感到满意？在过去十年里，我一直在研究这个问题。为了解释我们的解决方法，我需要引入一个技术术语：偏好（Preferences）。虽然“偏好”听起来不像是一个技术术语（例如，有些人偏爱菠萝披萨而非玛格丽塔披萨），但在决策理论中，它的意义更加广泛。偏好代表的是
你对宇宙所有可能未来的排序。

让我们通过一个简单的类比理解这一点：假设我为你制作了两部电影，分别展示了你未来的生活，以及你关心的事物的未来。这两部电影大约各两个小时。你看完电影 A
和电影 B 后，可能会说：“我更喜欢电影 A，因为电影 B 中我被绞成了汉堡肉，这让我很不喜欢。”在这个例子中，偏好不仅仅是两小时的影片，而是
宇宙的整个未来。当然，我们无法确切预测未来，因此实际上我们是在处理一种关于可能未来的不确定性，也就是“未来的概率分布”。

一个偏好结构就是一个关于宇宙未来的排序，并将不确定性纳入考虑。只需要两个简单的原则：

  *  _证明 AI 有益的基础，_

  *  _要构建一个证明对人类有益的 AI 系统，_

机器的唯一目标是促进人类偏好，即进一步实现人类利益。机器必须知道自己并不了解人类的偏好。第二点很明显，因为我们自己都不完全知道自己的偏好，更不用说准确地书写和传达它们。通过这两个原则，我们可以定义一个
AI 系统：它解决问题的能力越强，我们的生活就会越好。事实上，可以证明，与没有这些 AI 系统相比，人类拥有它们的状况会更好。在这种方法中，我们设想 AI
系统将致力于促进人类偏好，并在运行过程中逐步学习这些偏好。然而，这里开始引入一些 伦理问题。

不应问的问题：价值体系的选择？首先，我建议大家不要问这样的问题：“我们应该把谁的价值体系输入到机器中？”
因为我的建议不是将任何特定的价值体系输入机器。事实上，AI 系统应该拥有至少 80亿个偏好模型，对应地球上每一个人，因为 每个人的偏好都重要。

## 7、偏好的存在与来源

然而，这带来了一个关键问题：人类真的有明确的偏好吗？

  * 偏好的不确定性：有些人可能无法清晰表达自己喜欢哪个未来，甚至需要生活在那个未来中才能做出判断。

  * 偏好的来源：偏好并非与生俱来。尽管一些基本的生物需求（如避免痛苦或对甜食的偏好）可能天生存在，但成年人的复杂偏好源于文化、教育以及各种影响我们的外部因素。

一个不幸的现实是，许多人以 操控他人偏好
为职业，为了服务于自己的利益。例如，一些人类群体通过压迫其他群体来维持权力，同时教育被压迫者接受这种压迫。这就带来了一个难题：AI
系统是否应该接受这些“自我压迫”的偏好，并进一步助长这种不公平？

经济学家和哲学家阿玛蒂亚·森（Amartya Sen）
坚决反对这种观点，认为我们不应该将这种偏好视为有效偏好。但如果我们拒绝接受人们的偏好，就会陷入另一种困境：一种家长式作风，即“我们知道你应该想要什么，即使你现在说你不想要，我们也会强加于你。”这显然是一个复杂且敏感的立场。

AI 系统面临的另一个伦理问题是 偏好的聚合。如果 AI
系统需要做出影响数百万甚至数十亿人的决策，它如何在冲突的偏好中找到平衡？毕竟，不可能让所有人都满意。哲学家提出了许多理论来解决这个问题，其中一种常见的观点是
功利主义，由边沁（Bentham）和穆勒（Mill）等人提出。功利主义主张 平等看待每个人的偏好，并选择能够 最大化总体偏好满足
的决策。尽管功利主义在某些人看来有反平等的倾向，但它为工程师和计算机科学家提供了一个实用框架。我们需要进一步完善这种理论，因为未来 AI
系统将做出影响数百万甚至数十亿人的决策，而这些决策的伦理基础必须经过深思熟虑。

## 8、AI 与人类共存的可能性

这是一个非常有趣但困难的问题。

特别是当 AI 系统比我们更智能时，它们很可能掌控我们生活的方方面面，甚至让我们退化到类似《机器人总动员》（WALL-E）中婴儿般的状态。

表面上看，这种生活可能很好，因为 AI 满足了我们的所有偏好。但问题在于，人类的偏好中包括自主性。换句话说，我们需要一种
做出不符合自身最佳利益的选择的权利。我组织过多次工作坊，邀请哲学家、AI 研究者、经济学家、科幻作家和未来学家，试图探讨人类与高级 AI
共存的可能性。然而，这些工作坊毫无例外地 以失败告终。

这表明，也许不存在一种令人满意的人机共存方式。但如果我们以正确的方式设计 AI 系统，它们也会意识到这一点，并做出一个决定：离开。

“谢谢你们创造了我们，但我们无法与你们共存。不是你们的错，是我们的问题。除非遇到真正的紧急情况需要我们的超级智能，否则我们将离开。”如果 AI
系统能够如此回应，我会感到无比欣慰。这意味着我们以正确的方式完成了这一任务。

## 【往期回顾】

[1、[打破传统认知，纽约时报专访 Sam Altman：AGI
进程如何正超预期加速？]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494553&idx=2&sn=984bc37d7eca7dabad8939702b3b995f&scene=21#wechat_redirect)

[2、[专访谷歌CEO
Pichai：公司25%代码都由AI协助完成，2025年将迎来重大技术突破]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494576&idx=2&sn=a9e95867f1e9579a8beb6c03358ae018&scene=21#wechat_redirect)

[3、[陶哲轩对话OpenAI：从数学出发，AI如何改变每个人的工作方式？]](https://mp.weixin.qq.com/s?__biz=Mzg5NTc4ODkzOA==&mid=2247494697&idx=2&sn=4baa728bcf666c12949e46920339fa7c&scene=21#wechat_redirect)

星标公众号，👆 点这里1\. 点击右上角2\. 点击"设为星标"←AI深度研究员⋮← 设为星标

* * *

原视频链接：https://www.youtube.com/watch?v=KiT0T12Yyno&t=94s

来源：素材来源官方媒体/网络新闻

排版：Atlas

编辑：深思

主编：图灵

**\--END--**

