# 红杉专访｜O1核心研究员罗伯茨开脑洞：OpenAI为什么是物理学家的“曼哈顿计划”、反思缩放定律：规模和创意哪个更重要

文章作者: 瓜哥AI新知
发布时间: 2024-10-26 08:00
发布地: 浙江
原文链接: http://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650002840&idx=1&sn=9bb27829b29167e0ae8b200506213603&chksm=88ba5c9fbfcdd589dfe39ddcb49b5d74aeb31c2feb05c62123c8bef6a57afe9e9d715f30b5bc#rd

封面图链接: https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKjpyUcgHy8GZVCWy3BsquBZqXywl1LNXlfOenIVezeOyIEC83CP0rUA/300

**👇关注公众号后设🌟标，不错过第一手AI新鲜观点和动态**

****

本文访谈内容整理自**OpenAI研究员Dan Roberts** 接受**红杉资本**
Youtube频道专访，公开发表于2024年10月22日。原始内容参考：https://www.youtube.com/watch?v=XJsHIoIDhPY

## Dan Roberts接受红杉资本专访

> ★
>
> **内容导读** ：
>
> 本次专访中，Dan Roberts 主要表达了以下观点：
>
>   1. **物理学与AI的交叉:** Dan
> 认为物理学家的思维方式和工具非常适合研究AI，特别是大规模机器学习模型。他将微观层面的神经元、权重、偏差与宏观层面的模型输出（例如生成诗歌、解决数学问题）相比较，类比于统计物理学与热力学的关联，指出理解两者之间的联系是关键。他认为物理学中理论与实验的紧密循环也适用于AI研究。
>   2. **AI的理解与局限性:** Dan
> 对理解深度神经网络持乐观态度，认为虽然这些系统复杂，但可以通过借鉴物理学方法，结合大规模数据和计算能力，最终获得深入的理解。他认为规模（scaling）固然重要，但创新的想法（ideas）也必不可少，两者之间需要平衡。
>   3. **AI对物理学和数学的贡献:** Dan
> 相信AI能够显著促进物理学和数学的发展，特别是那些涉及推理和搜索的领域。他认为AI可以帮助寻找数学证明，并为物理学研究提供新的模型和工具，加速科学发现。
> 他认为，AI在解决物理问题上可能不像在数学证明中那样直接，而是更侧重于帮助科学家选择合适的模型、解释结果、提出新的研究方向等。
>   4. **对“AI曼哈顿计划”的看法:**
> Dan认为，OpenAI目前扮演着类似于“曼哈顿计划”的角色，吸引了大量顶尖人才致力于AI研究，这可能不需要政府主导的类似项目。
>   5. **对AI未来发展的展望:** Dan
> 对AI的短期、中期和长期发展都表达了乐观和谨慎的观点。他认为未来几年内，单纯的规模扩张可能会达到极限，需要新的想法和方法来推动AI进步。他期待看到下一代模型的突破，并关注规模扩张对AI实际能力的影响。
>   6. **技术写作风格:** Dan 认为技术写作应该通俗易懂，并加入幽默元素，以提高可读性和传播效果。总而言之，Dan
> 的演讲围绕着物理学与AI的深度关联展开，探讨了AI的理解、局限、应用和未来发展，并表达了对AI未来发展前景的乐观态度。
>

## 访谈完整记录

**主持人Sonya：** 加入我们本期节目的嘉宾是Dan
Roberts，他曾是红杉资本AI研究员，最近加入OpenAI担任研究员。本期节目录制于Dan在红杉资本的倒数第二天，当时他还不知道自己将成为O1（也称为Strawberry）的核心贡献者。Dan是一位量子物理学家，在麻省理工学院获得博士学位，并在传奇的普林斯顿高等研究院做博士后研究，本科期间曾从事隐形斗篷的研究。Dan对物理学与人工智能的交叉领域进行了广泛的研究和写作。我们希望从Dan在本期节目中学到两件事。首先，物理学能教会我们关于人工智能的什么？智能爆炸的物理极限和缩放定律的限制是什么？我们如何才能理解神经网络？其次，人工智能能教会我们关于物理学、数学以及世界运作方式的什么？

非常感谢您今天加入我们，Dan。

**Dan Roberts：** 谢谢。很高兴在可能是我在红杉资本的倒数第二天来到这里，这取决于节目播出时间和你们如何谈论它。

**主持人Sonya：**
也许一开始，先跟我们讲讲Dan是谁。你有一个引人入胜的背景故事。我认为你在大学时研究过隐形斗篷。是什么让你成为一名理论物理学家的呢？

**Dan Roberts：**
是的，这就是我现在的标准答案，但我认为这是真的。我只是一个从不长大的烦人的三岁孩子。我一直问为什么，好奇一切是如何运作的。我现在家里有一个19个月大的孩子，我能看到他跟着洗衣机修理工四处走动，非要看看洗衣机里面。所以我想我只是继续这样做了。当你更倾向于定量而不是定性时，而不是转向哲学，我认为你会转向物理学。

这就是让我感兴趣的东西。世界是如何运作的？那里所有其他的东西是什么？你没有问到的问题，但我可能会提前回答它，那种内向的东西感觉不太定量，更属于人文领域。但有了人工智能，似乎我们可以同时思考“成为智能意味着什么”以及“所有这些其他东西是什么”，而且都在某些相同的框架中。所以这对我来说非常令人兴奋。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKicu3I6oWtR06TV25uMBmGM8IRibJ5xj5KHIWNR7PNYSZZIKFhTWUciacQ/640?wx_fmt=jpeg&from=appmsg)

**主持人Sonya：** 所以你是在说我们现在应该尝试招募你19个月大的孩子。

**Dan Roberts：** 哦，是的，绝对的。他穿不进他的一件红杉连体衣了，但他现在能穿上红杉的幼儿T恤了。所以他，他绝对准备好成为未来的创始人。

**主持人Sonya：** 我想，你是什么时候知道自己想思考人工智能的？那个转变是什么时候开始的？

**Dan Roberts：**
是的，我认为和许多人一样，当我发现电脑时，我就想了解它是如何工作的以及如何编程。在本科时，我上了一门人工智能课，它非常符合老式人工智能的范畴。那一课中的许多想法实际上正在回归并变得相关，但在当时，它似乎不太实用。很多都是，你知道的，如果发生这种情况，就那样做。也有一些游戏方面的内容，这有点意思。它非常算法化，但它似乎与成为智能的意义无关。我们能快速讨论一下吗？比如，你怎么想？

**主持人Pat：** 我们能快速讨论一下吗？比如，你怎么想？智能的意义。

**Dan Roberts：** 这是一个好问题。

**主持人Pat：** 我看到你的思路在转动。

**Dan Roberts：**
是的，这个问题我没有现成的答案，但我认为重要的是不要说废话。人工智能让我兴奋的一点是，它能够构建出执行人类行为的系统，并且能够理解这些系统：从导致系统执行特定操作的Python代码行入手，追踪这些代码，理解系统的输出，以及系统如何感知和分类事物——什么是猫？什么不是猫？或者，如何创作诗歌？是的，仅仅几行代码而已。而如果你试图研究人类，并探究人类智能的意义，你必须从生物学到神经科学，再到心理学，以及其他更高级别的途径来研究这个问题。所以，**我认为对智能的一个不错的解释，至少对我来说很有趣的方面，就是人类所做的事情。然后如果我刚才说的答案再深入一层，那就是我与人工智能产生联系的方式**
。人工智能正在提取人类行为的部分要素，而我们正在理解一个相对简单易于研究的例子，这或许能帮助我们更好地理解人类的行为。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKia42pPCm7QDpggcc61Rj7qx6dIu629m5N1C6mzMF8NvfWgh9TtuxlqQ/640?wx_fmt=jpeg&from=appmsg)

**主持人Sonya：**
所以，丹，你提到你在大学学习人工智能时，很多内容听起来像是硬编码逻辑和蛮力方法。你有没有过这样的顿悟时刻，比如，“哦，原来如此，这不一样”？有没有什么关键性的结果或时刻让你意识到，我们正在走向比过去那种“如果这样，则那样”的逻辑更大的领域。

**Dan Roberts：**
是的，实际上并没有什么顿悟时刻。我当时把它搁置了。如果之后我要说的内容与当时之间隔了十年，那就太好了。但实际上，我搁置的时间可能只有一两年，因为之后我去英国读了研究生课程的第一部分。我在研究生院待了很长时间。在那里我发现了机器学习，以及一种更统计化的AI方法，这种方法使用大量数据的许多例子。或者当时，我们可能不会说大量数据，而是说，你有一些你想要执行的任务的数据示例。机器学习有不同的方法，但你会编写一个非常灵活的算法，它可以适应这些例子，并开始以类似于你提供的例子方式执行任务。

这种方法借鉴了很多物理学的思想。在我开始的时候，也就是2009年大学毕业，在2010年、2011年发现了机器学习。2012年是深度学习的重大一年。所以，这里并没有“搁置”和“重新发现”之间明显的界限。机器学习显然在2009年就存在了，只是与我当时上的课没有关系。但这种方法对我来说很有意义，而且我很幸运，它开始取得真正的进展，并且似乎符合我理解的科学框架。这让我非常兴奋。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HK9j2uepRf7iaJJ2Ef8JruGEHtMtGVibcyE17Aq3Cy3Y5EcicZHFWdN0icZw/640?wx_fmt=jpeg&from=appmsg)

**主持人Sonya：**
你认为为什么有这么多人与你有着相似的背景或相似的经历？比如很多前物理学家都在从事人工智能工作，这是巧合吗？是群体行为吗？或者你认为有什么东西让物理学家特别适合理解人工智能？

**Dan Roberts：**
我认为你的所有说法都是对的，你知道，物理学家涉足许多不同的领域，我们常常因为试图用我们的锤子，去敲打所有这些可能或不可能是钉子的东西而被戏谑。历史上，物理学家多次对看起来像机器学习的东西做出了贡献。**我认为在短期内，物理学家如果不在学术界继续发展，通常会进入量化金融领域，然后是数据科学领域。**
我认为机器学习在工业界的实现令人兴奋，因为，同样，它感觉很像实际的物理学，并且致力于解决对许多人来说非常有趣和令人兴奋的问题。你们制作这个播客是因为你们对人工智能感到兴奋。每个人都对人工智能感到兴奋。

在许多方面，它是一个研究问题，感觉很像人们所做的物理学研究。但我认为物理学的方法实际上与传统的计算机科学方法不同，并且非常适合研究我们用于人工智能工作的那些大规模机器学习。传统上，物理学涉及理论和实验之间的许多相互作用。你会提出某种你对某种理论直觉的模型。然后你进行大量实验，验证这个模型是否正确。然后在这个收集数据、提出理论、提出玩具模型、理解进步之间存在紧密的反馈循环。

而且，你知道，我们得到了这些非常好的解释性理论。我认为大型深度学习系统的工作方式是，你有一个紧密的反馈循环，你可以进行多次实验。我们使用的数学非常适合许多物理学家所熟悉的数学。因此，我认为许多物理学家从事这项工作是很自然的。其中一些工具与传统的，至少是理论计算机科学和理论机器学习工具不同，这些工具用于研究机器学习的理论方面，也许也区分了仅仅是一位优秀的工程师和一位科学家。科学研究中的工具对研究这些系统很有帮助。

**主持人Pat：**
丹，你写了一篇我认为很精彩的文章，《黑洞与智能爆炸》。在文章中，你谈到了微观视角和系统级视角的概念，以及物理学如何真正使人们能够从系统级视角思考问题。这对于理解这些系统具有互补性的益处。你能花一分钟解释一下微观视角与系统级视角，以及物理学的影响如何帮助理解系统级视角吗？

**Dan Roberts：**
当然可以，让我从一个我认为甚至超越比喻的类比开始。回到过去，现在是哪一年？也许是大约200年前，也就是工业革命时期，那时有蒸汽机和蒸汽动力，以及由此产生的大量技术，最终推动了工业化。起初，人们对这些蒸汽机进行了大量的工程设计，并且存在一个关于其工作原理的高级理论，即热力学。我想大家可能在高中都学过，其中理想气体定律告诉我们压力、体积和温度之间存在某种关系。这些都是宏观层面的东西，就像你可以买一个温度计，也可以测量你房间的体积，还可以买一个气压计，也许人们不怎么看天气预报，但这些都是我们使用和谈论的东西。

但是，在这个背后，我们直到稍后才验证并理解它，那就是原子和分子的概念——空气分子在四处碰撞。现在我们理解到，这些空气分子导致了温度、压力等现象，体积可能更容易理解，因为气体分子被限制在一个房间里。但是，你可以通过对这些分子的统计理解，精确地推导出热力学，例如从统计理解推导出理想气体定律。你可以更进一步，推导出它是理想的，因为它是不准确的，只是一个玩具模型，但它有修正项。你可以从微观角度——也就是分子——去理解，我们并没有真正地与它们相互作用，我们日常生活中也看不到它们，也无法与它们相互作用。但它们的统计聚集特性导致了我们在宏观尺度上看到的行为。

为了回答你的问题，我认为深度学习系统也存在类似的情况。我和Sho Yeda以及Boris
Hanin合著了一本书，内容是关于如何将这些思想应用于深度学习，至少在一个允许你初步进行此类尝试的初始框架中。为了回答你的问题，微观视角是：你拥有神经元、权重和偏差。我们可以详细讨论其工作原理。但当人们想到架构时，有些人会说电路，这些事物之间存在特定的方式，有一个输入信号，可能是图像或文本，然后有很多参数。写下来非常简单，即使考虑到机器学习库，代码也不多。

但它就像一组非常简单的方程，但有很多权重，有很多数字你需要知道才能让它做些什么。这就是微观层面，就像分子的视角。然后是宏观视角，即它做了什么？它创作了一首诗吗？它解决了一个数学问题吗？但是我们如何从这些权重和偏差过渡到宏观视角呢？对于统计物理学到热力学的过渡，我们完全理解了这一点。你可以想象尝试做同样的事情，从字面上应用相同的方法，去理解这些模型的底层微观统计行为是如何导致宏观或如你所说系统层面的视角的。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKKaTWhe6nnpyR3vFFpGExiapicfD6n4NFGthrswibTv4QAROMjxhv9l3hA/640?wx_fmt=jpeg&from=appmsg)

**主持人Sonya：** Dan，也许说到缩放定律（Scaling Law），我想你参加过我们的活动“AI Ascent”。Andrej
Karpathy提到，**目前的AI系统在效率方面与生物神经网络相比，相差了5到6个数量级。**
你对此怎么看？你认为缩放定律能让我们达到那个水平吗？仅仅是缩放定律加上硬件效率的提高？还是说需要在研究中取得某种大的阶跃式突破？

**Dan Roberts：**
这可能有两种含义。一种是人类似乎在与AI系统类似的规模下工作效率要高得多。你知道，我们不需要看到数万亿个token才能说话。我们看到的要少得多，你知道，我的幼儿已经开始说句子了，而他接触到的token远少于典型的大的语言模型。因此，人类学习效率与大型语言模型之间存在某种脱节。当然，它们是完全不同的系统，它们的学习方式现在非常不同。所以在某种程度上，这是可以预料的。所以这里存在你可以想象弥合的差距。

还有一些我认为你并非想表达的意思，但我认为是关于缩放定律需要回答的问题，即——我在文章中谈到过这一点，但很多人似乎也在谈论这个问题——什么是最终的GPT？现在是GPT-4。当然也可能是其他公司。但由于我将加入OpenAI，让我来代表我的新公司吧。那么，是GPT-6？是GPT-7？在某个时刻，如果假设我们必须按比例放大，那么有些事情会崩溃，无论是经济上的，我们将会耗尽……我们将尝试训练一个比世界GDP或GWP（无论世界GDP是怎么算的）更大的模型。或者我们会耗尽资源，我们无法生产足够的GPT，很多事情会在某个时候崩溃。所以经济上的限制可能会首先出现。

那么，**在实际的扩展能力耗尽之前，我们还能迭代多少次？这能让我们达到什么程度？**
然后我认为，我认为将这两种观点联系起来，仅仅是规模本身。当然，这不可能区分开来，因为人们正在提高效率，但是，你可以想象，你可以从字面意义上取GPT-2，也就是最初的大模型，并继续将其扩大。这会让我们达到某种超乎寻常的、令人兴奋的经济力量，或者无论你如何定义AI研究、AI初创公司以及AI在产业中的最终状态。还是我们需要很多新的、令人兴奋的想法？

当然，你不能简单地将这些区分开来，但我认为普遍的规模假设是，只有规模很重要，而想法并不重要。而我们如何才能像人类一样高效，我认为这需要一些非同寻常的想法。为了回答你的问题，我之所以对加入OpenAI感到兴奋，是因为我认为在超越规模方面，在想法方面，具有很高的杠杆作用，而且为了迈出下一步，我们需要做到这一点。而且我完全不知道我将从事什么工作。但是当这个节目播出的时候，我想我会知道我在做什么，但是，这对我来说真的很令人兴奋。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKP1kar01PaQwWGg5VmgxS5Yo4wQ9GtXeX0NFwibDAkmYQyxsgIbicNH6g/640?wx_fmt=jpeg&from=appmsg)

**主持人Pat：**
Dan，人们在AI领域付出的努力，是不是像钟摆一样，在规模和理念之间来回摆动？例如，Transformer出现后，这是一个伟大的想法。从那时起，我们主要是在进行规模竞赛。由于你提到的许多实际原因，感觉很多事情开始趋于饱和。钟摆是否正在摆回将“理念”占优的阶段？现在，重点不再是拥有最大的GPU集群，而是寻找新的架构突破，无论是推理还是其他什么。

**Dan Roberts：** 是的，这是一个非常好的问题。我认为Richard Sutton有一篇文章叫《痛苦的教训》（The Bitter
Lesson），不是《痛苦的药丸》。这篇文章基本上认为理念并不重要，重要的是规模，所有理念都会被规模化所超越。这说明了很多事情，但这也许是一个高级别的结论。有一种感觉，在80年代和90年代，出现许多有趣的想法，但人们并没有规模去探索它们。我还记得，在AlphaGo之后，DeepMind发表了很多论文，人们重新发现了这些论文，并在深度学习系统中重新实现它们。

但这仍然是在人们意识到“不，你需要做的是扩大规模”之前。即使现在有了Transformer，人们也在探索其他架构，甚至是以前知道的更简单的架构，有一种说法，**也许规模定律并非来自架构本身（只要架构不出现某种缺陷），而是来自底层的数据处理以及拥有大量数据，而不是来自某种特殊的想法**
。

我认为真正的答案是两者之间存在平衡，规模非常重要，也许只是以前没有被理解。有多重要？而且在不同的时期，我们也没有资源来扩大规模。你们也知道，生产这些生成这些模型的GPU集群需要很多东西，比如供应链或产品链（无论你称之为哪一个）的许多环节才能使这些事情发生并部署它们。甚至，你知道，GPU最初的样子，现在已经共同进化，非常适合这些模型。

从某种意义上说，Transformer之所以是一个好主意，是因为它被设计成适合在我们当时的系统上进行训练。所以，当然，这些其他的架构可以做到，在一个理想的科学层面，但**在实践层面，重要的是获得能够达到那个规模的东西。**
因此我认为，如果你把理念和规模结合起来，那么，我的意思是，我仍然认为最终，比如，有人提出了深度学习的想法，这是一个重要的想法。皮茨和麦卡洛克提出了神经元的原始想法。然后罗森布拉特提出了原始感知器。从大约80年前开始，就有很多人做出了重要的发现，这些发现都是有助于发展的理念。所以我认为两者兼而有之。

但很容易看出，如果规模遇到瓶颈，人们会考虑理念。然后，如果你以某种方式解锁了新的规模能力，那么你就会看到大量的成果。这似乎表明规模非常重要。而我认为这更像是两者之间的协同作用。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKLLfcGQ2QzyyuWxAhx8Yv8d6QnxohljrxoD3rdTgOJcraEwN2IbKhQg/640?wx_fmt=jpeg&from=appmsg)

**主持人Sonya：**
关于规模竞赛，Dan，你提到了经济限制和现实，我认为这在私营部门更像是实际的天花板。你之前也提到了曼哈顿计划，以及物理学家参与的一些事情。你认为我们需要一个类似曼哈顿计划的项目来发展AI吗？例如在国家层面或国际层面？

**Dan Roberts：** 嗯，我可以说，促使我加入OpenAI的部分过程是，我和你的合作伙伴肖恩·麦奎尔（Sean
McGuire）——他最初把我带到红杉资本——进行过讨论，试图弄清楚，有没有一个适合我参与的创业公司，它具有科学问题、研究问题以及作为一项业务的正确组合？我认为是肖恩说的，我不是指曼哈顿计划的影响，尤其是你可能想到的那种负面影响，而只是指规模和组织，他说，在40年代，即使物理学家在做其他事情，曼哈顿计划也是他们要去的地方。所以现在，AI也是一样。基本上说OpenAI就是那个地方。所以我们可能不需要公共部门组织，我不知道你是否听说过曼哈顿计划，但是，你知道，它可以是OpenAI。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKfgv2X9qB7ZicDx3W0RO6PE71R2rgnMSOqbDlNXoibyjwutxQX7Gqomog/640?wx_fmt=jpeg&from=appmsg)

**主持人Sonya：** 开启双眼的曼哈顿计划。

**Dan Roberts：**
是的，就规模和野心而言，我认为很多物理学家都喜欢在OpenAI工作，原因与他们可能兴奋的原因有很多相同之处。好吧，有很多不同的原因。

**主持人Sonya：** 我们能否谈谈这一点，我们能否理解AI，特别是当我们转向这些深度神经网络时，或者你认为它是一个无望的黑盒？

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKKGzjtUl2j9or9xVia8j7C48YKictvRUbPs7mRccWic0cVG76uN5jcJUiag/640?wx_fmt=jpeg&from=appmsg)

**Dan Roberts：**
在AI社区中，你知道，我反对这个观点，我认为我们可以真正理解这些系统。在……你知道，物理系统极其复杂。我们在理解它们方面取得了巨大进展。我认为这些系统处于相同的框架中。而且，你知道，肖恩和我在我们的书中谈到的另一个原理，也是物理学的原理，**那就是在非常大的尺度上经常存在极端的简单性。基本上是由于统计平均，或者更技术性地说，中心极限定理，事情可以简化。**
我并不是说这正是大型语言模型中发生的情况。当然不是。但我确实认为我们可以应用我们已经拥有的方法，并且，你知道，也许希望将来拥有AI来帮助我们做到这一点。而说到AI，我的意思是工具，而不是像独立的智能体那样，自己运行并解决这些问题。但我猜我感觉到了极端的一面，这不会是一种艺术，科学将会赶上，并且能够在真正理解这些系统的工作方式和行为方面取得巨大飞跃。

**主持人Pat：**
那么，Dan，我们已经讨论了很多物理学能教会我们关于人工智能的知识。我们能否谈谈人工智能能教会我们关于物理学的知识呢？你对物理学和数学等领域以及这些新兴模型如何进一步探索这些领域持乐观态度吗？

**Dan Roberts：**
是的，我绝对乐观。我想我的观点是，数学比物理学更容易，这或许暴露了我是物理学家而不是数学家的事实。我稍后可以解释我为什么这样认为。但我仍然有很多朋友在从事物理学研究，并且一种越来越强烈的，甚至接近恐惧感正在蔓延，那就是这或许正是物理学家从事人工智能研究的原因：**如果你关心的是你物理学问题的答案，并且希望尽快得到答案，那么你能做的最有影响力的事情是什么？也许不是致力于你所关心的物理学问题，而是致力于人工智能，因为你认为人工智能最终可能会很快解决这些问题。**

我不知道有多少人真的认真对待这个问题，但我认为在我所来自的理论物理学界，这是一个经常被提及和讨论的事情。我想，为了给出更具体的答案，我认为数学令人兴奋之处在于——如果你邀请Noam
Brown，他可能会谈到这一点，这是他在加入OpenAI之前就谈论过的事情——我们在解决游戏中取得了很多进展，这不仅仅是查找我们应该使用什么策略来玩游戏，而且还能够向前模拟。**如果我在某个游戏中处于非常困难的境地，与其凭直觉进行游戏，我可能会坐下来思考我应该怎么做。有时这被称为推理时间计算，而不是训练时间计算或预训练时间计算**
。

从某种意义上说，推理的意义与这种坐下来思考的能力密切相关。我们知道如何在游戏中做到这一点，因为有一个非常明确的输赢信号，因此你可以提前模拟并弄清楚什么是好什么是坏。我认为，在数学的某些领域（再次声明，我不是数学家，而且我总是害怕公开谈论数学并说一些错误的话来惹恼数学家），某些类型的数学问题不像游戏那样受到限制，但仍然受到足够的限制，使得存在寻找证明的概念，对吧？在搜索方面，在如何确定证明中的下一步方面存在明确的问题，但事实上我们可能称之为“一步”，这表明数学中有一些事情感觉很像游戏，因此我们可能会认为我们在游戏中表现良好意味着我们可能在某些类型的数学发现方面表现良好。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKXLtzMt3OG7SceL22Gic0ookd1nGjGLhGyjAOJ471HLdDXyTmubPXJLQ/640?wx_fmt=jpeg&from=appmsg)

**主持人Pat：**
对了，我正想说，既然你提到了Noam，他喜欢用测试时间计算的例子来说明它是否有助于证明黎曼假设。在物理学领域是否存在你乐观地认为人工智能可以在我们有生之年帮助解决的类似问题或假设？

**Dan Roberts：**
是的，我的意思是，存在一个与物理学相关的千禧年难题。如果我试图记住它究竟是什么，我肯定会在叙述中出错，然后没有人会相信我实际上是物理学家。但这是一个与杨-
米尔斯质量间隙相关的数学物理问题。但我认为我想说的是，我认为物理学家在进行物理学研究时所关心的一些事情的味道感觉有点不同。这就是我可能会遇到麻烦的地方。它感觉与一些数学证明类型的事情有点不同。物理学家以比较不正式和含糊不清而闻名，但另一方面，他们也与实验和物理学家研究的模型之间的相互作用联系在一起。

这或许是拯救他们的东西。他们有一些不正式和含糊不清的东西，但非常具有解释性。然后是数学家，就像我们之前说的那样，工程师发现了所有令人兴奋的工业机器，然后物理学家也许清理了关于其工作原理的大量理论。然后数学家后来才来清理，比如将所有东西形式化并进一步清理。因此，有一些数学家或数理物理学家清理了很多，使一些物理学家所做的事情变得正式，并试图以非正式的方式理解它们。所以我想这就是我的看法。

但我认为关键点是，对物理学家来说有趣的问题可能不像证明那样，但它们可能看起来像——也许这不是关于我们如何在一个特定的模型下实际解决它？就像一旦事情正确设置好，通常是，你知道，在这个领域接受过训练的人能够弄清楚如何分析系统。更多的是其他的东西，比如应该研究什么模型？它是否捕捉到了正确的问题？这是否与你所关心的事情相关？你应该从中得出什么见解？

因此，为了让AI在此提供帮助，我认为它看起来与我们为数学构建AI系统的方式不同。与其说是，你知道的，这是一个文字题，去解决这个问题，或者，证明黎曼假设，不如说是物理学中的问题是什么是量子引力？当某些东西进入黑洞时会发生什么？那甚至是什么样子？如果你去物理系，人们会在黑板前闲逛。他们会讨论事情。也许他们会勾勒出数学的东西。但是，还有很多其他的东西。所以也许你需要收集的数据看起来更像这样。或者也许它看起来像Slack上的随机邮件和对话以及草稿。

所以，我的意思是，我们肯定可以使用工具。我认为目前实施方式存在一些问题。但是，我认为有很多工具可以帮助加速物理学家的工作。就像Mathematica，这是一个进行积分的软件包。而且，它做的远不止这些。对不起，Stephen
Wilford。我用它来做积分。而且，有时它不知道积分。你可以查找。你可以在积分表中查找它们。无论如何。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKhVoRK3xcY9DicUibaKMYEw4hMlc9nmRoBBoxZ8HC2rdPTwpk9uoCoeDA/640?wx_fmt=jpeg&from=appmsg)

我认为，这同样适用于其他科学分支，比如，我认为提问的方式，以及在不同领域进行科学研究的意义，也许看起来，可以越来越远离游戏，我认为我们必须以不同的方式处理它们，也许最终我们会拥有一个能够胜任所有工作的通用事物，但在最初阶段，至少对我来说，很多这些事情感觉彼此之间有点不同。

**主持人Sonya：**
你将能近距离地观察到这一切，部分原因在于你也是AI数学奥林匹克竞赛的评委，而我个人对此非常感兴趣。关于你最后一点，即这些东西最终可能会泛化，我想问一下，为什么人们如此专注于解决当今最难的问题？比如物理、数学，这些科目是每个人上学时都害怕的，对吧？而现在还有许多其他领域尚未解决。你认为先攻克最难的领域能否让我们更接近通用人工智能？解决这些不同领域的难题如何在更大的谜题中相互契合？

**Dan Roberts：**
你提到这一点时，我首先想到的是反驳一下，不，这些并不难。这些都是简单的领域。我的意思是，我不擅长生物学，它对我来说完全没有意义。我的女朋友是生物工程和生物技术专业的。她所做的事情我完全不明白，我无法理解其中的任何内容。

而物理学对我来说却完全说得通。我认为更好的答案，或者说更不笼统的答案是，就像我之前关于数学所说的那样，存在约束条件。特别是对于数学来说，很多都是非具象的。你不需要进行真实的实验。它们是自给自足的。这与文本生成非常接近，就像语言模型的工作方式，甚至是某些强化学习系统在游戏中的工作方式。

因此，我认为你离这个越远，事情就越混乱，也可能越难。而且，获得训练这些系统所需正确类型的数据也越难。如果你想构建一个AI系统，人们正在尝试这样做，但这似乎很困难。如果你想构建一个解决生物学问题的AI系统，我想你不仅需要确保机器人技术能够运行，以便它能够进行那些实验并理解那种数据，或者也许需要人类来做。但对于一个自给自足的AI生物学家来说，似乎有很多事情要做。

是的。我的意思是，在此过程中，我们将拥有像最近发布的AlphaFold3这样的工具，我没有机会仔细阅读它的细节，但我看到他们正在尝试将其用于药物研发。因此，我认为这些领域中的每一个都将在发展过程中产生一些成果。但我认为，**约束条件越少，事情越混乱、越具象，就越难实现**
。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HK83SclsJrsURIFYkoRdMdYRvUA4qaq6QcFamqhEe8Dj2nich9p3BSc1w/640?wx_fmt=jpeg&from=appmsg)

**主持人Sonya：** 这说得通。对人类来说很难，并不意味着对机器来说也很难。两者并不相关。

我们中的一些人更像机器，然后我想第二个问题是，你认为所有这些都会融合成一个理解一切的大模型吗？因为现在看来，有很多领域特异性的问题正在被解决。

**Dan Roberts：** 是的，根据目前的情况，答案似乎是肯定的。在这个领域进行推测非常危险，因为你说的通常都是错的，而且错得很离谱……

**主持人Sonya：** 还好我们有记录在案，我们会让你兑现承诺的。

**Dan Roberts：**
是的，没错。但同样，什么是差异？你知道，有一种微不足道的方法可以使这两个问题都毫无意义，例如，你说模型是所有其他模型的集合。但也有一种感觉，专家混合最初并非如此，在实践中根本就不是这样。似乎人们，至少大型实验室都在追求一个大型模型。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKdLKraibvxKPj67pQDOToJzVqqxBTkcjJ8HrZxqaoeM40CZ2EqCga1lQ/640?wx_fmt=jpeg&from=appmsg)

**主持人Pat：**
Dan，我们还有一些更笼统的问题，用来结束今天的讨论。所以，我先问一个宏观的问题。如果我们从短期、中期、长期的角度来看，分别称之为五个月、五年、五十年，你对人工智能领域最兴奋或最乐观的是什么？

**Dan Roberts：**
五年前，大约是在Transformer模型出现之后，也许是GPT-2出现的时候。**所以，在过去的五年里，我们一直在进行规模扩展。我想在未来五年内，我们会看到这种规模扩展将会停止。也许它会在某种乌托邦中结束**
，你知道，人们对此感到兴奋。我们都处于后经济时代等等。你将不得不关闭你所有的基金，你知道，归还垄断资金，因为金钱将不再重要。或者，或者我们会发现我们需要很多想法。

也许还会有另一个AI寒冬。我设想，这再次令人害怕去真正地推测，但我设想，在五年内，关于人工智能的一些有趣的事情将会发生变化。这可能仅仅是因为人工智能已经结束，我们转向了下一个令人兴奋的投资机会。每个人都会转移到其他地方。你知道，我并不是说这并不是激励我对人工智能的动力。但是，你知道，所以也许五年足以看到这一点。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKFChHoLD6I64C9QnGkIpM9yocbVQxeDGbaLl2kcCvibIibjxZ5ic8xTcrQ/640?wx_fmt=jpeg&from=appmsg)

我想一年，我的意思是，也许是五个月。抱歉。是五个月。

**主持人Pat：** 没关系，这些都是近似值。风险投资家也很含糊其辞。这些都是近似值。

**Dan Roberts：**
是的，在物理学中，我喜欢开玩笑说只有三个数字：零、一和无穷大。这些是唯一重要的数字。你知道，事情要么任意小，要么任意大，要么大约是一阶的。但是是的，对于五个月来说，我很兴奋能够了解OpenAI这样大型研究实验室前沿的令人兴奋的东西。我认为一件有趣的事情将是下一代模型之间的差异，对吧？因为有些方面，**事情正在规模化，而且它不是公开的，我想，除了Meta之外，在数据大小、模型大小方面，我们看到了缩放定律**
。然而，规模定律与损失之类的东西有关。你知道，很难将其转化为实际能力。

那么与下一代模型对话会是什么感觉呢？它会是什么样子？它会产生巨大的经济影响吗？或者不会？我认为，就估计速度而言，你需要几个点。你不能只有一个点。我们开始用GPT-3到GPT-4这样做了。但是，你知道，我觉得有了下一个增量，我们将真正看到速度是什么样的，从一个模型到另一个模型的感觉是什么样的。也许我能在五个月后做出更好的预测。但我猜我可能不会告诉你们。

**主持人Sonya：**
谢谢，丹。我注意到一点，你的写作风格非常平易近人、轻松幽默。这与我平时阅读那些高度技术性的文章的体验完全不同。你认为所有技术性写作都应该轻松幽默吗？这是你刻意为之的吗？

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKN3LbkicRYsibBDMGu6r2x6gRibkUn1je9XcibicQ7YliaVY8hKj84lynCmpg/640?wx_fmt=jpeg&from=appmsg)

**Dan Roberts：**
这绝对是刻意为之的。这其中有一些原因。我认为从某种意义上说，这是我继承下来的风格，我的确不是一个严肃的人。但我也认为这源于我所来自的领域的风格。我来给你讲个故事。我当时是普林斯顿高等研究院的博士后，在午餐时与一位名叫纳迪·塞博格（Nadi
Cyborg）的教授开玩笑。我们聊到有人问起如何起一个好标题。我说，标题必须是个笑话，他对此表示赞同。然后我解释说，对我来说，写论文的目的是为了讲笑话。我脑子里会有一堆笑话，然后我想让人们读到这些笑话，所以我必须把它们包装成科学成果。

人们想读科学成果，所以他们被迫忍受这些笑话——这不容易。纳迪教授说，我不明白，为什么不能只写科学内容呢？为什么需要笑话？笑话也很棒，但你应该为科学而写作，而不是为笑话而写作。我坚持认为我是为笑话而写，但我认为这和你说的情况一样，在某个时刻，你了解了科学方法，知道了正式的做事方法，学习了所有这些规则。然后你成长了一些，或者也许是因为我有个室友是语言学家，他现在是德克萨斯大学奥斯汀分校的语言学教授。他经常强调我可以打破哪些规则，这些规则从何而来，以及它们为什么重要或不重要。你逐渐意识到你可以打破这些规则，最终的目标应该是：读者能否阅读、理解并享受它。所以，你不想做任何会影响他们阅读和理解能力的事情，你也不想让事情变得晦涩难懂。你想让它更易于理解，而且你知道，如果它更有趣，人们就更有可能阅读它并接受你的观点。如果你在写作过程中也更享受，那就更好了。所以，我认为这就是我写作风格的来源。

**主持人Sonya：**
丹，非常感谢你今天加入我们，我们学到了很多，也享受了你的笑话。我希望你在红杉资本的倒数第二天过得愉快，谢谢你抽出时间与我们在一起，我们非常感谢你。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO1iacaxqVGia8ogT755zU6HKtsicLFwCxnByf9qlUleg13Y07CaraUZgmxaUwVs4nywbL15SpGcoIxA/640?wx_fmt=jpeg&from=appmsg)

**Dan Roberts：** 谢谢，我很高兴能在这里与你们聊天，这太棒了。

 _参考资料: https://www.youtube.com/watch?v=XJsHIoIDhPY，公开发表于2024-10-22_

**👇关注公众号后设🌟标，不错过第一手AI新鲜观点和动态**

****

## 往期精选

  1. [黄仁勋专访：OpenAI在大模型混战中达到“逃逸速度”](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650001718&idx=1&sn=f8129a622e7611702be2cb23e8ce9418&chksm=88ba5831bfcdd127d06ce6492c821074407f805407b4182ca900916521cb5a4717f2a3d71ee8&token=1339625777&lang=zh_CN&scene=21#wechat_redirect)
  2. [李飞飞与Justin深度解读空间智能：数字世界需要三维表征，才能与现实世界融合](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000659&idx=1&sn=c71fb5b4ef501424dddd5e8b4dd5860e&chksm=88ba4414bfcdcd023c691a1adf75127a9fd883ceb305ca14cf97f719acaf999d40fa72f84bf3&token=1492077842&lang=zh_CN&scene=21#wechat_redirect)
  3. [PayPal创始人彼得·蒂尔：人类科技停滞源于原子方面的进展远慢于比特](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000240&idx=1&sn=26af6013981677b1e14137260857a6f0&chksm=88ba4277bfcdcb615d746615c262927bf51c43c920ed93fa36274ef87c6264d6548c84647121&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  4. [谷歌联合创始人布林：巨头们打造的“上帝模型”几乎可以理解一切](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=2&sn=0c714d804a72a52e002743d949e1685e&chksm=88ba40f9bfcdc9ef78749718480265922f4fba539abf6c9d62a6cd681f405dee9283d2429f84&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  5. [马斯克：AI将使商品和服务的成本趋近于零](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=1&sn=752f000a117a705e77950c82bfc4a004&chksm=88ba40f9bfcdc9ef5a5afe4a3ae73d5247bd54ed525dbdbedee1fcf74a6c082165e664a5c4d0&token=106920805&lang=zh_CN&poc_token=HDp86Waj18SFm2Y-xnv_Vqd_4J6emFoh10eH48wg&scene=21#wechat_redirect)
  6. [Karpathy最新专访：人形机器人、特斯拉、数据墙与合成数据](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999613&idx=1&sn=b8bdda7afe4c3ca08e324ac5bbd5a2bd&chksm=88ba41fabfcdc8ec0e21dbf4c7eb4d33252da70f47e1cfc9f5e113717911c417c2aebb3d6180&token=106920805&lang=zh_CN&scene=21#wechat_redirect)

  

