# PyTorch之母林乔：未来需要跨多模型/模态的复合AI系统，与持有各类知识的API协同工作

文章作者: 瓜哥AI新知
发布时间: 2024-12-17 09:54
发布地: 浙江
原文链接: http://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650005570&idx=1&sn=e60323b81d26b25e38082de28b796a5b&chksm=88ba6945bfcde053f3d506ce30f4dc05ab1c5e59f881232e59e76c4fa87397c4d61f55f0bd2b#rd

封面图链接: https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8eybYd1EWXxdoRj7OIFFn66a9IkQiavVsBWGZqWXGfP9QCENwVe8yZOTg/300

**👇关注公众号后设🌟标，掌握第一手AI新动态**

**  
**

本文内容整理自**Lin Qiao Fireworks.ai CEO** 接受**Unsupervised Learning: Redpoint's AI
Podcast**
Youtube频道专访，公开发表于2024年12月16日。原始内容参考：https://www.youtube.com/watch?v=zG-
kxc0q_cE

## 内容提要: 林乔接受Unsupervised Learning播客专访

**关于 Fireworks 和复合 AI 系统：**

  * Fireworks 专注于构建快速高效的推理平台，目标是提供最佳质量、最低延迟和最低成本的推理服务。
  * 推理的未来在于复合 AI 系统，它由跨不同模态的多个模型以及各种 API 组成，协同工作以提供最佳结果。
  * Fireworks 采用声明式设计原则（而非命令式），旨在简化用户体验，隐藏后端复杂性，同时保持可调试性和可维护性。
  * Fireworks 正在努力简化定制化模型的过程，包括微调和提示工程。
  * Fireworks 构建了 F1，一个复杂的逻辑推理系统，可以在底层协调多个模型和逻辑推理步骤。
  * Fireworks 的函数调用功能支持并行和顺序调用多个工具，并进行复杂的协调规划。
  * Fireworks 认为构建复合 AI 系统的核心编排层至关重要，因此他们选择自主研发而不是完全依赖开源模型。

**关于模型和 AI 发展趋势：**

  * 没有一个模型能够适用于所有情况，未来在于数百个小型专业模型。开源模型对于定制化和解决特定领域的问题非常有益。
  * 企业希望对模型有更多控制权和可操控性，因此倾向于定制化模型。定制化模型的过程包括提示工程和微调，Fireworks 正在努力简化这一过程。
  * 预训练模型的成本很高，许多企业选择在强大的基础模型上进行后训练，以获得更高的投资回报率。
  * 目前成功的生成式 AI 应用大多涉及人机协同自动化，而不是无人值守自动化。
  * 企业越来越重视模型评估，并意识到投资于良好的评估数据集的重要性。
  * 模型的发展趋势是更加专业化，从开放式模型到具有独特功能的更专业模型。
  * 推理模型的未来发展方向包括模型自我检查、潜在空间中的逻辑推理以及其他形式的逻辑推理。
  * 当前 AI 基础设施中，代理工作流程的用户体验和抽象层的设计仍处于早期探索阶段。
  * 硬件领域发展迅速，需要根据具体工作负载模式选择最佳硬件。
  * 超大规模企业在解决大规模基础设施问题方面具有优势，而 Fireworks 专注于解决需要工程技术和深入研究相结合的复杂推理问题。
  * 本地运行模型的主要原因是成本和隐私，但移动端和桌面端的适用性不同。
  * AI 行业的投资正在从预训练转向后训练和推理。

## Fireworks.ai CEO林乔简介

林乔（Lin Qiao）是 Fireworks.ai
的联合创始人，复旦才女，这家公司致力于构建新一代大型语言模型（LLM）应用开发平台。Fireworks.ai
提供了丰富的工具和服务，帮助开发者快速构建和部署基于 LLM 的应用程序，例如聊天机器人、写作助手、代码生成器等。

林乔拥有丰富的技术背景和创业经验。在创办 Fireworks.ai
之前，她在Meta曾担任PyTorch技术主管，积累了深厚的技术实力和行业洞察力。她敏锐地捕捉到了 LLM 技术的巨大潜力，并看到了开发者在构建 LLM
应用时面临的挑战。 Fireworks.ai 的创立正是为了解决这些挑战，降低 LLM 应用的开发门槛，让更多开发者能够参与到这场技术变革中。

## 访谈全文

**主持人：** 林乔是 Fireworks 公司的联合创始人兼首席执行官，该公司致力于为复合人工智能系统构建快速高效的推理。她也是 Meta 公司
PyTorch 的创始人之一，并已从投资者那里筹集了超过 7500 万美元的资金，作为 Qoian
基准。在《无监督学习》节目中，我们进行了一次引人入胜的广泛对话。我们谈到了林乔对不断发展的开源生态系统的看法，以及在 2025
年使智能体工作所需的基础设施。我们还讨论了当模型层发生如此多变化时，构建人工智能基础设施公司所面临的挑战。我认为大家会非常喜欢这次谈话。事不宜迟，下面请听林乔的分享。

好的，林乔，非常感谢你来参加播客。我真的很感激。谢谢你的邀请。是的，我期待这次对话已经有一段时间了。我觉得现在和你聊天可能是一个非常有趣的时机。显然，我觉得你们为开发者和在人工智能领域构建产品的人们建立了一个令人难以置信的平台。

人工智能领域总是充满变化，绝不会无聊。我觉得总是有新的事情发生。我非常想了解你对当前关于测试时计算的日益增长的讨论的看法，特别是像 O1
以及许多其他似乎即将跟进的模型。我想知道，鉴于这些类型的模型，这种趋势如何改变你们在 Fireworks 的策略或产品？

**林乔：** 是的，我认为从 Fireworks 创立之初，我们就一直考虑到这一点。我认为，嗯，Fireworks 是什么？Fireworks
是一个生成式AI平台，专注于推理。这里的最高目标是提供最佳的质量、最低的延迟和最低的成本。是的。在推理堆栈中，我们可以深入探讨细节。哦。因为推理不仅仅是单一的模型即服务推理。它没有那么简单。正如我刚才提到的测试时推理，测试时质量，扩展日志。**我们设想的未来推理系统是一个复杂的推理系统，具有逻辑推理能力，可以访问数百个小型专家模型等等**
。所以，**我们试图解决的问题的级别不是“嘿，这只是一个 API 调用，现在就完成了”** 。现在不是这样了。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8eNpOGVJjcNocaTEXUQoWWytba9txHdNAoNiapic6XoGkhoqxiaxqibeapug/640?wx_fmt=jpeg&from=appmsg)

**主持人：** 所以听起来你设想的世界是，用户输入一个查询，然后在 Fireworks，你们会进行路由，找出最适合该查询的最佳性能模型作为响应。

**林乔：**
是的，我认为让我们退后一步，了解一下我们试图解决的问题是什么。模型有很多局限性，这些局限性的产生是因为模型本质上是不确定的；它们本质上是概率性的。当你想要向最终用户提供真实的结果，始终真实的结果时，这种概率性是不理想的。因此，控制幻觉非常重要。

除此之外，我们还有一个复杂的业务问题，因为我们有很多客户在使用我们的服务。这需要组装跨不同模态的多个模型才能有效地解决这些问题。正如我们现在所说的，很多应用程序都是面向消费者的，我们不仅仅是在互相发短信。我正在处理音频和视觉信息，以便在我们的对话中创造良好的互动体验。这种方法类似于许多基于
JNI 的原生应用程序，它们也需要处理跨多种模态的信息。

此外，即使在同一模态内，让我们以语言模型（LM）为例，也有许多不同的专家 LM
专门处理各种任务，包括分类、摘要、多轮对话和工具调用。它们彼此之间都略有不同。因此，在解决现实世界的问题时，仅仅依赖一个模型是非常有限的。

最后但并非最不重要的一点是，单个模型的知识非常有限。它的知识受到训练数据的限制，而训练数据是有限的而不是无限的。许多现实世界的信息存在于 API
背后——这些可以是公共 API，甚至是企业内部的专有私有 API。如果没有与企业直接合作，通常无法访问这些信息。

因此，我们认为下一个障碍是如何超越单一模型即服务。**世界需要一个称为复合人工智能系统的概念，它由跨不同模态的多个模型以及持有知识的各种
API（包括数据库、存储系统和知识库）组成** ，这些 API 需要协同工作才能提供最佳的人工智能结果。

**主持人：** 是的。但是，当你考虑构建这些更复杂的复合人工智能系统时，你认为开发人员需要哪些工具才能有效地构建这些系统？

**林乔：** 也许你可以先从像完全相反的设计点开始讨论，对吧？**一种设计被称为命令式，你可以完全控制工作流程是什么，输入和输出是什么**
。你想要的一切都使其具有确定性。这是一种设计水平。所以你基本上是设计房子，对吧？支配它。

**另一种设计被称为声明式。在这种方法中，你定义“什么”——这个系统应该为你解决的问题——然后你让系统弄清楚“如何”实现它**
。一般来说，在业界，这并非人工智能独有；我们在系统设计中存在这两种思路。例如，在数据库领域，有很多这种二分法的例子。SQL
就是声明式设计的一个例子，你的数据工程师或分析师明确定义他们想要从数据库中检索什么，而数据库管理系统则会计算出执行计划——最佳、最有效的执行计划。

ETL
过程也是声明式的。在这种情况下，你定义了源和处理逻辑，包括如何触发下一步以及如何执行回填，而回填是非常必要的。这些方法都没有错；它们只是系统设计的不同方法。

根据我们的 PyTorch
经验，我们希望建立我们的设计原则，以提供最简单的用户体验。我们的目标是尽可能地隐藏后端的所有细节和复杂性，而不牺牲迭代速度。这是一个非常微妙的平衡，**我们更倾向于采用具有完全可调试性和可维护性的声明式系统。**

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8eNFvBPtevHDQ9cNIosBdBemmeZvTHLL42j6Ir0GZbibhYsjgQiakBnJRw/640?wx_fmt=jpeg&from=appmsg)

**主持人：** 你能举一些例子吗？比如你在一条线上，你会想，我们可以用这种更声明式的方法来做，或者用不同的方法来做？你必须考虑做出哪些权衡？

**林乔：**
例如，当我们刚开始时，我们从最低级别的抽象开始，即单一模型即服务。今天，我们提供了数百种跨不同类别的模型，包括大型语言模型、音频模型、转录、翻译、语音合成和对齐。我们还有视觉模型，其来源可以是
PDF
图像、屏幕截图等等。此外，我们还提供嵌入模型和图像生成模型，并且我们正在积极添加视频模型。这些代表了开发人员可以组装他们想要的东西的基础构建模块。但是，有很多东西需要组装，而且质量控制过程也很具挑战性，因为每周都会发布多个模型。

开发人员不断向我们寻求关于尝试哪些模型的建议。他们询问是否应该给新模型一个机会或决定放弃它。此外，还会出现关于生产稳定性、版本控制和管理大量可用选项的担忧。这些挑战对他们来说可能会变得难以承受。

鉴于我们的出发点和对行业发展的理解，我们很快意识到在可用性方面存在一个重大差距，尤其是在企业环境中。这个差距是巨大的，我们致力于解决和填补它。

**主持人：** 跟大家聊聊，为什么市面上没有更多生成式AI的应用呢？

**林乔：** 我认为实际上有很多障碍。**其中一个障碍是没有一个模型能够适用于所有情况**
。这是我们的观察。这有点像训练过程的本质。训练过程是一个非常主观的过程，你必须选择世界上数千个问题中的哪个子集是你最关心的。你会投入最多的资源和金钱来获取数据，并确保你在该领域的数据质量和多样性是最好的。如果我们解决的问题不是你关心的，那我们就白费功夫了，对吧？

正因为如此，模型的最终结果会在某些方面做得非常好，而在其他方面则做得非常糟糕。这就是模型训练的本质。我们认为未来在于数百个小型专业模型。当你把问题缩小到特定领域时，小型模型更容易蓬勃发展并提高质量。

事实上，这种方法对开源社区非常有益。基于开源的模型提供了很大的控制权来定制你的模型。有许多模型提供商专注于后训练或微调，提供服务于明确问题的专业模型。这种回馈开源社区的动态，对于有效地解决某些问题非常有价值。

因此，我们认为未来将由数百个小型模型组成。这就是我们看到企业界的发展方向。企业希望对他们的模型有更多的控制权和可操控性。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8eP6pt9EHzuicP5FPfj5FJGib8gI5ddaWwiahGkpicPiahoRHoIZ5EsLFQ10g/640?wx_fmt=jpeg&from=appmsg)

**主持人：**
在这个拥有数百个小型专业模型的世界里，我可以想象这样一种情况：很多人都在以某种方式调整开源模型。而Fireworks就拥有一个庞大的模型库。我是一家企业，我有一个问题。然后你们说，嘿，这里有十几个非常棒的模型，我们可以把它们组合起来。我也能想象到，在某些情况下，你可能会告诉企业，嘿，你应该针对这个用例进行微调。或者，实际上，我的意思是，在某些情况下，甚至可以对模型进行某种程度的预训练。
你是如何考虑这方面长期发展的？我想知道，你认为在五年内，企业会进行大量的模型微调还是预训练？

**林乔：**
它将如何发展？正如我所提到的，我们深信定制化，但这个过程并非一蹴而就。这不仅仅是分分钟钟就能完成的事情，它需要更长的时间。我们看到了微调和提示工程之间的微妙平衡。这里存在一个很强的权衡，而这正是我们工作的重点。因为我们相信定制化，所以我们正在努力使其变得极其简单。这种平衡正在发生变化，允许更快地获得结果。当使用提示工程时，这个过程更具响应性和交互性。这反映了这些系统运作的本质。

我们注意到，**许多企业或开发者都是从提示工程开始他们的旅程的**
。他们经常会问自己，是否可以将模型引导到他们想要的方向，并快速进行测试。然而，当他们遇到成千上万行的系统问题时，挑战就来了。在某个时刻，如果他们想继续引导模型，他们可能会陷入困境，因为他们不知道在哪里进行更改，从而导致方向迷失。解决这些复杂的系统管理问题本身就成了一个问题，而这最终是使定制化更容易的关键。我们计划推出一款专门解决此问题的产品。

在这个开发阶段，**一旦你有了成千上万行的系统提示，你应该做什么？这通常是采用微调将系统提示集成到模型本身的最佳时机**
。到那时，你应该已经证明该模型是可控的，并且可以有效地解决你的问题。你的指令，本质上是你提供给模型的数据，将通过微调来提高其性能。这表明了一个从“产品市场匹配前”到“产品市场匹配后”和产品规模化的转变。一旦你将冗长的系统提示融入到模型中，它就可以更快、更便宜、更高质量地运行。

我们认识到这种转变是非常自然的，但在将这些流程融入微调之前，管理漫长的流程仍然存在挑战。管理这些大量的提示并确保流程顺利进行是一项艰巨的任务。因此，找到有效的解决方案对于成功的定制化和模型演变至关重要。

**主持人：** 所以，是的。你认为预训练对企业来说有意义吗？

**林乔：**
预训练有点像整个行业都在说，预训练正在被整合，对吧？是的。所以整合到超大规模计算中。这几乎是现实。我们确实感觉到，我们看到一些企业进行模型预训练，因为这对于他们的业务至关重要，或者出于其他原因。但是，是的，所以，但是差异化，我们看到许多企业问自己的问题是，甚至初创企业也在问，差异化是什么？因为预训练非常昂贵，而且投资回报率必须证明你投入了大量的资金和人力资源是值得的。如果你可以在一个非常强大的基础模型之上进行后训练，那么投资回报率会更高，而且你也可以更灵活地测试不同的想法。

**主持人：** 你说的角度很有意思，因为你看到很多人在Fireworks之上构建应用。你觉得今天有哪些生成式AI的用例已经实现了产品市场匹配？

**林乔：** 我会把这些用例分为两个不同的类别。但总而言之，我认为我们看到的，**大多数成功获得采用的用例都涉及人机协同自动化，而不是无人值守自动化**
。我的假设是，一个生成式AI系统必须是可人工调试的、可理解的、可维护的和可操作的。如果人类无法评估它、维护它、影响它并在生产中操作它，那么它就很难被采用。

由于这种性质，我们看到各种旨在支持人类在不同类别中工作的辅助技术，涌现出了许多充满活力的产品。我们看到有人使用助手来帮助医生更轻松地进行记录。此外，还有针对教师和学生的助手，旨在帮助那些想在教育环境中学习外语的人。我们也看到了用于编程的助手，这是一个竞争非常激烈的领域；但是，我们与Cursor、Sourcegraph等许多优秀的公司密切合作。此外，我们还看到医疗助理之类的助手，特别是在北美，护士短缺超过一百万，突显了对病人护理的需求。

另一方面，还有更侧重于B2B的方面，例如呼叫中心环境中的自动化。呼叫中心自动化是一个很好的例子，你可以构建助手来支持人工客服，使他们能够更高效地工作并更好地回答问题，甚至可以取代人工客服。我们看到在构建这些助手来帮助人工客服方面取得了很大的成功。这导致了各种旨在优化业务逻辑、业务流程、效率等的过程。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8e9XytYKVxjgLica0YxbVKXKxziaoTcvYsvHmh4msZ3qUiaBP0XzG3S2QicQ/640?wx_fmt=jpeg&from=appmsg)

**主持人：** 那么在模型方面呢？比如，您注意到公司实际使用的模型有哪些？

**林乔：** 我们看到很多 LLaMA
模型的变体趋于收敛。我认为这证明了该模型的质量。它是一个非常强大的基础模型，指令遵循能力非常出色，而且非常适合微调。当然，Meta
的支持也非常重要，我们看到很多企业都在采用它。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8ePKgGq5zrnlnavEv2kITfGDkTFnBibxQOCnwx2iboQFkK4V5jfMgQ6bSA/640?wx_fmt=jpeg&from=appmsg)

**主持人：**
很明显，我确信您的企业客户非常关心评估（evals）。而且，我相信您显然也对此进行了很多思考。目前评估的状况如何？您如何看待为拥有不同用例，以及因此拥有不同评估成功方式的企业提供合适的构建模块？

**林乔：**
许多企业在评估的早期阶段都是基于感觉的，这并不奇怪，对吧？是的，他们是这样，但他们很快就意识到，我的意思是，在早期阶段，产品开发更像是基于感觉。我只是想了解一下，不同的模型会给产品带来什么样的感觉，等等，对吧？他们很快就会发展到有意识地构建评估的阶段，他们知道这是一个需要投资的领域，但为了保持领先地位，他们必须能够进行评估。而且，他们还必须能够在进行更深入的提示工程或微调后进行评估，比如，如何评估质量非常重要。他们不能总是进行
A/B 测试。A/B 测试是确定产品影响的最终过程，但周期较长。

**主持人：** 有趣的是，我们和一些，我想是 Sourcegraph 的客户（也是你们的客户）聊过，他们甚至不费心做评估，他们直接发布产品，进行 A/B
测试，他们的开发人员会很快知道哪个模型更好。

**林乔：**
是的，但是评估非常重要，因为从我们客户的角度来看，他们意识到投资于生成良好的评估数据集，并不断向其中添加更多内容，可以让他们非常清楚地了解哪些重要，哪些不重要。

在追赶那些不断变化的专家小模型的过程中，重要的是要注意到模型不仅仅是每周都在变得更好，就像在竞标或排行榜中一样。模型也变得更加专业化。我们的许多客户最初都从一个开放式的产品开始。他们最初对于用户会提出什么样的问题并没有明确的看法，但随着时间的推移，他们开始形成更清晰的观点。

随着他们不断改进理解，他们会加强产品设计，从开放式产品发展到具有独特功能的更专业的产品。对于这些特定的产品功能，他们希望开发专门的模型来有效地解决问题。这反映了产品开发的自然演变过程。

**主持人：** 我想，也许可以谈谈你们构建的一些东西，显然，你们正在利用开源世界中现有的优秀模型，然后你们也在构建自己的模型，对吧？你们构建了
F1。也许可以谈谈你们为什么决定这样做。

**林乔：** 我们通过 API 发布了 F1，这是一个模型 API。基本上，你使用 F1 的方式就像使用一个新模型一样。但 F1
实际上是一个复杂的逻辑推理系统，在其底层，我们还没有过多地谈论 F1 的底层是什么。这只是底层的一个片段。

所以，在底层，实际上有多个模型。我们的系统中还实现了逻辑推理步骤。构建一个系统非常复杂；它不像常规的单一模型即服务推理那样。我们必须解决许多与质量相关的问题，因为现在你让模型自己对话，让模型之间互相对话。

它们传递什么样的信息来提高质量是敏感的，而且在这种复杂的系统中弄清楚如何进行质量控制是具有挑战性的。我认为这种复杂性实际上比构建数据库管理系统更高。

此外，由于涉及多个步骤，整体的推理延迟和成本变得更加有趣。这就是我们的专长和交易，我们团队真的擅长优化这些方面。当我们刚开始公司时，我们构建了较低级别的单一模型即服务，它可以作为构建这种复杂逻辑的构建模块。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8esGKZfkSibEwjs7dG6rTFVkIs5AE6aibLW0JnfIs1aQicRRmibRlB8ibc8Lw/640?wx_fmt=jpeg&from=appmsg)

**主持人：** 然后，很明显，我认为一个重要部分是函数调用，对吧？我想，今天让函数调用变得更好的障碍是什么？感觉在很多方面我们仍然处于起步阶段。

**林乔：** 函数调用，就像许多人认识到的那样，是我们经常看到的东西。在我们推出 F1
后，我们有一个等待名单，让人们加入，我们和他们中的许多人进行了交谈。显然，**他们的大部分用例都涉及构建代理，而且他们需要函数调用。**

那么什么是函数调用呢，对吧？函数调用基本上是这个模型调用其他工具来增强答案质量的扩展点。然而，函数调用不仅仅是调用一个工具；如果你仔细想想，它实际上非常复杂。通常，人们在多轮聊天上下文中使用这些函数调用模型。模型需要保持对话中发生的较长上下文，然后使用该上下文来影响调用哪个工具是最佳的。

通常，他们还需要调用多个工具，有时多达数百个工具进行选择。此外，这不仅仅是一次调用一个工具；他们通常需要并行和顺序地调用多个工具。这需要在一个环节中进行复杂的协调规划。我们的函数调用能够进行并行和顺序的复杂规划，并且可以编排和执行该计划。

当然，定位很重要。例如，如果我要求模型生成前三大云提供商的股价总图，它会快速返回答案以及图表。然而，在底层，有一个搜索过程来识别前三大提供商，三个并行函数调用来获取股价，以及一个调用图表工具来检索图表。这是一个非常简单的例子，但它清楚地展示了编排的复杂性。

模型需要具备强大的能力来理解何时调用插入的工具以及如何驱动该过程，这非常重要。这使得微调过程相当复杂。然而，我们在这个领域已经投资了大约一年时间，我们开始看到进展。当我们第一次发布函数调用模型时，我认为我们领先于采用曲线，但用例尚未完全兴起。

**主持人：**
您如何看待，比如，为什么决定构建它，而不是我确信如果您等待一段时间，就会出现一些具有这些功能的优秀的开源模型。您如何决定何时在模型方面内部构建东西？

**林乔：**
是的，所以我们并非建立在开源社区之上，对吧？这绝对是事实，而且我们正在为此下注，因为我们相信数百个专家小模型将来自开源社区。是的。这与我们的愿景直接一致。

但与此同时，我们也必须投资于复合 AI 系统，其核心是将数百个专家小模型组合在一起，以非常简单的方式解决复杂的业务任务。这种可组合性的关键部分在于编排层。

该模型完全足以调用不同的工具。在这里，您可以考虑关于工具的一般思考方式：除了这个特定的大型语言模型之外，每个独立的小型专家模型也是一个工具。因此，它成为将所有内容联系在一起的关键要素。

我们将投资于那些我们不能仅仅等待事情发生，而具有战略关键意义的领域。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8e81JqsicDTKicFoYjoMhUIDCmnnyfkKHuo3Wf2JiaBrxsA2ZV6eJvTFibUA/640?wx_fmt=jpeg&from=appmsg)

**主持人：**
推理模型最终会适合在哪里呢？我的意思是，显然，至少我们今天看到的那些，或者我认为它们是笨重的，并且通常擅长各种推理。我们最终是否会使用小型专家模型，在计算密集型模型上进行测试？或者你认为我们只会在非常特定的情况下才使用它们？当您考虑这些复合系统时，我只是好奇这些类似
O1 的模型将如何融入其中。

**林乔：**
我认为即使是推理，解决推理问题也有不同的路径。而且会有不同的模型专门用于不同的路径。一种路径是让一个非常强大的基础模型本身进行自我检查。已经有很多技术正在被讨论，例如思维链、思维链以及回溯等技术。

所以这只是一个方面。将会有一组新的模型可以进行逻辑推理，而不是在提示空间中，这是我非常兴奋的事情，而是在潜在空间中。我们可以思考我们的思考过程；我们不必用语言表达。虽然我们可以清楚地表达我们的想法，但我们通常在不同的空间中思考。模型也是如此。

有很多积极的研究工作正在进行，以使思考过程更加高效，更贴近我们处理信息的方式。我对此类研究感到非常兴奋。还会有其他形式的逻辑推理。我们不想对哪种方法会成功过于固执己见。相反，我们的目标是将所有这些不同的形式整合到我们的逻辑推理系统中。

**主持人：** 我喜欢这个。我想，除了你们在 Fireworks 所做的事情之外，你觉得当前人工智能基础设施中还有哪些其他尚未解决的重大问题？

**林乔：**
我认为我们已经看到了构建代理工作流程的巨大进展。是的。而且我认为我们仍然处于探索正确用户体验的早期阶段。什么是抽象，整个行业如何适应它？什么是正确的抽象？我们应该在系统背后隐藏什么，又应该向开发人员公开什么？我们现在还处于非常早期的阶段。我认为现在它还处于非常实验性的阶段。

但是，抽象的位置将决定其背后隐藏的基础设施的复杂性。然而，我认为我们现在开始形成关于这个问题的观点。一两个月后，我们将会正式发布 F1。因此，我认为构建
F1 的过程是我们理解系统抽象和构建逻辑推理引擎复杂性的一个练习。

从那里，当我们达到 GA （普遍可用性**General Availability**
）时，我们希望公开面向开发人员的插件，并展示开发人员如何构建他们自己的 F1。所以，是的，我非常兴奋。

**主持人：**
沿着这个方向发展。这太酷了，因为很明显，通过自己构建，你会学习到必要的工具和抽象。然后你基本上允许开发人员重新创建它。我喜欢这种方法。我想很多感觉是在硬件方面，我的意思是，显然每个人都在使用
NVIDIA，但也有很多竞争对手涌现出来。我很好奇你对这个领域的看法以及其中一些努力的可行性。我认为你们的平台支持 AMD
芯片进行推理。这对开发人员来说什么时候有意义，你认为它将如何发展？

**林乔：**
总的来说，**我们看到开发人员在对硬件和底层硬件优化的理解方面存在一种匮乏感。硬件开发的节奏也发生了重大变化。以前，新的硬件技能大约每三年出现一次，但现在我们看到各种硬件供应商几乎每年都会推出新的硬件技能。**
整个硬件领域发展非常迅速，并且越来越需要访问最好的硬件。

当我提到“最好”的硬件时，重要的是要注意，没有一种通用的解决方案。最佳硬件实际上取决于您特定的工作负载模式。即使访问相同的模型，也没有针对该模型的单一最佳硬件选项。这是因为您的工作负载分配将决定最大的瓶颈出现在哪里。不同的硬件偏向将更擅长缓解特定的瓶颈。

在我们的层面上，我们承担起集成并确定哪种硬件最适合不同类型工作负载的责任。即使对于具有混合访问模式的单个工作负载，我们也可以将任务路由到不同的硬件选项。我们的目标是减轻开发人员的担忧和负担，让他们专注于构建自己的产品，而我们则负责管理和优化硬件的复杂性。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8eILvEKVoFM43NQAy6PnguU3q32s99bs05Nypsd1RzUkDnxFXSiaibtcyA/640?wx_fmt=jpeg&from=appmsg)

**主持人：**
是的。看起来你显然非常专注于这些复合系统。显然总会有一部分人只想直接调用模型并运行它。在那个世界里，感觉有一段时间在推理方面真的有很多竞争。一个新的模型，一个开源模型会出来，每个人都会提供他们的价格，而且价格会越来越低。在那种竞争中，你是否认为最终超大规模企业最适合赢得像开源模型上的直接推理？或者它将如何发展？

**林乔：** 这是一个非常复杂的问题，很难回答。我认为所有的超大规模企业都想成为苹果，对吧？所以他们想制造
iPhone。他们想要建立一个垂直整合的堆栈，因为他们有能力这样做。但是，我们正在朝着的方向是，我们觉得未来在于数百个小型专家模型。我们希望收获这种能量，并构建一个利用最佳模型来解决复杂问题的复合人工智能系统。

在我看来，我认为超大规模企业最大的优势在于它们有能力解决那些在资金和人力资本方面需要大量资源的问题。例如，建造数据中心、获取电力以及安装大量机器涉及到部署和启动大规模的存储和计算。云提供商可以大规模地解决这些大规模的问题。

我们专注于解决需要工程技术和深入研究相结合的问题，然后我们可以大规模地部署解决方案。我认为推理就是这样。我在 Mata 工作，但这并不意味着 Mata
有一个拥有数千人的推理团队，对吧？一旦你拥有一个具有高生产质量且可以水平扩展的系统，剩下的就是让它扩展。这就是设计高度可扩展系统的美妙之处。

然而，推理系统并不简单。它实际上将演变成这种复合逻辑推理推理系统，其中涉及构建它的很多复杂性。这种复杂性不能仅仅通过投入人员或资金来解决。所以，是的。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8eM9FAIKJrhibuHpgYVPR79gmz9sCSMycVpxibzNuOhg0Fdp0hU4iaKQdibA/640?wx_fmt=jpeg&from=appmsg)

**主持人：**
是的。我猜想，对于这些小型专家模型，我一直在想的一件事是，随着这些模型变得越来越小，我觉得也有一种很大的趋势是在本地运行它们。我很好奇你如何看待未来几年这种情况的发展，以及这是否也会成为
Fireworks 平台的一部分。

**林乔：**
嗯，我看到很多关于本地运行模型的讨论，主要有两个原因。而且我们应该先讨论一下“本地”到底是什么意思，对吧？一个原因是节省成本，因为在云端使用GPU需要付费，而在桌面设备上运行则不需要。另一个原因是隐私，对吧？我对这一点有不同的看法。我认为将计算从云端转移到桌面设备是有意义的。我认为许多应用，比如Zoom，通过这样做节省了大量成本。

然而，将计算从云端转移到移动设备则是另一回事。移动手机的性能越来越强，但它们的电力仍然非常有限，对吧？在Meta，对于应用程序来说，许多应用指标都会被密切监控，包括冷启动时间和功耗。所有这些因素都会影响应用程序的评分、用户采用率和整体体验。因此，可以实际部署到移动端的模型都很小，比如1B或10B参数，非常非常小。这些模型的功能有限，对吧？所以，我认为在模型容量方面，移动端和云端之间的差异非常显著。

相比之下，对于许多面向消费者的应用程序来说，将计算转移到桌面设备是有意义的。然而，还有另一种关于隐私的观点。隐私很有趣，因为很多个人数据已经在云端了。我们的大部分个人数据不再存储在本地磁盘上了。那么，在这种情况下，担心隐私还有意义吗？嗯，我认为这是一个单独的问题。

**主持人：**
嗯，太有趣了。我的意思是，在开源方面，你之前在Meta工作过。感觉他们通过训练越来越大的模型，为生态系统提供了巨大的服务。你认为他们在开源模型上的支出会持续扩大到什么程度？到某个时候，他们会停止吗？我的意思是，我觉得每个人都在问所有参与者这个问题，不仅仅是开源参与者。但是，你认为在预训练支出方面，继续投入的意义有多大？我不知道。

**林乔：**
这是个好问题，扎克。不，我开个玩笑，我们与Meta团队合作非常紧密。当然，我们来自Meta。我们实际上是共同设计的；他们不仅开源了LLAMA模型，还在构建一个名为LLAMA栈的标准。LLAMA栈的目的是使LLAMA模型周围的工具栈标准化。

我们与他们共同设计，因为我们从客户那里获得了很多信息，可以帮助他们做出设计选择。我认为这是Meta的雄心：构建一个类似Android的世界，一切都很好地标准化，允许你接入不同的组件，并使其非常容易采用。

从我的角度来看，我的理解是LLAMA
4即将推出，对吧？Meta将持续投资于训练。我没有看到这种投资停止。当然，普遍的问题是，模型提供商何时会停止或减少在预训练上的投资？通常这种情况发生在投资回报率（ROI）不高的时候。

投资回报率低的原因是我们正在触碰到数据瓶颈。**我们已经用尽了新鲜数据；每个人都抓取了相同的互联网数据。我们已经耗尽了合成生成的数据以及多媒体和文本数据的组合。**
因此，投资回报率较低。然而，在我们触碰到那个瓶颈之前，我相信会有持续的投资。

**主持人：** 你认为我们什么时候会触碰到那个瓶颈？

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8ewaQMAkIblNK6ickZPlbALY77g6icZWaroOH6Ur7OnW02JB2UEO2Ls9JQ/640?wx_fmt=jpeg&from=appmsg)

**林乔：**
**我认为从OpenAI的角度来看，这个时间肯定越来越长了。对吧？是的。所以，我确实看到大量的投资开始从预训练转向后训练，从后训练转向推理。对吧。所以，我认为我们已经触碰到了一个软瓶颈，而不是硬瓶颈。所以，总的来说，我认为作为一个行业，投资回报率正在从预训练转向后训练再转向推理。**

**主持人：** 你如何看待让一个代理成功的所需的所有工具？我的意思是，Fireworks
可以成为一个一站式商店，构建所有这些工具，也可能通过合作来实现，比如，我们不打算构建这个部分。你是怎么考虑的？

**林乔：**
嗯，**我们一直与命令式代理工具非常兼容，对吧？最值得注意的是Langchain。是的。我们一直是他们非常强大的合作伙伴，因为我们不会去构建他们正在做的东西。**
Langchain
在他们正在构建的东西方面做得非常出色。拥有庞大的社区和采用率，非常棒。我们只是想通过组合多个模型，在单模型即服务的基础上，将服务提升到更高的层次，从而更好地解决问题。因此，我们完全支持并会坚持我们的立场，我们会接入Langchain。例如，这是一个例子，当然还有很多其他的例子。

**主持人：** 这个社区。嗯，很有道理。当你考虑当今的竞争格局时，我猜当人们想到 Fireworks 时，他们可能也会把你和 Together AI
归为一类。我知道 Databricks 也经常谈论这些复合 AI 系统。你是如何看待 Fireworks
今天的差异化，以及五年后，最终将决定谁能在这个真正有趣的领域中脱颖而出？

**林乔：** 嗯，我们可能在考虑，所以复合 AI 实际上不是我们创造的术语，对吧？这个词是伯克利提出的。我们知道 Databricks
也在关注这个领域。我认为这很棒。这是一个我们正在定义的新类别，对吧？

所以，肯定会有多个玩家处于同一领域。我们很高兴 Databricks
也在考虑这个问题。我认为这个领域非常有意义，因为对于应用程序开发人员、产品开发人员和工程师来说，这是一个非常复杂的领域。

在这个领域将会出现一套丰富的工具，使开发效率更高。而今天我们还没有达到那个水平。所以我们决心成为这个领域的关键参与者。

除此之外，我们不是一个 GPU 云，例如提供廉价 GPU 的访问。那根本不是我们的玩法。我们实际上是在 GPU 云之上构建，以提供复杂的推理数据。

**主持人：** 我想关于公司有一件事真的很有趣，我猜你是在 ChatGPT 出现的几个月前创立了
Fireworks？所以我很好奇，当你思考公司的最初愿景时，以及你今天在生成式 AI 的狂潮中所取得的成就，有多少是相同的？你在 22 年 9
月的想法有多少需要改变，因为世界在过去几年里变化太大了？

**林乔：** 是的，这确实是一个非常有趣的问题。当我创立 Fireworks 时，实际上有一个激烈的辩论：AI
真的来了吗？因为在基础模型被广泛知晓之前，有太多分散的 AI 应用，数据也不足；AI 并没有真正到来。但我们清楚地看到 AI
即将到来。通常情况下，超大规模企业会领先整个行业三到五年，而 Meta 已经大规模使用 AI。行业正在经历 PyTorch 的采用，这清楚地表明 AI
的浪潮正在逼近。这就是 Fireworks 的大致时机。

生成式 AI 的发展确实严重扭曲了 AI 的采用曲线。有一种特殊的 AI 在这种转变中发挥了作用。这很有趣；生成式 AI
是一种不同的东西。它并非仅仅因为是生成式 AI 而神奇，而是因为它从根本上改变了可访问性。在生成式 AI
之前，当还是传统的机器学习或早期的深度学习模型时，任何投资 AI
的公司都必须首先雇用一个机器学习团队，因为他们需要从头开始训练模型。没有可供他们构建的替代预训练模型。

这种对从头开始训练的依赖意味着团队必须策划大量数据，这需要大量的时间投入。训练过程本身很漫长，公司需要资源来雇用那些非常稀缺的人才，并将资金投入到训练中。

**主持人：** 最初的Fireworks产品是为了那些人量身打造的吗？或者说，是因为你们知道最初感觉需要那样才能获得采用？

**林乔：**
是的，是的。当我们刚开始做的时候，我们就是考虑到那一批人。然后随着生成式人工智能的出现，它正在改变格局，对吧？你不再需要雇佣一个庞大的团队来处理数据，因为生成式人工智能的优势在于它创建了一个吸收大部分知识的基础模型。然后你只需要在其之上读取数据，或者进行微调，对吧？如果你有数千个样本，你就可以进行微调。

这样一来，你可能就不需要机器学习团队，你只需要一个应用开发团队直接在其上构建，或者你只需要一个小型的机器学习团队，对吧？这大大提高了这项技术的可及性。这也是我们看到采用曲线如此疯狂飙升的原因。由于这种可及性，它与之前和之后的情况有着根本的不同。

因此，我们专注于此，因为这个方向的拉力要强得多。另一个副作用是，所有这些模型，所有通用模型都是 PyTorch 模型。我们编写 PyTorch
代码多年，并且在生产环境中以高流量运行大型复杂的 PyTorch 模型多年。这是我们真正擅长的。

**主持人：** 这做得很好。是的，为之做好了充分的准备。你提到，当你身处像 Meta 这样的公司时，你会提前看到未来的趋势，就像在它变得明显之前一样。你在
Meta 工作时，有没有看到什么让你觉得，“天哪，这很快就会变得如此巨大”的事情？

**林乔：** 我认为更像是人工智能将会掀起巨浪，这很明显。我在 Meta 工作了几年，那是一段很有意思的时期。当他们加入 Meta
时，他们正在经历移动优先的转型，也处于尾声。然后整个行业也在经历移动优先，对吧？所以我从桌面端转向移动端。移动优先让消费者可以随时随地访问应用，这提高了采用率和参与度，并且因为它产生了大量数据，大量的数据正在为人工智能提供动力，对吧？所以整个行业也都在跟随移动优先的趋势，产生了大量的数据，而数据又推动了人工智能的发展，所以这种趋势非常明显。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8ewbosGXaDXCmGnk3oKxpp7lHicXiarGich6l56z3eA6gfibZOW7N1J7DP7Q/640?wx_fmt=jpeg&from=appmsg)

**主持人：** 你关注哪些人工智能研究？也许甚至不局限于Fireworks产品的日常核心工作？

**林乔：**
我通常关注两种研究。一种是模型系统协同设计的相关研究。这里存在一个有趣的组织分工：研究人员通常只关注质量，而像我们这样的系统构建者则专注于以低延迟和低成本提供最佳质量。我们解决系统问题。然而，最佳的投资回报率（ROI）通常来自于将这些要素综合考虑。这就是我们在
Meta
的运作方式：研究团队和信息团队紧密合作，讨论权衡和协同设计。协同设计领域有很多研究，我发现它对于在质量、延迟和成本这三个维度进行优化，找到最佳的设计点非常具有吸引力。

另一种我感兴趣的研究是根本性的颠覆性研究。Transformer 技术早就应该被颠覆了。这就提出了一个问题：下一代 Transformer
技术在哪里，它将改变我们训练模型和执行推理的方式？这个领域的研究非常有趣。此外，在智能体（agentic）世界中，理解不同的智能体如何相互沟通至关重要。正如我提到的，这种新的创新思维方式非常吸引人。

**主持人：**
我想，构建一家基础设施公司的一个挑战是，显然变化的步伐太快了，既包括模型的改进，也包括企业思考和实际使用这些东西的方式。我可以想象，一种观点是，它变化太快了。比如，我们会快速更新我们的核心工具，因为变化太快了。在某个时候，它会稳定下来，然后我们就可以构建一套标准的工具。你是如何看待这种张力的？即，在不确切知道的情况下，为人们今天做事的方式而构建，也许在两三年后，模型会有所有这些不同的功能，而我们正在以所有这些不同的方式设计系统？

**林乔：** 是的，这真是一个好问题。这正是我们一直在思考的问题，对吧？我们不想一直追逐即将发生的事情，因为追逐是令人疲惫的。我们总是想保持领先地位。

我认为模型的功能肯定在不断发展。它从两年前到现在一直在发展，特别是如果我们看看 OpenAI 的模型能力，从 GP3
到现在，就有九个不同之处。但从根本上说，一些趋势并没有改变。其中之一，再次回到我们的愿景：我们相信未来的方向是专业化和定制化。这不会改变模型核心功能的发展方式，因为我们不相信一个模型就能以最佳方式满足所有不同的工作负载，使用专有数据等等。

我们相信，如果你可以定制、可以引导并且可以控制，就会有更好的解决方案。这才是关键。这就是我们构建堆栈的原因，使其能够以一种简单的方式实现这一目标。具体来说，除了我们的一体化推理引擎之外，我们还提供一个优化器：一个一体化的文件优化器。

我们以推理工作负载和您的定制目标作为输入，生成推理部署配置，并可能为您调整模型，以便您可以控制是否要部署它。这只是一个我们闭环的过程，使其更容易定制。因此，我认为这在未来不会改变。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8eu4aB6kJIzJW4b81zXiaTjZMIxYh2VYd8LLiaZ6BtRuhD81v0ceM2sMfw/640?wx_fmt=jpeg&from=appmsg)

**主持人：**
完全同意。只是你定制的内容可能会改变，但你进行定制的方式仍然会一样，我认为这非常有道理。好吧，我们总是喜欢以快问快答的方式结束我们的对话，我们会请你回答一组标准问题。也许先从一个问题开始，你认为现在人工智能领域有什么被过度炒作了，又有什么被低估了？

**林乔：**
我认为被过度炒作的是人们认为通用人工智能是神奇的，它可以解决所有问题。我们只需要问它。任何问题，它都会给出正确的答案。我认为现在正处于纠正时期。同样，我们认为没有一个神奇的模型可以以最佳方式解决所有问题。

**主持人：** 或者以正确的方式解决。在过去一年里，你在人工智能领域改变了什么看法？

**林乔：**
我认为我建立这家公司以及GenAI技术如何适应、被采用以及我们的市场进入策略，在我看来一直是循序渐进的。初创公司就像GenAI的原生企业，所以它们会站在采用的前沿。然后我们会与数字化原生企业合作，它们拥有非常强大的工程资源，并且总是更倾向于技术前沿。最后是传统企业，因为它们有更多其他类型的问题需要解决。但现在我们同时与所有这些类型的企业合作。这对我来说有点疯狂。当然，用例并不完全相同，但采用曲线却同时发生。这与我之前想象的非常不同。

**主持人：**
完全同意。我的意思是，在应用方面，感觉过去那种需要很长时间才能争取到一个大企业客户，然后才能争取到一些后续客户的规则，现在都已经过时了，对吧？现在一些应用公司在大企业中的扩展速度非常快。我认为大家对它的需求非常旺盛。

**林乔：**
是的，没错。没错。所以我感觉这就像一场革命一样，对吧？很多事情都会以不同的方式完成，不仅仅是应用程序会有所不同，技术采用曲线也会不同，甚至连如何考虑市场进入策略也会不同。销售周期更短，人们也愿意以不同的方式考虑采购流程。所以，这种大规模的转型会带来一种非常有趣的连锁反应。

**主持人：** 你是否觉得，为企业用户构建产品和为初创公司构建产品，在需要构建的东西方面有什么不同，或者说它们的需求其实非常相似？

**林乔：**
我认为我的观察是，初创公司通常希望获得，当我们谈论抽象层时，他们希望获得底层抽象的访问权限。是的。因为他们想了很多，对吧，想把很多东西组装起来。而对于传统企业，我并不是说这是绝对的，但通常他们希望获得更高层级的抽象。如果他们不需要解决底层细节，就不需要关注这些细节，宁愿不关注。所以在Meta，我们为不同的团队提供了不同的抽象层，因为他们想挑挑拣拣，对吧？所以通常两层抽象就足够了，至少有两个选择就足以让他们满意。我们看到了一些这样的情况。

**主持人：** 在快速扩张的同时构建这两种类型的用户，肯定很有趣。

**林乔：** 对，对。无论如何，我们需要为自己提供底层抽象。所以对我们来说这不是额外的开销，但我们看到采用会发生在不同的层级。

**主持人：** 是的。我知道这可能很困难，我不会要求你选一个最喜欢的，但目前在Fireworks上构建的最喜欢的一个应用是什么？

**林乔：**
这是一个棘手的问题。我会说是Cursor，但我们看到很多类似的公司都在效率提升领域中，对吧？不仅仅是Cursor，还有Sourcegraph、Zed、Cognition、Factory。它们都是非常有前瞻性的公司。我认为在这个领域，现在还处于早期阶段。但是在这个领域，我们对整个领域都感到非常兴奋。

**主持人：** 你认为在未来几年内，会有人花费1000亿美元来训练一个模型吗？ 哇。

**林乔：** 也许吧。我认为只有当他们使用根本不同的模型架构进行训练时，这才有意义。是的，这种颠覆性的做法才值得这样的投资。

**主持人：** 是的。你已经提到了代码领域和一些初创公司，但除了Fireworks之外，你现在对其他哪些人工智能初创公司或领域感到特别兴奋？

**林乔：** 我认为智能体（agentic）领域还没有被完全弄清楚。

**主持人：** 你有没有看到任何应用在这方面做得很好？

**林乔：**
我们看到了一些早期的应用，例如数字销售开发代表（SDR），数字营销。是的，我们看到一些优秀的初创公司在那方面取得了很好的采用。但我确实认为，未来这个领域会更加复杂。我们还处于早期阶段。

**主持人：**
好的，这真是一场引人入胜的对话。我相信大家会想深入了解许多话题。所以我想把最后发言的机会给你。大家可以在哪里了解更多关于你，以及你在Fireworks构建的内容？
请你发言。

**林乔：**
好的，当然。为了我们开发者社区的利益，我们提供了一个自助平台。非常简单。只需访问fireworks.ai，您就可以访问我们的游乐场和我们拥有的数百种模型功能。是的。也欢迎随时与我联系。在LinkedIn上联系我，我很乐意听到您的用例、挑战和痛点。

**主持人：** 太棒了。非常感谢。这是一场引人入胜的对话。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBM4UIMticVhzmibIzh9UxYO8e1CroH46co6LXFjwFD4wIKyibJR16aBJloCyA9Z4Txtcsv6mj7liaEJ0A/640?wx_fmt=jpeg&from=appmsg)

**关注公众号后设🌟标，掌握第一手AI新动态**

##  往期精选

  1. [黄仁勋专访：OpenAI在大模型混战中达到“逃逸速度”](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650001718&idx=1&sn=f8129a622e7611702be2cb23e8ce9418&chksm=88ba5831bfcdd127d06ce6492c821074407f805407b4182ca900916521cb5a4717f2a3d71ee8&token=1339625777&lang=zh_CN&scene=21#wechat_redirect)
  2. [李飞飞与Justin深度解读空间智能：数字世界需要三维表征，才能与现实世界融合](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000659&idx=1&sn=c71fb5b4ef501424dddd5e8b4dd5860e&chksm=88ba4414bfcdcd023c691a1adf75127a9fd883ceb305ca14cf97f719acaf999d40fa72f84bf3&token=1492077842&lang=zh_CN&scene=21#wechat_redirect)
  3. [PayPal创始人彼得·蒂尔：人类科技停滞源于原子方面的进展远慢于比特](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000240&idx=1&sn=26af6013981677b1e14137260857a6f0&chksm=88ba4277bfcdcb615d746615c262927bf51c43c920ed93fa36274ef87c6264d6548c84647121&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  4. [谷歌联合创始人布林：巨头们打造的“上帝模型”几乎可以理解一切](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=2&sn=0c714d804a72a52e002743d949e1685e&chksm=88ba40f9bfcdc9ef78749718480265922f4fba539abf6c9d62a6cd681f405dee9283d2429f84&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  5. [马斯克：AI将使商品和服务的成本趋近于零](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=1&sn=752f000a117a705e77950c82bfc4a004&chksm=88ba40f9bfcdc9ef5a5afe4a3ae73d5247bd54ed525dbdbedee1fcf74a6c082165e664a5c4d0&token=106920805&lang=zh_CN&poc_token=HDp86Waj18SFm2Y-xnv_Vqd_4J6emFoh10eH48wg&scene=21#wechat_redirect)
  6. [Karpathy最新专访：人形机器人、特斯拉、数据墙与合成数据](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999613&idx=1&sn=b8bdda7afe4c3ca08e324ac5bbd5a2bd&chksm=88ba41fabfcdc8ec0e21dbf4c7eb4d33252da70f47e1cfc9f5e113717911c417c2aebb3d6180&token=106920805&lang=zh_CN&scene=21#wechat_redirect)

  

