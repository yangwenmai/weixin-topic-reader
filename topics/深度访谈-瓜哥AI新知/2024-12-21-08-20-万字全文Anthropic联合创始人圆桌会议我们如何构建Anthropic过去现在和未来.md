# 万字全文｜Anthropic联合创始人圆桌会议：我们如何构建Anthropic？过去、现在和未来

文章作者: 瓜哥AI新知
发布时间: 2024-12-21 08:20
发布地: 浙江
原文链接: http://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650005909&idx=1&sn=0a3d6ed50c30c2f03efb899c3f672b3b&chksm=88ba6892bfcde184585a47099fb6d39872570207dc14c6e0ea9fea1a4c6202bf7bea4c642d02#rd

封面图链接: https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33d1TPgW3TOFAnHDGtanG4CaE3fD0ic5WZsmxHzGB7fhUicyX2ic0icibiadQ3A/300

**👇关注公众号后设🌟标，掌握第一手AI新动态**

**  
**

本文内容整理自**Anthropic联合创始人圆桌会议**
，公开发表于2024年12月20日。原始内容参考：https://www.youtube.com/watch?v=om2lIWXLLN4

## 内容提要: Anthropic联合创始人圆桌会议

  1. **早期对AI安全的关注和共识的建立:** 访谈回顾了早期AI安全研究的艰难，以及如何通过撰写论文、建立共识，最终促使行业重视AI安全问题。 最初人们对AI安全问题的重视程度不足，被认为是“疯狂”的想法。
  2. **规模化定律和安全性的相互作用:** 团队成员认为，大型语言模型的规模化扩展与安全性紧密相连。更大的模型虽然能力更强，但也带来了更大的安全风险，需要通过RLHF等技术来解决。
  3. **负责任的规模化政策（RSP）的制定和实施:** Anthropic制定了RSP，旨在通过多阶段阈值和持续评估，在模型规模化过程中不断提升安全性，并将其作为一种内部和外部沟通的工具，促进行业规范。RSP被比作“宪法”，需要持续迭代和完善。
  4. **团队文化和价值观:** Anthropic团队成员强调了团队内部的高度信任、共同的使命感和实用主义精神，这对于应对AI安全挑战至关重要。 团队致力于创造有益于社会的AI技术，而非单纯追求商业利益。
  5. **AI安全并非抽象概念:** 访谈指出，通过具体评估和指标（如RSP），将抽象的AI安全概念转化为可衡量、可操作的标准，从而更有效地与政策制定者、专家和公众沟通。
  6. **AI的未来方向和机遇:** 团队成员对AI在生物学、医学和增强民主方面的应用充满期待，并认为可解释性是理解和控制AI的关键。他们相信AI可以解决人类面临的许多根本性问题。
  7. **竞争与合作并存:** Anthropic通过率先实践安全措施（如RSP、前沿红队），引导行业发展，形成良性竞争，促进整个AI领域的安全性提升。 这被比喻为“一场争先恐后的竞赛”，但目标是共同确保AI安全发展，而非单纯的商业竞争。

## Anthropic简介

Anthropic 并非个人，而是一家致力于构建安全、可靠和可解释的AI系统的美国人工智能公司。它由前OpenAI研究人员达里奥·阿莫迪（Dario
Amodei）、杰克·克拉克（Jack Clark）和众多其他成员于2021年创立。 与其他专注于追求最大化模型能力的公司不同，Anthropic
将安全性和可解释性放在首位，这反映在其核心价值观和研究方向上。

Anthropic
开发了名为Claude的大型语言模型，其目标是创建一个更安全、更有益的AI系统。与其他类似模型相比，Claude被设计得更易于理解其决策过程，并减少有害输出的可能性。
这意味着Anthropic在模型的训练和评估过程中投入了大量精力，致力于减少偏见、误导信息和有害行为。
他们正在积极探索如何使大型语言模型更安全、更可控，并开发能够解释其自身推理过程的AI系统。

## 圆桌会议全文

**主持人Mark：** 我们最初为什么要研究人工智能呢？我随便点一个，就问Jared吧。你们到底是怎么做人工智能的？

**Jared：** 我是说，我以前做物理研究做了很久，后来觉得无聊了，就想多和朋友们待在一起。

**达里奥·阿莫迪：**
我觉得我并没有明确向你推销什么观点。我只是给你展示了一些人工智能模型的结果，想说明它们非常通用，不只适用于一个特定领域。然后在给你看了足够多之后，你就觉得，哦，好像确实是这样。你成为一个人有多久了？

**Jared：** 我觉得我帮着招募了Sam。我和你聊过，你说，我觉得我在这里创造了一个很好的氛围。我的目标是让Tom回来。然后，当然，我也要回去。

**主持人Mark：** Chris，你做可解释性研究的时候，是在谷歌认识所有人的吗？

**克里斯：**
不，我其实是在19岁第一次去湾区的时候认识你们的。我记得当时认识了Dario和Jared，他们当时是博士后，我觉得非常酷。后来我在谷歌大脑工作，Dario也加入了，我们还并排坐了一段时间。我和Tom也在那里一起工作过。然后，当然，我去了OpenAI之后就和你们大家一起工作了。所以，我觉得我认识你们很多人都超过十年了，这还挺疯狂的。

**主持人Mark：** 如果我没记错的话，我是在2015年参加你们参加的会议时认识Dario的，我当时想采访你，谷歌公关说我得读完你所有的研究论文。

**达里奥·阿莫迪：** 是的，我觉得我当时在谷歌研究人工智能安全方面的具体问题。我想你写过关于那篇论文的故事。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dnvWaXicQtafyGUTL61hnCT8yicNkjnyPs7GaM3bE6CTdsDdREQFMmJvQ/640?wx_fmt=jpeg&from=appmsg)

**Jared：**
我写过。我记得在我开始和你一起工作之前，你邀请我去办公室，我们聊了很多关于人工智能的事情。我记得之后我就觉得，哦，原来这玩意比我想象的要严肃得多。你当时可能在解释大型计算、参数计数，以及大脑中有多少神经元等等。

**克里斯：** 我觉得Dario经常给人这种感觉：这比我想象的要严肃得多。

**达里奥·阿莫迪：** 我是带来好消息的人。

**主持人Mark：**
但我记得在OpenAI的时候，有关于规模定律的研究，就是把东西做得更大，然后它就开始看起来真的有效了。然后它好像在很多不同的项目上都诡异地有效，我觉得这就是我们最终走到一起工作的原因，因为先是GPT-2，然后是规模定律和GPT-2。

**达里奥·阿莫迪：** 我们最终变成了一大群人。

**Jared：**
我觉得我们也对安全性感到兴奋，因为在那个时候，有一种想法是，人工智能会变得非常强大，但可能不理解人类价值观，甚至可能无法与我们沟通。我觉得我们都对语言模型感到非常兴奋，认为这是一种保证人工智能系统必须理解隐含知识的方法。

**达里奥·阿莫迪：**
还有在语言模型之上使用人类反馈强化学习，这也是扩大这些模型规模的全部原因，因为当时的模型不够聪明，无法在上面进行RLHF。这就是安全性和模型规模扩展的相互交织。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dvruFPEKwlKKcun5vnQ32USwiaajibx6gnXpfChN34iclrHEo3TUy8hC9w/640?wx_fmt=jpeg&from=appmsg)

**克里斯：**
我们今天仍然相信这一点。是的。我觉得还有一个因素是，规模扩展的工作是作为Dario在OpenAI发起的安全团队的一部分进行的，因为我们认为预测人工智能趋势对于让我们认真对待它们，并认真对待安全问题非常重要。

**主持人Mark：**
没错。是的，我记得在英国的某个机场，我用GPT-2采样，用它来写假新闻文章，然后发给Dario，说，哦，这玩意儿真的有效，可能会产生巨大的政策影响。我记得Dario当时说了类似“是的”这样的话。但后来我们也在发布方面做了很多工作，这还挺疯狂的。

**Danielle：** 是的，我记得发布的事情。我想那是我们第一次开始一起工作的时候。那是一段快乐的时光。

**主持人Mark：**
是的，我觉得这对我们来说是件好事，因为我们一起做了一些有点奇怪的、以安全为导向的事情。然后我们最终做了Anthropic，这是一个更大、也稍微有点奇怪的、以安全为导向的事情。

**汤姆·布朗：**
所以我想回到具体的问题，因为我记得，我大概在2016年加入了OpenAI，是和Dario一起加入的最早的20名员工之一。我记得当时，人工智能安全方面的具体问题似乎是第一篇主流的人工智能安全论文。我想我从来没问过你那是怎么来的。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dC5GLD58skU91uOq5xynpkibwMl2uP5NH5OGNNou60T24IY5Hav5HcjQ/640?wx_fmt=jpeg&from=appmsg)

**达里奥·阿莫迪：**
Chris知道这个故事，因为他也参与其中。我觉得，你知道，我们当时都在谷歌。我忘了我当时在做哪个项目。但和许多事情一样，这只是我试图从我正在做的其他项目（我现在完全忘了是什么项目）中拖延出来的产物。我觉得当时Chris和我决定写下关于人工智能安全的一些开放问题。而且，人工智能安全通常是以一种非常抽象的方式讨论的。我们能否把它与当时正在进行的机器学习联系起来？我的意思是，现在已经有六七年的研究了。但在当时，这几乎是一个奇怪的想法。

**克里斯：**
是的，我觉得在某种程度上，这几乎是一个政治项目，因为当时很多人并不认真对待安全问题。所以我认为当时的目标是整理一份问题清单，这些问题大家普遍认为合理，而且往往已经存在于文献中，然后让来自不同机构的、有信誉的人成为作者。我记得我当时花了很长时间和谷歌大脑的20位不同的研究人员交谈，以争取对发表这篇论文的支持。在某种程度上，如果你从问题的角度来看，以及它强调的许多事情，我觉得它并没有很好地站住脚，也就是说，我觉得这并不是真正正确的问题。但如果你把它看作是一种建立共识的尝试，认为这里存在一些真实的东西，值得认真对待，那么它就是一个相当重要的时刻。

**主持人Mark：**
我的意思是，你最终会进入一个非常奇怪的科幻世界，我记得在Anthropic刚开始的时候，我们谈论的是宪法人工智能。我记得Jared说过，哦，我们要为语言模型写一部宪法，这会改变它的所有行为。我记得这听起来非常疯狂。但你们当时为什么认为这会起作用呢？因为我记得那是我们公司最早的重大研究想法之一。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33d2PjvprRa1x8GvhNWvmt3UBI2PqdnQ847ibHsMC6p9Pxn0JjqOm5YdNg/640?wx_fmt=jpeg&from=appmsg)

**Jared：**
是啊，我觉得达里奥和我早就讨论过这个问题。我认为在人工智能领域，简单的方法往往非常有效。我觉得最初的版本相当复杂，但后来我们逐渐简化，只利用了人工智能系统擅长解决选择题的特性，给它们一个提示，告诉它们要寻找什么。这正是我们需要的。然后我们就能直接写下这些原则。

**达里奥·阿莫迪：**
我的意思是，这又回到了大量计算力、苦涩的教训或规模化假设。如果你能找到一些你可以给人工智能提供数据的东西，并且有一个明确的目标，你就能让它做到。比如，这里有一组指令，这里有一组原则。人工智能语言模型可以读取这组原则，并将其与它们自身的行为进行比较。所以，你的训练目标就在那里。一旦你明白这一点，我认为我和贾里德的观点是，总有办法让它起作用。你只需要调整足够多的细节。

**Jared：**
是啊。我觉得对我来说，尤其是在早期，总是很奇怪，因为我之前是搞物理的。现在我们可能都忘了这一点，因为每个人都对人工智能感到兴奋。但我记得和达里奥讨论过具体的问题以及其他事情。我感觉人工智能研究人员在人工智能寒冬时期受到了严重的心理创伤，他们觉得有雄心壮志的想法或愿景是被禁止的。我觉得这就像讨论安全问题的情况一样。为了关心安全，你必须相信人工智能系统实际上可能非常强大和有用。我认为当时人们有一种禁止有雄心壮志的氛围。我认为好处之一是，物理学家非常自大，所以他们总是做一些非常有雄心壮志的事情，并从宏大的角度来谈论事情。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33d9JJjMtTntibBLVT1BGvkAcCwP71T22LCcn3zr5Yxs3iaVsJY2uQBIyFQ/640?wx_fmt=jpeg&from=appmsg)

**达里奥·阿莫迪：**
我的意思是，我绝对同意这一点。比如，我记得在2014年，有些话就是不能说，对吧？但我认为这实际上是除了理论物理学之外，整个学术界都存在的问题的延伸，由于多种原因，他们已经演变成非常规避风险的机构。甚至人工智能的工业领域也移植或照搬了这种心态。我认为直到2022年才摆脱这种心态。

**克里斯：**
关于什么是保守和尊重，存在一种奇怪的现象。你可能会认为，保守的一个版本是认真对待你正在做的事情的风险或潜在危害，并对此感到担忧。但另一种保守则认为，过分认真对待一个想法并相信它可能会成功，是一种科学上的傲慢。所以我认为存在两种不同的保守或谨慎。我认为我们当时正处于那种受后者控制的状态。我的意思是，你可以从历史上看到它，对吧？比如，如果你看看1939年参与核物理研究的人们早期关于核弹是否是一个严重问题的讨论，你会发现费米也存在同样的情况，他抵制这些想法，因为它看起来有点疯狂。而像齐拉德或泰勒这样的人则认真对待这些想法，因为他们担心风险。

**达里奥·阿莫迪：**
**过去十年里我学到的最深刻的教训，可能你们也都以某种形式学到过，那就是可能存在这种看似一致的共识，一些每个人都知道的事情，似乎很明智，似乎是常识，但实际上它们只是伪装成成熟和世故的群体行为。**
而当你看到这种共识一夜之间发生改变时，你会怀疑，但你并没有真正下注。你会想，哦，天哪，我好像也这么想过，但你知道什么？我怎么可能正确而所有人都错了呢？当你看到这种情况发生几次之后，你就会开始说，不，这就是我们要下的赌注。我不能确定我们是否正确，但先忽略所有其他的事情，看看它会发生什么。而且，即使你只有50%的正确率，50%的正确率也贡献巨大，对吧？你增加了许多其他人没有增加的东西。

**主持人Mark：**
感觉我们现在在某些安全问题上就处于这种状态，存在一种共识，认为很多安全问题都很不寻常，或者不是技术自然产生的。而在Anthropic，我们所做的所有研究都表明，奇怪的安全对齐问题是我们在构建技术时自然而然产生的。所以感觉我们现在正处于这种反共识的观点中。

**Danielle：**
但我觉得在过去，哪怕只是过去18个月，这种情况一直在转变。我们一直在帮助转变。我们肯定是的。我知道。通过发表文章和进行研究。持续地推动。但我认为，仅仅是世界对人工智能的态度就发生了巨大的转变。而且，在我们进行的用户研究中，更常见的是听到客户，普通人说，我真的很担心人工智能对世界更广泛的影响。有时这意味着工作、偏见或毒性，但有时也意味着，这会不会把世界搞砸了？这会如何根本上改变人类合作和运作的方式？我其实没预测到这一点。

**Jared：** 不知何故，似乎机器学习研究领域的人们一直比公众更悲观地看待人工智能变得非常强大。

**Danielle：** 也许这是一种奇怪的谦逊或者其他什么。

**主持人Mark：**
我记得在2014年，我当时还是个记者，为了发表关于ImageNet结果随时间变化的图表，我做了很多图表，当时人们都觉得我疯了。然后我记得在2015年，我试图说服彭博社让我写一篇关于英伟达的报道，因为每篇人工智能研究论文都开始提到使用GPU。他们说这完全是疯了。然后在2016年，当我离开新闻界进入人工智能领域时，我收到了这些邮件说，你正在犯人生中最大的错误，我现在偶尔还会回看这些邮件。但这就像，从很多角度来看，当时认真对待这件事，认为规模化会奏效，以及这个技术范式可能有所不同，都显得很疯狂。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33ddtLKNr3oTCEODKLibHKKVEu3E4IibiacAT45Q9J4aWFLZD2LxJzOhMlmg/640?wx_fmt=jpeg&from=appmsg)

**Danielle：** 你就像迈克尔·乔丹，而那些不相信他的高中教练。

**Jared：** 不过，你实际上是怎么做出决定的？你感到犹豫不决，还是觉得很明显？

**主持人Mark：**
我做了一个疯狂的反向赌注，我说，让我成为你们的全职人工智能记者，并把我的工资翻倍，我知道他们不会同意的。然后我睡了一觉，醒来后就辞职了。一切都相当轻松。

**Jared：** 你真是个果断的人。

**主持人Mark：**
在那件事上，我确实很果断。我想是因为我当时每天都在工作，阅读档案论文，然后打印出来，回家继续阅读，包括达里奥在百度时期的论文，我意识到这里正在发生一些完全疯狂的事情。在某个时刻，我觉得你应该坚定地押注，我认为这里的每个人在职业生涯中都做过这件事，就是坚定地押注这件事会成功。

**汤姆·布朗：** 我肯定没有你那么果断。我花了大概六个月的时间，像是在反复横跳，我一直在想，我应该做这件事吗？我应该尝试创业吗？我应该尝试做这件事吗？

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dYrMgZpoibrejjobpV9ZmMXlMpuCjwf5ORGd4uIV4oNeSMCg0pe2dovg/640?wx_fmt=jpeg&from=appmsg)

**Danielle：**
但我也觉得，在当时，关于工程师以及工程师在人工智能领域可能产生的影响的讨论并不多，对吧？现在这对我们来说很自然，而且我们对各种类型的工程师都有同样的渴求。但在当时，感觉只有研究人员才能从事人工智能工作。所以我认为你花时间考虑这些问题是很正常的。

**汤姆·布朗：**
是的，是的。我认为这基本上也是我加入OpenAI的原因。我给那里的人发了消息，他们说，是的，我们实际上认为你可以通过做工程工作来提供帮助。是的，你可以用这种方式来帮助人工智能安全，我认为当时还没有这样的机会。这就是我加入的原因。没错，你是我在OpenAI的经理。没错，我想我是在你加入一段时间后才加入的。稍微晚一点。我曾在Brain（谷歌大脑）待过一段时间。是的。我不知道我有没有问过你，是什么让你加入的？

**Danielle：**
是的，我在Stripe工作了大约五年半，我认识格雷格。他曾经是我在Stripe的老板。实际上是我把他介绍给了达里奥，因为我提到当他开始创建OpenAI时，我认识的最聪明的人是达里奥。我觉得他能得到达里奥会很幸运。达里奥当时在OpenAI，而且我有一些在Stripe的朋友也去了那里。

像你一样，我一直在思考在Stripe之后我想做什么。我在Stripe是为了在非营利组织和国际发展领域工作后获得更多技能。最初，我以为我会回到这些领域，因为从根本上来说，我一直想帮助那些不如我的人。然而，在我当时参与这些领域的时候，我没有足够的技能来产生重大影响。我考虑过回到公共卫生领域，并短暂地研究过政治，但我也在探索其他科技公司和产生影响的方式。

在这次探索中，OpenAI感觉就像我的兴趣的完美结合点。它是一个拥有远大崇高使命的非营利组织，我真的相信人工智能的潜力。对达里奥有一些了解，我知道他们需要管理方面的帮助——他们绝对需要，这是事实。它在某种程度上感觉“为我量身定做”，这与我的愿望产生了共鸣。我看到一个非营利组织与有才华、有良好意图的人一起工作，但看起来他们有点组织混乱。这对我来说是一个令人兴奋的帮助机会。

我把自己看作OpenAI的多面手。我管理着人力运营，同时也管理着一些技术团队。例如，我参与了规模化和语言团队的工作，并与克里斯一起解决了一些政策问题。我感受到OpenAI员工身上散发着巨大的善意，我非常渴望为让公司运转得更好做出贡献。

**主持人Mark：** 我记得在GPT-3完成之后，你就像在说，你们听说过“信任与安全”这个东西吗？是的。

**Danielle：**
我说，你知道，我以前在Stripe管理过一些信任与安全团队。有一种叫做信任与安全的东西，你可能要考虑一下这种技术。这很有趣，因为它有点像是人工智能安全研究的中间步骤，对吧？也就是，你如何才能真正使模型变得安全，而不仅仅是更实用？我认为，说“这将是一件大事”是有价值的。我们也必须每天做这种实际的工作，为当事情变得更加重要时做好准备。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33do0Q3yJFNgxFicPpg0RAUvR76UkptkADUEtVY5JOaDArMFT7gAnKNcfg/640?wx_fmt=jpeg&from=appmsg)

**主持人Mark：**
这也许是一个很好的过渡点，可以谈谈像“负责任的规模化政策”之类的东西，以及我们是如何提出它的，或者我们为什么要提出它，以及我们现在是如何使用它的，特别是考虑到我们今天在模型上做了多少信任与安全方面的工作。那么，是谁提出的RSP（负责任的规模化政策）？

**达里奥·阿莫迪：**
是的，我和保罗在2022年末首次谈到了这个问题。最初，讨论的中心是我们是否应该在达到某个特定点时停止扩大规模，直到我们找到解决某些安全问题的方法。然而，在某个单一的点上停止扩大规模，然后再将其解除，感觉很奇怪。这让我们想到了建立多个阈值的想法；在每个阈值，我们需要进行某些测试来评估模型的能力，并实施越来越多的安全和保障措施。

最初，我们有了这个想法，然后我们认为，如果由第三方来执行会更好。我们的结论是，它不应该只来自一家公司，因为这可能会降低其他公司采用这种方法的可能性。因此，保罗离开了，设计了这个方法，并在过程中进行了许多更改。当我们在努力弄清楚它应该如何运作的时候，保罗在设计方面取得了进展。

一旦保罗有了成果，他就宣布了这个概念，不久之后，我们在一两个月内发布了我们的公告。我们很多人都深入参与了这个过程；我记得我自己至少写过一份草稿，但总共有很多份草稿。这种协作努力意味着，当我们完善我们的想法时，文件的迭代次数非常多。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dFh7ge7bibJAAezYRkuOIGue3uMGZicNL58yibR6rB58FDEqictfJh5RrQA/640?wx_fmt=jpeg&from=appmsg)

**Jared：** 我认为它已经经历了一轮。

**汤姆·布朗：**
这是所有文档中草稿最多的一个。这很合理，对吧？我觉得它就像美国对待宪法那样，把它视为神圣的文件。是的，我认为这很大程度上增强了美国的力量。是的，我们不认为美国会偏离轨道，部分原因是美国每个人都认为宪法至关重要，如果你践踏它，我就会生气。是的，我觉得RSP就像是我们的基石，它对于Anthropic来说就像是神圣的文件。所以，值得进行大量的迭代。

**Danielle：**
我觉得在Aetheropic观察RSP的开发过程很酷的一点是，它经历了如此多不同的阶段，而且需要许多不同的技能才能使其发挥作用。这里有宏大的想法，我觉得Dario、Paul、Sam和Jared等等很多人都在思考：原则是什么？我们想表达什么？我们如何知道自己是对的？

但也有非常实际的操作方法，就是不断迭代。比如，我们原以为在某个安全级别会看到某种结果，但实际上没有。那么，我们是否应该做出调整，以确保我们能够履行自己的责任？然后，还有各种组织上的事情，对吧？比如，我们直接决定改变RSP组织的结构，以实现更清晰的责任划分。

我认为对于像这样重要的文件，就像宪法一样（我喜欢这个宪法的类比），美国存在各种机构和系统来确保我们遵守宪法，对吧？有法院、最高法院、总统、国会两院。当然，他们也做其他各种事情，但围绕着这一份文件，你需要所有这些基础设施。我觉得我们在这里也正在学习这个道理。

**Jared：**
我觉得这反映了我们很多人对安全的看法，即安全是一个可解决的问题。只是一个非常非常困难的问题，需要大量的努力。我们需要建立所有这些机构，就像围绕汽车安全建立的各种机构，这些机构都是经过多年建立起来的。但问题是，我们有时间这样做吗？我们必须尽快弄清楚人工智能安全所需的机构是什么，并建立这些机构，并尝试首先在这里建立，但要使其可导出。没错。

**达里奥·阿莫迪：**
它也迫使团结，因为如果组织的任何部分不符合我们的安全价值观，都会通过RSP表现出来。RSP会阻止他们做他们想做的事情。因此，这是一种不断提醒每个人的方式，基本上是使安全成为产品需求，成为产品规划过程的一部分。因此，它不仅仅是我们重复的一堆陈词滥调。如果你来到这里并且不认同，你实际上会遇到它。然后你要么学会适应这个计划，要么就无法成功。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dll3mEJRgaMZcmWlmFHCw4kNaTHD7LwvicjMnQLJzZVcoiaROL48k6VWg/640?wx_fmt=jpeg&from=appmsg)

**主持人Mark：**
RSP随着时间的推移变得有点可笑了，因为我们花了数千小时在这个上面。然后我去和参议员们谈话，我解释RSP。我说，我们有一些东西可以防止我们的成果被盗，而且是安全的。他们会说，是的，这是很正常的事情。你是说不是每个人都这样做吗？然后我就说，哦，好吧。

**达里奥·阿莫迪：** 是的。事实上，不是每个人都这样做。

**主持人Mark：** 每个人都这样做。这很惊人，因为我们在这里投入了如此多的精力。但当你把它精简一下，他们会说，是的，听起来是很正常的做法。

**Jared：** 是的，听起来不错。这就是我们的目标。就像Daniella所说，让这件事变得乏味且正常。

**Danielle：** 就像，让它成为一件财务方面的事情。

**达里奥·阿莫迪：** 就像审计一样。是的，是的，乏味和正常才是我们想要的。

**Danielle：**
当然，事后来看是这样。嗯，Dario，我认为除了推动统一之外，它还推动了清晰，因为它确实把我们想做的事情写了下来。而且，公司里的每个人都能看懂。从安全的角度来看，我们认为我们应该追求的目标，外部也可以理解。这并不完美。我们正在不断迭代，使其变得更好。但我认为，明确说出我们担心的事情是有价值的。比如，你不能用安全这个词来随意阻挠事情，无论是哪个方向。不能说，哦，因为安全，我们不能做X，或者因为安全，我们必须做X。我们真的想弄清楚我们的意思是什么。

**达里奥·阿莫迪：**
是的，它阻止你担心所有鸡毛蒜皮的小事。没错。因为实际上，长期来看，临时抱佛脚会损害安全事业。我说过，如果一栋楼每周都拉响火警警报，那这栋楼其实很危险，因为当真的发生火灾时，你只会觉得，哦，它总是响。所以校准非常重要。

**克里斯：**
我发现一种略微不同的视角可以澄清这个问题，那就是我认为RSP在很多层面都创造了健康的激励机制。我认为在内部，它使每个团队的激励与安全保持一致，因为这意味着如果我们不在安全方面取得进展，我们将受阻。我还认为，在外部，它创造了比其他可能性更健康的激励机制，至少在我看来是这样。因为它意味着，如果我们必须在某个时候采取某种戏剧性的行动，比如，如果我们必须在某个时候说，我们的模型已经到达某个点，而我们还不能使模型安全，那么它会与支持该决定的证据相一致。并且存在一个预先存在的框架来思考这个问题，而且它是清晰的。所以，我认为RSP在很多层面，以我最初讨论早期版本时可能没有理解的方式，它创建了一个比我所考虑过的任何其他框架都更好的框架。

**Jared：**
我认为这一切都是真的，但我觉得这低估了弄清楚正确的政策和评估，以及界限应该在哪里有多么具有挑战性。我认为我们在这一点上已经并继续进行了大量的迭代。还有一个难题，即什么时候非常清楚某件事情是危险的还是安全的。对于一些如此新的技术，实际上存在很大的灰色地带。

我认为这些灰色地带是我最初对RSP感到非常兴奋的原因之一，现在仍然如此。然而，以清晰的方式实施它并使其发挥作用，已经被证明比我预期的要困难得多，也复杂得多。

是的，我认为这正是重点。灰色地带是无法预测的，而且有很多。在你真正尝试实施所有事情之前，你不知道会出什么问题。所以我们正在努力实施所有事情，这样我们就可以尽早看到可能会出现什么问题。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dXWVjs90IvFm9T6Mk5Cm7kE2YiamBwTfg9qAGyMia3bic1URmp4Oc3LsSA/640?wx_fmt=jpeg&from=appmsg)

**达里奥·阿莫迪：**
是的，你得做三到四次迭代才能真正把它做好。迭代是非常强大的，你不可能第一次就做对。所以，如果风险越来越高，你最好尽早开始迭代，而不是拖到最后。

**主持人Mark：** 你同时也在建立内部的制度和流程。所以具体细节可能会经常变化，但建立起做事的肌肉记忆是非常有价值的。

**汤姆·布朗：** 我在 Anthropic
负责计算。这很重要。谢谢。我认为对我来说，我们必须和外部人士打交道。不同的外部人士对事情的发展速度有不同的看法。我认为这也是一个我最初认为事情不会那么快，但随着时间的推移而改变了想法的事情。我对此深有体会。所以我认为
RSP（风险评估计划）对我和那些认为事情可能需要更长时间的人进行沟通非常有用，因为这样我们就有了一个可以依据的标准，比如我们不需要采取极端的安全措施，直到情况变得非常紧张。然后我们就可以说，他们可能会认为事情不会在很长一段时间内变得紧张。然后我会说，好吧，是的，我们不需要采取极端的安全措施。所以这使得与其他人的沟通变得容易得多。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dwCsas8weBJUdVeuy2t6nBVj55ibUgyia4GXyroja01bORYCdMUHIUmJA/640?wx_fmt=jpeg&from=appmsg)

**主持人Mark：** 是的，这让它变成了一个你可以正常讨论的事情，而不是什么奇怪的东西。是的。它还以其他什么方式在人们身上体现呢？

**Jared：**
评估！很好。一切都与评估有关。每个人都在做评估。比如，你的训练团队一直在做评估。我们试图弄清楚，这个模型是否已经足够好，以至于有可能变得危险？我们有多少个评估团队？你有前沿红队。

**Danielle：** 基本上每个团队都会产出评估结果。这意味着你只是在根据 RSP 进行衡量。比如，衡量某些会让你担忧或不担忧的迹象。

**Jared：**
没错。很容易为模型的能力设定下限，但很难设定上限。所以我们投入了大量的研究精力来说，这个模型能不能做这种危险的事情，或者不能？也许有一些我们没有想到的技巧，比如思维链或者最佳事件，或者某种工具的使用，可以帮助它做一些非常危险的事情。

**主持人Mark：**
它在政策制定方面非常有用，因为安全一直是一个非常抽象的概念。当我表示我们有一个评估会影响模型的部署与否时，然后你可以和政策制定者或国家安全领域的专家，或者我们从事的某些生化武器领域（CBRN）的专家进行校准，来帮助我们建立校准良好的评估。如果不是这样，这一切就不会发生。但一旦你有了具体的东西，人们就更有动力帮助你使其准确。所以在这方面它很有用。是的。

**Danielle：** RSP 对我来说肯定适用。所有事情吗？经常适用。 我实际上认为，奇怪的是，我对 RSP
的思考方式，更多地是关于它的语调——就像它听起来的那样。我认为我们刚刚对 RSP
的语调进行了大规模的改写，因为它感觉过于技术官僚，甚至有点对抗性。我花了很多时间思考如何建立一个人们都想参与的系统。

如果 RSP 像 OKR 一样，可以被公司里的每个人随意讨论，那会好得多。例如，RSP 的首要目标是什么？我们如何知道我们是否达到了这些目标？我们现在的
AI 安全级别是多少？我们处于 ASL2 吗？还是 ASL3？
重要的是，人们要知道要关注什么，因为这才能让你对事情是否出错有良好的共识。如果它过于技术官僚，只有公司里的某些人才能接触到，它的效率就会降低。

我认为看到它转变成一个文件，我相信公司里的大部分人，如果不是全部，无论他们的职位如何，都可以阅读并说：“这感觉很合理”，这真的很酷。
我想确保我们以以下方式构建人工智能。我也能理解我为什么会担心这些事情，并且知道如果遇到问题该关注什么。这几乎就像把它变得足够简单，如果你在一家制造工厂工作，注意到安全带应该以某种方式连接，但它没有，你就能发现它。

领导层、董事会和公司其他成员（包括实际构建它的人）之间应该有健康的反馈流程。我真的相信，大多数情况下，事情出错只是因为线路没有连接或者交叉了。如果事情以这种方式出错，那将是非常可悲的。
最终，这一切都是关于使其运作起来，并让人们容易理解。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dTWOwULobxAsdzqC7qo4iadSwsDaLsgrktUthgByDI9T2ZYEo0TBhR6w/640?wx_fmt=jpeg&from=appmsg)

**Jared：** 是的，我想说的是，我们谁都不想创办公司。我们觉得这是我们的责任，对吧？ 我觉得我们必须这样做。就像，我们必须做这件事。这是我们让 AI
发展得更好的方式。就像，这也是我们做出承诺的原因，对吧？因为我们觉得，我们做这件事的原因是感觉是我们的责任。

**达里奥·阿莫迪：** 我希望以某种有益的方式发明和发现事物。这就是我开始做这件事的方式。这导致我开始研究 AI。AI 需要大量的工程技术。最终，AI
需要大量的资本。但我发现，如果你不以一种设置环境的方式来做这件事，如果你不建立这样的公司，那么很多事情都会重复发生，重复我在科技界发现的那些令人疏远的错误。还是那些人，还是同样的态度，还是同样的模式匹配。所以，在某个时候，我们以不同的方式来做这件事似乎是不可避免的。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dMibiahXRlo8eoslZdiamwlFYu7wb3Aw05GNadL08QybUlibRNppwIfXPRg/640?wx_fmt=jpeg&from=appmsg)

**Jared：**
当我们在研究生院的时候，我记得你有一个完整的计划，试图找出如何以一种能够促进公共利益的方式进行科学研究。我认为这和我们现在的想法很相似。也许你有一个
“Vannevar 项目” 之类的来做这件事。我曾经是一名教授，我审视了当时的情况，并确信 AI 在影响方面正处于一个非常非常陡峭的轨迹上。

似乎是因为对资本的需求，作为一名物理学教授，我无法继续这样做。我有点想和信任的人一起建立一个机构，努力使 AI
发展良好。然而，我永远不会建议创办一家公司，或者真的想这样做。

我的意思是，我认为这只是一种实现目标的手段。通常情况下，事情就是这样顺利发展的。如果你做某事只是为了让自己变得富有或获得权力，你必须真正关心在世界上实现一个真正的目标，然后你会找到你必须使用的任何手段。

**Danielle：**
嗯，我经常思考的一个问题是，我们拥有的一个战略优势，我觉得说出来可能有点好笑，但它确实就是我们团队之间的高度信任，对吧？我的意思是，Tom，你在其他初创公司待过。我以前从来没有做过创始人，但要让一大群人拥有相同的使命，实际上是非常困难的。我觉得在Anthropic工作时，我最开心、也最自豪的事情，是这种信任已经扩展到了很多人。我觉得在这个团队里，和整个领导层，每个人都是为了这个使命而来。而且我们的使命非常清晰，非常纯粹。我觉得这是我在科技行业不太常见的事情，正如Dario所说的那样。我们所做的事情有一种内在的纯洁性。就像，我同意，我们都不是抱着“让我们去创办一家公司”的心态。我们觉得我们必须这样做，对吧？感觉就像我们不能再继续在之前的地方做之前做的事情了。我们必须自己来做。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dQMJXRIwiczusvSQpd44yz1cP7BGYicP9xVOFbSqALibd16SJDRWhqaTFQ/640?wx_fmt=jpeg&from=appmsg)

**主持人Mark：**
我觉得，就像GPT-3，我们所有人都接触过或者参与过相关的工作，以及缩放定律等等，我们在2020年就看到了它摆在眼前。感觉就像，如果我们不尽快一起做点什么，就会到达无法回头的地步。我们必须做点什么，才能有能力改变环境。

**汤姆·布朗：**
我想接Danielle的话，我确实觉得这个团队之间有很多信任。我觉得我们每个人都知道，我们加入这里是因为我们想帮助这个世界。是的，我们做了那个80%的捐赠承诺，当时大家都很自然地表示“是的，我们肯定会这么做”。这是，是的，我确实认为信任是非常特别的，

**Jared：**
非常罕见的。是的。我感谢Danielle一直保持着高标准。我感谢你使我们能够扩展规模。把那些小丑排除在外。把小丑排除在外。你是文化形成的原因。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dFuhfPfgn0xEfUmuGnI3tpIPweoJpTUaOHZRyMxcEfhWGRPzNHwDlfA/640?wx_fmt=jpeg&from=appmsg)

**主持人Mark：** 我想。人们说这里的人都很好，这实际上是非常重要的一点。

**Danielle：**
我觉得Anthropic的政治氛围非常淡。当然，我们所有人的视角都和普通人不同，我总是提醒自己这一点。这是因为我们都比较谦逊。而且，我确实觉得我们的面试流程，以及在这里工作的人的类型，都对政治有一种近乎过敏的反应。

**达里奥·阿莫迪：**
还有团结。团结非常重要。产品团队、研究团队、信任与安全团队，还有市场团队、政策团队、安全团队，他们都在努力为公司同一个目标、同一个使命做出贡献，对吧？我觉得如果公司不同部门认为他们在做不同的事情，或者认为公司是为了不同的目标，或者认为其他部门试图破坏他们正在做的事情，那就很不正常了。我觉得我们设法保留的最重要的事情，而且像RSP这样的事情也在推动它，就是这种理念，不是公司的一部分在造成损害，另一部分在试图修复它，而是公司不同的部门在做不同的事情，但他们都在一个单一的变革理论下运作。极其务实。

**克里斯：**
是的。你知道，我一开始去OpenAI的原因，是因为它是一个非营利组织。在那里，我可以专注于安全。我觉得随着时间的推移，这可能不太适合。并且有一些艰难的决定。我觉得在很多方面，我非常信任Dario和Danielle的决定。但我不想离开。我觉得我实际上是非常不愿意接受这件事的，因为首先，我不确定有更多的AI实验室对世界来说是好事。我觉得我对此非常不情愿。而且，当我们离开的时候，我觉得我也很不愿意创办一家公司。我觉得我一直主张我们应该建立一个非营利组织，专注于安全研究。我觉得正是实用主义，以及面对限制，并诚实地面对限制对实现使命的影响，才促成了Anthropic的诞生。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dNGNvSvOeaMpKuEfzsDEkmeDJSakIpcgnUOVtGLrJH5ju0WHia4myTAw/640?wx_fmt=jpeg&from=appmsg)

**达里奥·阿莫迪：** 我觉得我们早期做对的一件非常重要的事情就是少做承诺，多去实现。努力校准，保持现实，面对权衡，因为信任和信誉比任何特定的政策都重要。

**Danielle：** 我们拥有的东西非常不寻常。看到Mike
Krieger为了安全原因而辩护，说我们不应该推出某个产品，但同时也看到Vinay说，“好吧，我们必须为业务做正确的事情。我们如何才能完成这个目标？”听到技术安全部门的同事深入讨论构建对人们实用的产品也很重要，以及听到推理工程师讨论安全，这真是太棒了。我觉得这是我们在这里工作最特别的事情之一，每个人都以这种团结一致的方式，优先考虑实用主义、安全和业务。这太不可思议了。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dqEu6KpIoaavTUcMEyJ9aW6icyiaLqNv7QNV9upkkJiaardGrBsscricB4Q/640?wx_fmt=jpeg&from=appmsg)

**达里奥·阿莫迪：**
我认为这是将权衡从公司领导层扩展到每个人的过程，对吧？我认为不正常的情况是，你有一群人只看到一个大方向，在这个方向上，安全是我们必须始终优先考虑的事情，而产品是我们必须始终推动的事情，而研究被认为是唯一我们关心的东西。然后你被困在顶层，必须在这些相互竞争的利益之间做出决定，而你拥有的信息却不如他们任何一方多。那是不正常的情况。

另一方面，正常的情况是，当你可以向每个人传达我们都在共同面对权衡时。世界远非完美，我们所做的一切都存在权衡。我们所做的每一件事都是为了尽可能地兼顾两个方面，但它并不总是像我们想象的那样顺利。

在一个正常的环境中，每个人都对共同面对这些权衡达成共识。他们觉得自己正在从他们独特的视角和角色来应对这些挑战，作为集体责任的一部分，为应对这些权衡的整个过程做出贡献。

**Jared：** 这是一场登顶之战，对吧？这是一场登顶之战。这并非纯粹的上行赌注。事情可能会出错。但是，我们都一致认为，这就是我们正在下的赌注。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33d4Kr6UGRiaKuD5DJzW1PoiaJDd4D4QGocGRUDibS5bfaOuHnuuaL45uyHA/640?wx_fmt=jpeg&from=appmsg)

**主持人Mark：** 而且市场是务实的。所以，Anthrop
作为一家公司越成功，人们就越有动力去复制那些使我们成功的东西。而且，这种成功越是与我们所做的实际安全措施紧密相连，就越会在行业中产生一种引力，促使整个行业进行竞争。这就像，当然，我们会制造安全带，其他人可以复制它们。这很好。这是一种善意。

**达里奥·阿莫迪：**
是的，这就是一场争先恐后的竞赛，对吧？但是，如果你说，我们不打算开发这项技术，你不会比其他人做得更好，那么最终，这是行不通的，因为你没有证明从这里到那里是可能的。

世界需要达到的目标，不仅仅是行业，不仅仅是一家公司，而是需要成功地从“这项技术不存在”过渡到“这项技术以非常强大的方式存在，并且社会已经成功地管理了它”。我认为唯一能实现这一点的方法是，在一家公司的层面，并最终在行业层面，你实际上要面对这些权衡取舍。

你必须找到一种方法，在某些情况下既能保持竞争力，又能真正引领行业，同时还能安全地做事。如果你能做到这一点，你施加的引力就非常巨大。从监管环境到想要在不同地方工作的人，甚至有时客户的看法，都有很多因素驱动着这个方向：如果你能证明你在安全方面做得很好，而又不牺牲竞争力，对吧？

如果你能找到这种双赢的局面，那么其他人也会受到激励去做这件事。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dblZ3kSpypq4Bqic3eUj6l4SjPeibXPpZc8p0ZbiatWTT1hq8jy5alkVQQ/640?wx_fmt=jpeg&from=appmsg)

**Jared：** 是的，我的意思是，我认为这就是为什么把诸如 RSP（此处疑似为缩写，可能指代某种安全标准，保留原文）
之类的东西做对非常重要的原因，因为我认为我们自己，在看到技术的发展方向时，经常会想，哇，我们必须对这件事非常小心。但与此同时，我们必须更加小心，不要发出狼来了的警告，说创新需要在这里停止。我们需要找到一种方法，让
AI
对客户来说有用、创新、令人愉快，但也要弄清楚我们能够坚持的真正约束是什么，这些约束可以使系统安全，这样其他人也会认为他们也能做到，他们可以与我们竞争。我们不是末日论者，对吧？我们想创造积极的东西。我们想创造好的东西。

**达里奥·阿莫迪：** 而且我们已经在实践中看到了这一点。在我们推出 RSP
的几个月后，三家最杰出的人工智能公司都有了一个，对吧？可解释性研究，那是我们做过的另一个领域。只是对安全性的整体关注，比如与人工智能安全研究所的合作。

**主持人Mark：** 是的，前沿红队几乎立即被复制了，这很好。你希望所有实验室都测试非常非常可怕的风险。输出安全带的标志。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dcznx4e8GkPoibG0l3HBIAlMSj3ED6QNUCtDNZXg2I51derWEDGCiavwg/640?wx_fmt=jpeg&from=appmsg)

**Danielle：** 所以，是的，输出安全带。好吧，Jack
早些时候也提到了，但客户也非常关心安全，对吧？客户不希望模型出现幻觉。他们不希望模型容易被破解。他们想要有帮助且无害的模型，对吧？因此，我们在客户电话中经常听到的是，我们选择
Claude
是因为我们知道它更安全。我认为这也是一个巨大的市场影响，对吧？因为我们拥有值得信赖和可靠的模型的能力，这对竞争对手也产生了巨大的市场压力。谢谢。

**克里斯：**
我需要进一步解读一下达里奥所说的一些内容。我认为有一种说法或想法，也许高尚的事情是几乎会高尚地失败，对吧？就像你应该去追求安全，你应该去做某些事情，你应该以一种不切实际的方式来证明你对事业的纯洁性，或者类似的事情。

我认为如果你这样做，实际上是非常适得其反的。首先，这意味着那些做出决定的人会是那些不关心安全、不优先考虑安全的人。

另一方面，如果你努力寻找方法来协调激励机制，并使其在有艰难决定时，发生在最有力量去支持做出正确艰难决定的地方，以及证据最多的地方，那么你就可以开始触发达里奥所描述的这场争先恐后的竞赛。不是让关心的人被排斥在影响力之外，而是拉动其他人去追随。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dGKHsQwzQjiacuZlX4qtRibmTEcOVCVWDvzf7oqiaia03js736Vu8LXNlEw/640?wx_fmt=jpeg&from=appmsg)

**主持人Mark：** 那么，当谈到我们接下来要做的项目时，你们都对什么感到兴奋？

**克里斯：**
我认为有很多理由让你对内部感到兴奋。**其中之一显然是安全。但还有另一个，我在情感层面觉得同样令人兴奋或同样有意义的事情，那就是我只是认为神经网络很美。我相信它们内部有很多我们看不到的美丽。**
我们把它们当作我们不特别感兴趣内部结构的黑盒子。

当你开始观察它们内部时，你会发现它们充满了惊人的、美丽的结构。这有点像如果人们看待生物学，然后想，“进化真的很无聊。”他们可能会认为这只是一个运行了很长时间的简单过程，然后产生了动物。事实上，进化产生的每一个动物都很复杂，就像优化一个神经网络一样。它们充满了令人难以置信的复杂性和结构。

此外，我们在神经网络内部有一个完整的人工生物学。如果你愿意观察它们的内部，你会发现所有这些惊人的东西都在等待被发现。我认为我们只是开始慢慢地解开它，这真是不可思议。那里有很多东西值得探索，但我们只是触及了表面。

有时我会想象，在十年后的未来，走进一家书店，买一本关于神经网络互操作性，或者更确切地说，关于神经网络生物学的教科书，以及其中将会包含的各种疯狂的事情。我真的相信，在未来十年，甚至在未来几年，我们将开始真正发现所有这些东西。这将是疯狂而不可思议的。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dvUlK4biakJOqfMVNM4Ubo3QSxmjs1750WDI531O2Z9rSqXVicILCQgiaA/640?wx_fmt=jpeg&from=appmsg)

**主持人Mark：**
你能够买自己的教科书也很棒。我很高兴，几年前，如果你说政府会设立新的机构来测试和评估人工智能系统，而且它们实际上会很称职和优秀，你不会认为情况会是这样。但它发生了。这有点像政府几乎建立了这些新的大使馆来处理这种新的技术或克里斯研究的这种东西。我很高兴看到它会发展到什么程度。我认为这实际上意味着我们有能力应对这种社会转型。所以，不仅仅是公司。我很高兴能为此提供帮助。

**Danielle：** 我今天在某种程度上已经对此感到兴奋了。
但我认为，仅仅是想象未来人工智能将能够为人们做些什么，就让人无法不感到兴奋。Dario经常谈到这一点。但我认为，即使是 Claude
能够帮助疫苗开发、癌症研究和生物研究的微光，都令人难以置信，就像能够看到它现在所能做的事情一样。但是，当我展望未来三年或五年时，想象着 Claude
实际上可以解决我们人类面临的许多根本问题，仅仅从健康角度来看，即使你把其他一切都排除在外，都让我感到非常兴奋。就像回想起我从事国际发展工作的时候，如果
Claude 能够负责帮助完成我当时 25 岁时试图做但效率不高的大量工作，那将是多么美妙。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33d4Zl5Cwz1RIgOK2ibImIsqLDYGCLYiaXXibRbhcmv4EZ6GzFjyJ9NvWSxg/640?wx_fmt=jpeg&from=appmsg)

**Jared：** 我也有类似的感觉，我很高兴能够为工作构建 Claude。 我很高兴将 Claude 融入公司，并融入世界各地的公司。

**汤姆·布朗：** 我想我很高兴，就我个人而言，我很喜欢使用 Claude。 确实，我花在家里的时间越来越多，比如，我会和 Claude
聊一些事情。我认为最近最大的变化是代码方面，比如，六个月前，我没有使用 Claude 做任何编码工作。我们的团队也没有真正使用 Claude
进行太多编码。而现在，情况已经完全不同了。我上上周在 YC 做了一个演讲。在开始的时候，我只是问了一下，比如，现在有多少人使用 Claude
进行编码？结果是 95% 的人都举起了手。房间里几乎所有人都举起了手，这与四个月前的情况完全不同。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMCksSYdWOYMjY0iaxA9j33dEF1FBhdXRl4Lcseay660zHLFj9rib4jSuTWSDnAYNiccbsxbESHsaqzA/640?wx_fmt=jpeg&from=appmsg)

**达里奥·阿莫迪：**
当我在思考我所兴奋的事情时，我会考虑那些似乎存在共识的地方——也就是大家普遍认为正确的事情——然后这种共识就会被打破。我特别感兴趣的是那些我认为转变即将发生但尚未发生的领域。其中一个领域是可解释性。我认为可解释性既是引导和构建安全人工智能系统的关键，我们也开始理解其全部意义。此外，可解释性还提供了对智能优化问题的见解，并阐明了人脑是如何运作的。

我说过，而且我真的不是在开玩笑，Chris Ola
将会成为未来的诺贝尔医学奖得主。我是认真的。作为一名神经科学家，我认识到许多我们尚未弄清的心理疾病，例如精神分裂症和情绪障碍，都涉及一些复杂的更高级别的系统交互。由于人脑如此复杂且难以分析，因此很难理解这些问题。神经网络虽然不是一个完美的类比，但随着时间的推移，它会变得更加完美。

与可解释性相关的第二个领域是人工智能在生物学中的应用。生物学是一个极其困难的问题，由于各种原因，人们对它与人工智能的交叉仍然持怀疑态度。然而，我认为这种怀疑正在开始消退。我们最近见证了
AlphaFold 获得了诺贝尔化学奖，这是一个了不起的成就。我们应该致力于创建可以产生 100 个 AlphaFold
的系统，从而增强我们在生物科学方面的理解和能力。

最后，我相信利用人工智能增强民主的潜力。我们经常担心，如果构建不当，人工智能可能会成为极权主义的工具。紧迫的问题是：人工智能如何才能成为自由和自决的工具？我认为与前两个领域相比，这方面仍处于早期阶段，但它在未来将同样重要。

**Jared：** 是的，我的意思是，至少有两件事与你之前说的话有关。我的意思是，一方面，我感觉人们加入 Anthropic
的原因往往是因为他们对人工智能的科学原理非常好奇，然后被人工智能的进步所说服，从而分享这样一种愿景，即不仅需要推进这项技术，还需要更深入地理解它，并确保它的安全性。但我觉得，与你一起工作的人，在他们对人工智能发展的愿景和与之相关的责任感方面，越来越团结一致，这实际上是令人兴奋的。

而且我觉得，由于去年发生了很多进步，就像 Tom
谈到的那样，这种情况已经发生了很多。另一方面，我的意思是，回到具体的现实问题，我觉得我们迄今为止在人工智能安全方面做了很多工作。其中很多都非常重要。但我觉得，随着最近的一些发展，我们真正开始瞥见非常先进的系统可能会带来的风险，这样我们就可以通过可解释性和其他安全机制直接调查和研究这些风险。

我认为我们真的可以理解非常先进的人工智能可能带来的风险是什么样的。而且我认为，这将真正使我们能够以一种非常深入的科学、经验主义的方式来推进这项使命。所以我对未来六个月如何利用我们对先进系统可能出错的理解来描述这些风险并找出如何避免这些陷阱感到兴奋。

**Danielle：** 完美。

**达里奥·阿莫迪：** 我们应该更频繁地这样做。这是我们唯一可以聚在一起的机会。

**关注公众号后设🌟标，掌握第一手AI新动态**

##  往期精选

  1. [黄仁勋专访：OpenAI在大模型混战中达到“逃逸速度”](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650001718&idx=1&sn=f8129a622e7611702be2cb23e8ce9418&chksm=88ba5831bfcdd127d06ce6492c821074407f805407b4182ca900916521cb5a4717f2a3d71ee8&token=1339625777&lang=zh_CN&scene=21#wechat_redirect)
  2. [李飞飞与Justin深度解读空间智能：数字世界需要三维表征，才能与现实世界融合](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000659&idx=1&sn=c71fb5b4ef501424dddd5e8b4dd5860e&chksm=88ba4414bfcdcd023c691a1adf75127a9fd883ceb305ca14cf97f719acaf999d40fa72f84bf3&token=1492077842&lang=zh_CN&scene=21#wechat_redirect)
  3. [PayPal创始人彼得·蒂尔：人类科技停滞源于原子方面的进展远慢于比特](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000240&idx=1&sn=26af6013981677b1e14137260857a6f0&chksm=88ba4277bfcdcb615d746615c262927bf51c43c920ed93fa36274ef87c6264d6548c84647121&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  4. [谷歌联合创始人布林：巨头们打造的“上帝模型”几乎可以理解一切](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=2&sn=0c714d804a72a52e002743d949e1685e&chksm=88ba40f9bfcdc9ef78749718480265922f4fba539abf6c9d62a6cd681f405dee9283d2429f84&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  5. [马斯克：AI将使商品和服务的成本趋近于零](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=1&sn=752f000a117a705e77950c82bfc4a004&chksm=88ba40f9bfcdc9ef5a5afe4a3ae73d5247bd54ed525dbdbedee1fcf74a6c082165e664a5c4d0&token=106920805&lang=zh_CN&poc_token=HDp86Waj18SFm2Y-xnv_Vqd_4J6emFoh10eH48wg&scene=21#wechat_redirect)
  6. [Karpathy最新专访：人形机器人、特斯拉、数据墙与合成数据](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999613&idx=1&sn=b8bdda7afe4c3ca08e324ac5bbd5a2bd&chksm=88ba41fabfcdc8ec0e21dbf4c7eb4d33252da70f47e1cfc9f5e113717911c417c2aebb3d6180&token=106920805&lang=zh_CN&scene=21#wechat_redirect)

  

