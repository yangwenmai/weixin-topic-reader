# 谷歌Astra项目主管韦恩深度揭秘：谷歌第一个能看、能听、拥有记忆和推理能力，还能多语言实时对话的通用AI助理

文章作者: 瓜哥AI新知
发布时间: 2024-12-23 07:31
发布地: 浙江
原文链接: http://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650006010&idx=2&sn=9ec8a1606c6e97828944f89560992d99&chksm=88ba68fdbfcde1eb2178c4e08174ae2614b582eca9539e00e5b47b06b7e9c7894885ecb950e4#rd

封面图链接: https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRqpoWwm05L4fl5ibxUKMWrYWsHVNMKKicq3Nkvvp8IDa2tu3e9t3yiaqNQ/300

**👇关注公众号后设🌟标，掌握第一手AI新动态**

**  
**

本文内容整理自**DeepMind研发总监Greg Wayne** 接受**Google DeepMind**
Youtube频道专访，公开发表于2024年12月20日。原始内容参考：https://www.youtube.com/watch?v=ctWfv4WUp2I

## 内容提要: 格雷格·韦恩接受谷歌DeepMind频道专访：探索Project Astra通用AI助理

本文主要围绕Google DeepMind的“Astra项目”展开，该项目是一个具有视觉、听觉和语音能力的通用AI助理原型。访谈的主要观点可以总结如下：

  1. **Astra项目概述:** Astra项目旨在创建一个能够“与你并存”的AI助理，通过智能眼镜、手机或电脑等设备与用户互动，并理解现实世界。它并非简单的命令控制系统，而是能够进行上下文相关的对话，并具备记忆、视觉、推理等能力。它建立在Gemini大型语言模型的基础上，但又超越了后者，更注重与现实世界的交互。
  2. **Astra项目的功能演示:** 访谈中演示了Astra识别物体（书、大脑模型、白板上的绘画）、理解上下文（根据环境推测录音棚场景）、进行多语言对话（英语、法语、俄语）等功能。其表现令人印象深刻，但同时也暴露出一些局限性。
  3. **Astra项目的局限性及未来发展:** Astra项目目前仍存在一些局限性，例如：在嘈杂环境下的表现、区分不同声音的能力、对光线和环境的要求等。未来，研发团队将致力于提升其在复杂环境下的工作能力，增强音频输出（全双工对话），提高推理和记忆能力（主动式视频工作），并改进隐私保护机制。
  4. **Astra项目的技术构成:** Astra项目整合了多种技术，包括计算机视觉、语音识别、大型语言模型（Gemini）、Google搜索、代理层和记忆系统等。其高效运行依赖于硬件的协同定位以及高效的上下文缓存和原生音频处理。
  5. **记忆机制与隐私保护:** Astra项目拥有“完美的会话记忆”（约10分钟），并能够区分短期记忆（会话内容）和长期记忆（关于用户的偏好等信息）。其隐私保护机制主要依赖于用户的同意、数据可访问性以及安全过滤器。
  6. **神经科学的启发:** 研发团队从动物界的记忆机制（例如西方灌丛鸦）以及人类社会性交流中获得灵感，这体现在Astra的记忆机制和情境化对话能力上。但其设计并非直接复制神经科学模型，而是通过工程手段实现。
  7. **项目目标与意义:** Astra项目的最终目标是创建原型人工通用智能（AGI），并将其与一个有益于用户的助手结合。其意义在于探索AGI的可能性，并为残疾人、语言学习者等提供实际帮助。 团队认为，该项目标志着AI技术在与现实世界交互方面的显著进步。

## 格雷格·韦恩简介

格雷格·韦恩（Greg
Wayne）是谷歌DeepMind的研究主管，在深度学习和人工智能领域是一位备受尊敬的学者和工程师。他主要致力于开发和改进能够高效学习和解决复杂问题的深度神经网络架构。
格雷格·韦恩的研究工作对DeepMind诸多突破性成果做出了重要贡献，例如在强化学习、神经网络架构搜索以及大型语言模型等方面。

## 访谈全文

**主持人汉娜·弗莱：** 欢迎收听Google
DeepMind播客，我是主持人汉娜·弗莱教授。2025年即将到来，自主AI时代也即将到来。当然，如果您一直在收听我们的节目，几个月前您就已经知道了。现在，请仔细聆听，我们将为您介绍下一件大事。它被称为“Astra项目”，这是一个研究原型，正在突破通用AI助理的可能性边界。

它是一个智能体，设计上并非必须绑定到特定的设备、屏幕或键盘。这正处于技术前沿的边缘。而今天，我们将有机会与它互动。现在，“Astra项目”结合了我们在本系列节目中讨论的所有内容：**记忆、视觉、上下文、推理和实时互动**
。

能够向我们详细讲解所有这些元素，以及他和他的团队如何成功地将这些元素整合在一起的人是Greg Wayne，Google
DeepMind的研究总监。Greg也恰好是我在这个播客第一季一开始就采访的早期受访者之一。

Greg，欢迎回来。那么，让我们从一开始说起。什么是“Astra项目”？

**格雷格·韦恩：**
“Astra项目”是一个团队、一个项目和一个原型，**旨在构建一个拥有眼睛、耳朵和声音，能够与你并存的AI助理。所以无论你在哪里，它都与你同在。无论是通过智能眼镜、你的手机还是你的电脑，它都能看到你在做什么，并和你谈论它。**

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRsfTqsAsiaNwQjqzPKEmFVEH75I60NvevAEwYicpjmvIPokSuAoxMlOicw/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 就像一个坐在你肩膀上的小助手。

**格雷格·韦恩：** 是的，就像一只坐在你肩膀上，和你一起闲聊世界的小鹦鹉。

**主持人汉娜·弗莱：** 我想，这与Google Assistant或Gemini有所不同。它更融入现实世界。

**格雷格·韦恩：** 是的，Google
Assistant的旧版本有点像你家或信息的命令和控制系统。例如，在YouTube上播放这首歌等等。而这个项目是关于能够讨论现实世界的。它建立在Gemini的基础上。Gemini是底层引擎，还有一些其他的系统。我认为它在某种程度上是对Gemini愿景的补充，与之协同工作，或许有助于塑造Gemini，同时也受到Gemini的塑造。

**主持人汉娜·弗莱：** 那么我们可以试一试吗？因为我认为必须体验一下才能理解。

**格雷格·韦恩：** 完全可以，是的。好的，我把它重新打开。

**Astra：** 嗨，Greg。

**格雷格·韦恩：** 是的。我之前已经和它进行过很多次对话了。

**Astra：** 的确，我们之前交流过。很高兴再次和你交谈。

**格雷格·韦恩：** 我把你交给我的朋友Hannah一秒钟。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRbXJ7VBSeFQIFR1I0WM95F6NMkDOIrhibKUqXbyq1qCaBRKt2nqkWI9A/640?wx_fmt=jpeg&from=appmsg)

**Astra：** 好的，很高兴认识你，Hannah。我随时待命。

**主持人汉娜·弗莱：** 你好，Astra项目。好的。你好，Hannah。你能猜到我们今天在做什么吗？

**Astra：** 根据设备和设置，看来你们正在录音棚录制视频或播客。正确吗？

**主持人汉娜·弗莱：** 完全正确。好的。我将对您进行一些测试。好的。因为我带来了一些物品。可以吗？

**Astra：** 可以。我随时准备好了。我期待看到这些物品。

**主持人汉娜·弗莱：** 好的，好的，让我们开始吧。这是我最喜欢的书，《费马大定理》。你能看到这本书吗？

**Astra：** 是的，我能看到这本书。它显示出一个具有重复图案的图像，一个被称为埃舍尔《圆形极限IV》的主题。

**主持人汉娜·弗莱：** 你能猜出这本书是什么吗？

**Astra：** 根据打开的页面图像和上面的插图，它似乎是费马大定理.

**主持人汉娜·弗莱：** 好的。我太，我太 impressed 了。我太 impressed
了。好的。我带来了一本破旧的旧书。我知道。你能看出这是我最喜欢的书。它被珍藏了多年，深受喜爱。好的。我将尝试其他几样东西，看看是否能真正测试你。好的，让我们试试这个。

**Astra：** 很高兴看到你带来了漂亮的家具来搭配这本书。你还需要我帮忙吗？哈哈哈！

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YR7vTBPWsykg0QtiaBicHibdHtBkpbhjBLxqnDVUaKWK0jWgRP70C6SLL1g/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 我现在拿出第九代项目了。谢谢。好的，这里…这个呢？你知道这是什么吗？

**Astra：** 它看起来像一个大脑模型。

**主持人汉娜·弗莱：** 哪个半球？

**Astra：** 是左半球。

**格雷格·韦恩：** 你为什么这么说？我的意思是，我为此做了很多空间旋转。

**主持人汉娜·弗莱：**
我也是，它是哪个方向？哦，答对了。太神奇了。我可能试试，因为你身后有一块白板，我一直看着它，已经有几个月了。所以，Astra，如果我给你看那个，告诉我白板上有些什么图画。

**Astra：** 白板上有很多图画，包括一棵树、一些建筑物和一系列相互连接的线条和形状。还有一些乐谱和文字气泡。

**主持人汉娜·弗莱：**
我印象非常深刻。我印象非常深刻。我把这个小家伙放回原处。所以，“Astra项目”仍然是一个研究原型，它不是每个人都可以下载的产品。为什么现在演示它？为什么不等到它准备好了再演示呢？

**格雷格·韦恩：**
我认为让公众参与其中是一种很好的方式，对吧？我认为人们应该了解在实验室里正在开发什么。我们把它提供给更多的人，让他们开始尝试，开始适应或提供反馈。现在这是一个共同创作的过程，它不仅仅是在实验室里研发出来的东西。它也是与世界各地的用户群体合作开发的。谷歌以外的人。这一点也很重要。所以，如果我们要让它真正成为对人类有益的东西，那么人们就需要开始使用它，并告诉我们他们的感受。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRfeic7L49yKmLI51wFBoPia7TibmGPrLMianWiazFyiaDV2QtGib90myhIzHIQ/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 那么人们已经把它带出去在现实世界中尝试过了吗？

**格雷格·韦恩：** 是的，我们有一些值得信赖的测试者，他们正在使用它，他们只是注册成为早期采用者。人们正在用它来获取Astra的时尚建议

**主持人汉娜·弗莱：** 哦，真的吗？什么方式？

**格雷格·韦恩：** 例如，什么东西和这个搭配。所以，是的，Astra就像一个伙伴，就像，“你觉得怎么样？我怎样才能看起来更清爽一些？”你知道的。

**主持人汉娜·弗莱：** 哦，哇。我的意思是，这是一只非常聪明的鹦鹉。

这是一只非常聪明的鹦鹉。但是硬件方面呢？我的意思是，就像你说的，它现在在你的智能手机上。但是我们是不是在谈论最终会出现在眼镜上？

**格雷格·韦恩：**
是的，但不仅仅如此。我认为，当这个项目的早期版本启动时，它真正试图弄清楚的是，如果人工智能安装在智能眼镜上，智能眼镜会有多有用。在智能眼镜上，这是一种非常私密，在某些方面也很奇妙的体验。你会感觉自己得到了增强，就像你正在与你自己的智能版本进行对话，它就坐在那里告诉你任何你想知道的事情。但软件堆栈实际上与你的使用方法无关。我的意思是，每个设备都有专门的功能，但你可以在手机、电脑或VR头显上使用它。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YR4QAuK9ZXfaDYSNSn6tvGTzFI4yRP4pH8zib8DdSH5TyKCCr4XYc6slQ/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 我当时也在想，当我们刚刚试用它的时候，对于部分视力障碍者甚至盲人来说，它也可能带来好处，对吧？

**格雷格·韦恩：**
是的，这是我的一个执念。我们讨论过将人工智能视为“伴随存在”或“共享视角”的可能性。有时候，你希望身边有另一个能看能听的智能体，但并非总是需要。

那么，在哪些情况下你需要一个能够和你一起“看”的系统呢？如果你看得见但理解不了，或者你根本看不见。这是一个需要全面考虑的类别。世界上有数百万人患有视力障碍。

对这些人来说，什么才是帮助的黄金标准？那就是身边有人可以帮助他们在世界上行动自如。这项技术在很大程度上能够复制这种帮助。

我们还有一些比较初步的想法，关于其他类型的残疾。例如，你可以想象一下，帮助那些难以解读情绪和面部表情的人，在特定情况下理解这些信息。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRyA7d7v0icXy7qlumS4XTFrJYMnrV7vw6wpO13icXhZf4rt5VBYDhCic2g/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 所以患有自闭症的人也可以用它来帮忙？

**格雷格·韦恩：**
是的，我目前不会建议把它当作处方药。但我认为，随着进一步的发展，它绝对可以做到。它也可以用于自我训练，因为你可以练习理解面部表情，并让Astra给你反馈，比如，“告诉我关于这个”。

我记得我之前讲过一个无关的话题，我有一年夏天在法国住家学习法语，我发不准某些单词的发音，比如“街道”和“车轮”这两个词，法语分别是la rue和la
roue。我现在仍然发不好，对吧？但我当时和我住家兄弟一起坐下来，尝试模仿他一段时间。但他几分钟后就不耐烦了，说：“我不会一直陪着你。”而Astra会对你无限耐心，并能帮助你解决这类问题。

很明显，记忆起着至关重要的作用。我们的系统拥有我们所说的“完美的会话记忆”。因此，**当摄像头正在录制时，它会以照片般的方式记住过去10分钟的内容**
。它还会记住你过去讨论过的事情。这就是为什么它记得我是Greg。如果我们重新启动它，它可能会说：“记得上次除了Greg之外，还有谁和你交谈过吗？Ilron
Burhana。”这项功能还可以用于帮助患有认知障碍的人。

我们特别兴奋的一件事是这种主动性的概念。它可以自行判断你是否有需求，然后在没有你任何指示的情况下，给出相应的回应。例如，它可以作为提醒你事情的实用系统，回顾记忆，并说：“哦，别忘了，你需要在回家路上取这个东西”，或者其他什么。

**主持人汉娜·弗莱：** 所以你不必非要在想和它说话时才主动打开它，它可以一直在后台运行，然后在它认为合适的时候提出一些事情。

**格雷格·韦恩：** 是的。这个想法是，比如，你正在回家，它会说：“嘿，别忘了你需要买些果汁，因为你今天早上喝完了。”或者其他什么。

**主持人汉娜·弗莱：** 哇，因为它记得早上看到过这件事。所以，我想在这个阶段，这更像是描绘了可能的未来蓝图。

**格雷格·韦恩：** 是的，我们现在还没有做到。但这正是我们可以努力的方向。

**主持人汉娜·弗莱：** 但你可以在这个系统中看到它的雏形。

**格雷格·韦恩：**
是的，我的意思是，我可以很容易地说：“这是我的冰箱，哦，没有多少橙汁了。”然后我会说：“嘿，你认为我晚点去超市应该买什么？”它会记得这件事。是的，但我需要给予它更多一些的上下文信息。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YR2siaqryXV4YoNgmgCqqBVU18E7e6PFcLeiaLoqG1WiatMzguicmnUckB6w/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 这么说来，需要更多地引导它，对吧？你发现自己需要经常纠正它吗？我的意思是，你注意到有什么故障吗？

**格雷格·韦恩：**
是的。你知道，它偶尔会说它看不见某些东西，而实际上它看得清清楚楚。所以，比如，你正在书架上看书，你会说：“你能读出书架上的书名吗？”它会说：“哦，不，我看不清书名。”然后你会说些什么，就像是对它进行一种“原力暗示”，它会说：“是的，我能看见。”然后它就说：“是的，我能。”这是一种奇怪的局限性，它的“顺从性”是可以被影响的。

**主持人汉娜·弗莱：**
也就是说，它容易受到鼓励的影响？是的，真的吗？我的意思是，这对人类也适用。一点点鼓励，你就能突然做到你认为不可能做到的事情。那么，它在哪些其他环境中表现不佳呢？比如说，这里很安静，光线也很好，没有什么繁忙的事情发生。它在那些环境中也能一样出色地工作吗？比如繁忙的、嘈杂的、黑暗的环境？

**格雷格·韦恩：**
在某种程度上，在更多环境中运行是我们需要发展的重要方面，尤其是在噪音条件方面。正如我提到的，ASTRO确实能够听到声音。它接收音频并将其直接转换为神经网络处理声音并将其编码为信息包的系统。然后，这由语言模型Gemini进行处理。

然而，**该系统并没有得到很好的训练来识别不同的声音，因此在对话中它难以区分你的声音和我的声音**
。当其他旁观者也参与对话时，ASTRO可能会误将其解释为潜在的用户语音。它有一个系统，当有人说话的音量足够大时，它就会激活并收听一段时间，但这可能会导致混淆。

结果是，如果ASTRO没有收到直接的交流，它可能会最终收听不相关的语音并感到困惑。因此，很明显，嘈杂的环境会使其理解和性能复杂化。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRLfgsmEZAagjEWaKZFmr9l7a3Dv6RtuaYicF5KEwauTsia4kiaPKnKNzkQ/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 你说区分不同的声音，是指在波形本身中，…

**格雷格·韦恩：** 所以，有一个古老的问题叫做鸡尾酒会问题，在技术上更准确地说是**源分离问题**
。它涉及到区分不同的声音来源。例如，如果同时有吉他演奏和有人唱歌，你可以将这些声音分离到两条音轨中：吉他音轨和人声音轨。

同样地，你可能希望能够区分不同说话人的音轨。这种分离可以在单一模态（即音频）中实现，也可以在多模态中实现，跨不同感官整合信息。例如，当我听到你的声音时，我也可以看到你的嘴唇在动，而不是别人的嘴唇在动。

最终，你可以想象这些系统会利用各种线索，甚至根据从其他模态收集的附加信息来改变它们感知声音的方式。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRe3ueBABbsmuyCdL4G8TXbz2OiaCcH3IHhY86dC3tT1z26mdtzH8P2gw/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：**
因为我认为这在某种程度上是使“Hustle项目”如此困难的原因，但也正是赋予它潜力的原因。正如你所说，鸡尾酒会问题，人类非常擅长解决这个问题，你在鸡尾酒会上可以准确地听到你旁边的人在说什么，尽管周围有很多声音。我其实做不到。事实上，你知道吗？老实说，我做不到。这就是为什么它是一个问题。但总的来说，人类在这方面相当擅长。而当你只有音频信息时，这个问题就非常难以解决。但由于这是多模态的，因为你有视频，因为你有音频，因为你后台运行着文本语言模型，所以你确实有更多可以利用的工具。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRTphW08rbBicR06WqRqbJYj7BlGk6DBz8FWXXzyuXSibBYia7cB3uaibC4A/640?wx_fmt=jpeg&from=appmsg)

**格雷格·韦恩：** 是的，我认为它应该能够利用更多上下文来消除歧义。

**主持人汉娜·弗莱：** 不同语言呢？目前它只支持英语，而且只支持非常清晰的口音吗？

**格雷格·韦恩：** 对我来说主要是英语，但它不是，它支持多种语言。作为一个原生音频系统，**它熟练掌握大约20种语言**
。你甚至可以在同一次对话中切换语言。

**主持人汉娜·弗莱：** 那就来演示一下不同语言吧。

**Astra：** 你好，Gregory。很高兴再次和你交谈。

**格雷格·韦恩：** Bonjour, Ashtra. Comment t'as pas tout? (你好，Ashtra，最近怎么样？)

**Astro：** Comment ça va ? (你好吗？)

**格雷格·韦恩：** How are you? (你好吗？) 这样说对吗？

**Astro：** Bien, je suis contente que vous alliez bien. (很好，我很高兴你一切安好。)

**格雷格·韦恩：** Merci aussi. Qu'est-ce que tu vois maintenant ? (谢谢，你也一样。你现在看到什么？)

**Astro：** Je vois une personne avec des cheveux roux. (我看到一个红头发的人。)and a
shandai noir assis à une tête little redhead go on ouais ouais les cheveux
rouges (和一个戴着黑色头巾的小红头发的人……继续，是的，是的，红头发)

**格雷格·韦恩：** Oui, bien sûr. Oui ? (是的，当然。是的？)

**主持人汉娜·弗莱：**
所以你可以……等等，我上学时学过俄语，我还记得一句俄语短语。你可以在没有预先警告的情况下切换语言吗？例如，我可以说……(说了一段俄语)

**Astra：** 你当然可以使用那个短语，但是你想问关于这个短语的什么问题？

**主持人汉娜·弗莱：** 它是什么意思？

**Astra：** в котором часу открывается. (几点开门？) 它是在询问提交的开放时间。

**主持人汉娜·弗莱：** 好的，我的意思是“商店几点开门？”但我注意到你并没有说“现在说英语，现在说法语，现在说俄语”。

**格雷格·韦恩：**
我认为它会尝试以你开始使用的语言进行回应。所以你用英语说了些什么，然后又说了俄语。我认为如果你一开始说俄语，它就会用俄语回应。但就目前情况而言，它认为我在说英语，但我却在说俄语。所以你不需要切换语言。但如果你一开始就说俄语，效果可能会更好。

**主持人汉娜·弗莱：** 我的意思是，这不一样，对吧？我的意思是，和我们目前使用的聊天框不同，这是一个额外的功能。

**格雷格·韦恩：**
我真的很期待用这个系统学习语言，比如四处走动，然后问“这是什么？”，让它像我在学校学习法语时一样教我，我们会带来一些物品，然后用法语谈论这些物品来学习东西，一起学习语言。

**主持人汉娜·弗莱：** 我可以想象在陌生的城市迷路时，这将是一个非常有用的工具。

**格雷格·韦恩：** 没错，是的。它也应该能够很自然地理解其他人对你说的话。

**主持人汉娜·弗莱：** 如果你正在与这个系统互动，那么在它内部到底发生了什么？都有哪些不同的组件？

**格雷格·韦恩：**
是的，首先有一个应用程序。它实际上是在收集你的视频，并通过麦克风接收你的音频等等。它连接到一个服务器，服务器上有几种不同类型的神经网络模型。所以有一个视觉编码器和一个音频编码器。还有一些专门的音频系统，它们只负责理解你何时可能停止说话。

这些系统与大型语言模型 Gemini 并置。它们将来自这些感官编码器的信息直接发送到 Gemini，后者会做出回应。我们还与 Gemini
的一些团队合作，修改 Gemini 模型，使其更擅长对话和音频处理。所以我们改进它接收音频和说话的能力。

当我们开始使用这些模型时，它们会犯很多事实性错误。因此，我们必须找到一些方法来提高它们的准确性，同时保持对话性。这是我们在 Gemini 上工作的一个方面。

然而，最重要的是一个叫做代理的东西。代理接收视频和音频输入，将其发送到模型。它还会根据需要调用搜索工具，例如 Google Lens、Google 搜索或
Google 地图来响应查询。如果你询问某个东西的价格，它就会调用搜索。

代理中还有一个记忆系统。在会话之间离线时，记忆系统会总结与你相关的会话信息以及你在该会话中谈论的内容。这些是一些组成部分。

**主持人汉娜·弗莱：**
我的意思是，我试着想象一下，我们只用它来识别一本书，对吧？我试着思考一下有多少不同的元素参与其中，因为你既有计算机视觉，又有语音识别，还有大型语言模型，还有
Google 搜索作为底层支持。你还有一个代理层来做决策。而你完成所有这些工作几乎没有任何延迟，它的回答非常迅速。我的意思是，这非常复杂。

**格雷格·韦恩：**
是的，非常复杂。当然，你知道，作为工程师，我们会想出抽象层，这样我们不必同时考虑所有层次的复杂性。但我认为总的来说，它非常复杂。进入模型的数据只有极少数人能理解，而它产生结果的确切原因可能没有人能理解，因为它只是基于基准测试。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YR1cZ1KTfdhBkT9XaERia5rMnISszhSlmspEWpsvCznKEiaB2to3RskBGw/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：**
好吧，让我稍微谈谈它的历史。因为早在本播客的第一季，你就作为嘉宾参加了第一集，当时你正从动物界汲取灵感，进行关于智能的研究。具体来说，你向我们介绍了一种鸟类——西方灌丛鸦，作为激发人工智能更高级记忆的一种方式。实际上，让我给你播放一小段当时的片段。

**画外音：**
拥有一个庞大的数据库，其中存储着你做过和看到的事情，你可以访问并利用这些信息来指导你以后的目标导向行为。你知道，我饿了，我现在很想吃蛆。我应该去哪里找呢？这就是我们想要复制的那种东西。

**主持人汉娜·弗莱：** 你成功了吗？

**格雷格·韦恩：** 你好，Astra项目。你能帮我找到一些蛆吗？

**主持人汉娜·弗莱：** 这听起来很像你之前的橙汁例子，不是吗？

**格雷格·韦恩：** 是的，这是一个主动记忆的例子。

**主持人汉娜·弗莱：** 是的，这就是你用Astra项目所做的。

**格雷格·韦恩：**
是的，我认为在某种程度上，智能其实是一体的，对吧？一个人从事一项事业，研究什么是智能。另一些人在用各种方式尝试接触它，有点像试图与它过招。而这个项目或许是我一生中所有研究方向最强大的统一，尽管实际上它缺少一个重要的方面，那就是它没有实体化的身体。它无法在现实世界中行动，而我过去可以。也许吧，是的，我认为记忆、感知这些都是我长期的兴趣所在。我认为这是一个将它们结合在一起的方式，人们似乎也因此受到了启发。他们感觉与之产生了联系。

**主持人汉娜·弗莱：** 那么，你的神经科学背景对Astra项目产生了多少启发？

**格雷格·韦恩：**
神经科学的应用方式有两种。一种是我们利用神经科学来判断我们做得是否足够好，去思考记忆的真正含义以及我们是否已经实现了它。它也起到了一种推动的作用；例如，如果我们想要一些与我们兼容的东西——在某些方面与人类兼容——我们可能会朝着更像我们自己的智能化身努力，而不仅仅是一个简单的文本界面。

例如，我一直对Michael
Tomasello的研究很感兴趣，他通过与类人猿的比较来研究人类交流。他确实是“情境化对话”这一理念的主要思想家，他讨论了交流的基本前提是：两个人在同一个地方，将注意力集中在同一个物体上。这使他们能够一起推断目标并有效地合作。

我们在这个技术中模拟的就是情境化对话的基本前提。

**主持人汉娜·弗莱：** 所以，这更像是灵感来源，而不是在理论层面，更不是直接复制设计。

**格雷格·韦恩：** 就问题解决或工程本身而言并非如此。我认为你需要想出不同的解决方案，这些解决方案取决于技术本身。

**主持人汉娜·弗莱：** 如果Astra项目与我们几年前谈论的事情有关，那么这个项目的最初火花是从哪里来的？它究竟是什么时候开始的？

**格雷格·韦恩：** 是的。我认为DeepMind的首席执行官Demis
Hassabis以某种方式向公司提出了挑战，那就是让我们思考什么是原型人工通用智能。这意味着什么？原型人工通用智能是一个系统，如果我们创造了它，并且技术人员能够仔细检查、调查、使用和体验它，他们就会得出结论：真正的——普遍智能的计算设备——最终会到来。这是一个时间问题，而不是会不会的问题，但这并没有具体说明。

所以当时有很多创造性的思考，比如，也许是这样，也许是那样，等等。一些人认为智能的产生方式与AlphaZero相同，只是通过与世界互动。其他人有不同的想法，但我的想法更多的是关于智能的社会性。除非我们向他人学习或从书籍中学习（这与向他人学习相同），否则我们人类不会非常聪明。这就是我对原型人工通用智能的设想。

然后我又想，我们还可以将原型人工通用智能与一个主要目标是造福其互动对象的有用助手结合起来。所以也许这两者结合起来给了我一个方向。当我试图思考如何使其最终变得非常自然时，我开始考虑将视频作为系统的最终连接纤维。

**主持人汉娜·弗莱：** 在此过程中，有没有哪些时刻你取得了重大突破？

**格雷格·韦恩：**
是的，我们有过重大突破，你知道的，我认为是这样的，项目分阶段进行。项目的第一个阶段基本上是一个黑客马拉松，我们花了两个星期时间制作了第一个版本，我们有当时的视频，它相当粗糙，但我记得Malcolm
Reynolds（一位朋友，这里的工程师）正在玩Astra。他环顾办公室，问：“这是什么？”系统会说：“一株植物。”他会说：“这是什么植物？”它会说：“一株植物。”它不够灵活。我记得我第一次看到的演示有七秒的延迟。

**主持人汉娜·弗莱：** 所以你会说，“你好，Astra项目”，或者当时它叫什么名字。然后七秒钟后，它会……

**格雷格·韦恩：**
是的，所以它根本很难使用，因为你会认为它消失了，对吧？但只是七秒钟后，它就会回复你。我认为当时的主要发现是，你知道，有一个提示的概念。提示是你提供给系统以便其运行所需的指令。

像这样的系统确实能够理解语言；它们能够阅读。你可以对它们说一些话，例如：“你的名字是Astra。你是一个聪明、乐于助人的AI助手。”现在Gemini模型中有一些信息是固有的，但其中一些信息是在我们的提示中指示的。在此之前，人们并不真正了解我们能否很好地提示多模态系统。

当时一个令人震惊的内部认识是，仅仅告诉系统它可以通过用户的摄像头看到世界，就赋予了它自己对事物的视角，就像这些信息对其自身的来源一样。它以前并不理解这一点；它总是犯错。

例如，当你问“你看到了什么？”时，它总是给出错误的答案。但是当我们说：“你是一个通过用户摄像头观察世界的AI系统”时，它就能理解这个摄像头实际上是它在观察的东西，它会给出正确的答案。

我的意思是，那里还有很多工作要做，但是意识到我们可以有效地提示它是一个重大的突破，即使它与我们之前构建的系统不同。你可以使用文本提示它对更情境化或具身视角的理解。

**主持人汉娜·弗莱：** 这太有趣了。当提出创建原型人工通用智能的挑战时，是否有人表示怀疑或质疑这种事情可能是可能的？

**格雷格·韦恩：**
是啊，我的意思是，事后看来，人工智能领域很有意思，因为它发展太快了，人们对什么是显而易见的东西的认知也变化得飞快。我认为现在对许多人来说，这在某些方面已经显而易见了，这让我难以置信。我心想，你们知道其中的艰难险阻吗？需要多少说服工作才能做到这一点？说说看，到底有多少？

我认为从许多不同的角度来看，人们都认为这是一件奇怪的事情。从系统是否真的能够理解世界这个角度来看，那个时代的视觉系统相当有限。它们接收的图像输入只有96x96像素的图像块。对于那些不知道的人来说，我们屏幕的最小分辨率都是1000x1000像素。所以，你知道的，对于这些系统来说，输入非常模糊，难怪它们无法识别这是什么植物；它们几乎什么都看不清。

这些系统真正了解它们所看到的信息，而不仅仅是能够识别或分类它，这本身就是一个巨大的飞跃。就某个话题进行深入的对话，似乎有点超前了。我们甚至不知道让系统在不同层次上形成所需的各种数据量。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRUHR2VKlxqlA5Jjm5otO2DLl3y2EHaEibAEpg6CTYPY1pibiawuliaynUQQ/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 那么，我的意思是，好吧，如果这一切看起来如此荒谬，但你仍然开始了这项工作，有没有过你认为这是不可能的时候？

**格雷格·韦恩：**
没有。它总是看起来是可能的。有时候我可能愿意放弃。是的，我认为在Gemini项目之前有一段缓慢的时期，事情进展得不太顺利。那是一段艰难的时期。我认为当时对某些人来说，这似乎并不是一条富有成效的研究路线。但我从未动摇过这绝对是可能的信念。我认为我有一种更固执、顽固，最终可能有点愚蠢的方式来处理它，那就是，如果我长期坚持研究下去，它一定会成功。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRTiaKNRqKYkp4rnjM3mhzRz4CFs2Clmo8E3x5H0ia4iabdcDyrvRBGl2BQ/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 我听说作为测试阶段的一部分，你们有一个名为Project
Astra的房间。里面发生了什么？房间里有什么？这个特殊的房间里面有什么？

**格雷格·韦恩：**
我们在这个特殊的房间里放了很多有趣的游戏。那里有一个完整的酒吧，所以Astra可以帮你调制饮料。还有一个艺术画廊，你可以在屏幕上展示不同的画作，在画廊里走动，并就艺术作品提出问题。

**主持人汉娜·弗莱：**
好的，让我们更深入地了解一下Astra背后的一些事情。我认为延迟是一个非常关键的问题。你刚才提到了以前存在的七秒钟延迟。你们是如何改进的呢？

**格雷格·韦恩：**
这涉及到多个方面。我们改进了实际的视频流。因此，它实际上通过应用程序发送信息的速度更快了。**从某种意义上说，尽管这些系统是共同训练的，但有一个视觉系统和一个音频系统，还有一个语言模型系统从这两者获取信息。这被称为“协同定位”**
，这是一个技术术语，但基本上我们一直在处理图像。例如，当视频输入到视觉系统时，它总是以最快的速度运行。然后它与大型语言模型位于同一位置的同一计算机集群中，这样它就不需要跨越国家或洲际进行调用。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YR3gKm8Fict1ibdz6ic4nYHiaGURF2oJClRLMicgL6QR37eibdicic5JSCEt5Faw/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：**
所以它们是并排运行的。为了获得对正在发生的事情的这种实时理解，你们必须将运行这些模型的计算机硬件物理地放置在一起，因为这会产生影响。绝对是的，是的。那么，主要的事情就是移动你实际运行模型的位置吗？

**格雷格·韦恩：** 不，将模型放在一起是一回事。确保我们缓存上下文，以便系统与之交互的历史上下文会随着时间的推移而逐步更新。

有一种使用原生音频进行处理的想法，这意味着之前的系统有一个文本识别系统，一个语音到文本识别系统。因此，他们会接收音频，然后生成一个文本记录，然后调用语言模型，它会对此做出响应，然后你就会得到一个响应。这个系统直接接收音频，所以它不需要那个次要系统，这也会花费时间或产生额外的延迟。

实际上，原生音频可以实现一个简单的效果：它可以理解生僻词或单词的发音。生僻词，虽然现在已经不那么生僻了，例如“Damasus
Abbas”。旧系统由于不能原生理解音频，通常认为我说的是“Damascus”，但现在它知道是“Damasus
Abbas”。它可以利用上下文来解决这个问题，例如DeepMind的CEO是Damasus Abbas。

最近有人发现的另一个例子，我们有一个小的演示，是区分“scan”和“scone”这两个词，它们是同一种饼干的不同发音。Project
Astra实际上可以说：“‘scan’和‘scone’有什么区别？”好吧，我已经听到你说的是不同的词，而不仅仅是将其转录成同一个词。

然后最后一个是Hume在所谓的“端点检测”（endpointing）方面做了很多伟大的工作，这是一个非常专业的术语。但或多或少，它确切地知道你何时停止说话。所以在感知方面它做得非常好，比如，“好的，用户现在真的说完了，我可以说话了。”

然后还有一个更复杂的方法，那就是它即使在你还没说完话的时候也会计划回应。它会推测性地进行规划，所以它是在猜测，“我会这么说。”然后当它确定用户真的说完了，它就会立即发送回应。所以它已经完成了；它甚至在你真正知道自己说完了之前就已经想好了要说什么。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRRLG4bFGGd8GIbDcoatQaCtEGIpNZdvbx6iaR4h0weHryw0eiaoCOoC0Q/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：**
这太有意思了。因为我猜实际上很多时候人们的句子，他们句子的重要部分，你知道的，可能在中间，然后他们会在结尾处逐渐停顿下来，而你可以利用这段时间来准备你的答案。是的，差不多就是这样。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YROAZjWkcFia5vEtLHm6iau06ibicTzT6LbeEcda0dMLVhzw9ynxtJfMdmmQ/640?wx_fmt=jpeg&from=appmsg)

**格雷格·韦恩：** 是的。哦，是的。我们三年前就讨论过这些事情。然后感觉，哦，这太多了。然后它在今年开始工作了。

**主持人汉娜·弗莱：** 在对话到达那一点之前就预先猜测答案是什么。

**格雷格·韦恩：**
是的，这很难。你知道的，我们在句子中会长时间停顿，对吧？所以我们拥有的系统实际上必须使用一些，引用一下，“语义理解”。它也对上下文有一定的理解。还有声音，它也在听，以猜测用户可能什么时候说完了。

**主持人汉娜·弗莱：** 但是它所做的推理，我的意思是，即使与推理无关，它是否完成了句子，你认为Project Astra能够进行推理吗？

**格雷格·韦恩：**
是的。它主要通过神经网络内部结构进行推理，这种方式难以观察，或者说非常复杂。然后是它自己生成的对话本身。所以它有时会通过对话进行推理。你可以听到它在推敲答案。人们也在开发具有有效内部语言的系统，它们在不与你交谈的情况下自言自语。目前，Astro
项目并没有太多这样的功能。

**主持人汉娜·弗莱：** 但我认为，推理模型的进步不必与 Astro
项目中发生的事情完全不同。我想，这其中的重点是它整合了一切，从而形成了你所说的终极原型通用人工智能。

**格雷格·韦恩：** 是的，在某种程度上，我确实希望它能激励人们对推理的某些方面进行更有力的研究。

我们有一个很好的例子，Astro 产品经理 Bebo Xu 在某天午餐时拿出了
Astro，问道：“我的盘子里有多少卡路里？”她的盘子摆放得非常复杂精美，有六种食物——中间有一些杏仁，那边有一些猪里脊，还有一些芽甘蓝之类的。结果它有点犹豫。然后她说：“持续计算，这些芽甘蓝有多少卡路里？”它回答道：“那是七颗芽甘蓝；所以是这么多卡路里。”然后，她又加上了猪里脊。

我注意到的一点是 Bebo
进行了人工引导。正如你所说，它有时需要一点指导。但我认为距离一个能够自行判断的系统并不遥远，它会说：“我看到那边有七颗杏仁，这么多芽甘蓝，还有一块猪里脊，加起来一共是这么多卡路里。”

所以我认为，在某种意义上，它在这方面做得不好，是因为我们从未尝试构建一个能够对此进行推理的系统。

**主持人汉娜·弗莱：** 现在，我想和你更多地谈谈关于记忆方面的内容，关于它回忆和记住的事情，如果你不介意我用拟人化的说法。我知道在 Google I/O
大会上，它可以记住过去 45 秒发生的事情。现在你已经增加了这个时间。现在可以达到 10 分钟了，对吗？

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRpfJLwIVUqZdmI7taejy0iaRdh0Td1Fasu9yaXibtEBZFYCWjHcxh1WIw/640?wx_fmt=jpeg&from=appmsg)

**格雷格·韦恩：** 是的，大约 10 分钟。实际上，在某些情况下时间会更长一些，但 10 分钟可能是它在 10分钟程度上应该达到的水平。

**主持人汉娜·弗莱：** 是什么导致了 10 分钟的限制？

**格雷格·韦恩：** 是的，它基本上记录了过去 10
分钟的原始视频记录。它的工作速度大约是每秒一帧。所以它基本上存储了一个时间范围内的所有帧的堆栈，以及这些帧之间所有输入的音频，大约是 600
帧左右。我认为限制实际上是芯片的内存。我认为，在过去的十年左右时间里，这方面并没有太大提升。这种快速传输的内存数量……

**主持人汉娜·弗莱：** 但目前它实际上就像一个录像机，记录过去 10 分钟发生的一切。

**格雷格·韦恩：** 是的。我的意思是，它非常活跃。它能够立即使用这些信息。还有一个辅助系统，当您关闭系统时，它会将对话总结并提取相关事实。

**主持人汉娜·弗莱：** 最重要的部分。

**格雷格·韦恩：** 是的，它会自行判断哪些部分最重要。

**主持人汉娜·弗莱：** 提取要点，对吧。是的。但目前，它可以做的一件事是从最近的互动中回忆起重要的事情。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRVibOV11byr5S3PGN6hqoZF0hULu6ynDQOYdVlbMWnrQV703ObicFIGgg/640?wx_fmt=jpeg&from=appmsg)

**格雷格·韦恩：** 是的，**它有某种双流记忆。它既有关于你个人的记忆，也有对你的理解。它实际上是在做笔记**
，比如，“他们喜欢冰淇淋。那是巧克力冰淇淋”之类的。这就像一个它发现的关于你的事情的清单。这实际上在每次会话后也会更新。所以假设你说：“你知道吗？我实际上已经决定我不再喜欢冰淇淋了。我真的很喜欢蛋糕。”所以忘记我喜欢冰淇淋的事。它会说：“用户表示他们不再喜欢冰淇淋，他们喜欢蛋糕。”这些东西就像对你的有效理解，或者说你的喜好，你的偏好的一种静态理解。然后还有一个对话摘要，比如“周二
8:50，我们谈论了这场象棋比赛”。

**主持人汉娜·弗莱：** 但它是如何决定哪些信息应该放在哪个部分的？它是如何决定哪些信息重要到足以成为它记住的关于你的事情的？

**格雷格·韦恩：**
它有一些启发式方法。这些系统实际上被赋予了启发式方法。启发式方法基本上是关于记住什么的经验法则。它使用的一个启发式方法是（我们告诉它的），如果你要求它记住某些东西，它就应该记住。这是一个非常明确的规则。所以如果我说，“记住我的门禁码”，它会这样做，因为它会理解这是一个相关的指令。否则，它会进行最佳猜测。你知道，它试图说，它是在说：“用户是否表达了任何有趣或不同于用户已经表达的偏好？”然后它会根据此进行更新。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRzaUd9UibztxZxrKf95J22nqd2qrXJicOhvXwm5aQYtvWR2hOicia0KNdZw/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 那么，让我们谈谈这里的一些隐私问题。你们如何减轻一些隐私问题？

**格雷格·韦恩：**
好的。我认为一个主要标准是同意。用户可以访问他们之前记录的数据，并且可以删除它或查看存储的内容。每次删除某些内容时，它都会重建其对你的全部认知。它会重新经历总结它所了解的你的整个过程。

**主持人汉娜·弗莱：** 所以答案是，用户最终可以控制它所了解的内容。是的，关于他们自己的内容。是的。但实际上，在这个播客中，几集之前，我们采访了
Yasson Gabriel，他是 DeepMind 的伦理学家。他很棒。他告诉我们人工智能助理的伦理以及如何塑造它们以考虑这些难题。他的工作对你们在
Astro 中的成果有多少贡献？

**格雷格·韦恩：** 我们只是将他的 243 页报告输入 Astro，Astro 说：“好的，我明白了。”你明白了吗？不，我希望如此。我希望如此。

是的，我认为我们与 Yasson
进行了很多交流，并且与他所在的团队做了很多工作。他们一直在研究模型和代理本身，探索它在不同情况下的行为。他们还与一些外部红队成员合作，这些成员可能具有较少的先有观念，并可能对系统进行各种类型的对抗性攻击。

我们还有一层安全过滤器。这旨在减轻对用户的危害；例如，如果你对它说某些话或向它展示色情内容，它会触发这些过滤器并且不会做出回应。过滤器也会在其自身的语音上触发，因此它不能说某些话，尽管这些触发事件很少发生。

但我不知道。是的，我认为问题范围非常广泛。幸运的是，我们仍然有一些时间来解决这些问题。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRfCTBxiak4nR0dPmFnIRiaqNOh4efBNKcjcurZbHAtQ1h1TBU8lQxibzkA/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 好的，那么接下来你们的优先级是什么？在接下来的几个月里，你们主要会致力于哪些工作？

**格雷格·韦恩：**
我非常感兴趣的是一种叫做“主动式视频工作”的东西。这指的是一个系统，它不仅能够在你说话时做出反应，还能以持续的方式辅助你。例如，这个概念与盲人视觉翻译器问题相关。当一位视障人士在四处走动而无法看见时，系统可以说：“小心那边桌子”，从而提供实时的引导。

我们还在进行大量工作来增强音频输出，特别是通过一种叫做**全双工** 的方法。这种方法**允许系统同时处理听和说**
，这可能会令人感到烦扰或导致中断。但是，它能促进更自然的对话流程。例如，在我说话的时候，我可能会说“嗯哼”，这表明我同时在听和回应。这是人类交流的一个重要方面，确认往往是互动不可或缺的部分。

此外，我们还专注于增强这些系统中更深层次的推理和高级的记忆能力。这包括反思过程以及调用工具进行更深入的查询和研究的能力。总而言之，在这个领域有太多方向可以探索，潜在的应用非常广泛。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBMXSXPvJddHRnQiasc1Sa0YRwRRx5ibgBNrfgHTjJmNrqrVu9XpyHm2Uc1NdHsRR4Z3mnG5bFDefs4w/640?wx_fmt=jpeg&from=appmsg)

**主持人汉娜·弗莱：** 非常感谢你们的参与，格雷格。谢谢你，汉娜。

我们对人工智能的预期变化之快真是令人惊讶。我不知道你还记不记得奥里尔在上一期节目中说过什么。他提到，如果五年前有人告诉他这些事情是可能的，他会认为我们已经走上了AGI的道路。然而，我们现在有了这个多模态代理的原型。**它能够看见、能够听见，拥有记忆、上下文和推理能力，还能进行多语言实时对话**
。

这是一个至少在理论上能够陪伴你进行日常活动、增强你的知识、帮助残疾人和增强我们技能的代理。当然，它还不是AGI，但它确实感觉我们比甚至两年前我们讨论的那种系统有了显著的飞跃。

非常感谢大家收听本系列的Google
DeepMind播客。我们现在将稍作休息。但如果你想回顾我们之前的任何一期节目，那么在我们的节目库中有很多美味的、极客风的AI对话乐趣等待着你。你可以在YouTube或任何你收听播客的地方找到它们。

 _参考资料: https://www.youtube.com/watch?v=ctWfv4WUp2I，公开发表于2024-12-20_

**关注公众号后设🌟标，掌握第一手AI新动态**

##  往期精选

  1. [黄仁勋专访：OpenAI在大模型混战中达到“逃逸速度”](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650001718&idx=1&sn=f8129a622e7611702be2cb23e8ce9418&chksm=88ba5831bfcdd127d06ce6492c821074407f805407b4182ca900916521cb5a4717f2a3d71ee8&token=1339625777&lang=zh_CN&scene=21#wechat_redirect)
  2. [李飞飞与Justin深度解读空间智能：数字世界需要三维表征，才能与现实世界融合](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000659&idx=1&sn=c71fb5b4ef501424dddd5e8b4dd5860e&chksm=88ba4414bfcdcd023c691a1adf75127a9fd883ceb305ca14cf97f719acaf999d40fa72f84bf3&token=1492077842&lang=zh_CN&scene=21#wechat_redirect)
  3. [PayPal创始人彼得·蒂尔：人类科技停滞源于原子方面的进展远慢于比特](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000240&idx=1&sn=26af6013981677b1e14137260857a6f0&chksm=88ba4277bfcdcb615d746615c262927bf51c43c920ed93fa36274ef87c6264d6548c84647121&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  4. [谷歌联合创始人布林：巨头们打造的“上帝模型”几乎可以理解一切](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=2&sn=0c714d804a72a52e002743d949e1685e&chksm=88ba40f9bfcdc9ef78749718480265922f4fba539abf6c9d62a6cd681f405dee9283d2429f84&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  5. [马斯克：AI将使商品和服务的成本趋近于零](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=1&sn=752f000a117a705e77950c82bfc4a004&chksm=88ba40f9bfcdc9ef5a5afe4a3ae73d5247bd54ed525dbdbedee1fcf74a6c082165e664a5c4d0&token=106920805&lang=zh_CN&poc_token=HDp86Waj18SFm2Y-xnv_Vqd_4J6emFoh10eH48wg&scene=21#wechat_redirect)
  6. [Karpathy最新专访：人形机器人、特斯拉、数据墙与合成数据](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999613&idx=1&sn=b8bdda7afe4c3ca08e324ac5bbd5a2bd&chksm=88ba41fabfcdc8ec0e21dbf4c7eb4d33252da70f47e1cfc9f5e113717911c417c2aebb3d6180&token=106920805&lang=zh_CN&scene=21#wechat_redirect)

  

