# 图灵奖得主杨立昆在约翰霍普金斯大学专访：新的AI基础架构在路上，开源有助于降低AI风险

文章作者: 瓜哥AI新知
发布时间: 2024-12-24 10:10
发布地: 浙江
原文链接: http://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650006066&idx=2&sn=285d19ebc5ea6938df77c3c20ae55f47&chksm=88ba6b35bfcde22334d0b98db3a813a7fe0dffe8b2a10077ee80970d85c98e8e1bf5de65cab4#rd

封面图链接: https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBNo9Al5YbbYB6Ty5ETxJKDxEib7Vc9n0Ab33ic1hq49Ya9iaJnwGbjFbLteARPKEmFzb9Nvfm1gic6Uyg/300

**👇关注公众号后设🌟标，掌握第一手AI新动态**

**  
**

本文内容整理自**Yann LeCun** 接受**Johns Hopkins University**
Youtube频道专访，公开发表于2024年12月22日。原始内容参考：https://www.youtube.com/watch?v=UmxlgLEscBs

![](https://mmbiz.qpic.cn/sz_mmbiz_png/ClW8NejCpBNo9Al5YbbYB6Ty5ETxJKDxFAfyDE4xDG9rajwH9iaIFSB46VaY6o2bqOUIySBAHnZic6HzZeZtR5Ng/640?wx_fmt=png&from=appmsg)

## 内容提要: 卡拉·斯威舍专访杨立昆

**关于人工智能技术：**

  1. **开源的重要性:** LeCun强烈主张人工智能模型的开源，认为这能促进技术进步和更广泛的应用，并能避免少数公司垄断AI技术。他认为Meta的Llama模型的成功正是开源的体现。
  2. **LLM的局限性:** LeCun认为当前流行的大型语言模型（LLM）已接近性能瓶颈，因为它们主要依赖于预测下一个单词，而忽略了对物理世界的理解。他认为未来的AI系统需要能够理解物理世界，并像婴儿学习那样通过观察和行动来学习。
  3. **下一代AI架构:** LeCun致力于研发一种基于目标驱动的AI架构，这种架构能够更安全、更可控，并能更好地理解和与物理世界互动。他认为这种架构能够解决LLM的局限性，并最终实现更接近人类水平的智能。
  4. **对AGI的看法:** LeCun认为通用人工智能(AGI)的实现比很多人预想的更遥远，他对AI末日论者的观点持批判态度，认为他们低估了AI的复杂性，并夸大了其潜在风险。他认为现在讨论AGI的安全问题为时尚早，应该专注于发展更安全的AI系统架构。

**关于AI治理和政策：**

  1. **反对过早监管研发:** LeCun反对对AI研发进行过早的严格监管，认为这会扼杀创新，并可能导致少数公司垄断AI技术。他认为应该专注于监管AI产品，而不是AI研发本身。
  2. **政府的角色:** LeCun认为政府应该在提供计算资源支持学术界研究、促进AI技术公平竞争以及推动产业政策方面发挥作用，但反对政府对AI研发进行限制。
  3. **开源模型的风险与益处:** LeCun承认开源模型存在被滥用的风险，但认为其益处大于风险，因为开源能够促进更广泛的参与和创新，并降低被少数公司垄断的风险。Meta正通过红队测试等方式来降低风险。

## 杨立昆简介

杨立昆（Yann
LeCun）是深度学习领域的三位奠基人之一（另外两位是杰弗里·辛顿和约书亚·本吉奥），被誉为卷积神经网络（CNN）之父。他是纽约大学Courant数学科学研究所的Silver教授，也是Meta（Facebook）的副总裁兼首席人工智能科学家。他为人工智能的发展做出了开创性的贡献，其研究成果广泛应用于图像识别、自然语言处理和语音识别等领域。

杨立昆出生于法国，在巴黎高等电子技术学校获得工程硕士学位，后于多伦多大学获得计算机科学博士学位。他早期的工作专注于反向传播算法在图像处理中的应用，并成功地将CNN应用于手写数字识别，取得了显著的成果。
此后，他持续改进CNN架构，并开发了LeNet-5，这是第一个成功的商用卷积神经网络，被广泛应用于支票识别等领域。

## 访谈节选

**主持人卡拉·斯威舍：**
感谢大家来到新的约翰·霍普金斯大学彭博中心参加这次特别的现场对话。我想告诉大家，我们正在为我的播客录制这段对话，所以请大家活跃一点。你们都很活跃。所以，你因在神经网络方面的奠基性工作而被誉为人工智能的教父之一。像你这样一直在这一领域工作的人不多，而这些工作是当今最强大的人工智能系统的基础。

对于不了解的人来说，人工智能已经存在一段时间了，只是现在迎来了爆发时刻。目前，你是Meta的首席科学家，负责监督世界上资金最充足的人工智能研究项目。我们稍后会谈到这一点，但你知道，我们这里即将迎来新一届政府，我必须说，你是我见过的在社交媒体上最有趣的专家。你也是一位非常直言不讳的科学家和个人，我认为你所谈论的是作为一个公民的责任。

我很好奇，为什么你去了Meta这样的地方，而不是像过去那样去一所大型研究型大学或其他地方。你如何看待你的权力？你的影响力是什么？我的意思是，你好像只是一个简单的科学家，在制造……

![](https://mmbiz.qpic.cn/sz_mmbiz_png/ClW8NejCpBNo9Al5YbbYB6Ty5ETxJKDxN9Aw31vhZuGsviawuPb84RHHaRnYk5jRYoFqudVvSmhspQ0RTekgkeg/640?wx_fmt=png&from=appmsg)

  

**杨立昆：**
我也是一位学者。我是纽约大学的教授，我保留了我在纽约大学的职位。大约11年前，就在今天，马克·扎克伯格找到我，他请我为Meta创建一个人工智能研究实验室，因为他有这样的愿景，认为这将产生重大影响和重要意义。他是对的。

我告诉他，我只有三个条件：我不离开纽约，我不辞去我在纽约大学的工作，以及我们所做的所有研究，我们都会公开进行。我们会公开我们所做的一切，我们会开源我们的代码。他的回答是，是，是。第三件事是，你不用担心这个。这在公司的基因里。我们已经开源了我们所有的平台代码。

这不是一个我在其他任何地方都能得到的答案，而这些地方本可以拥有创建研究实验室的资源。我在那里有机会从头开始在行业内创建一个研究机构，并按照我认为正确的方式塑造它。我在这方面有一些经验，因为我的职业生涯始于贝尔实验室，所以我很熟悉如何在行业内进行雄心勃勃的研究。我认为这是最令人兴奋的挑战。

**主持人卡拉·斯威舍：** 最近，许多大型科技公司推出了 LLM 更新或新的人工智能代理或人工智能功能。我想了解一下你目前在 Meta
做的事情。这有点不同。你们发布了 Llama 3.3。对吗？最新的更新。为 MetaEye
提供支持。谈谈它的作用，我会让你将它与其他模型进行比较，并坦诚地说。比如，它与其他模型相比有多好？你是如何看待它的？

**杨立昆：** 各位科学家，我需要坦诚地说。好吧。我的意思是，LLAMA 与大多数其他模型的主要区别在于它是免费和开源的。

**主持人卡拉·斯威舍：** 对，开源。所以，从技术上讲，给可能不理解这意味着什么的人解释一下。

**杨立昆：**
好的，开源软件是指附带源代码的软件。你可以修改它，自己编译它，并免费使用它。在大多数许可协议中，如果你对它进行了一些改进，并想在产品中使用这些改进，你还必须发布你的修改源代码。这使得平台式软件能够非常快速地发展，并且多年来作为分发平台软件的一种方式取得了惊人的成功。整个互联网都运行在开源软件之上。

世界上大多数计算机都运行在 Linux 上。几乎世界上所有的计算机都运行在 Linux 上，除了少数台式机和少数
iPhone。其他的一切，那可是大量的计算机，都运行在 Linux 上。在你的汽车里，在你的 Wi-Fi
路由器里，在你用手机连接的手机信号塔里，以及在你的手机里，如果你没有 iPhone 的话——它们都是 Linux。你的汽车里可能就有十台运行 Linux
的计算机。这非常成功，因为它充当了一个平台。人们需要能够修改它，使其更安全、更可靠，并调整它以在各种硬件上运行。这些修改是市场力量的结果，当涉及到平台时，市场力量自然会推动行业采用开源代码。

现在，对于人工智能来说，一个东西是否是开源的这个问题很复杂，因为构建一个人工智能系统涉及多个步骤。首先，你必须收集训练数据。其次，你需要在该训练数据上训练所谓的“基础模型”。通常，训练代码和训练数据不进行分发。例如，Meta
不分发 LLAMA 模型的训练数据和训练代码。

一旦基础模型被训练出来，你就可以分发它，这就是 LLAMA 的情况。它附带开源代码，允许你运行该系统，并根据需要进行微调，而无需向 Meta
付费或请求许可。但是，由于围绕人工智能系统使用的法律环境，存在一些限制。

**主持人卡拉·斯威舍：** 那么，为什么这样做更好呢？你认为其他的都不好，它们是封闭的系统，它们自己开发。

**杨立昆：** 还有一些其他的开放平台。对，但是那些大的平台呢？那些大的平台是封闭的。是的，来自 OpenAI、Anthropic 和 Google
的那些平台都是封闭的。

**主持人卡拉·斯威舍：** 从你的角度来看，他们为什么选择那样做？

**杨立昆：**
嗯，很可能是为了获得商业优势。如果你想直接从这类产品中获得收入，并且你认为自己在技术上处于领先地位，或者你认为自己可以处于领先地位，而且你的主要收入来源将来自这些服务，那么也许有理由保持它的封闭性。

但 Meta 的情况并非如此。对于 Meta 来说，人工智能工具是整套体验的一部分，所有这些体验都由广告资助。因此，那不是他们主要的收入来源。

另一方面，我们认为这个平台会发展得更快。事实上，我们已经从 LLaMA
上看到了这一点，它更具创新性。有很多我们无法构想的创新，或者我们没有足够的资源去执行的创新，其他人已经实现了，因为他们掌握了 LLaMA
系统，使他们能够进行实验并提出新的想法。

**主持人卡拉·斯威舍：** 那么，其中一个批评是你们落后了，而这是你们赶超的方式。你如何回应这一点？我从你的竞争对手那里听说了。

**杨立昆：** 所以，这一切都有一个有趣的历史，对吧？所以首先，你必须意识到，行业中的每个人，除了谷歌，在构建人工智能系统时都使用一个叫做 PyTorch
的开源软件平台，它最初是在 Meta 开发的。Meta 将它的所有权转让给了 Linux 基金会，所以它现在不再归 Meta
所有。但是，你知道，OpenAI、Anthropic，每个人都使用 PyTorch。所以没有 Meta，就不会有 ChatGPT 和 Claude
以及所有这些东西。不会达到他们今天的程度。在像 ChatGPT 这样的工具中使用的底层技术是在不同的地方发明的。OpenAI
在他们不保密的时候做出了一些贡献。

**主持人卡拉·斯威舍：** 我喜欢你把它加进去的方式，当他们不保密的时候。

**杨立昆：** 当他们不保密的时候，因为他们变得保密了，对吧？他们在过去三年左右的时间里有所攀升。谷歌也在某种程度上有所攀升。但并非完全如此。而
Anthropic 从未公开。所以他们试图秘密地推进这项技术。我认为我们在 Meta，也许我们是一个相当大的研究机构。而且我们还有一个叫做 Gen AI
的应用研究和高级开发机构。该研究机构被称为 FAIR。它过去的意思是 Facebook AI
Research。现在它的意思是基础研究。而我们正在研究的是真正意义上的下一代人工智能系统。因此，超越 LLM，超越大型语言模型，超越聊天机器人。

**主持人卡拉·斯威舍：** 对。所以这是一种叫做 **LCM**
的新型模型，对吗？一个大型概念模型。这只是其中一个特定的部分。解释一下那是什么。我很抱歉这么技术化，以及它与 LLM
有什么不同。大型语言模型是我们正在讨论的。你还说过，自回归 LLM 正在达到性能瓶颈。所以请谈谈这个，因为这是我认为来自 OpenAI 的 Ilya
Sutskever 刚刚说过的。好吧，他不再在 OpenAI 工作了。对。他离开了，对吗？好吧，这就是所有离开 OpenAI 并创办自己公司的人的情况。

**杨立昆：** 是的，现在我想它被称为安全超智能。对。是的，所以这是一个有趣的概念。过去有些人认为，你可以使用像
ChatGPT、MetaEye、Gemini 这样的
LLM，然后将它们放大，用更多的计算能力在更多的数据上训练它们，某种程度上人类水平的智能就会从中涌现出来。我从来不相信这个概念。Ilya
曾经是这个概念的坚定信徒，但现在，显然，不再是了。

**主持人卡拉·斯威舍：** 对。我们已经到达了尽头，没有更多了。

**杨立昆：** 对，很明显，**我们正在达到这些系统性能的上限，因为我们基本上用尽了自然数据。互联网上所有公开可用的文本目前都被用来训练所有这些
LLM，而我们不能获得更多的数据。所以人们正在生成合成数据和诸如此类的事情，但是我们不会将此提高 10 或 100 倍。所以它正在达到饱和。**

我们正在研究的是基本上不基于仅预测下一个单词的下一代人工智能系统。LLM 被称为大型语言模型，因为它基本上被训练为仅预测文本中的下一个单词。你通常收集大约
20
万亿个单词，大约是这个数量级的。这就是互联网上所有公开可用的文本，经过一些过滤。你用数十亿或数千亿个可调参数训练一些庞大的神经网络，只是为了预测下一个单词。给定一个几千个单词的序列，你能预测下一个将出现的单词吗？

你永远无法完全做到这一点，但是这些系统所做的是，它们基本上预测单词的概率分布，然后你可以使用该概率分布来生成文本。这就是它的自回归部分，对吧？你给系统一个单词序列，它预测下一个单词，然后你将其移到输入中，所以现在它是它自己的输出，对吧？现在你可以让它预测下一个单词。将其移入，第三个单词，将其移入，第四个单词。它们都是这样工作的。

现在，不能保证生成的任何单词序列都有意义，或者不会产生虚构，或者编造东西，对吧？所以，很多行业一直在努力的是基本上微调这些系统，在人的参与下训练它们来执行特定的任务，而不是产生无意义的东西。此外，这些系统需要查询数据库或搜索引擎，而它们实际上不知道答案。这需要系统能够检测它们是否知道答案，然后可能生成多个答案并选择哪些是好的答案。

但最终，这并不是未来人工智能系统的工作方式。

**主持人卡拉·斯威舍：** 那就说说这个吧。 我和很多人聊过，他们都用到了“智能体”这个概念。 是的。 我觉得萨蒂亚·纳德拉是最早听到这个概念的人。
上周，Meta 发布了 Meta Motivo。 它的目的是制作更逼真的数字虚拟形象，因为我理解。 我感觉这就像马克在试图重振元宇宙，让它再次流行起来。
但是说说它到底是什么吧。 我不太理解，因为你们在所有这些事情上都投入了大量资金。 是的，很多钱。 为了做出人们愿意购买的东西，对吧？
而不仅仅是为了更好地做广告。 你们必须有一个比这更大的目标。

**杨立昆：** 好的，我来告诉你一个秘密。 我现在正戴着智能眼镜。很酷，对吧？ 它有摄像头。 是的。 如果你微笑，就可以给你们拍照。

**主持人卡拉·斯威舍：** 是的。 我们已经发展到这个地步了。 我有最早的几副谷歌眼镜之一，但那标准很低。

**杨立昆：** 比那好多了。 现在，关键在于。
最终，我们将会在工作中，你知道，我们说的是五到十年后，我们将会使用智能眼镜，也许还有其他智能设备，它们都将配备人工智能助手。 这个眼镜就有一个。
我可以通过这个与 Meta AI 对话，对吧？ 这些东西将在我们的日常生活中帮助我们。

我们需要这些系统拥有本质上类人的智能，人类级别的智能，或者在很多方面甚至可能拥有超人的智能。 那么，我们如何达到这个目标呢？ 我们离这个目标还很遥远。
一些人让我们相信我们已经非常接近他们所说的 AGI，通用人工智能。 然而，我们实际上离它还很远。 我说很远，指的不是几个世纪。
可能不是几十年，但也要好几年。

判断的标准是，我们目前能够执行的任务类型。 我们有大型语言模型（LLM），可以通过律师资格考试或其他大学考试。
但是，我们的家用机器人呢？可以清洁房屋、清理餐桌、并将餐具放入洗碗机的那种？ 我们没有。 这不是因为我们不能制造机器人；而是因为我们无法使它们足够智能。
我们无法让它们理解物理世界。

事实证明，对于人工智能系统来说，理解物理世界比理解语言要困难得多。 语言相对简单。 我的意思是，人类会认为语言是智能的顶峰，这有点违反直觉。
它实际上很简单，因为它只是一系列离散的符号，我们可以处理它。 然而，真实世界要复杂得多。

**我们正在研究的，基本上是新的架构和新的系统，它们能够理解物理世界，并学习像婴儿和幼年动物那样通过观察世界和在其中行动来感知它。**
这些系统最终将能够规划行动序列，以实现特定目标。 这就是我们所说的“智能体”。 因此，智能体系统是指能够规划一系列行动以达到特定结果的系统。

目前，大家都在谈论的智能体系统实际上并没有执行这种规划。 它们有点作弊； 它们可以学习计划的模板。

**主持人卡拉·斯威舍：** 对，但它们不能真正做到。 你还在 Meta 开发的 AI 搜索引擎方面负责信息报告。
所以，我想你希望超越谷歌搜索，这是真的吗？你认为这很重要吗？

**杨立昆：** 嗯，你想要对话的智能助手的一个组成部分，显然是搜索。 你想要搜索事实，并链接到事实的来源，以便与你交谈的人相信结果。 因此，搜索引擎是整体
AI 系统的一个组成部分。

**主持人卡拉·斯威舍：** 并且可以绕过谷歌系统，大概是这样。

**杨立昆：** 嗯，我的意思是，目标不一定是直接与谷歌竞争，而是服务于那些想要 AI 系统的人。

**主持人卡拉·斯威舍：** 那么，你想象它会用来做什么呢？ 因为大多数人认为Meta在人工智能竞赛中落后了，尤其是在围绕ChatGPT的所有炒作之后。
但马克·扎克伯格刚说过，它有近6亿月活跃用户，并有望在年底成为全球使用最广泛的 AI。 这与人们在 ChatGPT 上所做的事情非常不同，ChatGPT
是一个独立的应用程序或用于搜索。 因此，除了让广告更有效率之外，它对你来说，对Meta来说，是用来做什么的？
对Meta意味着什么？我知道马克谈论过这个，但从你的角度和 Meta 的角度来看，它是用来做什么的？

**杨立昆：** 它是对未来的展望，每个人都会随时随地拥有一个 AI 助手。 它将彻底，我的意思是，这是一个新的计算平台，对吧？
我的意思是，以前我们称之为元宇宙。 但是，我的意思是，那些眼镜最终会有显示器，增强现实显示器。 我的意思是，最近展示的猎户座项目已经有这方面的演示了。
我们现在还不能以足够低的价格制造它们，所以我们还不能出售它们。 但最终它们会出现的。 所以这就是愿景，那个长远愿景。

**主持人卡拉·斯威舍：** 为了成为我们的健康助手。

**杨立昆：** 会是我们的助手。 或者帮手。 我的意思是，这就像每个人都会身边有一个虚拟助手，基本上就像一个人类助手。
或者最终会有一批非常聪明的人，也许比你更聪明的人，为你工作。

**主持人卡拉·斯威舍：** 这很棒，但现在，人类助手要便宜得多，我想说。 现在，**Meta 预计将花费 380 亿美元到 400 亿美元。
谷歌表示，它今年的支出将超过 510 亿美元。 分析师预测，微软的支出将接近 900 亿美元** 。 花费太多了吗？
马克·贝尼奥夫最近告诉我，这是一场竞相触底的竞赛。 你担心被花钱比下去吗？ 为了给我一个更聪明的助手，这似乎不是一个好生意，但我不知道。 我早年被邀请去
Facebook 工作的时候，我没有接受这份工作，所以别问我。 但请继续。

**杨立昆：** 嗯，这是一项长期投资。 我的意思是，你需要基础设施，以便能够为越来越多的人以合理的速度运行这些 AI 助手。 正如你所说，现在有 6
亿人正在使用 Meta AI。 顺便说一句，还有一个有趣的数字。Meta AI 构建在其上的开源引擎 Llama，已被下载 6.5 亿次。
这是一个惊人的数字。 顺便说一下，我不知道这些人都是谁。 但这是一个惊人的数字。 有 85,000 个项目是从 Llama
衍生出来的，这些项目是公开的或开源的。 这些项目大多在世界各地，很多项目基本上都在训练 Llama，例如，让它说塞内加尔或印度的多种语言。

**主持人卡拉·斯威舍：** 所以你不认为这笔钱花错地方了吗？

**杨立昆：** 不，我不这么认为，因为在未来一两年内，将会有非常多的人每天都会使用这些 AI 系统，而且这个数字还会增长。
而且，如果这些系统更强大，它们就更有用。 它们越强大，计算成本就越高。 因此，这项投资是对基础设施的投资。

**主持人卡拉·斯威舍：**
在基础设施方面，私人公司正在做些什么。现在，你说少数几家公司掌握着专有的顶尖模型，这显然是一个巨大的危险。同时，也有人批评开源模式。他们担心不良行为者可能会利用这些模型传播虚假信息，进行网络战，或者发动生物恐怖袭击。请谈谈两者之间的区别。考虑到你们以开源的方式提供这些强大的工具，Meta在防止这种情况发生方面是否应该发挥作用？

**杨立昆：**
好的，这是一个巨大的争议。确实如此。你知道，直到最近，也就是2023年初，我们开始分发Llama的时候，第一个Llama模型并不是开源的。你必须先申请许可，并证明你是一名研究人员。这是因为当时法律环境尚不明确，我们不知道人们会用它来做什么。所以它不是开源的。

但是，后来Meta内部收到了来自业界的很多请求，他们说我们必须开源下一个版本，因为这将创造一个完整的产业，能够促进大量初创企业和新产品的诞生。因此，我们进行了数月的内部讨论，每周开会两次，每次持续两个小时，涉及包括马克·扎克伯格在内的40个人。这些是非常严肃的讨论，内容包括安全性、法律环境以及各种各样的问题。

在某个时候，马克做出了决定，他说：“好吧，我们要开源Llama
2。告诉我该怎么做。”这个决定是在2023年夏天做出的。从那时起，它基本上完全推动了整个行业的发展。

**主持人卡拉·斯威舍：** 为什么它比那些由公司控制的专有模型更安全？

**杨立昆：**
因为有更多人关注它。因此，有更多的人在为各种各样的事情对其进行微调。所以问题在于，可能会有很多心怀恶意的人接触到它，然后将其用于不正当的目的。但也可以带来许多优秀的开源模型，比如有一个叫做Qwen（通义千问）的模型，就非常好，可以和最好的模型相媲美。我的意思是，中国有很好的研究、很好的工程师，他们开源了很多自己的模型。

**主持人卡拉·斯威舍：** 你不认为这是Meta的责任吗？你们发布了工具，然后人们会用它来做什么？

**杨立昆：**
不，在某种程度上，当然是。因此，Llama团队和GNI组织正在努力对我们发布的所有系统进行红队测试，以确保它们至少在发布时是最低限度的无毒且相对安全的。这实际上是一项非常重要的工作。我们甚至最初在DEF
CON大会上将Llama
2交给了一群黑客，并要求他们尝试用它来做一些坏事。太棒了。比如尝试入侵系统之类的。我的意思是，你必须这样做，让我们来做白帽测试。结果是，我们还没有发现任何我们分发的模型被用于真正糟糕的事情。

**主持人卡拉·斯威舍：** 快两年了。这可能是我对这件事的概括。

**杨立昆：**
嗯，是的，但你知道，如果真的会发生，早就发生了。我的意思是，在ChatGPT出现之前，开源的LLM已经存在很多年了，公众可能没有意识到这一点，因为他们认为它只是随着ChatGPT突然出现的。

我不知道你是否还记得，当OpenAI推出GPT-2时，他们说他们不会开源它，因为它非常危险。他们担心人们会做一些非常糟糕的事情，比如用虚假信息淹没互联网，所以他们决定不开源它。我当时嘲笑了他们，因为这有点可笑；该系统的能力真的没有那么糟糕。

所以，我的意思是，你必须接受这样一个事实，即这些东西已经存在好几年了，而且没有发生真正糟糕的事情。有人担心人们会利用它传播虚假信息，尤其是在美国大选前夕。我的意思是，今年世界上有三次重大选举，还有各种各样的事情，比如网络攻击。但这些实际上都没有发生。

**主持人卡拉·斯威舍：** 仍然需要对这些事情保持警惕。

**杨立昆：**
嗯，我的意思是，你必须保持警惕，尽你所能阻止这些事情发生。但关键是，你知道，你不需要任何这些人工智能系统来传播这些信息，正如Twitter向我们展示的那样。

**主持人卡拉·斯威舍：**
嗯哼。好的。很好。我喜欢你偶尔讽刺一下。我一直在密切关注。你讽刺了伊隆，还有OpenAI那些神秘兮兮的“戏剧女王”。我注意到了。你最近在网上也受到了很多批评，因为你说文化机构、图书馆和基金会应该将其内容提供给像Llama这样的免费和开源人工智能基础模型进行训练。据推测，你是在回应哈佛大学发布的一个新的数据集，其中包含超过一百万本书，但这些书是公共领域的作品，而不是在世的作家、艺术家和学者的作品。请谈谈人们的担忧以及你因此受到的批评，关于这些人工智能模型会吸走我们所有的文化知识，而创作者、作家和研究人员却得不到任何认可。我的意思是，众所周知，互联网公司会进行数据抓取，我认为沃尔特曾说过，我记得以前的Facebook被称为“贪婪的信息窃贼”，但他可能说的是谷歌。所以请跟我谈谈这件事，谈谈所发生的争议。

**杨立昆：**
好的。抛开所有这些法律问题不谈，如果你设想人工智能将成为所有人类知识的存储库，那么所有人类知识都必须可以用来训练这些模型，对吧？而其中大部分要么没有数字化，要么数字化了但没有公开。这不一定是受版权保护的材料。它可能是，你知道，法国国家图书馆的全部内容，其中很多已经数字化，但不能用于训练。所以我在那种情况下不一定是谈论受版权保护的作品。

这更像是，你知道，我来自我的家庭；我父亲的家人来自法国西部的布列塔尼，对吧？那里使用的传统语言，直到我的曾祖父还在使用，是布列塔尼语。布列塔尼语正在消失。每天说这种语言的人大约有3万，非常少。如果你希望未来的LLM能够说布列塔尼语，那么就需要有足够的布列塔尼语训练数据。你从哪里获得这些数据呢？

你将需要文化非营利组织，你知道的，他们会收集他们拥有的所有东西，也许政府会提供帮助，诸如此类的事情。他们会说，比如，使用我的数据。比如，我希望你的系统能说布列塔尼语。现在，他们可能不想仅仅把这些数据交给美国西海岸的大公司。

但我设想的未来——这不是公司政策；这只是我的观点——实现这一目标的最佳方式是通过以分布式的方式训练人工智能系统，一个通用的人工智能系统，一个人类知识的存储库。这样，世界上就会有多个数据中心，使用本地数据来帮助训练一个全球系统。

**主持人卡拉·斯威舍：** 但是谁来运行这个全球系统？

**杨立昆：** 谁编写Linux？

**主持人卡拉·斯威舍：** 是的，所以它应该为全人类而存在。

**杨立昆：** 嗯，我的意思是，谁会为维基百科付费呢，对吧？

**主持人卡拉·斯威舍：** 我每月付7美元。

**杨立昆：**
对，好主意。或者互联网档案，对吧？所以对于Linux，实际上，Linux主要由公司员工支持，他们被告知要实际贡献他们的成果。你可以有一个类似的系统，每个人都为这种全球模型做出贡献。

**主持人卡拉·斯威舍：** 这就是人人都能使用的AI。

**杨立昆：**
也就是短期内人人都能使用的AI，你知道，大语言模型。那些不一定能盈利的东西。嗯，你可以在此基础上盈利，对吧？我的意思是，你不用为Linux付费，但如果你购买一个运行Linux的设备，比如安卓手机或一辆触摸屏有Linux系统的汽车，你就要为购买的设备付费。AI也会是这样。人们可以这样做。基础模型将会是，哦，开放且免费。

**主持人卡拉·斯威舍：** 感觉像是少量权力在运行一切。现在确实是这样。这个愿景很美好，但它并没有发生。

**杨立昆：** 嗯，在我看来，这实际上是不可避免的。

**主持人卡拉·斯威舍：**
不可避免。好吧。说到辩论，这很有意思。你参加过公开辩论。你喜欢和其他AI教父辩论。你的图灵奖共同得主，杰弗里·辛顿，还有我认为是约书亚·本吉奥。是的。他们都敲响了警钟，警告AI的潜在危险，可以说非常戏剧化。他们呼吁更严格的政府监管，包括研发。

你称他们的警告完全是胡说八道。我认为你没有含糊其辞。跟我说说为什么这是胡说八道。你不同意的一件事是美国最早的AI监管尝试之一，加州SB
1047法案。辛顿和本吉奥都支持它，但你游说反对它。你写道，监管研发将对AI系统产生灾难性后果。先生，你真是太戏剧化了。

你说，对生存风险的幻想是由少数，引述“妄想的智库”推动的。我不认为这两个人是妄想的。辛顿刚刚因他的工作获得了诺贝尔奖。特别谈谈这个问题。顺便说一句，州长纽森否决了该法案，但正在与斯坦福大学教授李飞飞等人合作进行修订。分享一下你为什么称他们的警告是胡说八道。你在这个问题上的立场非常坚定。

**杨立昆：**
是的，我对此非常直言不讳。杰夫和约书亚都是我的好朋友。我们已经做了几十年的朋友。我于1987、88年和杰夫·辛顿一起做了博士后。所以我们认识很久了，现在已经40年了。约书亚也是。我第一次见到他时，他还是个硕士生，而我是一名博士后。所以我们一直都在一起工作。我们一起获得了这个奖项，因为我们共同致力于复兴我们现在称之为深度学习的兴趣，这也是当今许多AI技术的基础。所以我们在很多事情上达成了一致。我们在一些事情上存在分歧，这就是其中之一。

**主持人卡拉·斯威舍：** 对人类的生存威胁。

**杨立昆：**
我的意思是，杰夫认为当前的大语言模型具有主观体验。我完全不同意这一点。我认为他在这个问题上完全错了。我们以前在技术问题上存在分歧。当时不那么公开，更多是技术上的。但这并不是我们第一次意见不合。我只是认为他错了。我们仍然是好朋友。约书亚的观点略有不同。他有点担心这个问题，但更担心坏人利用AI系统做坏事。是的，我同意他说的。开发生物武器或化学武器之类的东西。坦率地说，这些危险已经被构思了很多年了，而且被极度夸大了，以至于被扭曲得不成样子，以至于它们真的没有意义了。

**主持人卡拉·斯威舍：** 是的，妄想是这个词。

**杨立昆：** 嗯，我不是说他们妄想。我称那些更极端的人，那些推动像SB
1047这样的监管的人，是妄想的。我的意思是，有些人会当面告诉你，比如一年前，你问他们，AI要多久才能杀死我们所有人？他们会说，比如，五个月。显然，他们错了。

**主持人卡拉·斯威舍：**
嗯哼。所以这就是你说的。这是关于AGI，通用人工智能，以及我们离它有多近。我想让你为人们解释一下。当他们听到它时，他们会想到《终结者》或《我，机器人》之类的剧情。所以辛顿和本吉奥认为AGI的时间线可能更像五年，而我们还没有做好准备。你说几年，如果不是十年。你知道，如果你错了，当它真的杀死我们时，你就会真的大错特错。所以，说说你为什么一点也不担心，因为很多人在这个问题上不同意你的观点。

**杨立昆：** 不，实际上更多的人同意这个观点，

**主持人卡拉·斯威舍：** 比不同意的人多。我说的是顶层的人。

**杨立昆：** 不，只是那些不同意的人，你知道，显然非常害怕，所以变得非常直言不讳。如果你认为存在某种生存风险，我当然也会非常直言不讳，并试图提醒所有人。

**主持人卡拉·斯威舍：**
对，所以你为什么不呢，我的意思是，我理解你的意思。有人转向我说，如果我不阻止山姆·奥特曼，全人类都将注定灭亡。我觉得他们，我说，那是《终结者》的剧情，我不是琳达·汉密尔顿，所以不行。但是说说你为什么不担心。

**杨立昆：**
好的，首先，毫无疑问，在未来的某个时候，我们将拥有比我们更聪明的AI系统。这将会发生。是五年，十年，二十年？这真的很难说。在我个人的看法中，它最早可能在五年、六年左右发生。但可能更像十年，甚至更长，因为它比我们想象的要难。在AI的几十年历史中，人们完全低估了它的复杂性。

此外，我们仍然没有自动机器人。我们没有5级自动驾驶汽车。我们今天有很多事情不知道如何用AI系统来做。在我们找到一套新的技术来朝着人类水平的智能迈进之前，我们还没有走上实现它的道路。几年后，一旦我们有了一个蓝图，并且有一些可信的演示表明了一条通向人类水平AI的潜在路径，我们就可以开始考虑安全措施。

我不喜欢称其为AGI，因为人类智能实际上非常专业化。我们常常认为我们拥有通用智能，但我们没有。一旦我们有了一个蓝图，我们就会有一个结构化的方法来确保安全。这有点类似于20世纪20年代，当时有人提出，在几十年后，我们将以接近音速的速度运送数百万人飞越大西洋。

有人会说，哦，我的天，你要怎么让它安全？涡轮喷气发动机还没有发明出来。如果你还没有发明涡轮喷气发动机，你又怎么能让涡轮喷气发动机安全呢？我们今天就处于这种情况。而且涡轮喷气发动机的设计并不是为了不安全。我的意思是，涡轮喷气发动机的可靠性令人难以置信，对吧？最近公布的一项统计数据显示，**自上次致命事故以来，人们乘坐美国航空公司飞行的总距离为2.3光年。这是一个惊人的数字。它非常安全**
。所以，你知道，使AI安全意味着以安全的方式设计这些AI系统。但是，在我们有一个设计之前，我们将无法使它们安全。所以问题是...

**主持人卡拉·斯威舍：**
你知道，这说不通。你似乎并不担心人工智能会想要统治人类。你这么说过。你谈过这个想法。我最近做了一个关于谷歌角色AI的节目，因为一位母亲的儿子因AI代理非常不寻常而自杀身亡。但你说过，目前的人工智能比家猫还笨。如果它感觉真实，人工智能是否被发送似乎并不重要，对吧？那么，如果它是笨的，或者它不想统治我们，或者它不想杀死我们，那么你认为对人工智能，以及可能对人工智能研发的限制是什么是合理的，如果有的话？我想你似乎是在说，没有限制。

**杨立昆：**
嗯，研发方面没有。我的意思是，很明显，如果你想推出一个家用机器人，而这个机器人可以为你做饭，你可能需要硬性规定一些规则，这样当周围有人，而机器人手里拿着刀时，它不会乱挥手臂之类的。所以，你知道，这些是安全防护措施。目前人工智能系统的设计，在某种程度上，本质上是不安全的。你可以这样说：很多人，我承认，会讨厌我这么说，但它们有点难以控制。你基本上必须训练它们才能表现得当。

你想要的是，这也是我提出的，另一种架构，我称之为目标驱动型，其中人工智能系统基本上是为了实现一个目标而存在的，除了实现这个目标之外，不能做任何其他事情，并且受一些安全防护措施的约束，这些安全防护措施只是其他目标。这种方法将保证系统产生的任何输出，它采取的任何行动，都满足这些安全防护措施和目标，并且是安全的。

现在，下一个问题是我们如何设计这些目标？很多人都在说，“哦，我们以前从未做过这个。这是全新的。我们必须创造一门新的科学。”
不，实际上，我们对这个很熟悉。它叫做制定法律。我们对人类也这样做。我们制定法律，而法律基本上改变了采取行动的成本，对吧？所以我们一直在通过制定法律来塑造人类的行为。我们将对人工智能系统做同样的事情。

不同之处在于，人类可以选择不遵守法律，而人工智能系统，通过构建，必须遵守。它没有选择。

**主持人卡拉·斯威舍：**
你会把法律放进去。但是现在，这两位，辛顿和本吉，都认可了一封由现任和前任OpenAI员工签署的信，呼吁人工智能公司的员工有权警告这些技术的严重风险，而普通举报人无法保护他们。你没有认可它。与此同时，我们在欧盟看到了一些监管。他们区分了高风险人工智能系统和更通用的模型。他们禁止某些“威胁公民权利”的应用，比如面部图像，我想也包括想要用刀袭击你的机器人。这里的模式是什么，为了让它更安全，为了让人们……你建议我们等到坏事发生后再设置安全防护措施。让我们等到发生一些谋杀案或什么的时候吗？

**杨立昆：** 我不能说。不，不，我不是这个意思。我的意思是，你知道，像禁止在公共场所大规模进行面部识别这样的措施，是件好事。

所以，有一些这样的措施是完全合理的，但它们处于产品层面。你知道，也比如，改变某人的一些尴尬视频中的脸之类的。我的意思是，它或多或少已经是合法的了。我们拥有这样做的工具的事实并没有使其不那么非法。可能需要制定针对此的特定规则，但我对此没有意见。

你知道，我对这种认为人工智能本质上是危险的，并且需要监管研发的想法有意见。我认为这会适得其反的原因是，在未来，你会有我所说的那些开源平台，我认为这些平台对于未来的民主之类的东西是必要的。那么这些规则就会适得其反。它们基本上会使开源对于任何公司来说都太危险而无法分发。

**主持人卡拉·斯威舍：** 这样这些私营公司就会控制一切。

**杨立昆：**
是的。少数位于美国西海岸的私营公司控制一切。现在，和美国以外的任何政府谈谈，告诉他们，在未来，每个人的数字信息都将由人工智能助手来管理。并告诉他们，这将来自美国西海岸的三家公司。他们会说，这完全不可接受。这就像民主的死亡。如果一切都来自美国西海岸的三家公司，人们如何获得多元化的意见，对吧？我们都有相同的文化，我们都说同一种语言。这完全不可接受。所以他们想要的是开放平台，然后可以针对任何文化、价值体系、兴趣中心等等进行微调，以便世界各地的用户都有选择。他们不必使用三个助手。他们可以使用...

**主持人卡拉·斯威舍：**
所以你担心OpenAI、微软、谷歌，可能还有亚马逊，以及Anthropic（实际上也是亚马逊）的统治。最后两个问题，我们可以回答观众的几个快速问题。你因对深度学习的变革性贡献而被授予了2024年VIN未来奖。在你的获奖感言中，你说人工智能不像人类或动物那样学习，后者会从物理世界中吸收大量的视觉观察。

但是你一直在努力实现这一点，而且你已经谈论这件事很久了。我想了解你在做什么，因为你还说过，人工智能末日论者是末日论者，因为他们不相信人本质上是善良的，而你相信，尽管从你的推特信息中看不出来。

我们为什么要认为人们在这些事情上本质上是善良的，而且你认为人工智能在未来几年会发展成什么样子？它会更像人类或动物，还是完全不同的东西？

**杨立昆：**
嗯，是的，我的意思是，在某个时候，我们将拥有一些系统，它们会像人类和动物一样学习，并且可以像人类和动物一样高效地学习新技能和新任务，这坦率地说，是非常惊人的速度。我们无法用机器重现这一点，对吧？我们有像特斯拉这样的公司，还有其他公司有数十万甚至数百万小时的人类驾驶汽车的记录。他们可以用这个来训练人工智能系统，他们也确实在这样做。但它们仍然不如人类好。

我们没有，是的，我们不能买一辆真正可以自动驾驶的汽车，或者一辆无人驾驶出租车，除非我们作弊。像Waymo可以做到，但是有很多技巧在里面。而且，我们不能买一个家用机器人，因为我们无法让它们足够聪明。原因很简单。正如我之前所说，我们用所有公开的文本以及其他一些文本来训练大型语言模型和聊天机器人。大约是20万亿个单词，大概。每个单词用三个字节表示，所以大约是60万亿个单词。这是一个6后面跟着13个零。让我们把它四舍五入到10的14次方，1后面跟着14个零。

现在，和发展心理学家谈谈。一位心理学家会告诉你，一个四岁的孩子总共清醒了16000个小时。在这16000个小时里，视觉信息以大约每秒2兆字节的速度到达孩子的大脑视觉皮层。计算方法是，我们有100万个视神经纤维，每个纤维大约每秒传输1个字节。我们有两只眼睛，所以大约是每秒2兆字节。计算一下：16000小时的这个，你会得到10的14次方字节。这和数据量是相同的，对吧？

但是如果一个四岁的孩子通过视觉看到的数据量基本上与最大的大型语言模型通过文本看到的数据量相同，那么阅读这些文本将需要我们任何人花费数十万年的时间。因此，这告诉你，我们永远无法通过仅仅训练文本来达到人类级别的人工智能。我们必须训练感官输入，这基本上是无限的供应。

16000小时的视频相当于30分钟的YouTube上传。我们有太多的视频数据，我们都不知道如何处理。因此，未来几年人工智能要想取得下一个层次的进展，最大的挑战是让系统通过观察世界的运行，观看视频，然后在世界中互动，来理解世界是如何运作的。这个问题尚未解决，但是你知道，未来五年内很有可能取得重大进展。

这就是为什么你看到所有这些公司开始制造人形机器人的原因。他们还不能让它们足够聪明，但他们指望人工智能在未来五年内取得足够的进展，以便在这些东西可以卖给公众时，人工智能将足够强大。

**主持人卡拉·斯威舍：**
好的，我现在要戴上眼镜了。我终于明白你们的用意了。说实话，我宁愿相信一个四岁小孩，也不愿相信硅谷的大部分人。好了，现在快速进入观众提问环节。我们有提问吗？

**现场提问者：**
迈克尔·罗宾斯，很高兴在领英上与您有过一些互动，谢谢。我想知道，当您谈到治理时，我看到您戴着眼镜，我最关心的事情之一是人工智能、空间计算和环境技术交叉领域的治理。您能否谈谈您认为这个领域会是什么样子，以及我们在构建这方面的治理时需要期待什么？

**杨立昆：**
好的，我再次强调，我不是产品方面的人，也不是政策方面的人。我主要做人工智能的基础研究。但是，你知道，你之前提到的谷歌眼镜基本上失败了，因为人们对这种社交互动感到不舒服。奇怪的是，现在这些东西并没有引起类似的争议。现在，当你拍照时，会有一个小灯亮起，所以我不能在你背后拍照。这和你用智能手机拍照没什么区别。

不，我不会做这种事。我在做之前会告诉别人。你看起来很熟练。好的，当然。所以，我无法针对具体案例发表评论。我的确非常不赞成在公共场所进行大规模人脸识别之类的行为，我认为这是对隐私的侵犯。还有各种类似的事情，但我没有灵丹妙药。

**现场提问者：**
好的，非常有意思。鉴于我对认知科学的初步理解，我真正感兴趣的是为理解AGI（通用人工智能）的主观性奠定基础。AGI在什么时间点，更重要的是，如何真正获得类似人类的意识，而不仅仅是在人类的时间尺度上处理信息？

**杨立昆：**
好的，我接下来要说一些可能有点挑衅的话。在我们设想并计划在未来几年构建的AI系统的愿景或蓝图中，这些AI系统将拥有情感。这基本上是这些系统设计中不可分割的一部分。

它们为什么会有情感？因为它们将由目标驱动。你给它们一个必须完成的目标、一个任务，它们的目的就是在硬编码到它们设计中的约束条件下完成这项任务。为了做到这一点，它们需要一些组件。

它们需要的第一个组件是确定我们给它们的目标是否已经完成的方法——这个目标。它们还需要我们称之为世界模型的东西。世界模型是我们在前额叶皮层中都拥有的东西，它使我们能够想象我们行动的后果是什么，并使我们能够计划一系列行动来实现特定目标。

如果你拥有预先预测一系列行动将会产生什么结果的能力，那么你就可以预测目标是否会被满足。这种能力使你能够预测结果是好还是坏。如果你预见到不好的结果，你会感到恐惧。相反，如果你预测到积极的结果，你会感到更像欣快。

因此，预测能力以及以实现这些预测的方式行动会产生等同于情感的东西。因此，足够聪明、能够推理和计划，并拥有世界模型的AI系统，确实会拥有情感。

**主持人卡拉·斯威舍：** 这很具有挑衅性。好的，抱歉，我们必须快速完成最后两个问题。请讲，抱歉。

**现场提问者：** 我是克里斯·麦克雷，我想知道您能否谈谈一两个积极的例子。例如，我们没有谈论AI
AlphaFold，这在医学院有点令人惊讶。或者如果我们回到最近的Llama 3，Jensen
Huang（黄仁勋）和印度的安巴尼，基本上安巴尼说，如果没有看到Llama
3，他就不可能制定出任何关于印度教育的计划。所以，为学生和教师提供辅导机构可能会很有趣。

**杨立昆：** 是的，Llama
3，或者我指的是整个Llama系列，因为它开源，它所实现的一件事就是让人们可以根据自己的需要微调它，使其能够为特定的垂直应用或特定语言服务。例如，我们一位在塞内加尔的前同事拥有一家公司，该公司使用一个可以用法语、沃洛夫语和其他六种当地语言进行交流的聊天机器人提供医疗帮助。

是的，我们正在与印度的几个组织合作，以便下一个版本的Llama可以使用印度全部22或29种官方语言。这甚至没有涵盖整个印度。它覆盖了95%的地区，但在印度使用的700种语言中，大多数没有书写形式，对吧？它们纯粹是口头语言。我们现在拥有的技术允许聊天机器人处理仅有口头形式的语言，这令人震惊。

你知道，我上周刚去越南参加这个奖项颁奖。这方面也有类似的努力，希望能够使用越南语，我们在世界各地都看到了这种情况。人们只是在微调这些模型，并将它们用于一些坦率地说我们不知道可能的事情。

因此，我认为我们需要一种更有计划性的全球合作关系，以便这些系统从一开始，作为基础模型，就可以使用世界上所有的语言，并理解所有的文化。因为这样一来，为各种应用构建专门系统的工作就更容易成功了。

我们把这些眼镜给了印度农村的人们，他们非常喜欢它。他们可以用自己的语言提问。例如，农民可以看着一种植物，如果这种植物患有疾病，他们可以问他们的AI助手：“看看这个，告诉我这是什么病，我该如何治疗它，一周后的天气会是什么样”，等等。

**主持人卡拉·斯威舍：** 可能会，因为这有点像他们一开始谈论的那样。一切都会向上发展。我当时在那里，我相信这一点。但有些事情并没有那样发展，对吧？

**杨立昆：** 什么？哪一部分？

**主持人卡拉·斯威舍：** 很多。那么我来问最后一个问题。然后我们就必须结束了。

**现场提问者：**
是的，您多次提到分布式系统，基本上是为了达到人类水平的人工智能。我之所以问这个问题，是因为我今年花了几乎一年的时间来训练人工智能模型，包括开源和闭源的。它们在英语和其他一些语言方面表现非常好。但上周我去约旦时，发现ChatGPT和其他大型语言模型真的很糟糕。而且，我感觉我向人们夸大了，比如“哦，这将解决世界问题”。您认为这会如何实现？

**杨立昆：**
嗯，我通过这种分布式的方式来看待这个问题。你引用的那条推文的目的是传达这样一个想法，即世界各地的人们聚集在一起采取行动。如果他们有能力，他们可以建立本地数据中心，特别是以人工智能为中心的数据中心。在这个倡议中，政府可能会发挥重要作用，但私营企业也会发挥作用。

此外，目标是收集所有对布列塔尼语和世界各地其他语言有用的文化材料。重要的是，人们已经在参与类似的努力。实际上，MBZ大学人工智能在阿布扎比昨天甚至今天发布了一个Llama
3的衍生模型。

他们所做的是对Llama
3进行微调，使其能够使用阿拉伯语（特别是阿联酋的变体）进行交流，并提供医疗帮助。这项发展值得关注，因为它是一个能够分析医学图像的多模态系统。显然，之所以能够开展这些举措，是因为该技术是开源的。

**主持人卡拉·斯威舍：**
正如我刚才说的，我见过像你这样的人。这是我最后一个问题，而且会很快，因为我们得走了。谁会喜欢这个呢？它将改变学习方式，它将改变这一切。它会让一切都变得更好，每个人都会相处融洽。正如你一直引用的，我很敬佩你这一点，我们有仇恨、有功能失调、有孤独感、女孩们自尊心低下、弱势群体面临危险，还有我们政府被亿万富翁控制。这次我为什么要信任你？

**杨立昆：** 好的。我不是亿万富翁。不是亿万富翁。这不是首要的。不过，我过得还不错。

**主持人卡拉·斯威舍：** 我猜你是的。

**杨立昆：**
好吧，我首先是一名科学家。我除非拥有某种程度的正直，至少是科学上的正直，否则我没法面对镜子里的自己。我可能会犯错，所以你可以相信我没有对你撒谎，我不是出于诸如贪婪之类的邪恶动机，但我可能错了。我很有可能犯错，事实上，这正是科学的整个过程，你必须接受你可能会犯错的事实，而正确想法的产生源于多种观点和持不同意见的人们的碰撞。但是，你知道，看看证据。

我们看看那些说人工智能会摧毁社会的人的证据，因为我们会被虚假信息或生成的仇恨言论淹没，或者诸如此类的东西。我们根本没有看到这种情况，我们没有看到。我的意思是，人们会制造仇恨言论，人们会制造虚假信息，他们会想方设法地传播它们。

我给你讲讲关于Facebook的统计数据。很多人试图在Facebook上传播仇恨言论，而这违反了Facebook的内容政策。现在，我们对抗这种情况最好的保护措施是人工智能系统。比如在2017年，我们做不到这一点。

在2017年，人工智能技术还不够好，不足以让Facebook和Instagram检测出世界上每种语言的仇恨言论。当时，Facebook上由人工智能系统自动删除的仇恨言论比例约为23%。到了2022年底，五年后，这个比例达到了95%。

这中间发生的是人工智能的进步。因此，人工智能并不是人们用来制造仇恨言论或虚假信息等的工具。它实际上是对抗这些问题的最佳对策。因此，你所需要的是更多掌握在好人手中、而不是坏人手中的更强大的人工智能。

**主持人卡拉·斯威舍：** 我担心坏人，但这真是一个很棒的回答。非常感谢。我真的很感激。

**关注公众号后设🌟标，掌握第一手AI新动态**

##  往期精选

  1. [黄仁勋专访：OpenAI在大模型混战中达到“逃逸速度”](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650001718&idx=1&sn=f8129a622e7611702be2cb23e8ce9418&chksm=88ba5831bfcdd127d06ce6492c821074407f805407b4182ca900916521cb5a4717f2a3d71ee8&token=1339625777&lang=zh_CN&scene=21#wechat_redirect)
  2. [李飞飞与Justin深度解读空间智能：数字世界需要三维表征，才能与现实世界融合](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000659&idx=1&sn=c71fb5b4ef501424dddd5e8b4dd5860e&chksm=88ba4414bfcdcd023c691a1adf75127a9fd883ceb305ca14cf97f719acaf999d40fa72f84bf3&token=1492077842&lang=zh_CN&scene=21#wechat_redirect)
  3. [PayPal创始人彼得·蒂尔：人类科技停滞源于原子方面的进展远慢于比特](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000240&idx=1&sn=26af6013981677b1e14137260857a6f0&chksm=88ba4277bfcdcb615d746615c262927bf51c43c920ed93fa36274ef87c6264d6548c84647121&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  4. [谷歌联合创始人布林：巨头们打造的“上帝模型”几乎可以理解一切](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=2&sn=0c714d804a72a52e002743d949e1685e&chksm=88ba40f9bfcdc9ef78749718480265922f4fba539abf6c9d62a6cd681f405dee9283d2429f84&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  5. [马斯克：AI将使商品和服务的成本趋近于零](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=1&sn=752f000a117a705e77950c82bfc4a004&chksm=88ba40f9bfcdc9ef5a5afe4a3ae73d5247bd54ed525dbdbedee1fcf74a6c082165e664a5c4d0&token=106920805&lang=zh_CN&poc_token=HDp86Waj18SFm2Y-xnv_Vqd_4J6emFoh10eH48wg&scene=21#wechat_redirect)
  6. [Karpathy最新专访：人形机器人、特斯拉、数据墙与合成数据](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999613&idx=1&sn=b8bdda7afe4c3ca08e324ac5bbd5a2bd&chksm=88ba41fabfcdc8ec0e21dbf4c7eb4d33252da70f47e1cfc9f5e113717911c417c2aebb3d6180&token=106920805&lang=zh_CN&scene=21#wechat_redirect)

  

