# 图灵奖得主杨立昆：自监督学习就像暗物质，我们不善于处理却构成了理解的大部分、AI末日论杞人忧天

文章作者: 瓜哥AI新知
发布时间: 2024-12-30 09:06
发布地: 浙江
原文链接: http://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650006174&idx=1&sn=eef4fb9f1dbbac6dd697e92190c3d7a7&chksm=88ba6b99bfcde28f50251bcd11368b1740f6901fed10361083bbc8604eab117cbb96da09a2d5#rd

封面图链接: https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7Qk3CjIJH061R2pEKJiabbLZ8icAHVRaB8boMHmjs7Sg1kX5yyAHWwrBt1g/300

**👇关注公众号后设🌟标，掌握第一手AI新动态**

**  
**

本文内容整理自**Yann LeCun** 在**Dr Brian Keating**
的访谈，公开发表于2024年12月29日。原始内容参考：https://www.youtube.com/watch?v=u7e0YUcZYbE

## 内容提要: 杨立昆谈AI：终结末日论

本文主要围绕Yann LeCun（杨立昆）对人工智能，特别是大语言模型（LLM）的观点展开，并涉及他对未来人工智能、物理学以及教育的展望。主要观点包括：

  1. **对大语言模型的批判性评价:** LeCun认为LLM只是人工智能的一个方面，并非全部。他将LLM比作“一把锤子”，所有问题都看起来像“钉子”，忽视了其在理解物理世界和常识方面的局限性，认为其智能水平仅相当于一只猫。

  2. **JEPA架构的提出:** LeCun介绍了他提出的JEPA（联合嵌入预测架构），认为这是一种能够理解现实世界并获得常识的架构，能更好地构建对世界的明确心智模型，减少输出的随机性，并可能应用于物理学、教育和医疗保健等复杂领域。他认为JEPA能解决现有自回归LLM架构在处理连续高维数据（如图像、视频）方面的不足。

  3. **对AGI的谨慎乐观:** LeCun对通用人工智能（AGI）的到来持谨慎乐观态度。他认为AGI并非一蹴而就，而是逐步迭代的过程，并对“AGI”一词本身持批判态度，更倾向于使用“高级机器智能”（AMI）。他预测，具备人类水平智能的AI系统可能需要5-6年甚至更长时间才能实现。

  4. **关于AGI安全性的观点:** LeCun认为，担心AGI会“接管”或“支配”人类是杞人忧天。他认为智能不必然与支配欲望联系在一起，构建安全的AI关键在于构建目标驱动的系统，设置合理的护栏（类似于法律），确保AI系统的目标与人类价值观一致。

  5. **人工智能对教育的冲击:** LeCun认为人工智能将深刻改变知识传递的方式，可能需要探索新的经济模式来支持科研和学术发展。但他认为师生之间的互动，特别是导师对学生的指导仍然不可替代。

  6. **物理学与计算的联系:** LeCun表达了对物理学和计算之间联系的长期兴趣，并认为理解世界的关键在于找到合适的表示和相关变量，以及合适的抽象层次。他认为JEPA架构可以帮助找到物理现象的有效表示，从而实现更准确的预测。

  7. **对自身身份的界定:** LeCun将自己定义为一名科学家和教育者，强调其在工业界和学术界的双重身份以及对产生智力影响的追求。

## 杨立昆简介

杨立昆（Yann
LeCun）是一位法国计算机科学家，主要从事机器学习、计算机视觉、移动机器人和计算神经科学领域的工作。他是纽约大学Courant数学科学研究所的Silver教授，也是Meta（Facebook）的副总裁兼首席人工智能科学家。

杨立昆以在卷积神经网络（CNN）方面的工作而闻名，尤其是在光学字符识别和计算机视觉方面的应用，他是卷积网络的先驱之一。他还与Léon
Bottou和Patrick Haffner一起创造了DjVu图像压缩技术，并与Léon Bottou共同开发了Lush编程语言。

杨立昆与Yoshua Bengio和Geoffrey
Hinton一起获得了2018年图灵奖，以表彰他们在深度学习方面的概念和工程突破。这三位科学家有时被称为“深度学习教父”。

## 访谈全文

**主持人布赖恩·基廷：**
加入我们，一起进行一场关于高级机器智能和智能本质的拓展思维的对话。我们将突破界限，探索教育工作者在人工智能驱动的未来中不断变化的角色。我们还将探索人工智能的财务激励，这在Meta等公司的利润率中占据了很大一部分。

现在，让我们进入与元宇宙幕后人物杨立昆的对话。嘿，Meta，杨立昆是谁？杨立昆，欢迎来到《不可能的探索》播客。很高兴来到这里。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkHCfHia6LII3zniaXtGibr4RIHdw8GCR0ibyyBwcFzvXgbl66ibNnicELS2Eg/640?wx_fmt=jpeg&from=appmsg)

这些是我最喜欢的科技产品。事实上，这是我的第二版，我实际上曾用它们和一位真正的中央情报局间谍一起诊断，它们是如何成为终极间谍工具的。所以，你们的这些设备值得称赞。

我其实有一个苹果Vision Pro，它对一位公立大学教授的工资来说有点奢侈，但我把它退了。我在苹果的退货期限内退了它。

**杨立昆：** 我现在用的是第三副Ray-
Ban眼镜。我用过第一版，然后是第二版，第二版被我弄坏了，因为我当时在航行，船翻了，它们掉进了水里。那是一个比较早期的型号，所以我把它送回了我们同事那里，他们正在试图找出问题所在。

**主持人布赖恩·基廷：**
是的，我真的觉得它们代表了未来。我的意思是，任何用过苹果Vision或甚至MetaQuest的人，老实说，我都喜欢它。你知道，如果我玩游戏什么的，我的孩子们会把它从我那里抢走。但它们很重，而且人类不喜欢自己的周围视野被遮挡，因为掠食者可能会从我们身后出现，对吧？

就我而言，我喜欢这些增强现实的设备。质量很好。这不是Meta的广告，但重点是，我认为苹果本可以做得更好，我不认为这款产品能存活下来。我非常想看看第三代产品何时问世，也许我会哄你给我一个早期试用机会。

但今天我们来这里是为了谈论物理学。然而，我们必须先从一个问题开始，因为我是加州大学圣地亚哥分校亚瑟·克拉克人类想象力中心的副主任。你可能注意到我的背景中有一句话，我想请你告诉我的听众这句话对你意味着什么。“打开舱门。”

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7Qkxbpe4IkXibcFFbywIINxkdjzJjzhcsbyTviaCjjicCjZHbeMWFN5Cmg5A/640?wx_fmt=jpeg&from=appmsg)

**杨立昆：**
嗯，那是《2001太空漫游》中的一句名言。我必须说，这部电影对我影响很大，因为我九岁时就看过这部电影了。这部电影让我印象非常深刻，因为它讲述了我当时非常着迷的事情，比如宇宙、太空旅行以及智能是如何出现的。我九岁的时候就对智能计算机等等这些东西感兴趣了。

**主持人布赖恩·基廷：** 大多数人没有意识到我们正在收听的播客这个词就是来源于那里的。你们的竞争对手公司之一的工程师，苹果的Vinny
Chieco，就像你一样，受到了HAL
9000的启发。他看到了这款白色、闪闪发光的小设备的样机，后来这款设备被命名为iPod。剩下的就是历史了。这就是播客的由来。

所以，我们总是以戴夫和哈尔对话打开舱门的声音来开始节目的音频部分，而哈尔拒绝打开舱门。这种拒绝可能会让你们的一些研究人员感到恐惧，包括最近的诺贝尔奖获得者格雷格·辛顿。

但我想先从你在《华尔街日报》10月份，也就是诺贝尔奖颁发前后被引用的一句话开始。你说了一些非常有趣或具有挑衅性的话，这很符合你的风格。你说，“**人工智能的智能程度仅仅相当于一只猫”**
。我心想，杨，你肯定没见过我的猫。我的猫会把水杯弄倒，只是为了把水洒在我的笔记本电脑上，它们玩弄死老鼠只是为了好玩。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7Qk74vymT6GUCHwPE7tNgJl8cmMnCQXRPgxnZGxZJ8ic5cCYbaj3TL5QvQ/640?wx_fmt=jpeg&from=appmsg)

我无法想象人工智能会这样做，因为，你知道，阻止这种情况的唯一方法就是在元宇宙的每个房间里都放上激光笔。所以你这话是什么意思？为什么这句话让我感到安慰？随便吧。

**杨立昆：**
我的意思是说，我们最好的大语言模型可以以惊人的方式操纵语言，但它们基本上不了解物理世界，因为它们纯粹是在文本上训练出来的。所以它们对世界的印象是通过人类的表述获得的，这些表述首先是极其符号化的，而且是近似的、简化的和离散的。**真实世界比这复杂得多，我们的人工智能系统完全无法处理真实世界**
。

这就是为什么我们有能通过律师资格考试的大语言模型，但我们仍然没有能像任何一个10岁孩子一样，在不需要花费任何大脑资源的情况下就能一次性学会的家用机器人。现在，我说一个10岁孩子能做到的事，实际上猫也能做到。如果你看到猫试图跳上一堆家具去拿一个特定的东西，它们会坐下来，然后移动它们的头，在它们跳跃之前规划它们的轨迹，蹦，蹦，蹦，蹦，蹦。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7Qkrfpj0C7uI9vyRtsDdfNdAlMGwrNFQsUAFk6ppiaug6Gdbjf654BWibIw/640?wx_fmt=jpeg&from=appmsg)

它们是怎么做到的？它们可以计划，可以推理，并且了解物理世界。它们对自己、自己的动态以及许多事物的直观物理学都有非常好的模型。这些都是我们无法用计算机复制的东西。

**主持人布赖恩·基廷：**
今天，关于这些物体，乐观和悲观的情绪总是让我觉得很突出。我想知道一种被称为“伪尼陷阱”的现象，即一个竞争对手的力量崛起，但它比主导力量弱，而主导力量随后会把所有的注意力都集中在这个竞争对手身上。这个概念与沉没成本谬误有些关系。

我想听听你对这种情况的看法。**我们是否在物理科学领域自我毁灭**
？GPU和LLM方法似乎正在吸走这个领域的所有氧气。就消费者而言，这种关注似乎推动了英伟达的市值达到3万亿美元。

我们现在是否基本上完全致力于GPU加LLM模型？如果是这样，这会不会扼杀物理学等领域的实际创新呢？

**杨立昆：**
嗯，可以说是，也可以说不是。如果说我们一直执着于大型语言模型（LLMs），而且大型语言模型正在吸走所有其他东西的养分，那答案就是“是”。目前，情况看起来有点像这样：大型语言模型就像一把锤子，现在一切都看起来像钉子。这是一个错误。是的，我的意思是我一直强调的观点是——大型语言模型并非人工智能的全部。考虑到它们概念上的简单性，它们的力量令人惊讶，确实如此。

但是，**有很多事情它们做不了，其中之一就是表示和理解物理世界**
。当然，在物理世界中规划行动不是大型语言模型能做的事情。所以我认为，未来几年人工智能面临的最大挑战是：超越自回归的大型语言模型式架构，转向能够理解现实世界并获得一定常识的架构。

推理的方式，至少对于需要深思熟虑的复杂任务而言，是我们对事物的工作方式有一些心理模型。我们可以想象我们的行动将会产生什么结果——我们行动的效果。这使我们能够进行规划，因为我们可以设想一系列行动的结果。我们可以优化这一系列行动来实现特定目标。

这正是当一只猫站着向上看，试图弄清楚要遵循什么轨迹时所发生的事情。那是规划，它们自己有一个心理模型；它们对将要跳跃的材料有一个心理模型。我们绝对是无时无刻不在做这件事，而且常常甚至没有意识到。这应该引起物理学家的兴趣，我希望我们可以讨论这个问题。

**主持人布赖恩·基廷：**
是的。不，我想提到这个人，阿尔伯特·爱因斯坦。1907年，他做了一个思想实验，他设想了一个在电梯里自由落体的观察者。天知道，如果电缆断裂，电梯坠落，这样的人将感受不到引力场。他称之为他一生中最快乐的想法。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkCJ58YFsfyLNq6tyZiaryUAYnW6pvtujia5BYIwEOCAe4SfiaYHXS8KicqQ/640?wx_fmt=jpeg&from=appmsg)

我想问你，简，在什么情况下，或者说是否有可能，A，一台计算机可以拥有一个快乐的想法，更别说最快乐的想法了，并且B，在没有具身，没有一些当我们坐过山车或者当电梯移动异常时我们都知道的那种胃部不适的本能感觉的情况下？

一个计算机系统如何才能像爱因斯坦那样构建新的物理定律？

**杨立昆：** 简短的回答是，今天，不行。**今天的人工智能系统无法拥有这种直觉。即使今天应用于科学发现的人工智能系统是最合适的，是专门的模型**
，对吧？所以，你想预测蛋白质的结构，或者预测两个分子之间的相互作用，或者预测材料的特性。你会为此开发一些专门的模型，你不能真的用大型语言模型来做这类事情。它们只会复述它们训练过的东西，但它们不会提出新的东西。

当然，这些模型是强大的，因为它们可以预测以前没有人尝试过的化学反应，以及以前没有人制造过的材料的特性等等。它们比大型语言模型更有点不落俗套。它们可以比大型语言模型更多地跳出既有框架，而大型语言模型基本上是索引现有知识的方式。但它们不会有爱因斯坦那种洞察力。目前还没有，但希望它们在某个时候会有。

所以，我的意思是，我最大的问题，科学问题和兴趣是如何做到这一点。我们人类，以及动物，通过什么样的过程来构建现实世界的模型？这里一个重要的事情是找出系统或你感兴趣建模的东西的适当表示和相关变量，以及该表示的正确抽象级别。

例如，你和我都知道，如果我们愿意，我们可以收集关于木星的无限量的数据。我们知道关于木星的大量数据，对吧，包括天气、密度、成分、温度等等。

但是，谁会想到，要预测木星未来几个世纪的轨迹，你只需要知道六个数字——三个位置和三个速度——就可以了。你甚至不需要知道密度、成分或自转；只需要六个数字，对吧？

因此，能够做出预测最困难的一步是找到现实的适当表示，并消除所有不相关的东西，这样你才能做出这些预测。

在过去的几年里，我一直沉迷于一种我认为能够做到这一点的架构，我们称之为JEPA，我可能会解释一下。

**主持人布赖恩·基廷：**
是的，我很想让你解释一下。我只是想感谢你再次提到《2001太空漫游》。木星当然是他们发现神秘巨石的地方，然后巨石让他们能够穿越可能是一个虫洞之类的东西。是的，说说JEPA吧。那是什么？我不熟悉。

**杨立昆：** 大型语言模型有一个特点，或者说大型语言模型使用的一个技巧，我长期以来一直提倡，叫做**自监督学习**
。那么什么是自监督学习呢？基本上，你获取一个输入，它可以是一个序列，或者可以是任何东西，可以是一个图像；你以某种方式破坏它。然后，你训练一个系统从被破坏的输入中恢复完整的输入。特别是在语言和大型语言模型的背景下，有几种类型的自然语言理解系统。然而，在当前这批大型语言模型之前的唯一一个方法是：你取一段文本，通过删除一些单词，用黑色标记替换它们，或替换成其他一些单词来破坏它。

然后，你训练一个巨大的神经网络来预测缺失或错误的单词。在这个过程中，系统学习了文本的良好内部表示，可以用于各种潜在的应用，作为特定任务系统的输入，例如翻译、情感分析或摘要。现在，大型语言模型是这种方法的一个特例，你构建系统的架构方式是，为了预测输入中的一个单词，系统只能查看它左边的单词。这意味着它只能考虑前面的单词来预测目标单词。

因此，你不再需要执行破坏过程，因为架构本身就限制了系统访问所有数据。它只能查看特定单词左边的内容来预测该单词。本质上，你输入一个输入，然后训练系统将输入作为输出进行复制。这个过程称为自监督学习，因为你没有要求系统完成任何特定的任务。输入和输出之间没有区别；一切都是输出和输入。

这种自监督学习在语言方面效果惊人，并且在例如 DNA
序列和各种其他任务中也表现出良好的性能。然而，它主要适用于离散元素的序列，如语言。语言在字典中有有限数量的单词，这使得可以预测给定序列的所有可能单词的概率分布。这是可管理的，因为你可以预测一个分数向量，或者一个概率分布，它只是一个介于零和一之间的大数字向量，总和为一。

但是，你如何处理来自传感器（例如相机）的自然数据呢？假设你的数据是视频，或者可能只是一个单独的图像。你可以尝试应用类似的策略：获取一个图像，通过遮盖它的部分来破坏它，然后训练一个神经网络来重建完整的图像。这种技术被称为掩码自动编码器（MAE）。然而，它的效果不是很好。事实上，有各种方法来训练系统从部分视图中重建，统称为自动编码器。许多这些技术都源于统计物理学，其中一种特定方法称为变分自动编码器，其中“变分”来自变分自由能——利用与统计物理学中相同的数学原理。

**主持人布赖恩·基廷：**
它（模型）是早期就失败了吗？它失败是因为缺少某些边界条件或初始条件吗，比如像三体问题那样？我去年有个本科生尝试回答以下问题。如果你有水星过去10000年的轨道数据——我们确实有，因为我们可以从JPL和NASA获得它的轨道数据——对吧？所以我们知道它大约200个水星年的轨道，因为它的年份比我们的短得多。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7Qk9aWmmtbUbZNn51BAZMcTGGd60MtUIC4CxwC0QYlyoPGdOO0ELka4PQ/640?wx_fmt=jpeg&from=appmsg)

我问，给定这些数据，你能不能预测到牛顿力学中缺少某些东西？换句话说，你必须用一个新的变分法来补充它，也就是爱因斯坦-
拉格朗日的变分法。那个学生没能成功。它什么都做不了。它知道它可以预测水星的一些异常进动，但它无法推导出方程。我们基本上是通过向它提供类似于爱因斯坦方程的东西来强迫它得出结论。

我们想得到这个问题的答案：如果我们在1899年拥有LLM，我们能预测到爱因斯坦的广义相对论吗？至少在我们机器学习中使用的模型类型下，答案是我们做不到。那么，这是缺失的东西吗？这就是它失败的原因吗？因为它缺乏爱因斯坦的伟大之处所拥有的核心洞察力，还是其他原因？不，是其他原因。

**杨立昆：**
好的，那是什么？很遗憾，它更普通。事实是，要预测一个连续的、高维的连续信号（比如图像或视频），很难表示所有可能图像的概率分布，对吧？当你在预测一个词的时候，你并不确切知道一个序列后会跟着哪个词，但是你可以近似知道。

**主持人布赖恩·基廷：** 如果它是真正的语言，它就不会是胡言乱语，对吧？

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkvFOpnhJum2GU44Ors0JfyYLibnMUrbSMCSteY7iaFg2QjRXVoFiaTtxNQ/640?wx_fmt=jpeg&from=appmsg)

**杨立昆：**
是的。而且，你知道，如果你有一个动词，后面可能跟着一个补语，诸如此类，对吧？你无法对视频做到这一点。如果你展示一个视频并训练一个系统来预测接下来会发生什么，你向它展示一段视频，停止视频，然后让它预测接下来会发生什么。在那之后，你向它展示真实发生的事情，然后你训练它进行准确的预测。然而，它效果不佳。我的意思是，我在这方面工作了大约过去15年的大部分时间，它确实不起作用。它不起作用的原因是，**如果你训练系统进行单个预测，它能做的最好的事情就是预测所有可能发生的未来情况的平均值，从而产生模糊的图像**
。

因为，你知道，即使我们拍摄像我们现在正在拍摄的我们说话的视频，我可以说一个词或另一个词。我可能会把头转向一边或另一边。我可能会以不同的方式移动我的手。如果系统必须进行一个预测，而我们训练它来最小化预测误差，它将简单地预测所有可能性的平均值。因此，你会看到我手的模糊版本、我脸的模糊版本，以及我嘴的非常模糊的版本，这不是一个好的预测。因此，通过重建或预测进行的自监督不适用于自然信号。

现在，我来讲讲JEPA的想法。JEPA代表联合嵌入预测架构。那么，什么是嵌入？嵌入是信号的一种表示。例如，你拍摄一张图像，你不在乎所有像素的精确值。你在乎的是一种表示，它将是一组数字，一个向量，它表示图像的内容，而没有详细说明它的所有细节。联合嵌入意味着，如果你拍摄一张图像以及该图像的损坏或轻微变换的版本（例如来自不同的视点），则图像的内容保持不变，因此嵌入应该相同。

联合嵌入架构本质上是一个大型神经网络，你训练它，以便当你向它展示同一图像的两个版本时，它会产生相同的嵌入。你本质上是强迫它产生相同的输出。“预测”方面体现在当你考虑视频中的一帧及其损坏版本时，该损坏版本可能是前一帧。现在，你需要根据前一帧预测下一帧，或预测接下来的几帧。这就是JEPA的宗旨：拥有两个嵌入，一个表示视频的未来，另一个表示过去。然后，系统尝试根据过去的表示来预测未来视频的表示。

当你使用这种类型的架构来训练系统以学习图像的表示时，它的效果非常好。在过去的几年里，我和我的同事以及其他许多人开发了各种促进此过程的技术。我们开始获得不仅是图像，而且最近还包括视频的良好表示。你可以设想使用关于木星或水星的这个原理。你收集关于这些行星的数据，然后指示系统找到该数据的良好表示，同时消除所有不可预测的元素，从而允许在表示空间中进行预测。

本质上，目标是消除所有不相关的细节——例如木星上的天气——而专注于找到一种有效表示，从而能够在该空间内进行一定范围的预测。我认为，**这正是物理学中理解世界的本质：努力通过过滤掉不相关的信息并专注于有效的表示来创建一个现象的模型**
。一组相关的变量可以让你做出预测。这实际上就是科学已经在做的事情。

**主持人布赖恩·基廷：** 这里面是否有主观的模拟？就像你谈论模型的温度之类的东西。你是否仍然需要指定这样的参数？

**杨立昆：**
在这种情况下，尤其不需要，因为当你拥有这种架构，或者至少是我描述的简单架构时，你会消除预测中的随机性，使用惩罚项。基本上，我的意思是，当系统被训练来做这件事时，它会同时训练自己来找到输入的良好表示，该表示尽可能多地保留信息，同时仍然是可预测的。

因此，如果输入中存在不可预测的现象，例如混沌行为或你无法预测的随机事件——例如由于热波动引起的粒子的个体运动——它就不会保留这类信息。相反，它会消除无用的东西，只保留对预测有帮助的输入的相关部分。

例如，让我们拿一个充满气体的腔室，我们可以测量关于它的各种参数，包括所有粒子的位置。这是一个你无法预测的庞大信息量，因为它需要知道每个粒子如何与壁、热浴以及其他一切相互作用。因此，要准确预测每个粒子的轨迹变得不可能。

然而，系统会识别到，“好吧，我将无法预测每个粒子的轨迹，但我可以测量压力、体积，也许是粒子的数量和温度。” 例如，当我压缩气体时，热量会增加。因此，PV =
nRT 或类似的东西。我认为这确实是机器学习与科学，特别是物理学联系的关键所在。

这方面的另一个方面，我认为非常引人入胜，我们还没有充分探索，那就是表示的抽象层次的思想。人们在物理学和科学中这样做，对吧？原则上，我们可以用量子场论来解释现在发生在我们周围的一切，对吧？

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkicxYkS5XeJjMC4xcJOmCOowP7cGGVcDELyTsOSibAiccraqxiapCMMcVWA/640?wx_fmt=jpeg&from=appmsg)

**主持人布赖恩·基廷：** 是的，我猜也是，虽然可能——是的，人类意识的主观性可能会发挥作用。

**杨立昆：** 那仅仅是粒子相互作用，对吧？所以原则上，一切都可以简化为量子场论。但当然，这完全不现实，因为你需要处理的信息量实在太大了，对吧？

我们使用不同层次的抽象来表示现象，再次强调，这消除了细节，对吧？你知道，量子场论，然后在此基础上，我们有粒子，基本粒子理论，原子理论，分子，材料，然后你向上层层递进。你可以升到很高，然后有生物学，研究彼此相互作用的物体。

**然后是心理学，可能在最顶端之类的。找到好的抽象表示，能够让你理解正在发生的事情，同时消除所有不相关的细节的表示层级，这实际上是智能的根源，我真的这么认为**
。

**主持人布赖恩·基廷：**
我在五月份的时候和某人就此争论过，我猜他不是你的好朋友，也不是彼得·蒂尔的拥护者。讨论围绕我们是否可以从大型语言模型（LLM）进行推断展开。它们确实具有某种涌现性，但目前尚不清楚它们所缺乏的是否会将其提升到我所谓的“人工爱因斯坦”或A-
E的水平。我认为，缺失的是训练数据。你在去年与我们的共同朋友莱克斯·弗里德曼的对话中讨论过这一点，强调尽管大型语言模型有20万亿个token，但一个四岁的孩子可能拥有的token数量级更高。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkmpQLrJeYfEibY9OC6TcFkAlb52NQRWSNcFnAPADTUibrDqicKB9YCgDEQ/640?wx_fmt=jpeg&from=appmsg)

此外，这也引出了一个问题，即仅仅增加数据量是否能帮助大型语言模型赶上。当前的限制是否阻碍了我们取得像广义相对论或万物理论这样的突破？例如，人工智能目前不知道《角斗士2》的情节是否是一个障碍？我不这么认为。可以以标记化的形式提供无限量的训练数据，但问题的关键在于更深层次。爱因斯坦不需要知道《速度与激情》系列就能提出广义相对论或洛伦兹不变性原理。

至于未来物理学的进步，你认为最有可能的途径是什么？你认为是通过像JEPA这样的方法，利用更多的视觉数据和基于观察到的现象进行建模，在这些领域之间建立预测桥梁吗？或者你认为需要像符号回归这样的东西，这可能需要只有人类才能提供的监督水平？

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkdC9RtxBGTejHT32UmHr04Q0CtPkkCPichSDJYcgVnGeegUfPxpQ3BGg/640?wx_fmt=jpeg&from=appmsg)

让我们把讨论重点放在对万物理论的探索上，这目前是我所在领域的圣杯。你认为年轻人应该追求哪些工具和技术才能朝着这个目标前进？

**杨立昆：**
好的，我认为人们已经研究了一段时间的许多技术，在短期内可能会非常有用。所以，像符号回归之类的东西。我的一个名叫斯克莱默（Scramer）的朋友一直在研究这类东西，他与纽约大学和弗莱特艾伦研究所都有联系，我也和他有联系。所以，是的，这真的很有趣。关于这类工作的研究可以追溯到几十年前，但当时效果并不好，因为计算机的功能还不够强大。现在已经取得了很大进展。

我不认为这会产生我们正在谈论的那种洞察力——爱因斯坦和我，或者像费曼这样的许多其他物理学家所拥有的那种洞察力。当然，它本身不会产生万物理论。我认为缺失的是更根本的东西：构建世界的心理模型的能力，系统能够在自己的头脑中操纵这些模型，并使用极端情况和边缘情况。

我的意思是，这就是你之前谈到的，爱因斯坦著名的思想实验。对某事有一个心理模型，提出一个假设，然后试图将该模型推向极端情况，看看那里会发生什么，这是至关重要的。或者，就像人们经常用来解释由于相对速度引起的时间收缩的思想实验。如果你观察火车上的人，让光在两面镜子之间上下反射，对那个人来说，光以光速运动，并且只在车厢的特定高度上下传播。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkdHlk5TBXqFEBAe9Or5f7BzOQicdEbzjicLTuKUCPicb2BtPMbT2KWX60A/640?wx_fmt=jpeg&from=appmsg)

然而，对于从外部观察的人来说，光是倾斜地上下反射的，实际上行进了更长的距离，但仍然以光速运动。因此，必然是时间发生了收缩。我的意思是，这是一个非常简单的概念；一旦你知道了结果，它似乎有点显而易见，但我们必须做出一个巨大的假设，即光速对于每个人都是相同的。

这就是你之前提到的关于训练数据的问题：你需要了解，或者你需要看过《角斗士》才能提出相对论吗？当然不需要。有趣的是，科学史学家似乎说爱因斯坦并不知道芝加哥大学的实验，也就是迈克尔逊-
莫雷实验，该实验表明……

**主持人布赖恩·基廷：** 抱歉，我必须打断你一下。那是在我的母校凯斯西储大学。哦，抱歉。我不能让那个错误存在。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkNNQkvOh9CxSReCpsiabKax0fuibOuSrb5Pm6tzc45Avla2ibGbt6yOwjw/640?wx_fmt=jpeg&from=appmsg)

**杨立昆：**
确实，确实。他们试图证明以太的存在，但他们无法证明，他们认为他们的实验有缺陷。而且我认为爱因斯坦并不知道这一点。至少，历史学家说他并不知道。因此，即使在缺乏实验证据支持他的假设的情况下，他也能提出这个概念。

**主持人布赖恩·基廷：**
我的意思是，这太不可思议了。当然，他面临着来自你的同胞亨利·庞加莱的强大竞争。我想，扬，虽然认识你还不到40分钟，但我认为你是一个内心深处隐藏的物理学家。我是说，非常明显。是的。但我想把你从衣柜里拉出来。现在是安全的。

你最近说了一些令人难以置信的话，我忍不住要提，因为它确实是我的领域，那就是你**将自我监督学习比作人工智能的暗物质**
。就像物理学中的暗物质一样，它是必不可少的。我们知道它存在，或者我们认为它存在，尽管如果你有兴趣，我会谈到一些叛逆者。

所以我们知道——我的意思是，中微子是暗物质的一种形式。我们知道它存在。我们知道它们不足以解释观测到的缺失物质的数量。但是你是什么意思呢？你所说的暗物质类似于自我监督学习是什么意思？

**杨立昆：**
那个评论实际上已经八年前了。我是在多年前的一个主题演讲中说的。当时在场的有我以前的同事凯尔·克莱默，他是当时纽约大学的一位高能物理学家，他不是威斯康星州人。他说，“你不应该使用暗物质作为类比。你应该使用暗能量，因为这才是宇宙中大部分质量的所在，”对吧？

我当时试图解释以下类比：我们所学到的大部分知识，不是通过被告知答案，也不是通过反复试验来学习的。我们只是通过自我监督学习或类似的方法来学习我们感官输入的结构，对吧？我们实际上并不知道人类和动物使用了什么，但它肯定更像是自我监督学习，而不是监督学习或强化学习。

监督学习是指你有一个清晰的输入和一个清晰的输出，并且你训练系统将输入映射到输出的情况。例如，你展示一张大象的图片，并告诉系统那是一只大象。如果它错误地将其识别为猫，你会调整参数，使输出更接近于将其识别为大象。这就是监督学习。

另一方面，强化学习是指你向它展示一只大象，等待答案，然后只是告诉它答案是否正确。你不提供正确答案；你只是对其准确性进行反馈，可能还会给出某种分数。然后，系统必须在所有可能的答案中搜索正确的答案。如果有无数个答案，那就非常低效了。因此，**强化学习是如此低效，以至于它不可能解释我们在人类和动物身上观察到的那种高效学习**
。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7Qks4TYc2HuW0ia5Ent4ZbFYUQxxnXibw0bISiaiaWqAQnJWygJN1M6f6AqmQ/640?wx_fmt=jpeg&from=appmsg)

监督学习也无法解释这一点，因为我们学到的大部分东西，我们都不是主动被教的。我们似乎只是自己弄清楚了。此外，许多动物物种在没有见过父母的情况下变得相当聪明。一个很好的例子是章鱼，但在鸟类和其他物种中也有很多例子。他们对世界的了解很多，但没有被告知任何事情，也没有以任何正式方式被教导。

然后，还有一种我们现在称之为自监督学习的模糊概念。这实际上是大部分学习发生的地方。大型语言模型（LLM）的成功有力地证明了自监督学习的力量。**我用一个类比来展示，我会展示一张巧克力蛋糕的图片，说蛋糕的主体部分，也就是海绵蛋糕，如果你愿意这么称呼的话，代表了自监督学习。蛋糕上的糖霜代表了监督学习，而顶部的樱桃则是强化学习**
。

如果你想量化这些不同学习模式的相对重要性，这是一个恰当的类比。当我在2016年说这些的时候，全世界都完全专注于强化学习，因为它被认为是通往人类水平AI的道路。我从来不赞同这种观点，所以当时这有点争议性。然而，这种观点现在已经不再那么有争议了。

然后我指出，**海绵蛋糕的主体部分里也有巧克力——那是暗物质。所以，是的，那是人工智能的暗物质。这是我们需要弄清楚如何解决的概念。这类似于物理学家面临的尴尬境地：我们知道如何进行强化学习和监督学习，但我们真的不知道如何处理自监督学习方面的问题，而这构成了理解的大部分**
。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QknZ6vjiaXCcIbkdTtwxr0g5ZRgmjZgR0QcH5tB9urlJh3bLNGfqHSTfA/640?wx_fmt=jpeg&from=appmsg)

**主持人布赖恩·基廷：** 上周，我和你的一个亲近的同事Stephen
Wolfram谈过，并且还在谈论暗物质的话题，他相信一个非传统的观点：宇宙是一个超图，根据他的说法，通过纯粹的计算规则演变。他认为时间是由超图的更新速率产生的。此外，他认为，由于时间和温度通过热力学定律与熵相关，暗物质是他所谓的时空热。

我不是要你专门评论这个。我实际上并没有完全理解。我们辩论过，因为我提出的问题是：它可以吗？好的，所以有我们知道存在的暗物质，还有我们不知道是什么的暗物质。它可能是一些奇怪的新粒子，比如轴子，或者可能是我们不了解的某种新的力场。但我们绝对知道存在暗物质：中微子，100%，WIMP（弱相互作用大质量粒子）。

那么，时空热能否解释中微子，它们在宇宙中今天的温度约为1.9开尔文？我们为此争论了一番。但总的来说，你如何看待宇宙是纯粹计算的这种超图的想法？作为一名研究人员，你对它感兴趣吗？

**杨立昆：**
我不了解具体的超图理论，但我可以告诉你，我长期以来一直对物理学和计算之间的联系着迷。当我1988年在贝尔实验室开始我的职业生涯时，我的所有同事都是物理学家。实验室是一个物理实验室。我是唯一一个非物理学家的人。我不想说计算机科学家，因为我的本科学位实际上是电子工程，而且我做了很多物理方面的工作。但我的所有同事都是物理学家。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkuUYhAaVZS93eU70FrU4TP4qhlWQEELyibSJN9bjJ16aotHnNDBy6vTw/640?wx_fmt=jpeg&from=appmsg)

我有一位非常出色的同事叫John
Danker，他的办公室在我隔壁。我们两个都对物理学中的基本问题以及它们与计算的联系非常感兴趣。我们参加了在圣达菲研究所举办的几次研讨会，其中一次由Wojciech
Zurek组织，他也对这些问题感兴趣。我不知道你是否了解他的任何工作。还有像Seth
Lloyd这样的人，他当时（大约在1991或1992年）刚刚完成博士学位，还有像Murray Gell-Mann和John Wheeler这样的人物。

John Wheeler做了一个题为“It From
Bit”的演讲，这也是他做过的一系列讲座的标题。他提到，一切的底层都是信息，强调需要用信息处理来表达所有的物理学。我发现这个概念很吸引人，并且长期以来一直在思考这个想法。然而，我还没有将它发展到足够具体的程度来实际写一篇关于它的论文，尽管我有一些关于它的有趣想法。

我在这方面的一个联系是可逆计算的想法，由于量子计算的兴起，它已经获得了显著的关注。然而，它在90年代早期并不那么受欢迎。

**主持人布赖恩·基廷：** 我们再说回物理学家，我从观众那里收集了一些问题，我刚刚收到我好朋友，也可能是你的朋友Max
Tegmark发来的短信提问。他通过短信给我发了两个问题。第一个问题是，Yann，你预计什么时候会出现AGI（通用人工智能），被定义为可以胜任几乎所有人类工作的人工智能？

**杨立昆：**
我一直不太喜欢使用“AGI”这个短语。原因不是我不相信人工智能系统最终会变得像人类一样聪明。我当然毫不怀疑，在未来的某个时候，我们将拥有在人类所擅长的所有领域都像人类一样聪明的机器。这毫无疑问会发生。好吧，毫无疑问。这只是时间问题。

但是称之为AGI是完全无稽之谈，因为人类的智能非常专业化。我们很难接受人类智能是专业化的这个概念，但它的确非常专业化。这就是我不喜欢这个术语的原因。我一直使用的术语是人类水平的AI或AMI。所以AMI代表高级机器智能。这有点像我们在Meta内部使用的术语。因为它意味着“朋友”。在法语中，它也有相同的含义，对吧？但它是同一个概念。

那么，这需要多长时间呢？奇怪的是，像马克·扎克伯格这样的人也会问我这个问题。原因是，如果你想投资数百亿美元的基础设施来训练大型人工智能系统，那么了解这一点很重要。如果你想告诉人们，在几年内，他们就可以佩戴你最初展示给我们的智能眼镜，而在这些眼镜中，将会有一个智能助手，你可以随时要求它与你同在。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkxjXQg560qibcUX3tPA5REIfkyBG9GjIgPWHKqwFBUR6yT0buTqrfVTQ/640?wx_fmt=jpeg&from=appmsg)

你可以问任何问题，这个助手可能会比你更聪明。你不应该感到受到威胁；它就像拥有一个你可以交谈并问任何问题的聪明同事一样。所以，这需要多长时间呢？我认为可能需要一些时间才能拥有一个至少对大多数人来说，感觉上具有与人类相似的多个智能水平的系统。

我们正在想象的所有事情都会奏效。好吧，所以那些JEPA架构和我们正在尝试的其他一些想法都成功了。我认为这在五年或六年内不会发生。

好吧，**但现在这会在五年或六年内发生吗？我认为这是一个分布，尾部很长。人工智能的历史表明，人们一直低估了它的难度。我可能现在也在犯同样的错误**
。当我说五年或六年时，这是假设我们没有遇到任何我们没有预料到的重大障碍，假设我们计划尝试的所有事情都奏效，假设事情可以扩展，假设计算机加速等等。

有很多事情，很多星球需要排列在一起才能发生。所以这是最好的情况，对吧？它不会在明年发生。你可能从一些人那里听说过……

**主持人布赖恩·基廷：** 其他人，比如Sam Altman。

**杨立昆：** 对，没错。你知道，很多人。或者，达里奥·阿莫迪（Anthropic
CEO）。是的，这会在未来两年内发生，或者类似的时间。不，**未来两年内可能发生的是，越来越难找到普通人能够向最新的聊天机器人提出问题，而聊天机器人却无法回答的情况**
。但是，再想想，我的猫在哪里？我的家用机器人在哪里？我的L5级自动驾驶汽车在哪里？哪里有能够通过20个小时的练习就学会驾驶，且不会撞死人的自动驾驶汽车？

**主持人布赖恩·基廷：**
我想知道，有多少，你知道，仅仅是——不是作为这个领域的专家，而是仅仅作为一个对它着迷并从中受益的人——它对我的生活产生了如此大的益处。现在，你知道，我有一群孩子，我不给他们读书；我让Meta给他们读书。不，不，我没那样做。但我觉得这在道德上没有任何问题。我感觉很好，因为如果你在读别人的书，基本上是一样的。然而，我认为我们现在争论的事情可能才是最重要的。

我能想到的最相似的事情是德雷克方程。德雷克方程参数化了，你知道，基本上是对探测外星人的一种乐观陈述。它基于一系列总是没有不确定性地给出的参数。作为一名科学家，我知道最重要的因素是系统误差和统计误差。系统误差很难处理，这才是物理学的核心。这才是直觉和技艺发挥作用的地方。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QklfavMnaaTuyuJOVxWMnyQiabCxHWSic0b5ibaS55WJ0ReR9uMzq8vBZ4w/640?wx_fmt=jpeg&from=appmsg)

在这些讨论中，你总是会听到诸如“宇宙中有数十亿个文明”或者“一个也没有”之类的数字，这取决于你如何选择你的误差范围。同样地，对于AGI，这是一个非常模糊的概念。人们以各种不同的方式定义它，而且我同意你的观点——我不认为这是一个已经解决的问题。然而，如果我能冒昧地提出，基廷测试可能类似于提出一个新的物理定律，一个可以做出可测试和可证伪的预测的解决方案。

这将使我们能够说，“这确实是新的”。它不仅仅是复制现有的知识，也不是预测某种温度依赖的东西。那么，如果可以用拉库恩测试而不是图灵测试，你会怎么说？我认为图灵测试在当时很棒，但与德雷克方程的类比是，德雷克方程问的是“谁在和我们说话？”而图灵测试问的是“谁在听我们说话？”然而，我认为这两种方式都不够。你会提出什么样的拉库恩测试，让你觉得可以接受？

**杨立昆：**
坏消息是，我不认为存在任何单一的测试可以奏效。这可能是对的。因为任何你可以公式化的领域或子问题，都可能存在一个专门的解决方案来以超人类的性能解决该问题。我们在计算机上看到了这一点；这就是计算机科学的历史。计算机的计算速度比人类快。现在，它们可以双向翻译数千种语言。一个30美元的小玩意可以在国际象棋中击败你，而且肯定可以击败我。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkRibVl2dLSLJ3QyKLsdqcGAUKptoC6OpnM1uacvZgfE3nA2e7kg4PQ9w/640?wx_fmt=jpeg&from=appmsg)

在我们提出的所有这些任务中，比如游戏，我们开发它们是因为它们对人类来说很难，但事实证明对机器来说并不那么难。因此，任何搜索算法，比如图中的最短路径——诸如此类的东西——都是你的GPS或地图软件所使用的。这些都是相当简单的算法，它们表现出超人类的性能。因此，对于你选择的任何特定应用，都会有一个专门的解决方案。因此，没有任何单一的测试能够充分衡量智能。

我们现在观察到的是，人们对大型语言模型可以操纵语言这一事实感到惊讶。事实证明，操纵语言很简单；它比我们想象的要简单得多。事实上，它必须很简单，因为它在进化过程中只是在过去的几十万年才出现的。考虑到人类和黑猩猩或其他物种的基因组之间的差异，语言只占基因组的一小部分——如果有什么，它可能相当于只有几兆字节的基因组信息，这实际上并不多。

在大脑中，语言由位于这里的两个小区域管理：布罗卡区和韦尼克区。布罗卡区对于产生语言至关重要，而韦尼克区对于理解语言很重要。我们被迷惑，以为这些区域和实现这些能力的系统具有普遍的智能，因为它们的行为有点像人类。然而，它们实际上非常肤浅。

当我们试图构建能够完成非常简单的物理任务的系统时，这一点就很明显了；事实证明，这非常复杂。它们真的不能有效地执行这些任务。我的意思是，我认为我们还没有一个好的解决方案。尽管由于机器学习，机器人技术和其他领域正在取得进展，但我们仍然远未实现真正的智能。

**主持人布赖恩·基廷：** 我们需要达到的目标。Max提出了第二个问题，你可能能猜到，Yann，你有什么计划来防止对更智能的AGI失去控制？

**杨立昆：** 好的，所以Max和我在这个问题上意见不一致，对吧？我们参加过各种讨论这个问题的座谈会。我也在这个问题上和Jeff
Hinton意见不一致，对吧？是的，我们是好朋友，但我们在这个问题上意见不一致。

首先，这里隐含着一种观点，即如果一个系统是智能的，它就会想要以某种方式接管或支配。这完全是错误的。它不仅是错误的，即使在人类物种中也不是真的。你知道，我们当中最聪明的人不是那些想当首领的人，对吧？我们在政治舞台上有很多例子。没错。我们不谈政治。

认为智能必然与支配的欲望联系在一起的想法是完全错误的。为了有支配的欲望，或者说不是欲望，而是仅仅是意外地支配，必须有某种硬连线到实体中的驱动力，例如竞争，资源，或者影响其他实体以从中获利或其他。

这种支配的欲望是生物学中社会物种的独特特征，对吧？所以在狒狒中有支配-
服从行为，在黑猩猩中有，在狼和狗中也有，在人类中也有。尽管在人类中，还有另一种在人类社会中获得地位的方式，那就是声望。你和我都不是通过武力影响他人；我们是通过声望，或者至少我们希望是这样。

但再看看猩猩。猩猩不是群居的；它们是独居的。事实上，它们是领地性的，而且它们没有任何支配任何人的欲望，因为它们不需要。因此，认为与智能联系在一起存在内在支配欲望的想法是完全错误的。它就是错误的。

好的，现在的问题是，你如何确保AI系统的驱动力，其目标将与人类价值观保持一致。

而且这些系统不会通过故意的行动，也不会通过意外的事故来摧毁我们。如果你预测，如果你推断出大型语言模型的能力，那么你可能会感到害怕，因为大型语言模型在某种程度上是本质上不安全的。

它们不是很聪明，所以这无关紧要，但它们是不可控的，因为它们产生输出的方式不是通过优化一个目标。它不是试图找出能够满足目标的一系列行动。

它们只是在没有太多思考的情况下，自回归地一个接一个地产生token。

**主持人布赖恩·基廷：**
对。但你为什么说那不安全？我的意思是，我的孩子也会做同样的事情，但她没有力量，对吧？没有实体。没有可控制的网络，可以让她真的对我做些什么，即使她可能在随机地发疯，对吧？我是从成年人的角度来说的。

**杨立昆：** 她可能会，你知道，坐在你腿上，在你电脑前，然后随意地拍打键盘，毁掉你整个文件系统。对吧。

**主持人布赖恩·基廷：** 但不会发动核战争。她不会……

**杨立昆：** 不会，因为她没有那种力量，但人们也没有那种力量，而且人工智能系统也不会有那种力量，除非我们在构建它的时候非常愚蠢。

你女儿所拥有的，是一套被进化硬编码到她体内的驱动力，其中一些只是为了探索世界之类的，从而学习世界是如何运作的。但其中一些非常具体，所以大约一岁的孩子有一种走路和站起来的驱动力，因为那是你学习走路的方式，对吧？所以他们站起来的时候会很高兴。那是硬编码的。存在硬编码的目标。

我不是在谈论硬编码的行为。我谈论的是，你碰到婴儿的嘴唇，婴儿就会开始吮吸，对吧？那只是直接的硬编码行为。就像一个神经网络电路，只是那样做。

我谈论的是硬编码的目标，所以是驱动你去做的那些事情，但自然不会告诉你如何去做。比如吃饭，对吧？我的意思是，自然不会告诉你如何找到食物。你必须自己学习。我的意思是，我们不会帮忙。

**主持人布赖恩·基廷：**
你的父母。马克斯的瑞典同胞，尼克·博斯特罗姆，曾上过播客，他因这个回形针问题而闻名。但我向他指出，你知道，你不可能生产无限的回形针，因为地球核心内部，或任何小行星，或任何太阳系中，只有那么多铁。所以这有点荒谬。他们首先必须要有能动性，欲望，目标目的论，目标导向。我不想说这不可能，因为那是我的一个规则。我不说任何事情是不可能的。但马克斯似乎执着于证明一些无法证明的事情。他在问你，可证明的安全，但如果那是证明一个否定呢？

**杨立昆：**
我不相信，我的意思是，罗素也想，正在寻找一个可证明安全的人工智能系统。我认为这就像可证明安全的涡轮喷气发动机一样不可能。你无法证明涡轮喷气发动机是安全的。然而，我们可以制造出非常可靠的涡轮喷气发动机，对吧？它们可以让你乘坐只有两个引擎的飞机安全地飞到世界各地，对吧？我的意思是，这就是我在技术方面的交易。但我们可以制造这些东西。人工智能也会一样。不会有神奇的解决方案。不会有证明我们可以构建安全系统的证据。但我们将设计安全的系统。

我认为，我们将要设计它们的方式，也是我认为事情将会发展的方式，就是我们将构建目标驱动的系统。我称之为**目标驱动的人工智能。事实是，人工智能系统产生的输出，不仅仅是产生一个又一个的token的结果，而是通过对你采取的一系列行动优化一个目标的结果**
。所以你在你的头脑中，在你的思维中，有一些心智模型。系统对它想要行动的情况或环境有一个心智模型。它正在想象它将要完成的一系列行动。

通过这个心智模型中的一系列行动，它可以预测结果会是什么。现在你可以检查这个结果是否满足一组目标。其中之一是，我是否完成了我着手完成的任务？例如，制造一千个回形针。但可能还有其他更像是约束的目标，它们将是护栏。例如，你杀死或伤害某人，或者采取某些消耗太多能量的行动，都要付出很高的代价，或者其他什么，对吧？

你可以想象拥有一系列这样的目标，其中一些是护栏，一些是任务目标。系统产生输出的方式是，它在行动序列的空间中搜索一个最小化所有这些目标和护栏的序列。现在，这就是目标驱动的。这些系统除非你破坏它们，否则无法被破解。通过给它一个奇怪的提示，让它超出其条件限制，如果你想的话，对吧？

所以系统不能被破解。**它们能产生的唯一输出，是根据它们内部对情况的心智模型，满足护栏的输出**
。要制造安全的人工智能，关键在于那些关于情况的心智模型能有多准确，以及你需要设置哪些护栏，以确保那些东西不会失控，把地球变成回形针。这真的很容易做到。我的意思是，我们知道如何为人类做到这一点。我们为人类做这件事已经几千年了。这被称为制定法律。法律是一种护栏目标，它告诉人们，“好吧，也许你计划在这里做的行为对你来说看起来不错。”

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkK0pLlic8TcZtPVDto5vMOF6jn44LVwu4c0aCmMF5uccVVibdQuylsKjw/640?wx_fmt=jpeg&from=appmsg)

但是，如果你那样做，你就会被判五年监禁。好的，这改变了你的成本。

**主持人布赖恩·基廷：** 人工智能的某个功能会烧毁GPU中的电路，从而导致疼痛。

**杨立昆：** 你知道，人类可以选择忽略那个护栏，但一个目标驱动的人工智能系统，由于其构造，将无法忽略它，因为它们必须对其进行优化，所以它无法逃脱。

**主持人布赖恩·基廷：**
我总是称之为“间隙中的AGI”。它有点像这种间隙之神。他们的行为就好像，我喜欢马克斯，他对我个人非常友善，我也多次请他来做节目，但重点是，我们不会有一天突然就拥有AGI，对吧？这将是一个迭代的过程。我们已经看到了，对吧？我们看到了Waymo。

所以，就在上周，我实际上在洛杉矶看到了Waymo，但它是由人驾驶的。它非常迷茫。前排座位上有一个人开着这辆Waymo，我想，这有什么意义呢？但我觉得，如果你开始看到，你知道，比如称之为第零代或完全自动驾驶。

你知道，特斯拉，我坐过，它们不会在人行道上行驶。那将是到达某个地方的最短路径。你知道，Waymo可以直接穿过人行道来避开交通堵塞，当时很忙。但它不会那样做。**所以我们会看到证据，如果存在护栏，在汽车的情况下是字面意义上的护栏，比如脱轨**
。

我们将在0.1版本迭代中看到这一点。然后，你知道，我们不是有一天突然就拥有了AGI。即使是如何，你知道，我想说，就像第一个操作系统不是用操作系统构建的。总会有一个先驱。你知道，第一台计算机不是在计算机上设计的，我的意思是，根据定义。

因此，**第一个真正的AGI不会由AGI制造。不可能有这种递归**
。但在我转到我想要问你的关于在这个新时代当教授的最后问题之前，我想给你最后一个发言的机会。你对AGI还有什么其他想法吗？

我还有数百万个问题，但我们必须等到下一部分。我知道你很忙。关于危险你还有什么其他想法吗？或者那是你最常被问到的问题，也是我的听众问你的？

**杨立昆：**
我有一个非常乐观的看法，对吧？我的意思是，我认为智力是我们在社会中进步最迫切需要的、最令人向往的商品之一。所以我认为，拥有能够有效放大我们智力的机器的影响，可能就像15世纪印刷术的发明和书籍的传播一样具有变革性。

印刷术的发明使得知识得以传播，这让人们有了学习阅读的充分理由，而之前并没有这样的理由。这最终促进了启蒙运动、科学、民主的传播，并使人们摆脱了宗教教条的束缚，从而走向一个更加理性的社会。我认为印刷术的影响是深远的，尽管它也带来了一些暂时的负面影响，比如，由于宗教教条，一些思想的传播在欧洲导致了大约200年的暴力和冲突。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkIULlZI73F5SNeOj0YxhzgtXKicMuh0f3pETQCMxeaPDbCDfaPtkAZlA/640?wx_fmt=jpeg&from=appmsg)

然而，印刷术的长期影响是巨大的；它帮助瓦解了封建制度，并引发了像美国革命和法国大革命这样的革命运动。我认为人工智能将通过放大人类的智力，并协助人类完成原本需要其他人才能完成的任务，从而产生类似的变革性影响。

如果我们能够正确地利用这种潜力，人类将拥有一个光明的未来。我并不特别害怕Max所说的那种情景。

**主持人布赖恩·基廷：**
所以你认为人工智能对人类的变革性影响，真的会比2000年代早期的Facebook戳一下功能更大吗？但说到Facebook，你是一位学者。你是如何看待自己的？你是一位教授？还是一位科学家？还是地球上排名前三的公司的员工？如果早上被一个超级智能的人工智能叫醒，他们问你这个问题，你会如何定义自己？

**杨立昆：**
我是一名科学家。我也会说我是一名教育者，这不仅仅是因为我是一所大学的教授，还因为我做着像这样与公众谈论科学某些方面的事情。但我真的是一名科学家。我的职业生涯中，在工业界和学术界花费的时间几乎相等。我的职业生涯始于工业界的贝尔实验室，后来变成了AT&T实验室。之后，我曾在NEC研究所短暂工作过。

然后，在我40岁出头的时候，我成为了一名教授。我之前从来没有当过教授。做了10年的纯教授之后，我加入了Facebook，在那里创建了FAIR。我管理FAIR四年。在那段时间里，我是一名兼职的研究经理；同时我还是纽约大学的教授，基本上三分之二的时间在Facebook或者现在的Meta，三分之一的时间在纽约大学。

在建立并管理FAIR四年后，我卸任了这个职位。现在，我是Meta的首席人工智能科学家，**我是一个所谓的“个人贡献者”，这意味着我不管理任何人，也不负责任何项目**
。我讨厌管理事情，我是一个糟糕的管理者，做事没有条理，而且我不喜欢它——这对我来说是一种折磨。我做了四年，但我真正的热情在于产生智力上的影响。

我在Meta的影响是，我正在规划一条通往人类水平智能的道路，如果你愿意这样说的话，这就是我生命中的科学问题。此外，智能眼镜中具有人类水平智能的智能助手也有产品需求。因此，这是极少数的几种情况之一，我可能拥有的崇高的宇宙目标，与人们愿意为之付费的目标是一致的。

**主持人布赖恩·基廷：** 我可以看到我们之前谈论的那种视频技术，可能会为Instagram提供更好的滤镜。我也用过一些。

实际上，我有一个小技巧要告诉你，扬。我不知道你有没有发现这一点，但我希望你没有，这样我就可以给你留下深刻印象。

你有没有坐飞机的时候，Wi-Fi要19美元，而飞行时间只有两个小时，或者你可以免费发消息？你有没有遇到过这种情况？

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7Qk4ATskCHVWQAYRcct71CcMgRSO2OXsZicLDEGZooFQt9wTx9NlUFibwDw/640?wx_fmt=jpeg&from=appmsg)

你知道你可以免费使用WhatsApp AI，Meta AI，你的创造吗？这算作免费消息。你不需要支付任何Wi-
Fi费用就可以连接到互联网。这是真的。你知道吗？我本想给你留下深刻印象。拜托。

**杨立昆：** 不不，这非常酷。我认为很多人都没有意识到这一点。是的，是的。

**主持人布赖恩·基廷：** 你或许可以通过人工智能访问互联网。花19美元用每小时1兆比特的互联网。
无论如何，别太大声说，因为航空公司正在这么做。我知道，我知道。嗯，是的，幸运的是我们的观众还没有像莱克斯·弗里德曼的那么多，但我们会看到的。

马克对此的兴趣是什么？我的意思是，这会让他——只是为了做出更好的——我的意思是，AGI与Facebook、Meta的主要产品相比，除了聊天工具WhatsApp、Llama，还有Instagram、Facebook、Messenger和商店，以及Facebook和Meta的各种很酷的功能？

是什么在科学层面上驱动着他，也许是因为他显然没有受过科学家的训练？但他对未来有这样的愿景，而且不能仅仅是关于消费，对吧？肯定还有其他原因。他的使命是什么？他人生中最重要的目标是什么？

**杨立昆：** **他最重要的目标是将人们彼此联系起来。这就是Meta的全部目的。只是连接人**
，对吧？而且它非常专注于此。但是连接人也意味着不仅仅将人与人联系起来，而是将人与知识联系起来，或者帮助人们的日常生活，对吧？

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkJDfcsAtKaE8IcPbrbwBiaxicxD21aHlCWAAeAwHQWBKTVh538qdoZpFQ/640?wx_fmt=jpeg&from=appmsg)

所以，设想的未来，你有没有看过2013年的电影《她》？斯派克·琼斯的那部电影？在电影里，有一个家伙总是带着一个人工智能助手，要么在眼镜里，要么放在耳朵里，要么是一些带有摄像头的随身设备。这种愿景描绘了一个未来，我们每个人都会带着超级智能的助手为我们工作。

就像一位商业领袖、政治家或学者与比他们更聪明的一群人一起工作，这是不可避免的。我不知道你怎么看，但我倾向于聘请比我更聪明的人。这太棒了。这是一件好事。人们应该为这样的未来感到振奋。

如果你有这样的未来愿景——Meta有这样的愿景并且正在为此制造设备——那么你基本上需要具有人类水平智能的人工智能。这是一个产品的需求。如果我们今天拥有了它，它将会产生巨大的影响；比如，世界上每个人都会使用它。我们已经做了一些实验；当我说我们的时候，我指的是整个公司。我没有参与其中，但是有人把一些雷朋的beta测试眼镜带到了印度的农村地区，把它给了农民。

**主持人布赖恩·基廷：** 他们绝对喜欢它。看看这个，告诉我你看到了什么。告诉我发生了什么。想象一下公司是什么。

**杨立昆：**
我的意思是，他们看着自己的植物，然后说，嗯，这个看起来病了。你知道，那是什么病吗？或者这是什么虫子？你知道，我需要对它们做些什么吗？或者，或者像，你知道，我应该现在收割吗？明天天气会怎么样？我的意思是，各种各样的问题，他们可以使用，他们可以在他们自己的当地语言中这样做。

**主持人布赖恩·基廷：** 我可以和他们用，你知道，一些印地语或类似的东西交谈，他们可以...嗯，印地语是...

**杨立昆：** 它是一种广泛传播的官方语言，但印度大多数人不说。

**主持人布赖恩·基廷：** 对。当然。我不太熟悉印地语，对吧？它是一种方言。是的。他们那里有900种不同的方言，对吧？所以。

**杨立昆：** 我听说有700种，但差不多了。然后，你知道，在20到30种之间，

**主持人布赖恩·基廷：**
是官方语言。当我们快结束时，我还有两个问题。第一个问题与我们所做的事情有关。我把自己定义为，嗯，你知道，首先，一个父亲、丈夫等等，但也同时是一个科学家和教育家。我总是喜欢问这个问题：我的英雄伽利略，他生活在一个他既是教授又是科学家，也必须谋生的时代。他只有在可以出售使用说明书，如《星际信使》和《对话》时才会制造望远镜。

我称你我所做的事情为第二古老的职业，因为自公元1000年以来，在意大利博洛尼亚，然后在牛津和索邦大学就已经有教授了。我不需要告诉你这些机构的历史意义。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkI5NQnCXNNf4ohkyicicasfL0IqxlKxhEMLn2wKTR2icgg9C2g3Wv4PCCQ/640?wx_fmt=jpeg&from=appmsg)

你如何看待人工智能对教育的影响？为什么有人应该听？对我来说，当他们可以向伟大的阿尔伯特·爱因斯坦学习时，他们为什么要向布赖恩·基廷学习宇宙学和广义相对论？作为教授，我和我的同事面临的威胁和机遇是什么？我们开始吧。

**杨立昆：**
我的意思是，很明显，知识传递这一职业将会被非常深刻地改变。我们可能需要为研究、科学和学术寻找一些新的经济模式，这些模式在社会中发挥着重要作用，但不一定与教育相关联。

现在，我认为仍然存在博士学位和导师的整个概念，这有点像绝地大师和学徒。我认为这种关系仍然会存在，因为它不仅仅是关于知识。我不知道你怎么样，但我可能从我的学生那里学到的东西和他们从我这里学到的一样多。这只是一种不同类型的学习方式或信息交流。

但我认为，这种互动在行为、伦理、什么有趣、该做什么以及科学和研究的实践方面都很重要。在某种程度上，在未来，有了人工智能，我们所有人都会成为一个由虚拟人组成的团队的机器人。你可以这样想。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7Qk5LzxjHu4Bib0gnoFlXFobjN6ws3ohpCiaLAOUjo3rict40SaoplmLTfMA/640?wx_fmt=jpeg&from=appmsg)

这将包括商业领袖、教授，我的意思是，不仅仅是领导者，而是所有人。嗯，我们就像今天一个拥有一群聪明人为他们工作的人一样。学生也将如此。因此，你与学生的互动将不仅仅是与学生本身互动；而是与学生通过人工智能系统增强后的互动。

**主持人布赖恩·基廷：**
我觉得太棒了。我并不觉得受到威胁。我一直试图做，即使我制造望远镜并寻找大爆炸遗留下来的热量，我仍然对它着迷。而且我实际上认为人们现在，我们正处于开端，对吧？有人说，我们现在正处于人工智能最糟糕的状态。它只会变得更好。

而且我可以如此快速地完成很多事情。有些事情你必须被某种程度地监督，但对我来说意义重大的是它是多么令人愉快。我的意思是戴着眼镜谈论物理世界并与之互动，同时也学习。它在地球上几乎所有科目中都已经有120的智商，特别是新的Llama模型。我对此感到非常兴奋。

但我想问你的最后一个问题来自这个播客的同名人物。那是阿瑟·C·克拉克的说法，了解可能性的极限的唯一方法是进入不可能并超越它们。但他还说了另一件事。他实际上说了一些非常有趣的事情。他说，对于每一位专家，都有一位同等且相反的专家。所以我时不时地对我的系主任使用它，当我想摆脱教学任务时。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBPTPBtpqgoUtMoWA1WiaC7QkxSBy2EZ69XsHDDJia88w0ja36wIJEgYwNSFw7OYkCFJqOeLrichGOIiaw/640?wx_fmt=jpeg&from=appmsg)

但他说了以下内容，扬。他说，当一位年长的——我不是说你年长，但我说当一位年长但杰出的科学家——当然你是——说某事是可能的时候，他很可能说对了。但是，当他说某事是不可能的时，他很可能说错了。我想问你，扬，你有哪些事情是错的？你改变了对什么事情的想法，如果有的话？

**杨立昆：** 哦，我改变了很多事情的想法。一个例子是，在神经网络的早期，当我开始与杰夫·芬顿互动时。我在 87 年和 88
年与杰夫·辛顿一起做了博士后。当时，我对我们称之为无监督学习的东西没有兴趣。我认为这是定义不清的，我不明白它的意义。

然而，杰夫认为这是该领域最有趣的方面。他一直在研究波士顿机器，他最终因此获得了诺贝尔奖。虽然现在没有人再使用波士顿机器了，但这与主题无关。**杰夫的观点非常有影响力，他强调说，大部分学习都必须是无监督的。他在这方面是对的。**

在 2000 年代初，我最终加入了他的阵营。从 80 年代后期到 2000
年代初，**我花了很长时间——将近十五年——才改变了对这个概念的想法，并成为无监督学习的真正信徒** 。到 2010 年代，我开始以更明确的方式倡导它。

**主持人布赖恩·基廷：** 扬。我该如何对扬说非常感谢和周末愉快？非常感谢你，扬，祝你周末愉快。这太令人着迷了。

**杨立昆：**
我需要告诉你一件事，因为你一直在谈论望远镜，所以我不是制造望远镜的，但我确实以业余爱好者的身份进行天体摄影，所以我不是做科学，但我拍一些漂亮的照片，你知道吗。

**主持人布赖恩·基廷：**
我很想看看。我的意思是，最初的天体摄影师是伽利略，他不仅勾勒出了他所看到的东西，还勾勒出了他对宇宙的感受。杨立昆，这太令人着迷了。我迫不及待地想在下次我来参观西蒙斯基金会、扁平铁研究所时与你见面，这将是一种荣幸。

**关注公众号后设🌟标，掌握第一手AI新动态**

##  往期精选

  1. [黄仁勋专访：OpenAI在大模型混战中达到“逃逸速度”](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650001718&idx=1&sn=f8129a622e7611702be2cb23e8ce9418&chksm=88ba5831bfcdd127d06ce6492c821074407f805407b4182ca900916521cb5a4717f2a3d71ee8&token=1339625777&lang=zh_CN&scene=21#wechat_redirect)
  2. [李飞飞与Justin深度解读空间智能：数字世界需要三维表征，才能与现实世界融合](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000659&idx=1&sn=c71fb5b4ef501424dddd5e8b4dd5860e&chksm=88ba4414bfcdcd023c691a1adf75127a9fd883ceb305ca14cf97f719acaf999d40fa72f84bf3&token=1492077842&lang=zh_CN&scene=21#wechat_redirect)
  3. [PayPal创始人彼得·蒂尔：人类科技停滞源于原子方面的进展远慢于比特](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000240&idx=1&sn=26af6013981677b1e14137260857a6f0&chksm=88ba4277bfcdcb615d746615c262927bf51c43c920ed93fa36274ef87c6264d6548c84647121&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  4. [谷歌联合创始人布林：巨头们打造的“上帝模型”几乎可以理解一切](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=2&sn=0c714d804a72a52e002743d949e1685e&chksm=88ba40f9bfcdc9ef78749718480265922f4fba539abf6c9d62a6cd681f405dee9283d2429f84&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  5. [马斯克：AI将使商品和服务的成本趋近于零](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=1&sn=752f000a117a705e77950c82bfc4a004&chksm=88ba40f9bfcdc9ef5a5afe4a3ae73d5247bd54ed525dbdbedee1fcf74a6c082165e664a5c4d0&token=106920805&lang=zh_CN&poc_token=HDp86Waj18SFm2Y-xnv_Vqd_4J6emFoh10eH48wg&scene=21#wechat_redirect)
  6. [Karpathy最新专访：人形机器人、特斯拉、数据墙与合成数据](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999613&idx=1&sn=b8bdda7afe4c3ca08e324ac5bbd5a2bd&chksm=88ba41fabfcdc8ec0e21dbf4c7eb4d33252da70f47e1cfc9f5e113717911c417c2aebb3d6180&token=106920805&lang=zh_CN&scene=21#wechat_redirect)

  

