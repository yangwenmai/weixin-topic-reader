# 年度盘点｜IBM携同行业专家360度解读2024 AI进展：模型、代理、硬件、开源、安全治理

文章作者: 瓜哥AI新知
发布时间: 2025-01-01 11:00
发布地: 浙江
原文链接: http://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650006285&idx=1&sn=019e6c40d4304d72e0a4f1844d43c993&chksm=88ba6a0abfcde31c0b67874f47d0c0a1dd62a340f2f7663efe56cab73dac7e5e58a63e04d860#rd

封面图链接: https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbnyGicV2uXk6CY2xfjWpxcs5VqHSuQg4icyWTBhflkzrC66OsVVc9PQbA/300

**👇关注公众号后设🌟标，掌握第一手AI新动态**

**  
**

本文内容整理自**IBM 2024 AI盘点**
，公开发表于2024年12月27日。原始内容参考：https://www.youtube.com/watch?v=l8plyR8aqVQ

## 2024人工智能回顾：IBM携同行业专家深度解读模型、代理、硬件及产品

**一、2024年人工智能模型发展：**

  * **规模化定律的时代终结，转向效率和成本控制：** 大型模型（如Llama和GPT-4）取得显著成果后，行业关注点转向构建更小、更高效、更具成本效益的模型，并利用高质量的企业数据进行训练。
  * **推理能力的提升和工具的应用：** 模型开始具备推理能力，能够制定计划并使用工具来完成任务，类似于人类的学习过程。
  * **多模态模型的兴起：** Gemini Flash等小型多模态模型的出现，标志着多模态处理能力的显著提升，未来将应用于更多场景，并推动计算基础设施向设备端转移。
  * **竞争激烈，多家公司参与：** OpenAI、谷歌、Meta等巨头以及新兴公司纷纷推出新模型，竞争激烈，推动了技术的快速发展。
  * **模型序列而非单一模型更重要：** Llama模型序列体现了预训练和后训练的持续迭代，以及对规模的不断追求，这比关注单一最佳模型更重要。
  * **企业级应用的成熟：** 模型的质量提升到足以支持企业级解决方案的程度，为企业带来切实价值。

**二、2024年人工智能代理发展：**

  * **代理技术被低估，2025年将出现超级代理：** 代理技术将成为未来发展的核心，并出现功能强大的“超级代理”。
  * **标准化和协议的制定：** Meta和Anthropic等公司致力于制定代理之间交互的标准和协议，为代理生态系统的建立奠定基础。
  * **安全性和人机交互是主要挑战：** 代理技术的安全性和人机交互模式需要进一步完善，避免数据泄露和过度依赖等问题。
  * **未来将出现“Web 4.0”：** 网络将为代理的使用进行优化，出现专门针对代理设计的网页内容。
  * **翻译和专业领域服务是早期主要应用场景：** 代理技术在翻译和专业领域服务（如法律服务）中具有显著的应用潜力。

**三、2024年人工智能硬件发展：**

  * **英伟达仍保持领先地位，但竞争加剧：** 英伟达在训练领域保持领先，但AMD、英特尔等公司以及一些初创公司正积极竞争，未来几年可能改变市场格局。
  * **推理硬件的快速发展：** 推理优化技术（如VLLM、Triton）以及专用推理引擎的出现，推动了推理硬件的发展，为竞争对手提供了更多机会。
  * **边缘计算的兴起：** 苹果等公司在移动设备上集成AI芯片，推动了边缘计算的发展，并促使芯片设计向更低功耗、更低成本的方向发展。
  * **成本和能效是重要考量因素：** 英伟达GPU的高成本和高功耗成为其发展的瓶颈，其他公司正试图提供更具成本效益和能效的替代方案。

**四、开源、治理和其他趋势：**

  * **开源模型的崛起：** Granite 3.0等开源模型的发布，以及Llama 3等大型开源模型的成功，标志着开源运动在人工智能领域的崛起。
  * **从“更努力工作”转向“更聪明工作”：** 行业关注点从单纯增加训练计算转向提高推理效率和性能，GPT-4O模型系列是这一趋势的体现。
  * **人工智能治理日益重要：** 国际社会对人工智能安全和治理的关注度日益提高，相关峰会和研讨会频频举行。
  * **自主AI和模型安全：** 自主AI技术的发展将进一步凸显治理和安全的重要性，并促使开发用于管理和监控代理的工具。
  * **未来界面将超越聊天：** 未来的人工智能界面将超越简单的聊天界面，转向支持共同创作和协同创作的模式。
  * **模块化组件的潜力：** 构建模块化、可互换的模型组件，将提高模型的灵活性和效率，并简化模型的开发和部署。

## 对话全文

**主持人Tim Huang：** 我是Tim
Huang，欢迎收听“专家混合”。每周，“专家混合”都致力于为您带来黄金标准的对话，帮助您理解不断发展的人工智能领域。今天，我们回顾2024年的巨大变革。

大家都知道，回溯到2024年1月，我们都在讨论GPT商店的发布，以及Claude 2.1的超长上下文窗口。当时，我们还在等待Llama
3的发布。2024年无疑是人工智能领域充满活力的一年。我们聚集了一批最优秀的专家，讨论他们认为突出的亮点，哪些方面进展不尽如人意，以及他们对2025年的展望。

我们将讨论全年的代理、硬件和产品发布。但首先，我们将从2024年人工智能模型领域发生的事情开始。为了帮助我们梳理这段历程，我们请来了高级研究科学家Marina
Danilevsky，以及负责美国、加拿大和拉丁美洲人工智能咨询的高级合伙人Shobit Varshini。

我想先从一个更直接的故事开始，甚至在回顾2024年1月的“黑暗时代”之前，那就是O1的发布。这显然是一个重大公告，是今年最重要的公告之一。我知道Shobu，在节目开始前，你和我聊过，你指出O1的发布标志着这些公司在开发和扩展模型方面的思路发生了重大变化。也许我们可以从这里开始，如果你想开始的话。

**Shobit Varshini：**
太好了。现在能活在这个时代真是太棒了。我们周围发生的一切都印证了这一点。在你的整个职业生涯中，没有哪一年比今天更值得活下去。在过去的一年左右，我们看到了规模化定律的时代。我们意识到，增加计算量，构建更大的模型，并推动更高的性能，可以为这些模型带来令人难以置信的成果。现在，我们已经达到了拥有超大型模型的地步，例如拥有4050亿参数的LLAMA和拥有1.75万亿参数的GPT-4。你可以看到，这些庞大的模型正在做着惊人的工作。

现在，我们正在向市场上的几个不同转变过渡。首先，我们看到这些模型正朝着推理阶段转变。这包括放慢速度，思考我们想要实现什么，并制定实现目标的计划。此外，我们已经开始为这些模型配备更多的工具，就像我们小时候学习使用工具一样。这些代理流程也在帮助我们提高模型的智能。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonb6RicUbib1hXVenurGcN91JY1u1icfX1Aia4QibVgaU82SicBqPdgJtwVUwNQ/640?wx_fmt=jpeg&from=appmsg)

我们还观察到整体成本结构发生了重大变化。在过去一年中，专有模型的成本已经开始实施，但较小的模型变得更加高效，并且开始表现得更好。因此，我们目睹了向这些能够更深入思考的超大型模型的转变。此外，我们已经耗尽了所有可用的公共互联网数据，现在正更加专注于高质量的企业数据或为特定模型构建的特定数据集。

因此，**我们正达到这样一个阶段，即我们有一个非常庞大的教师模型，它非常擅长全面理解问题。这个模型可以生成合成数据，协助训练较小的模型，并将知识提炼到以较低价格提供高性能的模型中。**
我们在如何思考人工智能模型以及如何投资构建它们方面已经发生了重大转变。关于人工智能模型能实现什么，2025年及以后的发展态势将完全不同。

**Marina Danilevsky：**
是的，我认为你是对的。就我们开始时的状态和最终所达到的状态而言，今年是非常有趣的一年。我们已经看到，是的，我们可以变得越来越大。而现在我们终于到了这里。我们可以说，太好了。既然我们可以变小，那么我们还能继续做得多好？

最初关于“我们可以变得多大”的研究推动，最终让我们有条件说，好的，现在是时候讲效率了。现在是时候削减成本了。现在，或许最终可以谈论环境因素和诸如此类的东西了，也许明年吧。这算是对2025年的预测吗？

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonb99mrKky8ZCa7HKFwJU1tiaYJCbnA8WbEQ88SMEtVUM8mtJcTYVjVGRQ/640?wx_fmt=jpeg&from=appmsg)

所以，2025年是一个重要的里程碑。这部分非常有趣。**这也意味着质量已经达到了我们可以开始可靠地构建企业级解决方案的程度** 。我对此感到兴奋。

我知道我们还没有谈论NextG，但那是我真正兴奋的事情。我认为质量终于达到了。我们可以开始认真对待企业解决方案了。

**主持人Tim Huang：**
是的，我的意思是，我认为这似乎是今年非常重要的趋势，你知道，我作为一个在业余时间喜欢搞软件工程的人，今年我真的觉得，哇，我终于可以用这些代码助手做一些我本来做不了的事情了。它终于适合我在日常生活中使用了。我认为这是一个非常大的飞跃。我认为，在过去的12个月里，我们注意到了这一点。我想，Marina，有没有什么特别的故事让你印象深刻，比如，在春季早期或其他时候，你觉得，当回顾2024年时，你会因为某件事而真正记住它？

**Marina Danilevsky：**
我的意思是，首先，我会记住它竞争非常激烈的程度。感觉每两周就有人推出新的东西。甚至是你可能没有想到的公司，比如最近的亚马逊，他们说，哦，他们在研究这个。哦，这实际上还不错。所以我认为，我会记住很多人都在以一种良好的方式相互超越，这种方式实际上推动了事物的发展。

但我认为，今年我们拥有的玩家数量才是真正让我印象深刻的地方。正如我们在之前的节目中讨论的那样，一些首次亮相的产品更成功，而另一些则不那么成功。有时人们没有完全仔细检查一切。有时人们认为演示有点过度渲染。

所以我认为，这将使我真正记住今年的是：如何加入竞争并展示你的特色。Shobit，你呢？

**Shobit Varshini：**
我认为从企业的角度来看，今年是令人惊叹的一年。我们最近进行了一项关于人工智能报告的调查，结果显示，全球约有15%的客户通过应用生成式人工智能获得了真正的、切实的价值。之前有很多知识被锁在文档和流程中。我们观察到，客户正专注于少数小型、复杂的工作流程，并从中获得卓越的价值，这方面有了显著的进展。

此外，我认为我们没有从通用的副驾驶或助手那里获得足够的价值。重点已经更多地转向将这些技术建立在特定的数据、知识和相关背景之上。总的来说，我们刚刚经历的过去两周代表了过去两到三年人工智能发展中最活跃的时期。OpenAI和谷歌之间的竞争，以及Meta的参与，都是一项了不起的举动，激发了整个社区的活力。

现在，我们开始看到一种转变，即拥有卓越的模型，并找出如何更好地控制它们，使它们适应我们的企业工作流程和数据集，并使它们能够使用必要的工具进行思考和推理。围绕人工智能的重大进步很可能被视为一个关键的时刻。我们开始意识到，每月在人工智能解决方案上花费200美元可以被视为巨大的价值。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbCcsnjK0ETL2T3ETPrLuKYZibU1vpvrxHNUtIH6qZlI4oAia0mImTryLA/640?wx_fmt=jpeg&from=appmsg)

在这个时刻，各组织在哪些工作流程可以真正从人工智能应用中受益方面变得非常有战略性。我们已经达到这样一个地步，企业基本上是在为增强其日常运营的各个方面而付费。我相信，随着我们接近2035年，我们将积蓄巨大的势头。

**主持人Tim Huang：**
是的，当然。我想，我不知道大家有没有关于最佳的提名，或者说，O1版本是年度最佳发布吗？我的意思是，从模型的角度来看，或者说还有其他一些比较突出的模型吗？我的意思是，我们今年也有Llama
3，对吧？那也是一个非常非常重大的发布。

**Shobit Varshini：** 对我来说，是**Gemini Flash**
。我认为他们用一个小型模型实现的、能进行多模态处理的能力，将推动未来两到三年的计算发展。我这么说的原因是，现在你可以解锁一切。如果你们最近关注了Android
XR的发布，你们现在就会明白，多模态模型本质上是非常大的。它们需要大量的计算，并且总是在服务器上运行。

现在，**有了像Google Flash这样的模型，你将达到这样一个程度，即小型模型可以非常好地进行多模态处理**
。真正让你惊叹的是它如何开始记住你刚刚看到的东西。我认为它将开始增强我们日常工作流程的各个部分，包括记忆。这是我们迄今为止没有看到的。我们过去通常是在一个“冷启动”的情况下提问。现在，我们将达到一个这样的程度：这些模型将拥有无限的记忆，并且可以像我们一样访问工具。

我对小尺寸的高性能非常兴奋。这一进步最终将使我们能够实现一个计算基础设施，让你可以拥有XR和AR体验，从而使计算更接近设备。这将驱动更多的隐私，因为数据将被锁定在我随身携带的设备中，而不是存储在其他人的云端。

**Marina Danilevsky：**
是的，实际上我想同意这一点。关于小型模型的事情，因为我认为，至少在未来一两年内，我们将看到更多的正式监管出现，并且更多的人开始意识到这到底意味着什么。正如你在说的那样，Shobit，如果模型开始记住东西，开始变得个性化，开始变得定制化，那将变得极其极其重要。所以，拥有一个小的、本地的、你可以通过技术来保证的模型，这将变得非常非常重要。

**主持人Tim Huang：** 是的，当然。Shobit说，哦，一是一个巨大的进步。如果你有一个，比如，年度最佳模型的提名，这很难。

**Marina Danilevsky：** 我喜欢以一种整体的方式来看待它们，而且我觉得，目前很难判断某件事什么时候会真正转变。

我要提名一个序列，我认为，也就是Llama模型的序列，不是Llama模型本身，而是我们有Llama
3的序列，然后，所以我们已经看到了我们用预训练可以做什么，然后我们将看到我们用后训练可以做什么。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbqtzaSLKZnD1yMEmg1hN2wztP1ZRZUkZRuY84PdiaYicHayu09VtM1TzA/640?wx_fmt=jpeg&from=appmsg)

所以我们会变得更大、更大、更大，然后我们会看到我们能走多远。我希望看到人们以一种持续的视角来看待它，作为一个序列，人们尝试推动预训练、推动后训练、推动规模，并以迭代的方式做到这一点。

我希望看到这种情况继续下去。

**主持人Tim Huang：** 是的，我觉得这就像我们知道你是个鉴赏家，Marina，你喜欢Llama的策展。这不仅仅是任何给定的模型是最好的模型。

**Shobit Varshini：**
Marina，**我认为我们将达到这样一个地步，即大型研究实验室将构建更大的模型，但他们可能不会以模型的方式向公众发布它们。绝对的。我们将更多地使用它来创建合成数据，用于将知识提炼成教师模型，等等**
。

我真的很兴奋，我们终于要达到一个我们探索这个想法一段时间的程度了。我们说，哦，如果我只是让这个模型在回答之前思考一下，瞧！这类似于小学老师对孩子们所做的事情，对吧？现在我们正在尝试重新学习如何教导年幼的孩子们解决问题。他们需要观察不同的事物，制定计划，然后回答问题。如有必要，他们应该拿起计算器，而不是试图在头脑中完成一切。

我觉得我们在训练孩子和我们对他们进行的强化学习之间有很多相似之处，给予奖励和机制。我们将问题分解成较小的部分，然后他们分别解决每个问题。当他们做对事情时，会有一个积极的强化方面。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbvPqk1zGU8qs465DEtJVFe6P7PGib2UcEkX8j91pNeItDl8WQnFCia8pQ/640?wx_fmt=jpeg&from=appmsg)

我认为我们正在达到一个我们也在学习这些模型如何学习的程度。这导致了良好的共生关系。我相信，我们将开始停止要求这些模型去做人类擅长的事情。相反，我们将更好地相互理解哪些任务应该委派给这些模型。这种转变也意味着基准以及我们如何评估这些模型将发生很大的变化。

今天，我认为我们开始非常了解这些模型了。到2025年和2026年，我预计我们将与它们建立一种截然不同的关系，它们将更多地成为一种伴侣，而不是我们试图弄清楚，“嘿，你能做得和我一样好吗？”

**主持人Tim Huang：**
是的，当然。我觉得今年最有趣的结果之一就是所有“你能不能再努力一点？”的例子，然后模型实际上就做得更好了。这真的很有趣。我的意思是，以前的计算机可不会这样。所以，我想最后一个问题，然后我们就可以结束这一部分了。我们还没有过多地谈论多模态，但它似乎将在2025年成为一个非常重要的领域。我很好奇，我想也许从玛丽娜开始，你对明年多模态领域的发展有什么预测吗？

**Marina Danilevsky：**
是的，多模态。当我们最初出现基础模型时，我们就有过这些想法，因为我们都对这个事实感到非常兴奋，哦，它只是按顺序排列的token。它不一定是文本；它可以是任何东西。但我认为我们都选择了文本作为最早的领域之一，代码也算其中一部分，是因为我们拥有大量的训练数据，以及大量的例子。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbRJ6f7Mg4ezYXrN1vgOZjq5Nib9jewFibF8LuCgb33aibk6pC9wuYvnQ2A/640?wx_fmt=jpeg&from=appmsg)

所以，尤其是在我们利用合成数据做得越来越好之后，就像你说的，你指的是教师模型，我们将能够更多地探索这个领域。我认为我们可能终于到了一个程度，它们再次变得有用了。大家对多模态模型非常感兴趣，因为现在，你知道文本模型，我们有一个想法，当你有一个模型做很多任务时，它会互相学习，现在如果有一个多模态模型，将会更有趣，这是否会使它在每个单独的模态方面也表现得更好？

再次强调，我认为数据现在终于到位了，不仅仅是算力，还有数据和创造更多数据的能力。我认为明年我们应该会看到更多。我本以为今年会看到更多以科学为目标的模型。也许现在，明年我们可能会看到在视频方面更成功的模型，不仅仅是Sora，而是更实用的、更贴近底层的模型。想想机器人技术；那里有很多东西可以挖掘。

所以，我想这就是我看到的情况。也许那些炫目的部分很有趣，但真正的用处可能是在更底层，需要艰苦努力的地方。

**Shobit Varshini：**
我认为多模态领域在未来几年将会非常惊人。重要的是，要理解人类所看到的、感受到的、观察到的、阅读的和听到的所有方面，才能在它到来时帮助我们。这种理解将对我们如何感知周围的世界产生巨大的影响。

到目前为止，我们已经做过一些事情，比如拍摄某物的照片，或将其翻译成文本，以便向聊天机器人提问。然而，这种模式并没有有效地扩展。随着多模态模型变得更好、更小，比如Gemini
2.0 Flash实验版，这些模型将会在我们的日常生活中带来更丰富的体验。这个领域的竞争将会非常激烈，各种模型将从各个地方涌现出来。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbQcxe5r2jbAcIcwva98d334Vufc9qvQPpdGUkrPu0sN2XiaoXrsiaNibGg/640?wx_fmt=jpeg&from=appmsg)

传统上，人工智能的操作方法是先进行语音转文本，然后使用人工智能模型处理文本，最后将响应转换回语音。然而，在整个翻译和转录过程中，会损失很多信息。随着任何到任何模型的发展，例如直接语音到语音，我们可以增强沟通并提供卓越的客户体验。

通过在媒体之间进行转换，比如从语音到语音，这些模型将开始理解人类对话的细微差别。我非常期待明年在多模态内容方面的进展，以及它在改变我们与技术互动方式方面的潜力。

**主持人Tim Huang：**
太棒了。这就是我们今天讨论人工智能模型的所有时间了。肖伯特（Shobit），玛丽娜，感谢你们的到来。节日快乐。我们明年再来谈论这些以及更多内容。

在接下来的环节中，我想谈谈2024年的代理。为了帮助我做到这一点，我将请来客户转型的首席技术官、杰出工程师克里斯·海，以及人工智能孵化的产品经理玛雅·穆拉德。玛雅、克里斯，欢迎回到节目。

好吧，2024年是代理的一年。代理、代理、代理。我觉得在MOE内部，这几乎成了一个玩笑，如果我们有一集节目没有包含代理，那将是一件非常大的事，而且是一件不寻常的事。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbC9UKu6a7XD24ZJTQAicicV9g9bPDLTV0nfI51t49GVic8RJCzZAATnXsg/640?wx_fmt=jpeg&from=appmsg)

所以我想也许可以这样说，我想也许克里斯，我们先问你：2024年的代理是被过度炒作了还是被低估了？

**克里斯·海：** 被低估了，不够炒作。代理就是世界。代理就是一切。在2025年，我们将拥有超级代理。这就是2025年的发展方向。

**主持人Tim Huang：**
好的，明白了。我想，玛雅，我的意思是，回顾过去，我不知道你是否同意克里斯的观点，或者在2024年代理的开发过程中，有没有什么特别的故事让你印象深刻，如果它们真的会像克里斯所说的在2025年变得如此重要。

**玛雅·穆拉德：**
我完全同意。我会说2024年，有很多关于人工智能代理的讨论。我很高兴看到更多的执行。我期望看到更多的障碍。一旦我们看到更多的代理被投入生产，我认为我们才刚刚触及所需的表面。

**我今年开始看到的一个趋势是，有更多的协议和标准化工作。所以我们看到Meta正在尝试用Llama堆栈来做到这一点，Anthropic则使用他们的模型上下文协议（MCP）**
。

我认为这将是一场关于我们如何标准化大型语言模型与外部世界交互方式的小型战斗。我相信，未来它还将涉及代理之间如何相互交互。

我认为这才是下一个前沿领域，也是我们许多努力将要投入的方向。

**主持人Tim Huang：**
是的，这感觉就像是重要准备的一年。我一直在看所有的新闻报道，我想，今年最大的代理故事难道是Salesforce正在聘请大量销售代理来销售代理吗？感觉就像那样，而且在两者之间，以及技术标准之间，感觉几乎很少出现这样的情况：“哦，是的，这是今年杀手级的代理发布。”实际上，更多的是准备工作。我不知道玛雅你是否同意。

**玛雅·穆拉德：**
感觉就像是为即将发生的事情以及我们需要考虑的所有不同因素做准备的一年，然后是谁想要拥有这个类别。所以很有趣的是，例如，Meta很早就推出了。Llama堆栈的第一个版本有点粗糙，但他们尝试做的事情是意义重大的。他们说，“我们是长期投入的，我们想帮助**定义那些代理之间的通信协议**
。”我相信，如果这是Meta想要采取的方向，他们会做得很好。

这也预示着一些有趣的事情。过去两年主要看到该领域对OpenAI发布的内容做出反应。OpenAI发布了他们的聊天完成API，整个生态系统都随之效仿。如果你没有那个完全相同的API，你的产品就更难被采用。

然而，现在我们看到更多的玩家争夺成为设定这些标准和协议的人。这种转变表明这个领域的多样性在不断增长，这可能会在未来带来更多的创新和竞争。

**主持人Tim Huang：**
是的，当然。然后，克里斯，也许我想把话题转回给你，我的意思是，你，我觉得你刚才用了“智能体即世界”这个说法，这是一个非常大胆的断言。但我的意思是，2025年，我的意思是，你知道的，假设智能体变得更加流行，作为大环境的一部分，变得更加突出。那么，Meta
是否能很好地占据领先地位？或者，你对我们将会看到谁在这个领域领先，谁又可能稍微落后，有什么预测吗？

**克里斯·海：** 我真的很喜欢玛雅关于 Anthropic
和**模型上下文协议的看法。我实际上认为这将是明年智能体最大的推动因素之一。他们很好地解决了远程调用工具的问题**
。这可能是他们解决的最大问题，对吧？如果我们考虑一下企业，你不会有智能体在网络上搜索或下载文档；它将是访问你的企业工具。

它将是访问 Slack、你的 Dropbox 或 Box 文件夹或 GitHub
之类的东西。其中很多正在被标准化。更重要的是，你希望以智能体可以标准化使用的方式，获取你自己的数据并公开你自己的 API。我认为 MCP
在允许你远程调用工具，然后能够将它们与多个服务器链接在一起方面做得非常好。我相信这将是未来发展的一大推动因素。

有趣的是，例如，它可以很容易地连接不同的 LLM。它不与 Claude 堆栈绑定；你可以连接你想要的任何其他模型。一切都与函数调用相关联，而函数调用又是
OpenAI 创建的标准。我很欣赏你刚才说的，玛雅，关于不同的提供商聚集在一个生态系统中的看法。这正是我希望看到的：没有一家公司主导这个领域。

这个提供商的生态系统将推动一切向前发展，引领我们进入一个大型智能体市场的世界。这就是我为什么说超级智能体即将到来，因为它将是一个围绕 2025
年开始出现的庞大生态系统。

**主持人Tim Huang：** 当你提到超级智能体时，你具体指的是什么？我只是临时想出来的这个词，蒂姆。你是在 MOE
这里第一次听到它。一个真正优秀的智能体，就是一个超级智能体。这是来自超级智能的概念，还是你自己的定义？或者，它的意义类似于好莱坞的超级经纪人？

**克里斯·海：**
谢谢你的解围，玛雅。我将把超级智能体定义为推理模型、现在刚刚出现的推理时计算模型与工具访问的结合，因此它们比你今天拥有的智能体更强大。所以，你第一次听到这个定义，你说的对，蒂姆，这就是超级智能体。

**主持人Tim Huang：**
非常好。玛雅，当你对我的第一个问题做出反应时，你说了一个有趣的短语，那就是，你知道，明年的智能体将无处不在，但也将是我们发现障碍或局限性的一年。你知道，基本上，智能体的全部力量将猛烈冲击现实。我认为我们将学到很多东西。而且，你知道，我想，我为这一集问了很多嘉宾的一个问题是，你知道，什么是被低估的？人们没有想到，但可能成为智能体未来发展的一大障碍的又是什么？

**玛雅·穆拉德：** 第一位的答案是，安全，这是被严重低估的。我认为已经有报道说，这个领域中的许多现有参与者正在泄露敏感数据。我认为智能体是加剧 LLM
这些固有风险的一种方式。我们目前低估了要做好这件事需要付出什么。

另一个重要的方面是，要准确把握人机交互。当你能够自动化更复杂的任务时，就会产生哪些任务仍然需要委托给人类的问题。我们如何确保人参与其中？此外，我们如何避免在这些自动化系统中出现过度信任的问题？我的团队进行了一些用户研究，我们发现，当信息由一个看起来和感觉都很聪明的行为者整齐地呈现时，很容易就全盘接受。

我相信将会出现一种全新的人机交互模式，或者说是人-
智能体交互模式。我对未来充满期待，因为我认为这本质上是一项创造性的练习。我们必须探索如何在将某些流程自动化为人工智能的同时，保留我们的创造力和批判性思维能力。要找到这种平衡将是一个引人入胜的挑战。

**主持人Tim Huang：**
是的，我认为委派问题最终会变得非常非常困难。我认为，即使是那些听起来很聪明但实际上并不聪明的人，也很容易依赖他们。我想，对于智能体来说也是如此。

嗯，我想这样说吧：听起来我们都非常感兴趣。你们两位的重大预测似乎都是智能体市场，对吧？这可能是我们明年将看到的大事。

一个重要的问题也是，在某种程度上，第一个最流行的智能体用例是什么？你考虑一下大型市场；智能体可以做很多事情，而且可能很有趣。但是，你知道，我认为我们几乎在寻找类似于智能体世界的电子邮件的东西，对吧？比如，什么会成为智能体世界的
Slack？

我很好奇你们两位的经验——与客户交谈，了解他们对智能体真正希望看到什么，有什么特别的希望和梦想。如果有什么反复出现的事情，那对我们的听众来说是有价值的。

**克里斯·海：**
我认为，从我的角度来看，蒂姆，在这个市场中，有一些明显的机遇，比如翻译。如果我真的诚实地说，今天的语言模型并没有真正很好地掌握翻译。一些模型在某些语言上表现良好，但在涉及更深奥的语言——特别是那些不太流行的语言时，大型模型通常会表现不佳。这为那些接受过特定语言训练的专业模型创造了真正的机会。通过将这些较小的语言模型与智能体相结合，在提供翻译服务方面可能会有重大进展。

此外，这个概念可以扩展到领域服务。例如，在像法律服务这样的领域，你非常了解，蒂姆，我相信这将在市场中发挥重要作用。然而，我希望它不会仅仅局限于这些单独的智能体。信息范围可能非常广泛——它可能涵盖从体育比分到各种游戏的细节，涵盖任何内容。

此外，我对 2025 年的预测之一是，我们将见证万维网的转变。目前，HTML
和类似的标记语言主导着互联网，但它们并不是为大型语言模型或智能体设计的。因此，我不知道，为了让这些智能体蓬勃发展——不仅在市场中，而且在数据公开方面——我们是否会开始看到新型网页的出现。这些页面可以针对智能体使用进行优化，而不是主要面向人类用户。

本质上，我预测**我们可能正处于向我谨慎地称之为“Web 4.0”的转变的边缘** 。我试图避免使用“Web
3.0”这个短语，但其理念是，我们将拥有专门为智能体设计的内容，从而提高它们检索和有效利用信息的能力。

**主持人Tim Huang：**
是的，而且似乎你们俩都暗示了一个预测，那就是人们对智能体的潜力如此感兴趣，以至于我们几乎要重建网络，使其对智能体安全或使其能够为智能体工作。我想，现在构建的很多堆栈和互操作性方面的东西，在某种程度上都是为了实现这个目标。玛雅，你同意吗？你认为这将是未来吗？**我们将会有智能体标记语言，基本上就是ATML**
？

**玛雅·穆拉德：**
我认为，当由不同供应商构建、由不同组织拥有的不同智能体能够彼此互动时，许多有趣的用例将会被解锁。比如，如何建立安全协议？如何才能高效地做到这一点？这里的希望在于，我们如何打破所有这些不同系统的孤岛，以及不必手动设计每个系统之间如何通信？我们能否达成一个通用的交互协议？这确实是一个令人期待的希望。我不知道明年我们是否能够完全实现它，但很多不同的参与者都希望朝着这个方向发展。

在达到这种理想状态之前，我们应该先解决一些简单的事情。我知道有很多投资都投入到了软件工程任务中。然而，我仍然认为没有人充分解决普通商业用户的需求。普通商业用户必须在他们的计算机和机器上使用，我不知道，十几种不同的工具。它们之间没有任何通信，而且每个工具都有自己的入门体验。

我看到了很多机会来简化这些复杂的体验，使其更加动态和集成。这才是这项技术的真正前景。

**主持人Tim Huang：**
这大概是最终的梦想，我的意思是，因为你描述的世界几乎就像智能体成为你所有这些应用程序的整个界面。它们保持独立。但是，是的，未来的操作系统实际上是代表你执行操作的智能体。

**玛雅·穆拉德：**
它是自然语言。就像LLMs改变了我们对如何与数字世界互动的看法。我们期望一切都用自然语言进行，或者你可以填写表格，然后可以选择使用自然语言交互。我认为这种期望将会扩大。

**主持人Tim Huang：**
是的，没错，我认为这很有道理。我想我们最后应该稍微谈论一下工程和编码方面的问题，对吧？我今年在想，编码辅助已经变得非常好了。但梦想是，你最终会拥有智能体，比如，“我真的设想了一个像这样的软件代码库。”并且它能够在该代码库的所有部分上构建和互操作。我们认为这种自动化和智能体行为的前景如何？

**克里斯·海：**
我来开头，我将一如既往地提出一些有争议的观点。这里有一些让大家思考的事情，那就是今天的编程语言是为人类设计的，对吧？如果你想到循环，while循环，for循环等等，有多少个版本，条件语句也是如此，if语句，等等。然而，当你深入到汇编级别时，所有这些都不存在。一切都回到了分支和跳转语句等等。

因此，我们正处于一个智能体的世界，在这个世界里，我们让人们用一种为人类设计的语言进行编程。我认为，最大的挑战是，在未来几年里，你将会看到一种更原生于智能体的语言，这种语言更适合LLMs。这将减少目前为了满足人类而需要的语法糖。因此，我认为编程将会发生演变，而且你现在已经可以看到它了。

例如，LLMs已经在生成像斐波那契函数这样的函数。坦率地说，我生活中不需要另一个斐波那契函数了；我们已经有很多了。我会抓住这些点，没错。展望未来，我设想会出现类似NPM的东西，你可以在那里拥有一个庞大的AI库，从中提取你需要的函数。

我相信，随着AI操作系统的发展，我们将获得更原生的AI编程语言和库。这将有助于代码的开发。所以我认为这是一个有趣的前景。会是2025年吗？也许吧。也许是2026年。但我认为这是我们前进的方向。

**玛雅·穆拉德：**
就我们目前的技术而言，我对我在Replit上看到的东西印象深刻，它能够建立像完整堆栈应用程序这样的东西。在我正在进行项目中，这是一种非常有趣的范例，比如通过聊天来构建应用程序。我真的看到了创建数字界面和代码库的能力以前所未有的方式被普及，这完全是由我们当前拥有的智能体技术驱动的。我只是觉得还存在需要解决的“最后一公里”问题。而且我认为明年，这种情况将会大规模爆发。

**主持人Tim Huang：**
太棒了。好的，你们在这里首次听到了这个消息。我们关于智能体的时间就到这里了。在这么短的时间里涵盖了很多内容。Chris、Maya，感谢你们来到节目，我们明年再见。

我想让我们接下来谈谈2024年为人工智能提供动力的硬件。我再也找不到比今天和我连线的两位更好的人来帮助解释这些了。Katar El-
Megraoui是人工智能工程、人工智能硬件中心的首席研究科学家。Volkmar Ulig是人工智能基础设施组合主管副总裁。欢迎来到节目。

Volkmar，也许我先问你。所以，你知道，当我们谈论人工智能的硬件时，它几乎成了我们想谈论英伟达的代名词。我很好奇你认为今年英伟达最大的新闻是什么？我印象最深刻的是即将发布的GB200的公告，但我很好奇，当我们思考2024年的重大新闻时，你是否还有其他关注点？

**Volkmar Ulig：**
英伟达为GB200制造了很大的轰动。我认为我们看到在训练方面，特别是对于非常大的机架规模计算机，正在向更集成化的系统和协议发生重大转变。液冷正在发挥作用，多年来我们看到的所有东西——比如如何将更多计算能力塞入更小的外形尺寸，并使其速度更快，背后有更好的网络——英伟达正在努力推动这些，以保持其领导地位。

我们还看到了一些反映当前模型状态的升级。例如，700亿参数的模型提出了重大挑战；即使是量化的模型，也需要8位时70GB和16位时140GB。由于这些需求，人们不想必须购买完整的卡。因此，我们看到，随着制造商响应这些需求，所有加速器的内存容量都在增加。

然而，英伟达并不是这个领域唯一的参与者。AMD正在宣布其产品前景广阔的路线图，具有非常大的内存容量和高内存带宽，旨在满足大型语言模型的需求。英特尔也在市场上推出有竞争力的产品。此外，还有一些初创公司正在引入有趣的技术。例如，一年之前还在讨论扩展人工智能的Cerebras，现在可以作为云服务使用。Kroc正在成为另一个参与者，我们预计会看到更多的创新，比如The
Matrix的适配器计划在明年初发布。

随着新参与者的加入，竞争格局正在进一步扩大。值得注意的是，Broadcom上周宣布了重要的收入目标以及与苹果的合作关系。高通也正在加入竞争，他们计划推出一种新的芯片架构，其中一些已经上市，以及他们未来发展的可靠路线图。这种市场多元化，不仅仅局限于英伟达，对于整个行业来说都是令人鼓舞的。

随着所有这些变化的展开，市场正以极快的速度发展。虽然我们目前看到正在开发训练系统，但人们越来越关注推理。在我看来，这种转变至关重要，因为它很可能是最终盈利的地方。

**主持人Tim Huang：**
嗯，当然。我想，Katar，我不知道你是否想谈谈这个。我想确保我们稍微讨论一下今年推理方面的重大趋势，因为感觉这实际上是这个市场发展的一个重要主题。如果你想谈谈这方面，以及你认为
2024 年的情况如何。

**Katar El-Megraoui：**
好的，当然，有很多事情正在发生，尤其是在推理引擎和优化推理引擎方面。许多硬件软件设计也在其中发挥着关键作用。因此，我们看到了像 VLLM
这样的技术。我们还看到了像 Triton 他们正在做的事情，以及所有围绕 KVCache 优化、推理优化中的批处理等。

因此，在开源领域，围绕构建和扩展推理，特别是在大型语言模型方面，正在发生很多创新。但是我们看到的许多优化不仅仅是针对 LLM 的，它们也可以扩展到其他模型。

VLLM 正在进行大量的开发工作。甚至在 IBM
研究院和其他机构也在为开源做出贡献，基本上是在调度、批处理方面引入许多协同优化，并弄清楚如何最好地协同定位所有这些推理请求，以使硬件能够高效地运行它们。

**主持人Tim Huang：** 是的，完全同意。Volkmar，你想稍微展望一下 2025
年吗？我的意思是，随着这个市场变得越来越拥挤，我认为每个人都在觊觎英伟达的王冠。你认为 2025 年会发生什么？英伟达是否仍将保持领先地位？或者我们会在
2025 年 12 月结束时看到，这个市场，特别是训练方面，变得比传统上更加分散和多样化？

**Volkmar Ulig：** 我认为训练方面，这是我的预测，仍然会牢牢掌握在英伟达手中。我认为 AMD 和英特尔会尝试打入这个市场，但我认为这可能会在
2026 年、2027 年左右发生。我这么说的原因是，你需要构建的体系结构才能创建一个真正成功的训练系统。这不仅仅是 GPU，而是一个系统。

你需要非常好的低延迟网络。你还必须解决可靠性问题。现在有一个强烈的趋势，将计算转移到结构中，以进一步减少延迟并更有效地利用硬件。英伟达收购 Mellanox
后，实际上收购了高性能计算领域的头号网络供应商，而训练正是依赖于高性能计算。

正在形成一些联盟，例如 Ultra Ethernet，他们正试图实现与 InfiniBand 类似的功能。尽管 InfiniBand
是一个开放标准，但实际上地球上只有一家供应商提供它，那就是 Mellanox，现在归英伟达所有。所以我认为英伟达在这个市场方面有着强大的锁定能力。

因此，其他公司的大量投资更多地是在推理市场，这个市场更容易进入。例如，你不会在手机或边缘设备上看到英伟达的系统。推理所需的软件投入远低于训练所需的软件投入。因此，我认为训练在英伟达手中非常安全。

然而，我认为现在有足够的竞争出现，Gaudi 3 即将上线，它集成了以太网，还有 AMD 正在推向市场的产品。我预计将会缓慢渗透到这个市场。到 2026
年，我们可能会看到这个市场的重大突破，导致英伟达失去其目前拥有的非常独特的地位。

**主持人Tim Huang：** 是的，这将是一个巨大的转变。Katar，你同意对 2025 年的预测吗？

**Katar El-Megraoui：** 是的，我同意。当然，正如 Volkmar 提到的那样，人工智能硬件领域的竞争正在加剧。像
AMD、英特尔这样的公司，以及像 Grog 和 Graphcore 这样的初创公司，都在开发有竞争力的硬件。IBM
也在开发用于训练和推理的具有竞争力的硬件。

英伟达 GPU 的问题在于它们的成本和能源效率。英伟达 GPU 非常昂贵且耗电，这使得它们吸引力下降，尤其是在边缘 AI 和对成本敏感的部署方面。因此，像
AWS Inferentia、Google TPU 和 Graphcore IPU
这样的竞争对手提供了专门的硬件，这些硬件通常更便宜，并且对于某些应用程序来说更节能。

像 OpenAI Triton 和 Onyx
这样的开放标准，以及新的框架，都在努力减少对英伟达专有生态系统的依赖。这种发展使竞争对手更容易在市场上获得发展。此外，在特定于推理的硬件领域，像
VLLM、SGLang 和 Triton 这样专用的推理引擎的兴起，突出了替代英伟达硬件的潜力。

这些创新为竞争打开了大门，并允许新的进入者在推理场景中脱颖而出，特别是对于大型语言模型。因此，我们正在目睹由 ASIC
驱动的边缘推理解决方案的广泛兴起，这正在挑战英伟达在快速增长的边缘 AI 市场中的作用。

**主持人Tim Huang：**
是的，我认为边缘是我想确保在进入下一个环节之前讨论的最后一点。Volkmar，在我看来，显然一个重要的故事是苹果公司进军苹果智能，并确保所有手机都配备了
AI 芯片。我假设这种情况将在 2025 年继续下去，但我很好奇，对于那些不太关注硬件领域日常动态的听众来说，在我们进入未来 12
个月时，你认为有哪些趋势值得人们关注。

**Volkmar Ulig：**
我认为苹果的模式非常优雅，尤其是在你处于功耗受限的环境中时。因此，在功耗受限的环境中，无论你能以较低的精度做什么，你都可以在设备上完成。然后，当你需要更多的时候，你会去其他地方。

我还认为苹果公司在与手机和云端相同的芯片上运行的架构非常有趣。这种架构简化了开发人员和部署流程。我相信我们未来会看到更多这种类型的分离。此外，我们可以期待更多的计算发生在边缘设备上。

随着芯片技术的成熟和更多选择的出现，你将不再需要高性能的卡了。芯片将变得更加专门用于简单的矩阵乘法。我预测，几乎所有出厂的芯片都将以某种形式包含人工智能功能。

这种设备上和设备外处理的混合架构使得芯片具有较长的使用寿命。在边缘设备上，这不仅限于手机，还包括工业设备，其生命周期为 5 到 10
年。你不会因为想训练另一个网络而每两年更换一次芯片。因此，我认为苹果推出的架构将进一步巩固，我们将看到围绕它建立的软件生态系统。

**主持人Tim Huang：**
是的，太好了。Katar，我让你说最后一句。我一直在问大多数与会者，他们在这个特定领域中最被低估的事情是什么？因此，对于人工智能硬件，是否有人们没有关注的事情？人工智能硬件领域有很多炒作。因此，我很好奇，是否有任何更微妙的趋势你认为值得关注。

**Katar El-Megraoui：**
是的，这个问题问得很好。我认为在实时计算优化方面有很多工作要做。例如，像测试时计算这样的技术，它允许人工智能模型在推理过程中分配额外的计算资源。我们在OpenAI的O1模型中看到了这一点。我认为它确实在这里开创了一些先例，它使模型能够有效地分解这些复杂的问题，并模仿我们在人类推理中所做的事情。它也对我们如何设计这些模型以及模型如何与硬件交互产生影响。因此，它在推理过程中推动了更多的硬件软件协同设计。

我认为我看到的**另一个趋势是硬件对所有人的可访问性** 。我们在LLAMA
3系列中看到了这一点，它表明新的硬件生态系统正在为高端研究模型和消费级应用发展。LLAMA模型发布了多个版本，如400B和8B，展示了这一趋势。弥合提供昂贵计算资源和基础设施的高端数据中心与更易于访问的解决方案之间的差距正变得越来越重要。

另一个重要趋势是开源和企业之间的协同作用。IBM发布的Granite
3是朝着正确方向迈出的重要一步，突出了开源人工智能的重要性及其最大限度地提高企业硬件性能的能力。然而，仍有一些硬件设计挑战需要解决。例如，NVIDIA的Blackwell
GPU面临着与散热管理和服务器架构相关的问题。为了有效地扩展并满足下一代人工智能模型的需求，电源效率正变得至关重要。

因此，我认为如果要总结这些趋势的现状，2024年展示了硬件软件协同设计的重要性，以及行业向专用人工智能加速器、开源采用和实时计算创新的转变，这些都非常重要，并为进一步的突破奠定了基础。

**主持人Tim Huang：** 是的，这是一个很好的结尾。好了，我们关于硬件的时间就到这里了。Katar
Volkmar，感谢你的加入，以及你在2024年对硬件世界的解读。我们会在2025年再次邀请你。

最后，为了完善我们对2024年的总结，我们需要讨论一下那些让我们震惊、惊叹，并引发我们思考的产品发布。现在请Kate
Sol，Granite的技术产品管理总监，以及IBM人工智能治理研究员Kush Varshney来谈谈。

Kate，也许我先问你。显然，今年的产品发布时间表非常疯狂。感觉好像每隔一周就会有新东西出现。但我想回顾过去的12个月，我很好奇，你认为最大的事情是什么？就是我们回顾2024年时会说，是的，这一年发生了这些事情。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbCdA36YRBRcPkHdemibkRLpbBzibaibWPpMHmm3ak0yiaYCCicpXMH8Ml3oA/640?wx_fmt=jpeg&from=appmsg)

**凯特·索尔：** 作为Granite的技术产品管理总监，我觉得我必须祝贺IBM团队在发布Granite
3.0模型系列方面取得的成就。这个系列专注于采用Apache
2许可的透明模型，展示了其中所用数据的道德来源。我们在报告中分享了所有关于这方面的详细信息，我很高兴能够继续履行对开源人工智能的承诺。我们的目标是创建最先进的20亿到80亿参数规模的语言模型，并以允许我们客户和开源社区利用的条款发布。

更广泛地说，除了IBM之外，我认为GPT-4O模型系列和产品的发布非常令人兴奋。它标志着人们对如何继续提高性能而不只是在训练计算上花费更多资金的新一轮兴趣的开始。这种转变正在引领我们期望在2025年看到的下一波浪潮，即专注于在推理时花费更多。

通过这样做，我们可以使模型和使用这些模型的产品的计算和推理调用更加高级，从而提高性能。重点将从仅仅扩大我们在训练方面的投资，例如投入更多资金用于训练或收集更多数据，转移到寻找更有效的方法来利用资源和提高整体结果。我非常期待看到这一发展。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbEo6b2s4ibqJM1em0tog7ibDm4WD57wpj65yiaL9PRgXRt90sUwaSicicTRQ/640?wx_fmt=jpeg&from=appmsg)

**主持人Tim Huang：**
是的，我们绝对应该讨论这两个主题。我的意思是，我认为在第一个主题上，2024年真的像是开源的进攻。感觉好像有一段时间，所有闭源模型真的会占上风。开源方面的活跃表现真是令人兴奋。

然后我认为第二个主题有点像“更聪明地工作，而不是更努力”的方法，我认为我们在许多地方都看到了一系列新的技术在发挥作用。也许Kush，我们先从第一个主题开始。在开源世界中，当然，今年也是Llama
3的一年。开源领域发生了很多事情。

我很想知道，当你回顾Kate在这里指出的这两个主题时，无论是开源方面还是在人工智能的不同方法方面，是否有一些事情你想让我们的听众记住2024年？

**Kush Varshney：**
是的，我的意思是，我认为你对它的措辞，我的意思是，开源回归，或者你想称之为的任何名称。是的，我的意思是，我认为这是正确的表达方式。

我认为我们正在意识到，我的意思是，当我们与各地的客户交谈时，他们在2023年的时候，都是关于POCs之类的，让人们在他们自己的公司里感到兴奋，哦，也许生成式人工智能可以发挥作用。但是随着时间的推移，他们意识到，哦，实际上，我们需要担心受版权保护的数据，其他治理方面的问题，成本，以及如何让这些东西运行起来。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbic82tvY7w5NYBn8iaCsMrcBQ5HBFuId34M6k1tHvD1FNDktrqk1la6lg/640?wx_fmt=jpeg&from=appmsg)

我认为IBM的产品WatsonX，以及Granite模型，在这方面表现出色。那么，我们如何将我们在2023年的科学实验（今年更多地被使用）转变成接下来一年尽可能认真对待的事情，我想说的是。

**主持人Tim Huang：**
是的，当然。我认为Kush，既然你现在参与了这个环节，我觉这是一个好时机问你。显然，你花了很多时间思考人工智能治理，对吗？今年也有很多这方面的事情发生。我不知道你是否想重点指出2024年的哪些事情。

**Kush Varshney：**
是的，不，我的意思是，仅仅是整个人工智能安全世界都聚集在一起的事实，对吧？我的意思是，我们有韩国峰会。我们在11月份在旧金山举行了峰会。是的，我的意思是，这现在是主题。我认为这是我们需要克服的事情，因为仅仅拥有人工智能，生成式人工智能，而没有安全保障，没有治理，是很危险的。我认为，在克服治理问题之前，投资回报的承诺仅仅是一个承诺。

**主持人Tim Huang：**
是的，当然。你对2025年在这方面的发展有什么预测吗？我的意思是，你知道，我觉得我在这里发现了一个主题，那就是2024年几乎建立了很多东西。2025年，我们几乎会看到它是如何发展的。我的意思是，无论是在开源还是在治理方面，看起来都是如此。

**Kush Varshney：**
是的，没错，我认为预测是，我的意思是，节目早些时候的片段是关于自主AI的。所以我认为这方面也会真正爆发。而且我认为那里的治理将把治理推回到其他的用例中。因为当你拥有自主代理时，治理和信任就变得极其重要。你对这些东西可能会做什么几乎没有控制。

泰特提到的那些东西，你将会看到的额外的推理周期，我认为主要目的是为了治理。是为了让这些东西进行一些自我反思，也许在给出答案之前三思而后行等等。所以你也将拥有更多管理代理的工具。

刚刚发布的 Granite Guardian 3.1
版本实际上包含了一个函数调用幻觉检测器。这是代理实际做的事情之一，对吧？作为LLM的一部分，它们实际上会调用其他工具、其他代理、其他函数。如果它本身就出现了幻觉，参数、参数的类型、函数名称，所有这些都可能出错。所以我们有方法来检测那里的问题。

**凯特·索尔：**
所以，库什，我很好奇，你说推理运行时间将更多地用于治理和自我反思。但我记得你最近还分享了一篇论文，关于这也会打开一堆其他风险和潜在的安全问题，对吧？当模型离线运行所有这些循环，并且人们自然能够观察到模型内部的情况时。

**Kush Varshney：**
是的，我的意思是，我认为整个自我反思，你可以称之为元认知，你可以称之为智慧。我的意思是，我认为这些将会是发生的事情的一部分。但是，是的，我的意思是，任何时候你有额外的事情发生，更多的循环，更多的机会，更多的攻击面，对吧？所以我认为这肯定会是其中的一部分。但我希望，就像在其他系统一样，你可以有更好的控制，你也可以有更多的机会去影响发生的事情。

**主持人Tim Huang：** 是的，我认为这最终会是至关重要的。而且我认为还有一个转变，我想提一下并把它抛回给你，凯特，如果所有的开源都在 2024
年如此迅速地涌现，感觉 2025
年可能最终会是这样的一年，我们达到了一致，甚至在某种意义上开源超越了闭源。我认为这不仅是因为技术变得更好，而且就像库什所说的那样，我认为我们在部署开源模型时确保安全性的组件的能力也在变得更好，对吧？过去，我们必须依赖闭源，因为他们真正了解如何进行对齐和安全。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbBDPia90CIARjfgs4LZVBvdPBK3hqCkVfG6ZibYSYZf3Glmibibxq0iaL7nQ/640?wx_fmt=jpeg&from=appmsg)

**凯特·索尔：**
那里有很多恐吓策略。是的，没错。只有大型模型提供商才有预算能够研究如何安全地做到这一点或拥有专业知识。是的，没错。我认为我们最终在一点点地消除那种观念。例如，我们看到
Meta 在发布非常大的模型方面做得非常出色，这些模型具有出色的安全性对齐，并表明你可以在公开场合做到这一点。它不需要被藏在所谓的黑幕背后。

**主持人Tim Huang：** 是的，当然。这是一个对 2025
年的预测吗，我们可以鱼和熊掌兼得？比如，既可以开源，又可以是安全的。绝对是。是的，这很令人兴奋。你对未来 12
个月的开源有什么预测吗？比如我们接下来会走向哪里？你知道，我想，更多的 Granite，甚至更好的 Granite。

**凯特·索尔：** 我认为明年将真正把重点稍微放在模型之上的堆栈上，并共同优化模型和执行它们的开发人员框架。

所以我们在 2024 年看到了 Llama Stack 的发布，对吧？我认为随着它的成熟，我们将看到它发生巨大的演变，以及其他类似类型的能力和堆栈的开发。

我认为我们也都已经接受了 OpenAI 端点与模型一起工作的方式作为现有的操作模式。但是，既然我们已经经历了几次，可能还有其他方法可以继续创新和改进。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbwCle0VrHOSwl2qfxKUlzJf6GiaeEyiaiaz9AmBbT1LCqW0KeFcM9lwhrg/640?wx_fmt=jpeg&from=appmsg)

因此，我认为我们将开始看到许多开源创新在堆栈的更高层发生，特别是来自那些正在研究如何进一步提高性能的模型提供商。它是相辅相成的；如果你试图在推理时进行优化和创新，你需要一个能够处理它的堆栈。

我认为这才是许多开发将会发生的地方。

**主持人Tim Huang：**
是的，当然。是的，我觉得我们已经在某种程度上把很多东西都视为理所当然，仅仅是因为那是事情开始的地方。但即使考虑到有那么多新闻，也很容易忘记，这一切都非常新鲜。就像几年前，它基本上还不存在。

我认为我向小组提出的一个观点，特别是考虑到我们正在讨论产品发布，那就是今年关于专家混合模型，我们谈论了很多关于聊天只是我们开始使用的一个界面，仅仅因为
ChatGPT 非常成功。

但是，没有理由说这必须是我们未来与这些系统交互的方式。我很好奇你们是否有关于界面的预测。我们是否会开始以一种与我们已经习惯的方式截然不同的方式与这些系统交互？

**Kush Varshney：** 是的，我的意思是，我认为共同创造和协同创作将变得更加重要。让多人参与创作过程至关重要。我知道今年也出现了一些
Canvas 的倡议，但我认为这种趋势只会增长。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbnxSxchFatK5zSnDPeDichaaUwiawB0GiaEuBibdOI7iafQ3EmSmUicuCvfaQ/640?wx_fmt=jpeg&from=appmsg)

让我简单地向我的兄弟致意。他有一个名为 Ko-Cree 的初创公司，K-O-C-R-E-E。不错，一定要提到！没错，没错！Ko-Cree 专注于利用 AI
为人们共同创作音乐，但它也旨在帮助个人和社会改善他们的福祉等等。

当你与他人共同创作时，这实际上是一种积极的体验。我认为重点可能会转向更多的人类繁荣和福祉。寻找人们真正共同工作的方式，培养开放性，促进协作可能是在未来突出出现的事情。

**主持人Tim Huang：**
我们在这个片段还剩几分钟的时间。有什么是大家没有在谈论的事情吗？我想这其中的一件事是，我觉得，你知道，特别是在人工智能领域，每个人总是对最新的模型发布或最新的东西感到兴奋。是的，我总是试图看清未来的趋势。我认为你们两位都是对此有深入思考的专家。目前被低估、可能被低估的、真正值得在接下来的一天中更多关注的是什么？

**凯特·索尔：**
明年？我认为在构建LLM（大型语言模型）的模块化组件方面，将会有一个巨大的机会，我真的很希望这方面能取得进展。所以，我们如何，就像现在正在进行的工作，例如，如何达到这样的程度：你可以微调一个LoRa适配器，对吧，一种权重集合，你为了你的任务进行微调，它位于模型的顶层。现在，它们必须针对你将要部署的特定模型进行定制，当新版本发布时，你必须重新调整你的模型。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbPIuYb7OGw25m3xYh34jFMibjly4icjA8DPCrTxc4hO9hb4iaHphQGeMMQ/640?wx_fmt=jpeg&from=appmsg)

但是我们如何创建这些东西的版本呢？例如，有一些有趣的研究是通用的，可以应用于任何地方。这创造了一些非常好的模块化组件，你可以运送或者拥有一个目录，从中你可以选择、实时配置，并进行替换。再次强调，在推理时，你可以替换这些类型的组件。

我认为还有一些方面，比如我们现在都听过的专家混合架构。我认为，人们会越来越多地关注我们是否可以构建模块化组件，在架构方面，可以替换这些模块化的专家。我很希望看到这种情况发生，我认为在基础层面正在进行一些非常有趣的研究，这些研究可以支持在2025年，围绕如何使构建和专业化模型更加模块化的方向发展。

**主持人Tim Huang：**
是的，这太酷了。而且我认为它没有得到足够的关注。我的意思是，我觉得每个人总是觉得人工智能就可以做到一切。一个大模型可以做所有事情。是的。我为什么要选择呢？还有一旦我们有了大模型，所有问题都会解决，对吧？越大越好，对吧？Kush，你呢？在我们结束这个环节之前，有什么被低估的事情你想指出给我们的听众吗？

**Kush Varshney：**
是的，我认为，我的意思是，代理的中间件也是其中之一。在Kate刚才说的模块化的基础上，考虑如何在多代理系统中注册和编排不同的代理很重要。在IBM研究院，我们有这个B框架——B就像在我耳边嗡嗡作响的东西一样。那个框架已经发布了，还有其他的初创公司也在做。一些前IBM研究员创办了一家名为Emergence
AI的公司，他们也开发了自己的解决方案。

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/ClW8NejCpBO3ticTZWdADeB063HBDnonbib6b2Shh1pxVIBxYv5AicZCtkRibNXiapjUduAe5PcvxB84kphqKufBd0g/640?wx_fmt=jpeg&from=appmsg)

还有其他的公司也在做。我认为这个领域将会发展起来。同样，这与Kate说的关于开发环境和模型之间更多连接，以及将它们更紧密地联系起来有关。一旦我们达到模型都足够好的程度，那么问题就变成如何高效地使用它们。我们如何高效地利用它们？以及我们如何更好地开发它们？

**主持人Tim Huang：**
是的，当然。绝对要关注这个领域。好的，Kate，Kush，感谢你们参加本次环节。感谢你们帮助我们回顾2024年的产品发布，以及展望2025年的产品发布。我们新年再见。

**关注公众号后设🌟标，掌握第一手AI新动态**

##  往期精选

  1. [黄仁勋专访：OpenAI在大模型混战中达到“逃逸速度”](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650001718&idx=1&sn=f8129a622e7611702be2cb23e8ce9418&chksm=88ba5831bfcdd127d06ce6492c821074407f805407b4182ca900916521cb5a4717f2a3d71ee8&token=1339625777&lang=zh_CN&scene=21#wechat_redirect)
  2. [李飞飞与Justin深度解读空间智能：数字世界需要三维表征，才能与现实世界融合](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000659&idx=1&sn=c71fb5b4ef501424dddd5e8b4dd5860e&chksm=88ba4414bfcdcd023c691a1adf75127a9fd883ceb305ca14cf97f719acaf999d40fa72f84bf3&token=1492077842&lang=zh_CN&scene=21#wechat_redirect)
  3. [PayPal创始人彼得·蒂尔：人类科技停滞源于原子方面的进展远慢于比特](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2650000240&idx=1&sn=26af6013981677b1e14137260857a6f0&chksm=88ba4277bfcdcb615d746615c262927bf51c43c920ed93fa36274ef87c6264d6548c84647121&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  4. [谷歌联合创始人布林：巨头们打造的“上帝模型”几乎可以理解一切](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=2&sn=0c714d804a72a52e002743d949e1685e&chksm=88ba40f9bfcdc9ef78749718480265922f4fba539abf6c9d62a6cd681f405dee9283d2429f84&token=106920805&lang=zh_CN&scene=21#wechat_redirect)
  5. [马斯克：AI将使商品和服务的成本趋近于零](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999870&idx=1&sn=752f000a117a705e77950c82bfc4a004&chksm=88ba40f9bfcdc9ef5a5afe4a3ae73d5247bd54ed525dbdbedee1fcf74a6c082165e664a5c4d0&token=106920805&lang=zh_CN&poc_token=HDp86Waj18SFm2Y-xnv_Vqd_4J6emFoh10eH48wg&scene=21#wechat_redirect)
  6. [Karpathy最新专访：人形机器人、特斯拉、数据墙与合成数据](https://mp.weixin.qq.com/s?__biz=MzA5NTU4NDM2MA==&mid=2649999613&idx=1&sn=b8bdda7afe4c3ca08e324ac5bbd5a2bd&chksm=88ba41fabfcdc8ec0e21dbf4c7eb4d33252da70f47e1cfc9f5e113717911c417c2aebb3d6180&token=106920805&lang=zh_CN&scene=21#wechat_redirect)

  

